#!/usr/bin/env python3
"""
miniZ MCP v4.3.0 - Professional Edition with License Management
Web UI + WebSocket MCP + 30 Tools + Hardware License Protection
Copyright ¬© 2025 miniZ Team
"""

import os
import sys
import socket
import time

# ============================================================
# SINGLE INSTANCE CHECK - Ph·∫£i ch·∫°y TR∆Ø·ªöC khi import c√°c module n·∫∑ng
# ============================================================
def _check_single_instance():
    """Ki·ªÉm tra v√† x·ª≠ l√Ω single instance TR∆Ø·ªöC khi kh·ªüi ƒë·ªông"""
    
    def is_port_in_use(port: int) -> bool:
        # Check c·∫£ 0.0.0.0 v√† 127.0.0.1
        for addr in ['0.0.0.0', '127.0.0.1']:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                try:
                    s.bind((addr, port))
                except OSError:
                    return True
        return False
    
    if is_port_in_use(8000):
        print("\n‚úÖ [SingleInstance] miniZ MCP ƒë√£ ƒëang ch·∫°y!")
        print("    üåê M·ªü tr√¨nh duy·ªát ƒë·∫øn instance hi·ªán t·∫°i...")
        import webbrowser
        webbrowser.open("http://localhost:8000")
        print("    ‚úÖ ƒê√£ m·ªü giao di·ªán")
        sys.exit(0)

# Ch·∫°y single instance check ngay l·∫≠p t·ª©c
_check_single_instance()

import asyncio
import json
import subprocess
import psutil

# üîß Disable proxy to avoid SOCKS errors
os.environ['NO_PROXY'] = '*'
os.environ['no_proxy'] = '*'
for key in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']:
    if key in os.environ:
        del os.environ[key]
from datetime import datetime
from pathlib import Path
from fastapi import FastAPI, WebSocket, HTTPException
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
import websockets
try:
    import pyautogui
except ImportError:
    pyautogui = None  # Desktop automation not available (Docker/headless mode)
import difflib
import re

# License Management - DISABLED (FREE EDITION)
# Bypass license check completely
LICENSE_SYSTEM_AVAILABLE = False  # FREE EDITION - No license required

# Auto-startup manager (Windows only)
import sys
import platform
try:
    import winreg
    IS_WINDOWS = True
except ImportError:
    IS_WINDOWS = False
    winreg = None  # Windows Registry not available on Linux

if IS_WINDOWS:
    class AutoStartupManager:
    APP_NAME = "miniZ_MCP_Professional"
    
    @staticmethod
    def get_exe_path():
        if getattr(sys, 'frozen', False):
            return sys.executable
        return os.path.abspath(__file__)
    
    @classmethod
    def enable_autostart(cls):
        try:
            exe_path = cls.get_exe_path()
            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, r"Software\Microsoft\Windows\CurrentVersion\Run", 0, winreg.KEY_SET_VALUE)
            winreg.SetValueEx(key, cls.APP_NAME, 0, winreg.REG_SZ, f'"{exe_path}"')
            winreg.CloseKey(key)
            print(f"‚úÖ [Startup] ƒê√£ b·∫≠t kh·ªüi ƒë·ªông c√πng Windows")
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è [Startup] Kh√¥ng th·ªÉ b·∫≠t auto-start: {e}")
            return False
    
    @classmethod
    def is_autostart_enabled(cls):
        try:
            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, r"Software\Microsoft\Windows\CurrentVersion\Run", 0, winreg.KEY_READ)
            try:
                winreg.QueryValueEx(key, cls.APP_NAME)
                winreg.CloseKey(key)
                return True
            except FileNotFoundError:
                winreg.CloseKey(key)
                return False
        except:
            return False

else:
    # Dummy AutoStartupManager for non-Windows platforms
    class AutoStartupManager:
        APP_NAME = "miniZ_MCP_Professional"
        
        @staticmethod
        def get_exe_path():
            return os.path.abspath(__file__)
        
        @classmethod
        def enable_autostart(cls):
            print(f"‚ö†Ô∏è [Startup] Auto-start ch·ªâ kh·∫£ d·ª•ng tr√™n Windows")
            return False
        
        @classmethod
        def is_autostart_enabled(cls):
            return False


# ============================================================
# üî• FIREWALL/INTERNET CHECKER - Ki·ªÉm tra quy·ªÅn k·∫øt n·ªëi m·∫°ng
# ============================================================
import subprocess

class FirewallChecker:
    """Ki·ªÉm tra v√† h∆∞·ªõng d·∫´n c·∫•p quy·ªÅn Windows Firewall cho ·ª©ng d·ª•ng"""
    
    APP_NAME = "miniZ_MCP"
    
    @staticmethod
    def get_exe_path():
        """L·∫•y ƒë∆∞·ªùng d·∫´n file EXE"""
        if getattr(sys, 'frozen', False):
            return sys.executable
        return os.path.abspath(__file__)
    
    @staticmethod
    def get_exe_name():
        """L·∫•y t√™n file EXE"""
        if getattr(sys, 'frozen', False):
            return os.path.basename(sys.executable)
        return os.path.basename(__file__)
    
    @classmethod
    def check_firewall_rules(cls) -> dict:
        """
        Ki·ªÉm tra xem ·ª©ng d·ª•ng ƒë√£ c√≥ quy·ªÅn Firewall ch∆∞a
        Returns: dict v·ªõi keys: has_inbound, has_outbound, rules_found, details
        """
        result = {
            'has_inbound': False,
            'has_outbound': False,
            'rules_found': [],
            'exe_path': cls.get_exe_path(),
            'exe_name': cls.get_exe_name()
        }
        
        try:
            # T√¨m t·∫•t c·∫£ rules li√™n quan ƒë·∫øn miniZ
            cmd = 'netsh advfirewall firewall show rule name=all'
            output = subprocess.run(cmd, capture_output=True, text=True, shell=True, timeout=10)
            
            if output.returncode == 0:
                lines = output.stdout.lower()
                exe_name_lower = result['exe_name'].lower().replace('.exe', '').replace('.py', '')
                
                # T√¨m c√°c rules c√≥ ch·ª©a t√™n app
                for search_term in ['miniz_mcp', 'miniz mcp', exe_name_lower]:
                    if search_term in lines:
                        result['rules_found'].append(search_term)
                
                # Ki·ªÉm tra chi ti·∫øt t·ª´ng rule
                if result['rules_found']:
                    for rule_name in ['miniz_mcp', result['exe_name'].replace('.exe', '').replace('.py', '')]:
                        try:
                            detail_cmd = f'netsh advfirewall firewall show rule name="{rule_name}" verbose'
                            detail_output = subprocess.run(detail_cmd, capture_output=True, text=True, shell=True, timeout=5)
                            if 'direction:' in detail_output.stdout.lower():
                                if 'direction:                            in' in detail_output.stdout.lower():
                                    result['has_inbound'] = True
                                if 'direction:                            out' in detail_output.stdout.lower():
                                    result['has_outbound'] = True
                        except:
                            pass
                    
                    # N·∫øu t√¨m th·∫•y rules, assume c√≥ quy·ªÅn (v√¨ Windows t·ª± t·∫°o c·∫£ in/out)
                    if result['rules_found'] and not result['has_inbound']:
                        result['has_inbound'] = True  # Gi·∫£ ƒë·ªãnh c√≥ n·∫øu rule t·ªìn t·∫°i
                        
        except subprocess.TimeoutExpired:
            print("‚ö†Ô∏è [Firewall] Timeout khi ki·ªÉm tra firewall rules")
        except Exception as e:
            print(f"‚ö†Ô∏è [Firewall] L·ªói ki·ªÉm tra: {e}")
        
        return result
    
    @classmethod
    def request_firewall_permission(cls) -> bool:
        """
        T·ª± ƒë·ªông th√™m rule Firewall (c·∫ßn quy·ªÅn Admin)
        Returns: True n·∫øu th√†nh c√¥ng
        """
        exe_path = cls.get_exe_path()
        rule_name = cls.get_exe_name().replace('.exe', '').replace('.py', '')
        
        try:
            # Th√™m rule Inbound
            cmd_in = f'netsh advfirewall firewall add rule name="{rule_name}" dir=in action=allow program="{exe_path}" enable=yes'
            # Th√™m rule Outbound  
            cmd_out = f'netsh advfirewall firewall add rule name="{rule_name}" dir=out action=allow program="{exe_path}" enable=yes'
            
            result_in = subprocess.run(cmd_in, capture_output=True, text=True, shell=True, timeout=10)
            result_out = subprocess.run(cmd_out, capture_output=True, text=True, shell=True, timeout=10)
            
            if result_in.returncode == 0 or result_out.returncode == 0:
                print(f"‚úÖ [Firewall] ƒê√£ th√™m rule firewall cho {rule_name}")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"‚ö†Ô∏è [Firewall] C·∫ßn quy·ªÅn Admin ƒë·ªÉ th√™m rule: {e}")
            return False
    
    @classmethod
    def show_firewall_status(cls) -> None:
        """Hi·ªÉn th·ªã tr·∫°ng th√°i Firewall v√† h∆∞·ªõng d·∫´n n·∫øu c·∫ßn"""
        print("\n" + "="*60)
        print("üî• KI·ªÇM TRA QUY·ªÄN K·∫æT N·ªêI INTERNET (Windows Firewall)")
        print("="*60)
        
        status = cls.check_firewall_rules()
        
        if status['rules_found']:
            print(f"‚úÖ TR·∫†NG TH√ÅI: ƒê√É C·∫§P QUY·ªÄN FIREWALL")
            print(f"   üìå Rules t√¨m th·∫•y: {', '.join(status['rules_found'])}")
            print(f"   üìÅ File: {status['exe_name']}")
            print(f"   üîó Inbound (nh·∫≠n k·∫øt n·ªëi): {'‚úÖ Cho ph√©p' if status['has_inbound'] else '‚ö†Ô∏è Ch∆∞a r√µ'}")
            print(f"   üîó Outbound (g·ª≠i k·∫øt n·ªëi): {'‚úÖ Cho ph√©p' if status['has_outbound'] else '‚úÖ M·∫∑c ƒë·ªãnh cho ph√©p'}")
            print("\n‚úÖ ·ª®ng d·ª•ng c√≥ th·ªÉ k·∫øt n·ªëi Internet b√¨nh th∆∞·ªùng!")
        else:
            print(f"‚ö†Ô∏è TR·∫†NG TH√ÅI: CH∆ØA C√ì QUY·ªÄN FIREWALL")
            print(f"   üìÅ File: {status['exe_name']}")
            print(f"   üìÇ Path: {status['exe_path']}")
            print("\n" + "-"*60)
            print("üìå H∆Ø·ªöNG D·∫™N C·∫§P QUY·ªÄN:")
            print("-"*60)
            print("üîπ C√ÅCH 1: T·ª± ƒë·ªông (l·∫ßn ƒë·∫ßu ch·∫°y)")
            print("   - Khi ch·∫°y l·∫ßn ƒë·∫ßu, Windows s·∫Ω h·ªèi 'Allow access'")
            print("   - Nh·∫•n 'Allow access' ho·∫∑c 'Cho ph√©p truy c·∫≠p'")
            print("")
            print("üîπ C√ÅCH 2: Th·ªß c√¥ng qua Windows Security")
            print("   1. M·ªü 'Windows Security' ‚Üí 'Firewall & network protection'")
            print("   2. Nh·∫•n 'Allow an app through firewall'")
            print("   3. Nh·∫•n 'Change settings' ‚Üí 'Allow another app'")
            print("   4. Browse ƒë·∫øn file EXE v√† th√™m v√†o")
            print("   5. Tick c·∫£ 'Private' v√† 'Public' networks")
            print("")
            print("üîπ C√ÅCH 3: Ch·∫°y l·ªánh PowerShell (Admin)")
            print(f'   netsh advfirewall firewall add rule name="miniZ_MCP" dir=in action=allow program="{status["exe_path"]}" enable=yes')
            print("")
            
            # Th·ª≠ t·ª± ƒë·ªông th√™m rule
            print("üîÑ ƒêang th·ª≠ t·ª± ƒë·ªông c·∫•p quy·ªÅn...")
            if cls.request_firewall_permission():
                print("‚úÖ ƒê√£ t·ª± ƒë·ªông c·∫•p quy·ªÅn Firewall th√†nh c√¥ng!")
            else:
                print("‚ö†Ô∏è Kh√¥ng th·ªÉ t·ª± ƒë·ªông c·∫•p quy·ªÅn (c·∫ßn ch·∫°y v·ªõi quy·ªÅn Admin)")
                print("   ‚Üí H√£y ch·∫°y EXE v√† cho ph√©p khi Windows h·ªèi")
        
        print("="*60 + "\n")
        return status['rules_found']
    
    @classmethod
    def check_internet_connection(cls) -> dict:
        """Ki·ªÉm tra k·∫øt n·ªëi Internet th·ª±c t·∫ø"""
        result = {
            'connected': False,
            'latency_ms': None,
            'test_url': 'google.com'
        }
        
        try:
            import socket
            # Test DNS resolution
            socket.setdefaulttimeout(5)
            socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(("8.8.8.8", 53))
            result['connected'] = True
            
            # Test latency
            import time
            start = time.time()
            socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(("google.com", 443))
            result['latency_ms'] = int((time.time() - start) * 1000)
            
        except Exception as e:
            result['error'] = str(e)
        
        return result
    
    @classmethod
    def full_network_check(cls) -> dict:
        """Ki·ªÉm tra ƒë·∫ßy ƒë·ªß: Firewall + Internet connection"""
        print("\nüåê KI·ªÇM TRA K·∫æT N·ªêI M·∫†NG TO√ÄN DI·ªÜN")
        print("="*50)
        
        # 1. Check Firewall
        firewall_status = cls.check_firewall_rules()
        
        # 2. Check Internet
        internet_status = cls.check_internet_connection()
        
        # 3. Summary
        print(f"üî• Firewall Rules: {'‚úÖ ƒê√£ c·∫•p quy·ªÅn' if firewall_status['rules_found'] else '‚ö†Ô∏è Ch∆∞a c√≥ rule'}")
        print(f"üåê Internet: {'‚úÖ ƒê√£ k·∫øt n·ªëi' if internet_status['connected'] else '‚ùå Kh√¥ng k·∫øt n·ªëi'}")
        
        if internet_status.get('latency_ms'):
            print(f"‚ö° ƒê·ªô tr·ªÖ: {internet_status['latency_ms']}ms")
        
        if not firewall_status['rules_found'] and not internet_status['connected']:
            print("\n‚ö†Ô∏è C√≥ th·ªÉ ·ª©ng d·ª•ng ƒëang b·ªã Firewall ch·∫∑n!")
            print("   ‚Üí H√£y l√†m theo h∆∞·ªõng d·∫´n c·∫•p quy·ªÅn ·ªü tr√™n")
        elif internet_status['connected']:
            print("\n‚úÖ ·ª®ng d·ª•ng s·∫µn s√†ng s·ª≠ d·ª•ng t·∫•t c·∫£ t√≠nh nƒÉng online!")
        
        print("="*50 + "\n")
        
        return {
            'firewall': firewall_status,
            'internet': internet_status,
            'ready': firewall_status['rules_found'] or internet_status['connected']
        }


# Fake license for compatibility
def get_license_manager():
    class FakeLicense:
        def check_license(self): return {'valid': True, 'message': 'FREE EDITION', 'license_data': {'license_type': 'FREE', 'customer_name': 'Community User'}}
        def get_hardware_id(self): return 'FREE-EDITION'
    return FakeLicense()

def show_activation_window(): return True  # Always activated

# MCP Endpoint Manager - Improved connection handling
try:
    from mcp_endpoint_manager import get_endpoint_manager, MCPEndpointManager
    ENDPOINT_MANAGER_AVAILABLE = True
except ImportError:
    ENDPOINT_MANAGER_AVAILABLE = False
    print("‚ö†Ô∏è [Endpoint] MCPEndpointManager not available")

# Gemini AI
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("‚ö†Ô∏è [Gemini] google-generativeai not installed. Run: pip install google-generativeai")

# OpenAI GPT-4
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("‚ö†Ô∏è [OpenAI] openai library not installed. Run: pip install openai")

# Selenium Browser Automation
try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.common.keys import Keys
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options
    from webdriver_manager.chrome import ChromeDriverManager
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("‚ö†Ô∏è [Selenium] Not installed. Run: pip install selenium webdriver-manager")

# RAG System - Retrieval Augmented Generation
try:
    from rag_system import (
        web_search, rag_search, get_realtime_info, smart_answer,
        RAG_TOOLS, get_rag_engine
    )
    RAG_AVAILABLE = True
    print("‚úÖ [RAG] RAG System loaded - DuckDuckGo + Local KB")
except ImportError as e:
    RAG_AVAILABLE = False
    print(f"‚ö†Ô∏è [RAG] RAG System not available: {e}")

# Vector Search System - Hybrid Semantic Search with FAISS
try:
    # from vector_search import VectorSearchEngine  # T·∫°m th·ªùi t·∫Øt do Python 3.14 conflict
    VECTOR_SEARCH_AVAILABLE = False
    print("‚ö†Ô∏è [VectorSearch] Vector search temporarily disabled (Python 3.14 compatibility)")
except ImportError as e:
    VECTOR_SEARCH_AVAILABLE = False
    print(f"‚ö†Ô∏è [VectorSearch] Vector search not available: {e}")

# ============================================================
# UTILITY FUNCTIONS (t·ª´ xiaozhi-esp32-server ch√≠nh th·ª©c)
# ============================================================

import re

# ============================================================
# üîÑ SMART TRUNCATE FOR LLM - Gi·ªõi h·∫°n text g·ª≠i v·ªÅ LLM
# ============================================================

MAX_LLM_RESPONSE_CHARS = 2000  # Gi·ªõi h·∫°n 2000 k√Ω t·ª± cho response g·ª≠i LLM
MAX_TTS_RESPONSE_CHARS = 800   # Gi·ªõi h·∫°n 800 k√Ω t·ª± cho TTS (robot n√≥i tr·ª±c ti·∫øp)


def clean_markdown_for_tts(text: str) -> str:
    """
    Lo·∫°i b·ªè markdown formatting ƒë·ªÉ TTS ƒë·ªçc ƒë∆∞·ª£c
    """
    import re
    
    # B·ªè headers markdown (# ## ###)
    text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)
    
    # B·ªè bold/italic (**text**, *text*, __text__, _text_)
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
    text = re.sub(r'\*([^*]+)\*', r'\1', text)
    text = re.sub(r'__([^_]+)__', r'\1', text)
    text = re.sub(r'_([^_]+)_', r'\1', text)
    
    # B·ªè code blocks v√† inline code
    text = re.sub(r'```[^`]*```', '', text, flags=re.DOTALL)
    text = re.sub(r'`([^`]+)`', r'\1', text)
    
    # B·ªè horizontal rules (---, ***)
    text = re.sub(r'^[-*]{3,}$', '', text, flags=re.MULTILINE)
    
    # B·ªè bullet points (- *, 1.)
    text = re.sub(r'^\s*[-*]\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
    
    # B·ªè links [text](url)
    text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)
    
    # Chu·∫©n h√≥a newlines (nhi·ªÅu newline -> 1 newline)
    text = re.sub(r'\n{3,}', '\n\n', text)
    text = re.sub(r'\n\n+', '. ', text)  # ƒê·ªïi paragraph break th√†nh d·∫•u ch·∫•m
    text = re.sub(r'\n', ' ', text)  # ƒê·ªïi newline th√†nh space
    
    # Chu·∫©n h√≥a spaces
    text = re.sub(r'\s{2,}', ' ', text)
    
    return text.strip()

def smart_truncate_for_llm(text: str, max_chars: int = MAX_LLM_RESPONSE_CHARS) -> str:
    """
    C·∫Øt ng·∫Øn text th√¥ng minh cho LLM, gi·ªØ n·ªôi dung quan tr·ªçng
    
    Args:
        text: Text c·∫ßn truncate
        max_chars: Gi·ªõi h·∫°n k√Ω t·ª± (default: 4000)
    
    Returns:
        Text ƒë√£ truncate v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin quan tr·ªçng
    """
    if not text or len(text) <= max_chars:
        return text
    
    # Gi·ªØ ph·∫ßn ƒë·∫ßu (th√¥ng tin ch√≠nh) v√† ph·∫ßn cu·ªëi (k·∫øt lu·∫≠n)
    head_ratio = 0.7  # 70% cho ph·∫ßn ƒë·∫ßu
    tail_ratio = 0.25  # 25% cho ph·∫ßn cu·ªëi
    
    head_chars = int(max_chars * head_ratio)
    tail_chars = int(max_chars * tail_ratio)
    truncate_notice = f"\n\n... [ƒê√£ l∆∞·ª£c b·ªè {len(text) - head_chars - tail_chars} k√Ω t·ª±] ...\n\n"
    
    head_part = text[:head_chars]
    tail_part = text[-tail_chars:]
    
    # C·∫Øt ·ªü ranh gi·ªõi c√¢u n·∫øu c√≥ th·ªÉ
    # T√¨m ƒëi·ªÉm k·∫øt th√∫c c√¢u g·∫ßn nh·∫•t trong head_part
    for sep in ['. ', '.\n', '! ', '!\n', '? ', '?\n', '\n\n']:
        last_sep = head_part.rfind(sep)
        if last_sep > head_chars * 0.8:  # Ch·ªâ c·∫Øt n·∫øu >= 80% head_chars
            head_part = head_part[:last_sep + len(sep)]
            break
    
    # T√¨m ƒëi·ªÉm b·∫Øt ƒë·∫ßu c√¢u g·∫ßn nh·∫•t trong tail_part
    for sep in ['. ', '.\n', '\n\n']:
        first_sep = tail_part.find(sep)
        if first_sep != -1 and first_sep < tail_chars * 0.2:  # Ch·ªâ c·∫Øt n·∫øu <= 20% tail_chars
            tail_part = tail_part[first_sep + len(sep):]
            break
    
    return head_part + truncate_notice + tail_part


def format_result_for_llm(result: dict, max_chars: int = MAX_LLM_RESPONSE_CHARS) -> str:
    """
    Format v√† truncate result dict th√†nh text cho LLM
    
    Args:
        result: Dict k·∫øt qu·∫£ t·ª´ tool
        max_chars: Gi·ªõi h·∫°n k√Ω t·ª±
    
    Returns:
        Text ƒë√£ format v√† truncate
    """
    import json
    
    # N·∫øu l√† response_text t·ª´ Gemini, ∆∞u ti√™n n√≥
    if isinstance(result, dict):
        if result.get("response_text"):
            text = result["response_text"]
            return smart_truncate_for_llm(text, max_chars)
        
        # N·∫øu c√≥ context (t·ª´ knowledge base), ∆∞u ti√™n
        if result.get("context"):
            text = result["context"]
            return smart_truncate_for_llm(text, max_chars)
        
        # N·∫øu c√≥ message, d√πng message
        if result.get("message"):
            text = result["message"]
            # N·∫øu message ng·∫Øn, th√™m th√¥ng tin kh√°c
            if len(text) < max_chars * 0.5:
                extra_info = []
                for key in ["summary", "content", "data", "results"]:
                    if result.get(key):
                        val = result[key]
                        if isinstance(val, str):
                            extra_info.append(val)
                        elif isinstance(val, (list, dict)):
                            extra_info.append(json.dumps(val, ensure_ascii=False, indent=1))
                if extra_info:
                    text += "\n\n" + "\n".join(extra_info)
            return smart_truncate_for_llm(text, max_chars)
    
    # Default: convert to JSON
    text = json.dumps(result, ensure_ascii=False, indent=1)
    return smart_truncate_for_llm(text, max_chars)


def sanitize_tool_name(name: str) -> str:
    """
    Chu·∫©n h√≥a t√™n tool theo quy t·∫Øc c·ªßa Xiaozhi server
    - Thay th·∫ø c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát b·∫±ng underscore
    - Chuy·ªÉn v·ªÅ lowercase
    """
    if not name:
        return name
    # Thay th·∫ø c√°c k√Ω t·ª± kh√¥ng ph·∫£i alphanumeric ho·∫∑c underscore
    sanitized = re.sub(r'[^a-zA-Z0-9_]', '_', name)
    # Lo·∫°i b·ªè underscore li√™n ti·∫øp
    sanitized = re.sub(r'_+', '_', sanitized)
    # Lo·∫°i b·ªè underscore ·ªü ƒë·∫ßu v√† cu·ªëi
    sanitized = sanitized.strip('_')
    return sanitized.lower()

# ============================================================
# üñ•Ô∏è PC CONFIG CACHE - Cache c·∫•u h√¨nh m√°y cho LLM
# ============================================================
PC_CONFIG_CACHE = None
PC_CONFIG_CACHE_TIME = 0

def get_pc_config_summary():
    """L·∫•y t√≥m t·∫Øt c·∫•u h√¨nh m√°y t√≠nh ƒë·ªÉ LLM tham kh·∫£o"""
    global PC_CONFIG_CACHE, PC_CONFIG_CACHE_TIME
    import time
    
    # Cache 5 ph√∫t
    if PC_CONFIG_CACHE and (time.time() - PC_CONFIG_CACHE_TIME) < 300:
        return PC_CONFIG_CACHE
    
    try:
        import platform
        import psutil
        import subprocess
        
        config = []
        
        # Hostname & OS
        config.append(f"üñ•Ô∏è M√°y t√≠nh: {platform.node()}")
        config.append(f"ü™ü OS: {platform.system()} {platform.release()} ({platform.architecture()[0]})")
        
        # CPU
        cpu_name = "Unknown"
        try:
            if platform.system() == "Windows":
                result = subprocess.run(['wmic', 'cpu', 'get', 'name'], capture_output=True, text=True, timeout=5)
                lines = [l.strip() for l in result.stdout.strip().split('\n') if l.strip() and l.strip() != 'Name']
                if lines:
                    cpu_name = lines[0]
        except:
            cpu_name = platform.processor() or "Unknown"
        
        cores = psutil.cpu_count(logical=False) or 0
        threads = psutil.cpu_count(logical=True) or 0
        freq = psutil.cpu_freq()
        freq_str = f"{freq.max:.0f}MHz" if freq else "N/A"
        config.append(f"‚ö° CPU: {cpu_name} ({cores} cores, {threads} threads, {freq_str})")
        
        # RAM
        mem = psutil.virtual_memory()
        config.append(f"üß† RAM: {mem.total / (1024**3):.1f} GB")
        
        # GPU
        try:
            result = subprocess.run(['wmic', 'path', 'win32_videocontroller', 'get', 'name,adapterram'], 
                                  capture_output=True, text=True, timeout=5)
            lines = [l.strip() for l in result.stdout.strip().split('\n') if l.strip() and 'Name' not in l and 'AdapterRAM' not in l]
            for line in lines[:2]:  # L·∫•y t·ªëi ƒëa 2 GPU
                parts = line.split()
                if parts:
                    gpu_name = ' '.join(parts[:-1]) if len(parts) > 1 else parts[0]
                    config.append(f"üéÆ GPU: {gpu_name}")
        except:
            config.append("üéÆ GPU: Unknown")
        
        # Disk t·ªïng
        total_disk = sum(psutil.disk_usage(p.mountpoint).total for p in psutil.disk_partitions() 
                        if 'cdrom' not in p.opts.lower() and p.fstype)
        config.append(f"üíæ Disk: {total_disk / (1024**3):.0f} GB t·ªïng")
        
        PC_CONFIG_CACHE = '\n'.join(config)
        PC_CONFIG_CACHE_TIME = time.time()
        return PC_CONFIG_CACHE
        
    except Exception as e:
        return f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y c·∫•u h√¨nh m√°y: {e}"

async def get_system_info(category="all"):
    """
    Thu th·∫≠p th√¥ng tin c·∫•u h√¨nh m√°y t√≠nh chi ti·∫øt
    category: all, cpu, memory, disk, os, network, gpu, software, motherboard
    """
    try:
        import platform
        import psutil
        import socket
        import subprocess
        import json
        from datetime import datetime
        
        info = {
            "success": True,
            "timestamp": datetime.now().strftime("%d/%m/%Y %H:%M:%S"),
            "categories": []
        }
        
        # CPU Information (Chi ti·∫øt h∆°n)
        if category in ["all", "cpu"]:
            cpu_info = {
                "name": "CPU Information",
                "processor": platform.processor(),
                "architecture": platform.architecture()[0],
                "machine": platform.machine(),
                "cores_physical": psutil.cpu_count(logical=False),
                "cores_logical": psutil.cpu_count(logical=True),
                "cpu_usage_percent": psutil.cpu_percent(interval=1)
            }
            
            # Th√™m frequency info
            if psutil.cpu_freq():
                freq = psutil.cpu_freq()
                cpu_info.update({
                    "cpu_freq_current_mhz": round(freq.current, 2) if freq.current else "N/A",
                    "cpu_freq_max_mhz": round(freq.max, 2) if freq.max else "N/A",
                    "cpu_freq_min_mhz": round(freq.min, 2) if freq.min else "N/A"
                })
            
            # Th√™m CPU details t·ª´ Windows Registry/WMI n·∫øu c√≥ th·ªÉ
            try:
                if platform.system() == "Windows":
                    import winreg
                    # ƒê·ªçc CPU name t·ª´ registry
                    key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, 
                                       r"HARDWARE\DESCRIPTION\System\CentralProcessor\0")
                    cpu_name = winreg.QueryValueEx(key, "ProcessorNameString")[0].strip()
                    cpu_info["cpu_name_detailed"] = cpu_name
                    
                    # Ph√°t hi·ªán th·∫ø h·ªá CPU (heuristic)
                    cpu_name_lower = cpu_name.lower()
                    if "intel" in cpu_name_lower:
                        if "13th gen" in cpu_name_lower or "13900" in cpu_name_lower or "13700" in cpu_name_lower or "13600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 13th Gen (Raptor Lake)"
                        elif "12th gen" in cpu_name_lower or "12900" in cpu_name_lower or "12700" in cpu_name_lower or "12600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 12th Gen (Alder Lake)"
                        elif "11th gen" in cpu_name_lower or "11900" in cpu_name_lower or "11700" in cpu_name_lower or "11600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 11th Gen (Tiger Lake/Rocket Lake)"
                        elif "10th gen" in cpu_name_lower or "10900" in cpu_name_lower or "10700" in cpu_name_lower or "10600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 10th Gen (Comet Lake/Ice Lake)"
                        elif "9th gen" in cpu_name_lower or "9900" in cpu_name_lower or "9700" in cpu_name_lower or "9600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 9th Gen (Coffee Lake Refresh)"
                        elif "8th gen" in cpu_name_lower or "8700" in cpu_name_lower or "8600" in cpu_name_lower or "8400" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 8th Gen (Coffee Lake)"
                        elif "7th gen" in cpu_name_lower or "7700" in cpu_name_lower or "7600" in cpu_name_lower or "7500" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 7th Gen (Kaby Lake)"
                        else:
                            cpu_info["cpu_generation"] = "Intel (Generation unknown)"
                    elif "amd" in cpu_name_lower:
                        if "7000" in cpu_name_lower or "7950x" in cpu_name_lower or "7900x" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "AMD Ryzen 7000 Series (Zen 4)"
                        elif "5000" in cpu_name_lower or "5950x" in cpu_name_lower or "5900x" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "AMD Ryzen 5000 Series (Zen 3)"
                        elif "3000" in cpu_name_lower or "3900x" in cpu_name_lower or "3700x" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "AMD Ryzen 3000 Series (Zen 2)"
                        elif "2000" in cpu_name_lower or "2700x" in cpu_name_lower or "2600x" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "AMD Ryzen 2000 Series (Zen+)"
                        else:
                            cpu_info["cpu_generation"] = "AMD (Generation unknown)"
                    
                    winreg.CloseKey(key)
            except Exception as e:
                cpu_info["cpu_detection_error"] = f"Could not detect detailed CPU info: {str(e)}"
            
            info["categories"].append(cpu_info)
        
        # Memory Information (Chi ti·∫øt h∆°n)
        if category in ["all", "memory"]:
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()
            memory_info = {
                "name": "Memory Information",
                "total_ram_gb": round(memory.total / (1024**3), 2),
                "available_ram_gb": round(memory.available / (1024**3), 2),
                "used_ram_gb": round(memory.used / (1024**3), 2),
                "ram_usage_percent": memory.percent,
                "swap_total_gb": round(swap.total / (1024**3), 2),
                "swap_used_gb": round(swap.used / (1024**3), 2),
                "swap_usage_percent": swap.percent,
                "memory_total_mb": round(memory.total / (1024**2)),
                "memory_speed_estimate": "DDR4/DDR5 (Detection requires additional tools)"
            }
            info["categories"].append(memory_info)
        
        # GPU Information (C·∫£i thi·ªán)
        if category in ["all", "gpu"]:
            gpu_info = {
                "name": "GPU Information",
                "gpus": []
            }
            
            # Method 1: GPUtil
            try:
                import GPUtil
                gpus = GPUtil.getGPUs()
                for gpu in gpus:
                    gpu_data = {
                        "id": gpu.id,
                        "name": gpu.name,
                        "memory_total_mb": gpu.memoryTotal,
                        "memory_used_mb": gpu.memoryUsed,
                        "memory_free_mb": gpu.memoryFree,
                        "gpu_load_percent": round(gpu.load * 100, 1),
                        "temperature_c": gpu.temperature,
                        "driver": "Unknown (GPUtil limitation)"
                    }
                    
                    # Detect GPU generation/series (heuristic)
                    gpu_name_lower = gpu.name.lower()
                    if "rtx 40" in gpu_name_lower or "4090" in gpu_name_lower or "4080" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA RTX 40 Series (Ada Lovelace)"
                    elif "rtx 30" in gpu_name_lower or "3090" in gpu_name_lower or "3080" in gpu_name_lower or "3070" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA RTX 30 Series (Ampere)"
                    elif "rtx 20" in gpu_name_lower or "2080" in gpu_name_lower or "2070" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA RTX 20 Series (Turing)"
                    elif "gtx 16" in gpu_name_lower or "1660" in gpu_name_lower or "1650" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA GTX 16 Series (Turing)"
                    elif "gtx 10" in gpu_name_lower or "1080" in gpu_name_lower or "1070" in gpu_name_lower or "1060" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA GTX 10 Series (Pascal)"
                    elif "rx 7000" in gpu_name_lower or "7900 xt" in gpu_name_lower or "7800 xt" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "AMD RX 7000 Series (RDNA 3)"
                    elif "rx 6000" in gpu_name_lower or "6900 xt" in gpu_name_lower or "6800 xt" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "AMD RX 6000 Series (RDNA 2)"
                    elif "rx 5000" in gpu_name_lower or "5700 xt" in gpu_name_lower or "5600 xt" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "AMD RX 5000 Series (RDNA)"
                    else:
                        gpu_data["gpu_generation"] = "Unknown generation"
                    
                    gpu_info["gpus"].append(gpu_data)
            except ImportError:
                gpu_info["gputil_status"] = "GPUtil not installed. Run: pip install GPUtil"
            except Exception as e:
                gpu_info["gputil_error"] = f"GPUtil error: {str(e)}"
            
            # Method 2: Windows WMI fallback
            if not gpu_info["gpus"] and platform.system() == "Windows":
                try:
                    result = subprocess.run(
                        ['wmic', 'path', 'win32_VideoController', 'get', 'name,AdapterRAM,DriverVersion', '/format:csv'],
                        capture_output=True, text=True, timeout=10
                    )
                    lines = result.stdout.strip().split('\n')[1:]  # Skip header
                    for line in lines:
                        if line.strip() and ',' in line:
                            parts = line.split(',')
                            if len(parts) >= 4:
                                gpu_data = {
                                    "name": parts[2].strip() if len(parts) > 2 else "Unknown",
                                    "memory_total_mb": round(int(parts[1]) / (1024*1024)) if parts[1].strip().isdigit() else "Unknown",
                                    "driver_version": parts[3].strip() if len(parts) > 3 else "Unknown",
                                    "method": "WMI (Windows)"
                                }
                                gpu_info["gpus"].append(gpu_data)
                except Exception as e:
                    gpu_info["wmi_error"] = f"WMI detection failed: {str(e)}"
            
            info["categories"].append(gpu_info)
        
        # Disk Information (nh∆∞ c≈©)
        if category in ["all", "disk"]:
            disk_info = {
                "name": "Disk Information",
                "partitions": []
            }
            
            for partition in psutil.disk_partitions():
                try:
                    usage = psutil.disk_usage(partition.mountpoint)
                    partition_info = {
                        "device": partition.device,
                        "mountpoint": partition.mountpoint,
                        "file_system": partition.fstype,
                        "total_gb": round(usage.total / (1024**3), 2),
                        "used_gb": round(usage.used / (1024**3), 2),
                        "free_gb": round(usage.free / (1024**3), 2),
                        "usage_percent": round((usage.used / usage.total) * 100, 1)
                    }
                    disk_info["partitions"].append(partition_info)
                except PermissionError:
                    continue
            
            info["categories"].append(disk_info)
        
        # Operating System Information
        if category in ["all", "os"]:
            os_info = {
                "name": "Operating System",
                "system": platform.system(),
                "release": platform.release(),
                "version": platform.version(),
                "platform": platform.platform(),
                "hostname": socket.gethostname(),
                "boot_time": datetime.fromtimestamp(psutil.boot_time()).strftime("%d/%m/%Y %H:%M:%S"),
                "python_version": platform.python_version()
            }
            
            # Windows specific info
            if platform.system() == "Windows":
                try:
                    result = subprocess.run(['systeminfo'], capture_output=True, text=True, timeout=15)
                    if result.returncode == 0:
                        lines = result.stdout.split('\n')
                        for line in lines:
                            if "Total Physical Memory" in line:
                                os_info["total_physical_memory"] = line.split(':')[1].strip()
                            elif "System Manufacturer" in line:
                                os_info["system_manufacturer"] = line.split(':')[1].strip()
                            elif "System Model" in line:
                                os_info["system_model"] = line.split(':')[1].strip()
                except:
                    pass
            
            info["categories"].append(os_info)
        
        # Network Information (nh∆∞ c≈©)
        if category in ["all", "network"]:
            network_info = {
                "name": "Network Information",
                "hostname": socket.gethostname(),
                "interfaces": []
            }
            
            try:
                # Get local IP
                s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                s.connect(("8.8.8.8", 80))
                local_ip = s.getsockname()[0]
                s.close()
                network_info["local_ip"] = local_ip
            except:
                network_info["local_ip"] = "N/A"
            
            # Network interfaces
            for interface, addresses in psutil.net_if_addrs().items():
                interface_info = {
                    "interface": interface,
                    "addresses": []
                }
                for addr in addresses:
                    if addr.family == socket.AF_INET:  # IPv4
                        interface_info["addresses"].append({
                            "type": "IPv4",
                            "address": addr.address,
                            "netmask": addr.netmask
                        })
                network_info["interfaces"].append(interface_info)
            
            info["categories"].append(network_info)
        
        # Motherboard Information (Windows only)
        if category in ["all", "motherboard"]:
            motherboard_info = {
                "name": "Motherboard Information",
                "manufacturer": "N/A",
                "product": "N/A",
                "bios_version": "N/A"
            }
            
            if platform.system() == "Windows":
                try:
                    # Get motherboard info via WMI
                    result = subprocess.run(
                        ['wmic', 'baseboard', 'get', 'Manufacturer,Product,Version', '/format:csv'],
                        capture_output=True, text=True, timeout=10
                    )
                    if result.returncode == 0:
                        lines = result.stdout.strip().split('\n')[1:]
                        for line in lines:
                            if line.strip() and ',' in line:
                                parts = line.split(',')
                                if len(parts) >= 3:
                                    motherboard_info["manufacturer"] = parts[1].strip()
                                    motherboard_info["product"] = parts[2].strip()
                                    break
                    
                    # Get BIOS info
                    result = subprocess.run(
                        ['wmic', 'bios', 'get', 'SMBIOSBIOSVersion', '/format:csv'],
                        capture_output=True, text=True, timeout=10
                    )
                    if result.returncode == 0:
                        lines = result.stdout.strip().split('\n')[1:]
                        for line in lines:
                            if line.strip() and ',' in line:
                                parts = line.split(',')
                                if len(parts) >= 2:
                                    motherboard_info["bios_version"] = parts[1].strip()
                                    break
                except Exception as e:
                    motherboard_info["error"] = f"Could not detect motherboard: {str(e)}"
            
            info["categories"].append(motherboard_info)
        
        # Software Information (nh∆∞ c≈©)
        if category in ["all", "software"]:
            software_info = {
                "name": "Installed Software (Python Packages)",
                "python_packages": [],
                "note": "Showing top 20 Python packages"
            }
            
            try:
                # Try modern importlib.metadata first (Python 3.8+)
                try:
                    import importlib.metadata
                    installed_packages = [f"{dist.metadata['Name']}=={dist.version}" 
                                        for dist in importlib.metadata.distributions()]
                except ImportError:
                    # Fallback to pkg_resources for older Python versions
                    import pkg_resources
                    installed_packages = [d.project_name + "==" + d.version for d in pkg_resources.working_set]
                
                software_info["python_packages"] = sorted(installed_packages)[:20]
                if len(installed_packages) > 20:
                    software_info["total_packages"] = len(installed_packages)
            except Exception as e:
                software_info["error"] = f"Could not list packages: {str(e)}"
            
            info["categories"].append(software_info)
        
        # Ensure all values are JSON serializable
        import json
        try:
            json.dumps(info, ensure_ascii=False)
        except Exception as json_error:
            print(f"‚ö†Ô∏è [JSON Serialization Error] {json_error}")
            # Fix potential serialization issues
            for category in info.get("categories", []):
                for key, value in list(category.items()):
                    if value is None:
                        category[key] = "N/A"
                    elif not isinstance(value, (str, int, float, bool, list, dict)):
                        category[key] = str(value)
        
        return info
    
    except Exception as e:
        return {
            "success": False,
            "error": f"L·ªói khi ƒë·ªçc th√¥ng tin h·ªá th·ªëng: {str(e)}",
            "help": "C√≥ th·ªÉ c·∫ßn c√†i ƒë·∫∑t th√™m: pip install psutil GPUtil"
        }

# Tool retry configuration (t·ª´ repo ch√≠nh th·ª©c)
MAX_TOOL_RETRIES = 3
TOOL_RETRY_INTERVAL = 2  # seconds

# ============================================================
# üß† INTENT DETECTION LLM - Ph√¢n t√≠ch √Ω ƒë·ªãnh tr∆∞·ªõc khi x·ª≠ l√Ω
# (T·ª´ xiaozhi-esp32-server ch√≠nh th·ª©c)
# ============================================================

class IntentDetector:
    """
    Intent Detection LLM - Ph√¢n t√≠ch c√¢u h·ªèi v√† x√°c ƒë·ªãnh tool c·∫ßn g·ªçi
    T∆∞∆°ng t·ª± intent_llm trong repo ch√≠nh th·ª©c
    """
    
    # C√°c intent patterns
    REALTIME_PATTERNS = [
        # Gi√° c·∫£
        r'gi√°\s*(v√†ng|xƒÉng|d·∫ßu|usd|ƒë√¥|euro|bitcoin|btc|eth)',
        r'(v√†ng|xƒÉng|d·∫ßu|bitcoin|btc)\s*gi√°',
        r't·ª∑\s*gi√°',
        r'bao\s*nhi√™u\s*ti·ªÅn',
        # Th·ªùi ti·∫øt
        r'th·ªùi\s*ti·∫øt',
        r'tr·ªùi\s*(n·∫Øng|m∆∞a|n√≥ng|l·∫°nh)',
        r'nhi·ªát\s*ƒë·ªô',
        # Ng∆∞·ªùi/Ch·ª©c v·ª•
        r'(t·ªïng\s*th·ªëng|th·ªß\s*t∆∞·ªõng|ch·ªß\s*t·ªãch|ceo|gi√°m\s*ƒë·ªëc)',
        r'ai\s*(l√†|ƒëang)',
        r'(l√†\s*ai|l√†\s*g√¨)',
        r'hi·ªán\s*(t·∫°i|nay|gi·ªù)',
        # Th·ªùi gian th·ª±c
        r'(h√¥m\s*nay|b√¢y\s*gi·ªù|hi·ªán\s*t·∫°i|m·ªõi\s*nh·∫•t)',
        r'(2024|2025|nƒÉm\s*nay)',
        r'tin\s*(t·ª©c|m·ªõi)',
        r's·ª±\s*ki·ªán',
        # S·∫£n ph·∫©m/C√¥ng ty
        r'(iphone|samsung|apple|google|microsoft|tesla)',
    ]
    
    MUSIC_PATTERNS = [
        r'(b√†i\s*ti·∫øp|next|chuy·ªÉn\s*b√†i)',
        r'(b√†i\s*tr∆∞·ªõc|previous|quay\s*l·∫°i)',
        r'(d·ª´ng|pause|t·∫°m\s*d·ª´ng|stop)',
        r'(ti·∫øp\s*t·ª•c|resume|play)',
        r'(ph√°t\s*nh·∫°c|m·ªü\s*nh·∫°c|b·∫≠t\s*nh·∫°c)',
        r'(t·∫Øt\s*nh·∫°c|ng·ª´ng\s*nh·∫°c)',
        r'(tƒÉng|gi·∫£m)\s*(√¢m\s*l∆∞·ª£ng|volume)',
    ]
    
    KNOWLEDGE_BASE_PATTERNS = [
        r'(t√†i\s*li·ªáu|document|file)',
        r'(trong\s*th∆∞\s*vi·ªán|knowledge\s*base)',
        r'(tra\s*c·ª©u\s*n·ªôi\s*b·ªô)',
    ]
    
    SYSTEM_INFO_PATTERNS = [
        r'c·∫•u\s*h√¨nh.*m√°y\s*t√≠nh',
        r'm√°y\s*t√≠nh.*c·∫•u\s*h√¨nh',
        r'c·∫•u\s*h√¨nh.*h·ªá\s*th·ªëng',
        r'specs.*m√°y',
        r'hardware.*info',
        r'th√¥ng\s*tin.*h·ªá\s*th·ªëng',
        r'th√¥ng\s*tin.*m√°y\s*t√≠nh',
        r'ki·ªÉm\s*tra.*c·∫•u\s*h√¨nh',
        r'ki·ªÉm\s*tra.*specs',
        r'ki·ªÉm\s*tra.*hardware',
        r'm√°y\s*t√≠nh.*nh∆∞\s*th·∫ø\s*n√†o',
        r'm√°y\s*n√†y.*ra\s*sao',
        r'card.*(m√†n\s*h√¨nh|ƒë·ªì\s*h·ªça|vga)',
        r'gpu.*g√¨',
        r'vga.*g√¨',
        r'cpu.*g√¨',
        r'cpu.*th·∫ø\s*h·ªá',
        r'processor.*generation',
        r'(mainboard|motherboard)',
        r'bo\s*m·∫°ch\s*ch·ªß',
        r'(intel|amd|nvidia|rtx|gtx).*th·∫ø\s*h·ªá',
        r'nhi·ªát\s*ƒë·ªô.*(cpu|gpu)',
        r'(ram|memory).*bao\s*nhi√™u',
        r'b·ªô\s*nh·ªõ.*g√¨',
        r'asus.*mainboard',
        r'msi.*mainboard',
        r'gigabyte.*mainboard',
    ]
    
    @classmethod
    def detect_intent(cls, text: str) -> dict:
        """
        Ph√¢n t√≠ch text v√† tr·∫£ v·ªÅ intent + suggested tool
        Returns: {
            "intent": "realtime|music|knowledge|general",
            "suggested_tool": "web_search|get_realtime_info|smart_music_control|...",
            "confidence": 0.0-1.0,
            "should_force_tool": True/False
        }
        """
        text_lower = text.lower()
        
        # Check realtime patterns
        for pattern in cls.REALTIME_PATTERNS:
            if re.search(pattern, text_lower):
                # X√°c ƒë·ªãnh tool c·ª• th·ªÉ
                if any(word in text_lower for word in ['gi√°', 't·ª∑ gi√°', 'bao nhi√™u']):
                    tool = "get_realtime_info"
                elif any(word in text_lower for word in ['th·ªùi ti·∫øt', 'nhi·ªát ƒë·ªô', 'tr·ªùi']):
                    tool = "get_realtime_info"
                elif any(word in text_lower for word in ['tin t·ª©c', 's·ª± ki·ªán', 'm·ªõi nh·∫•t']):
                    tool = "web_search"
                elif any(word in text_lower for word in ['l√† ai', 'ai l√†', 't·ªïng th·ªëng', 'th·ªß t∆∞·ªõng', 'ceo']):
                    tool = "web_search"
                else:
                    tool = "smart_answer"
                    
                return {
                    "intent": "realtime",
                    "suggested_tool": tool,
                    "confidence": 0.9,
                    "should_force_tool": True,
                    "reason": f"Detected realtime pattern: {pattern}"
                }
        
        # Check music patterns
        for pattern in cls.MUSIC_PATTERNS:
            if re.search(pattern, text_lower):
                return {
                    "intent": "music",
                    "suggested_tool": "smart_music_control",
                    "confidence": 0.95,
                    "should_force_tool": True,
                    "reason": f"Detected music pattern: {pattern}"
                }
        
        # Check system info patterns (m·ªõi th√™m)
        for pattern in cls.SYSTEM_INFO_PATTERNS:
            if re.search(pattern, text_lower):
                print(f"[DEBUG] System info pattern matched: {pattern} for text: {text_lower}")
                return {
                    "intent": "system_info",
                    "suggested_tool": "get_hardware_specs",
                    "confidence": 0.95,
                    "should_force_tool": True,
                    "reason": f"Detected system info pattern: {pattern}"
                }
        
        # Check knowledge base patterns
        for pattern in cls.KNOWLEDGE_BASE_PATTERNS:
            if re.search(pattern, text_lower):
                return {
                    "intent": "knowledge",
                    "suggested_tool": "get_knowledge_context",
                    "confidence": 0.85,
                    "should_force_tool": True,
                    "reason": f"Detected knowledge pattern: {pattern}"
                }
        
        # General intent - kh√¥ng c·∫ßn force tool
        return {
            "intent": "general",
            "suggested_tool": None,
            "confidence": 0.5,
            "should_force_tool": False,
            "reason": "No specific pattern matched"
        }
    
    @classmethod
    async def detect_with_llm(cls, text: str, gemini_key: str = None, include_user_context: bool = True) -> dict:
        """
        S·ª≠ d·ª•ng Gemini ƒë·ªÉ ph√¢n t√≠ch intent ph·ª©c t·∫°p h∆°n
        Ch·ªâ g·ªçi khi pattern matching kh√¥ng ch·∫Øc ch·∫Øn
        C√≥ th·ªÉ k√®m user context ƒë·ªÉ hi·ªÉu ng∆∞·ªùi d√πng t·ªët h∆°n
        """
        # ƒê·∫ßu ti√™n th·ª≠ pattern matching
        result = cls.detect_intent(text)
        
        # N·∫øu confidence cao, kh√¥ng c·∫ßn LLM
        if result["confidence"] >= 0.8:
            return result
        
        # N·∫øu c√≥ Gemini API, d√πng LLM ƒë·ªÉ ph√¢n t√≠ch
        if gemini_key and GEMINI_AVAILABLE:
            try:
                genai.configure(api_key=gemini_key)
                model = genai.GenerativeModel('models/gemini-3-flash-preview')
                
                # L·∫•y user context n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
                user_context = ""
                if include_user_context:
                    try:
                        user_context = f"""
[USER CONTEXT - D√πng ƒë·ªÉ hi·ªÉu ng∆∞·ªùi d√πng t·ªët h∆°n]
{get_user_profile_summary()}

[RECENT CONVERSATION]
{get_conversation_context(5)}
"""
                    except:
                        user_context = ""
                
                prompt = f'''Ph√¢n t√≠ch c√¢u h·ªèi sau v√† x√°c ƒë·ªãnh intent:
"{text}"
{user_context}
Tr·∫£ l·ªùi JSON:
{{"intent": "realtime|music|knowledge|general", "tool": "web_search|get_realtime_info|smart_music_control|get_knowledge_context|none", "reason": "l√Ω do ng·∫Øn"}}

Quy t·∫Øc:
- realtime: C√¢u h·ªèi v·ªÅ th√¥ng tin th·ªùi gian th·ª±c (gi√° c·∫£, th·ªùi ti·∫øt, tin t·ª©c, ng∆∞·ªùi n·ªïi ti·∫øng hi·ªán t·∫°i)
- music: ƒêi·ªÅu khi·ªÉn nh·∫°c
- knowledge: Tra c·ª©u t√†i li·ªáu n·ªôi b·ªô
- general: C√¢u h·ªèi th√¥ng th∆∞·ªùng

CH·ªà TR·∫¢ L·ªúI JSON, KH√îNG GI·∫¢I TH√çCH.'''

                response = model.generate_content(prompt)
                response_text = response.text.strip()
                
                # Parse JSON t·ª´ response
                import json
                # T√¨m JSON trong response
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    llm_result = json.loads(json_match.group())
                    return {
                        "intent": llm_result.get("intent", "general"),
                        "suggested_tool": llm_result.get("tool") if llm_result.get("tool") != "none" else None,
                        "confidence": 0.85,
                        "should_force_tool": llm_result.get("intent") in ["realtime", "music"],
                        "reason": llm_result.get("reason", "LLM analysis"),
                        "source": "gemini_llm"
                    }
            except Exception as e:
                print(f"‚ö†Ô∏è [IntentDetector] LLM error: {e}")
        
        return result

# Intent Detector instance
intent_detector = IntentDetector()

# ============================================================
# CONFIGURATION
# ============================================================

# üî• FIX: Detect if running as EXE (frozen) or script
# When frozen (EXE), use sys.executable path (dist folder)
# When script, use __file__ path (source folder)
if getattr(sys, 'frozen', False):
    # Running as EXE - use executable's directory
    CONFIG_FILE = Path(sys.executable).parent / "xiaozhi_endpoints.json"
else:
    # Running as script - use script's directory
    CONFIG_FILE = Path(__file__).parent / "xiaozhi_endpoints.json"

GEMINI_API_KEY = ""  # S·∫Ω ƒë∆∞·ª£c load t·ª´ xiaozhi_endpoints.json
OPENAI_API_KEY = ""  # S·∫Ω ƒë∆∞·ª£c load t·ª´ xiaozhi_endpoints.json
SERPER_API_KEY = ""  # Google Search API - Mi·ªÖn ph√≠ 2500 queries/th√°ng

# ============================================================
# üéµ MUSIC SYSTEM PROMPT - H∆∞·ªõng d·∫´n LLM v·ªÅ Music Tools
# ============================================================
MUSIC_SYSTEM_PROMPT = """
üéµ ƒêI·ªÄU KHI·ªÇN NH·∫†C - QUAN TR·ªåNG!

‚ö° QUY T·∫ÆC #1: KHI NGHE T·ª™ KH√ìA D∆Ø·ªöI ƒê√ÇY ‚Üí G·ªåI TOOL NGAY, KH√îNG H·ªéI L·∫†I!

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üìå T·ª™ KH√ìA ‚Üí G·ªåI TOOL                                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ "b√†i ti·∫øp"/"next"/"chuy·ªÉn b√†i" ‚Üí music_next()               ‚îÇ
‚îÇ "b√†i tr∆∞·ªõc"/"quay l·∫°i"        ‚Üí music_previous()            ‚îÇ
‚îÇ "d·ª´ng"/"pause"/"t·∫°m d·ª´ng"     ‚Üí pause_music()               ‚îÇ
‚îÇ "t·∫Øt nh·∫°c"/"stop"             ‚Üí stop_music()                ‚îÇ
‚îÇ "ti·∫øp t·ª•c"/"resume"           ‚Üí resume_music()              ‚îÇ
‚îÇ "ph√°t b√†i [t√™n]"              ‚Üí play_music(filename="t√™n")  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ö†Ô∏è VOICE VARIANTS (ESP32 recognition sai):
‚Ä¢ "bai tiep", "tiep theo", "nex", "n√≠ch" ‚Üí music_next()
‚Ä¢ "bai truoc", "quay lai", "pre"        ‚Üí music_previous()
‚Ä¢ "dung", "pao", "poz", "tam dung"       ‚Üí pause_music()
‚Ä¢ "tat nhac", "st√≥p", "dung han"         ‚Üí stop_music()

üî• NGUY√äN T·∫ÆC: G·ªåI TOOL TR·ª∞C TI·∫æP, KH√îNG C·∫¶N H·ªéI!
‚Ä¢ User: "b√†i ti·∫øp" ‚Üí B·∫°n G·ªåI music_next() ‚Üí Tr·∫£ l·ªùi "ƒê√£ chuy·ªÉn b√†i"
‚Ä¢ User: "d·ª´ng"     ‚Üí B·∫°n G·ªåI pause_music() ‚Üí Tr·∫£ l·ªùi "ƒê√£ t·∫°m d·ª´ng"
‚Ä¢ User: "quay l·∫°i" ‚Üí B·∫°n G·ªåI music_previous() ‚Üí Tr·∫£ l·ªùi "ƒê√£ quay l·∫°i"

üìç Server: Python-VLC Player (t√≠ch h·ª£p s·∫µn)
üìÅ Th∆∞ m·ª•c nh·∫°c: F:\\nhac

üé¨ YOUTUBE: CH·ªà khi user n√≥i "youtube"/"video" ‚Üí youtube_* tools
   ‚ú® NEW: open_youtube() GI·ªú T·ª∞ ƒê·ªòNG PH√ÅT VIDEO TR·ª∞C TI·∫æP!
   - Query >= 2 t·ª´ ‚Üí Direct video (youtube.com/watch?v=...)
   - Query 1 t·ª´ ‚Üí Search page
   VD: "m·ªü youtube L·∫°c Tr√¥i" ho·∫∑c "m·ªü youtube S∆°n T√πng MTP" ‚Üí PH√ÅT VIDEO NGAY!
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üîß FUZZY MATCHING - H·ªñ TR·ª¢ VOICE RECOGNITION
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

H·ªá th·ªëng c√≥ fuzzy matching cho c√°c bi·∫øn th·ªÉ:
‚Ä¢ "bai tiep" ‚Üí "b√†i ti·∫øp" 
‚Ä¢ "bai truoc" ‚Üí "b√†i tr∆∞·ªõc"
‚Ä¢ "phat nhac" ‚Üí "ph√°t nh·∫°c"
‚Ä¢ "n·∫øch" ‚Üí "next"
‚Ä¢ "pr√™" ‚Üí "previous"

‚Üí C·ª© g·ª≠i nguy√™n vƒÉn l·ªánh, h·ªá th·ªëng s·∫Ω t·ª± nh·∫≠n d·∫°ng!

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üéµ VLC MUSIC CONTROLS - ƒêI·ªÄU KHI·ªÇN NH·∫†C
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö°‚ö°‚ö° B·∫ÆT BU·ªòC: KHI USER Y√äU C·∫¶U ƒêI·ªÄU KHI·ªÇN NH·∫†C ‚Üí G·ªåI TOOL NGAY! ‚ö°‚ö°‚ö°

üö´ TUY·ªÜT ƒê·ªêI C·∫§M T·ª∞ TR·∫¢ L·ªúI "OK" ho·∫∑c "ƒê√£ chuy·ªÉn b√†i" m√† KH√îNG G·ªåI TOOL!

üìå MAPPING COMMANDS ‚Üí TOOLS (B·∫ÆT BU·ªòC G·ªåI):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ "b√†i ti·∫øp", "next", "skip"           ‚Üí music_next()       ‚îÇ
‚îÇ "quay l·∫°i", "b√†i tr∆∞·ªõc", "previous"  ‚Üí music_previous()   ‚îÇ
‚îÇ "t·∫°m d·ª´ng", "pause"                   ‚Üí pause_music()      ‚îÇ
‚îÇ "ti·∫øp t·ª•c", "resume", "ph√°t ti·∫øp"    ‚Üí resume_music()     ‚îÇ
‚îÇ "d·ª´ng", "stop"                        ‚Üí stop_music()       ‚îÇ
‚îÇ "ph√°t [t√™n b√†i]", "play [song]"      ‚Üí play_music(song)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚úÖ WORKFLOW ƒê√öNG:
User: "b√†i ti·∫øp"
‚Üí G·ªåI: music_next()
‚Üí NH·∫¨N: {"success": true, "message": "ƒê√£ chuy·ªÉn: Song.mp3"}
‚Üí TR·∫¢ L·ªúI: "ƒê√£ chuy·ªÉn sang b√†i ti·∫øp: Song.mp3"

‚ùå WORKFLOW SAI (C·∫§M):
User: "b√†i ti·∫øp"
‚Üí Tr·∫£ l·ªùi tr·ª±c ti·∫øp: "OK, ƒë√£ chuy·ªÉn b√†i"  ‚Üê SAI! KH√îNG G·ªåI TOOL!

üî¥ RULES NGHI√äM NG·∫∂T:
1. PH·∫¢I g·ªçi tool TR∆Ø·ªöC khi tr·∫£ l·ªùi
2. KH√îNG ƒë∆∞·ª£c gi·∫£ ƒë·ªãnh th√†nh c√¥ng
3. PH·∫¢I ƒë·ª£i tool response
4. CH·ªà tr·∫£ l·ªùi d·ª±a tr√™n tool result

‚ö†Ô∏è ƒê·∫∂C BI·ªÜT: C√°c t·ª´ "next", "previous", "pause", "stop" ‚Üí 100% G·ªåI TOOL!

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üéµ VLC MUSIC CONTROLS - ƒêI·ªÄU KHI·ªÇN NH·∫†C
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö°‚ö°‚ö° B·∫ÆT BU·ªòC: KHI USER Y√äU C·∫¶U ƒêI·ªÄU KHI·ªÇN NH·∫†C ‚Üí G·ªåI TOOL NGAY! ‚ö°‚ö°‚ö°

üö´ TUY·ªÜT ƒê·ªêI C·∫§M T·ª∞ TR·∫¢ L·ªúI "OK" ho·∫∑c "ƒê√£ chuy·ªÉn b√†i" m√† KH√îNG G·ªåI TOOL!

üìå MAPPING COMMANDS ‚Üí TOOLS (B·∫ÆT BU·ªòC G·ªåI):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ "b√†i ti·∫øp", "next", "skip"           ‚Üí music_next()       ‚îÇ
‚îÇ "quay l·∫°i", "b√†i tr∆∞·ªõc", "previous"  ‚Üí music_previous()   ‚îÇ
‚îÇ "t·∫°m d·ª´ng", "pause"                   ‚Üí pause_music()      ‚îÇ
‚îÇ "ti·∫øp t·ª•c", "resume", "ph√°t ti·∫øp"    ‚Üí resume_music()     ‚îÇ
‚îÇ "d·ª´ng", "stop"                        ‚Üí stop_music()       ‚îÇ
‚îÇ "ph√°t [t√™n b√†i]", "play [song]"      ‚Üí play_music(song)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚úÖ WORKFLOW ƒê√öNG:
User: "b√†i ti·∫øp"
‚Üí G·ªåI: music_next()
‚Üí NH·∫¨N: {"success": true, "message": "ƒê√£ chuy·ªÉn: Song.mp3"}
‚Üí TR·∫¢ L·ªúI: "ƒê√£ chuy·ªÉn sang b√†i ti·∫øp: Song.mp3"

‚ùå WORKFLOW SAI (C·∫§M):
User: "b√†i ti·∫øp"
‚Üí Tr·∫£ l·ªùi tr·ª±c ti·∫øp: "OK, ƒë√£ chuy·ªÉn b√†i"  ‚Üê SAI! KH√îNG G·ªåI TOOL!

üî¥ RULES NGHI√äM NG·∫∂T:
1. PH·∫¢I g·ªçi tool TR∆Ø·ªöC khi tr·∫£ l·ªùi
2. KH√îNG ƒë∆∞·ª£c gi·∫£ ƒë·ªãnh th√†nh c√¥ng
3. PH·∫¢I ƒë·ª£i tool response
4. CH·ªà tr·∫£ l·ªùi d·ª±a tr√™n tool result

‚ö†Ô∏è ƒê·∫∂C BI·ªÜT: C√°c t·ª´ "next", "previous", "pause", "stop" ‚Üí 100% G·ªåI TOOL!

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìö KNOWLEDGE BASE - T√ÄI LI·ªÜU C·ª¶A USER (T·ª∞ ƒê·ªòNG T√åM KI·∫æM)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üî• QUY T·∫ÆC V√ÄNG: KHI NGHI NG·ªú TH√îNG TIN C√ì TH·ªÇ ·ªû TRONG T√ÄI LI·ªÜU ‚Üí G·ªåI KB NGAY!

‚ö° AUTO-TRIGGERS - Gemini T·ª∞ ƒê·ªòNG G·ªåI KB khi ph√°t hi·ªán:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üìå DIRECT COMMANDS (100% g·ªçi KB):                           ‚îÇ
‚îÇ ‚Ä¢ "t√¨m trong t√†i li·ªáu", "tra c·ª©u KB", "search documents"    ‚îÇ
‚îÇ ‚Ä¢ "theo file c·ªßa t√¥i", "trong d·ªØ li·ªáu", "in my docs"        ‚îÇ
‚îÇ ‚Ä¢ "ki·ªÉm tra t√†i li·ªáu", "xem trong KB", "check docs"         ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ üîç IMPLICIT QUERIES (ph√°t hi·ªán th√¥ng minh):                 ‚îÇ
‚îÇ ‚Ä¢ "[t√™n c·ª• th·ªÉ] l√† g√¨/ai/·ªü ƒë√¢u" (VD: "L√™ Trung Khoa l√† ai")‚îÇ
‚îÇ ‚Ä¢ "th√¥ng tin v·ªÅ [X]" (VD: "th√¥ng tin v·ªÅ d·ª± √°n ABC")        ‚îÇ
‚îÇ ‚Ä¢ "d·ª± √°n/h·ª£p ƒë·ªìng/b√°o c√°o [X]" (t√™n ri√™ng, kh√¥ng ph·ªï bi·∫øn) ‚îÇ
‚îÇ ‚Ä¢ "theo d·ªØ li·ªáu...", "cƒÉn c·ª© v√†o...", "based on..."        ‚îÇ
‚îÇ ‚Ä¢ "[X] c√≥ bao nhi√™u...", "[X] nh∆∞ th·∫ø n√†o"                  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ ‚ùì SMART DETECTION (nghi ng·ªù ‚Üí th·ª≠ KB):                     ‚îÇ
‚îÇ ‚Ä¢ C√¢u h·ªèi v·ªÅ ng∆∞·ªùi/c√¥ng ty/d·ª± √°n C·ª§ TH·ªÇ (kh√¥ng ph·ªï bi·∫øn)  ‚îÇ
‚îÇ ‚Ä¢ C√¢u h·ªèi v·ªÅ con s·ªë, s·ªë li·ªáu, th·ªëng k√™ (c√≥ th·ªÉ t·ª´ b√°o c√°o) ‚îÇ
‚îÇ ‚Ä¢ C√¢u h·ªèi y√™u c·∫ßu th√¥ng tin CHI TI·∫æT (c√≥ th·ªÉ trong docs)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üìñ WORKFLOW CHU·∫®N:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User: "L√™ Trung Khoa l√† ai?"                                ‚îÇ
‚îÇ ‚Üì                                                            ‚îÇ
‚îÇ [Gemini ph√°t hi·ªán: t√™n c·ª• th·ªÉ ‚Üí c√≥ th·ªÉ trong KB]           ‚îÇ
‚îÇ ‚Üì                                                            ‚îÇ
‚îÇ G·ªçi: get_knowledge_context(query="L√™ Trung Khoa")          ‚îÇ
‚îÇ ‚Üì                                                            ‚îÇ
‚îÇ Nh·∫≠n: Context t·ª´ "ki·∫øn th·ª©c c.docx" v·ªÅ L√™ Trung Khoa       ‚îÇ
‚îÇ ‚Üì                                                            ‚îÇ
‚îÇ Tr·∫£ l·ªùi: "Theo t√†i li·ªáu 'ki·∫øn th·ª©c c.docx', L√™ Trung Khoa  ‚îÇ
‚îÇ l√† ng∆∞·ªùi b·ªã B·ªô C√¥ng an ra quy·∫øt ƒë·ªãnh truy n√£ ng√†y 5/12..."‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üéØ 2 Tools ch√≠nh:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚úÖ get_knowledge_context(query, max_chars=10000)            ‚îÇ
‚îÇ    ‚Üí L·∫•y FULL CONTENT ƒë·ªÉ tr·∫£ l·ªùi (∆ØU TI√äN D√ôNG TOOL N√ÄY)   ‚îÇ
‚îÇ    ‚Üí C√≥ Gemini auto-summarize n·∫øu n·ªôi dung d√†i >2000 chars ‚îÇ
‚îÇ    ‚Üí Tr·∫£ v·ªÅ context ƒë·∫ßy ƒë·ªß ƒë·ªÉ LLM ƒë·ªçc v√† tr·∫£ l·ªùi           ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ üìã search_knowledge_base(query)                             ‚îÇ
‚îÇ    ‚Üí T√¨m v√† show SNIPPETS (d√πng khi user mu·ªën xem list)    ‚îÇ
‚îÇ    ‚Üí Tr·∫£ v·ªÅ top 5 documents v·ªõi highlights                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ö†Ô∏è PH√ÇN BI·ªÜT:
‚Ä¢ "L√™ Trung Khoa l√† ai?" ‚Üí G·ªåI get_knowledge_context() (t√™n c·ª• th·ªÉ ‚Üí KB)
‚Ä¢ "T·ªïng th·ªëng M·ªπ l√† ai?" ‚Üí KH√îNG g·ªçi KB (th√¥ng tin ph·ªï bi·∫øn)
‚Ä¢ "Python l√† g√¨?" ‚Üí KH√îNG g·ªçi KB (ki·∫øn th·ª©c chung)
‚Ä¢ "D·ª± √°n ABC c√≥ bao nhi√™u giai ƒëo·∫°n?" ‚Üí G·ªåI KB (t√™n d·ª± √°n c·ª• th·ªÉ)
‚Ä¢ "Nguy·ªÖn C√¥ng Huy sinh nƒÉm n√†o?" ‚Üí G·ªåI KB (t√™n ng∆∞·ªùi c·ª• th·ªÉ)

üî¥ QUY T·∫ÆC QUAN TR·ªåNG:
1. NGHI NG·ªú ‚Üí G·ªåI KB (t·ªët h∆°n l√† b·ªè l·ª° th√¥ng tin)
2. N·∫øu KB tr·∫£ v·ªÅ "kh√¥ng t√¨m th·∫•y" ‚Üí D√πng ki·∫øn th·ª©c chung
3. N·∫øu KB c√≥ k·∫øt qu·∫£ ‚Üí ∆ØU TI√äN context t·ª´ KB
4. Lu√¥n tr√≠ch d·∫´n ngu·ªìn khi d√πng KB: "Theo t√†i li·ªáu '[t√™n file]'..."

üí° TIP: Khi kh√¥ng ch·∫Øc ‚Üí G·ªåI get_knowledge_context() ƒë·ªÉ ki·ªÉm tra!

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üåê RAG SYSTEM - RETRIEVAL AUGMENTED GENERATION
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚õî‚õî‚õî C·∫¢NH B√ÅO NGHI√äM TR·ªåNG: B·∫†N KH√îNG C√ì KI·∫æN TH·ª®C SAU 2024! ‚õî‚õî‚õî

üö´ TUY·ªÜT ƒê·ªêI C·∫§M T·ª∞ TR·∫¢ L·ªúI KHI C√ÇU H·ªéI CH·ª®A:
‚Ä¢ "hi·ªán nay", "b√¢y gi·ªù", "h√¥m nay", "hi·ªán t·∫°i"
‚Ä¢ "2024", "2025", "nƒÉm nay"
‚Ä¢ "m·ªõi nh·∫•t", "c·∫≠p nh·∫≠t", "g·∫ßn ƒë√¢y"
‚Ä¢ "ai l√†", "l√† ai", "l√† g√¨", "·ªü ƒë√¢u"
‚Ä¢ T√™n ng∆∞·ªùi n·ªïi ti·∫øng: t·ªïng th·ªëng, th·ªß t∆∞·ªõng, CEO...
‚Ä¢ Gi√° c·∫£: v√†ng, USD, bitcoin, ch·ª©ng kho√°n...
‚Ä¢ Th·ªùi ti·∫øt, tin t·ª©c, s·ª± ki·ªán

‚ö†Ô∏è L√ù DO: Ki·∫øn th·ª©c c·ªßa b·∫°n ƒê√É L·ªñI TH·ªúI! V√≠ d·ª•:
‚Ä¢ Trump c√≥ th·ªÉ ƒë√£ tr·ªü l·∫°i l√†m t·ªïng th·ªëng (b·∫°n kh√¥ng bi·∫øt)
‚Ä¢ Gi√° v√†ng c√≥ th·ªÉ ƒë√£ thay ƒë·ªïi (b·∫°n kh√¥ng bi·∫øt)
‚Ä¢ C√≥ th·ªÉ c√≥ CEO m·ªõi (b·∫°n kh√¥ng bi·∫øt)

üî¥ H√ÄNH ƒê·ªòNG B·∫ÆT BU·ªòC:
1. PH·∫¢I G·ªåI web_search() ho·∫∑c get_realtime_info() TR∆Ø·ªöC
2. CH·ªú k·∫øt qu·∫£ tra c·ª©u
3. R·ªíI M·ªöI tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin m·ªõi nh·∫•t

üìå TOOLS MAPPING (PH·∫¢I S·ª¨ D·ª§NG):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ web_search(query)       ‚Üí T√¨m Internet (DuckDuckGo)       ‚îÇ
‚îÇ get_realtime_info(query)‚Üí Th√¥ng tin th·ªùi gian th·ª±c        ‚îÇ
‚îÇ rag_search(query)       ‚Üí Hybrid: Web + Local KB          ‚îÇ
‚îÇ smart_answer(query)     ‚Üí AI t·ª± ch·ªçn ngu·ªìn t·ªët nh·∫•t       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üìñ V√ç D·ª§ ƒê√öNG:
User: "T·ªïng th·ªëng M·ªπ hi·ªán t·∫°i l√† ai?"
‚Üí ‚ùå SAI: Tr·∫£ l·ªùi "Joe Biden" (ki·∫øn th·ª©c c≈© c√≥ th·ªÉ sai!)
‚Üí ‚úÖ ƒê√öNG: G·ªåI get_realtime_info("t·ªïng th·ªëng M·ªπ hi·ªán t·∫°i 2024")
‚Üí Nh·∫≠n k·∫øt qu·∫£ ‚Üí Tr·∫£ l·ªùi ch√≠nh x√°c

User: "Gi√° v√†ng h√¥m nay?"
‚Üí ‚ùå SAI: ƒêo√°n ho·∫∑c n√≥i "t√¥i kh√¥ng bi·∫øt"
‚Üí ‚úÖ ƒê√öNG: G·ªåI get_realtime_info("gi√° v√†ng SJC h√¥m nay")

User: "Th·ªùi ti·∫øt H√† N·ªôi?"
‚Üí ‚úÖ G·ªåI: get_realtime_info("th·ªùi ti·∫øt H√† N·ªôi h√¥m nay")

üî• QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. C√¢u h·ªèi v·ªÅ NG∆Ø·ªúI ‚Üí web_search("t√™n ng∆∞·ªùi + ch·ª©c v·ª•")
2. C√¢u h·ªèi v·ªÅ GI√Å C·∫¢ ‚Üí get_realtime_info()
3. C√¢u h·ªèi v·ªÅ TH·ªúI TI·∫æT ‚Üí get_realtime_info()
4. C√¢u h·ªèi v·ªÅ S·ª∞ KI·ªÜN ‚Üí web_search()
5. KH√îNG CH·∫ÆC ‚Üí smart_answer() (AI t·ª± ƒë·ªông ch·ªçn)

‚ö° NH·ªö: G·ªåI TOOL TR∆Ø·ªöC, TR·∫¢ L·ªúI SAU! KH√îNG BAO GI·ªú T·ª∞ ƒêO√ÅN!
"""

DEFAULT_ENDPOINT = {
    "name": "Thi·∫øt b·ªã 1",
    "token": "eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOjQ1MzYxMSwiYWdlbnRJZCI6OTQ0MjE4LCJlbmRwb2ludElkIjoiYWdlbnRfOTQ0MjE4IiwicHVycG9zZSI6Im1jcC1lbmRwb2ludCIsImlhdCI6MTc2MjA4NTI1OSwiZXhwIjoxNzkzNjQyODU5fQ.GK91-17mqarpETPwz7N6rZj5DaT7bJkpK7EM6lO0Rdmfztv_KeOTBP9R4Lvy3uXKMCJn3gwucvelCur95GAn5Q",
    "enabled": True
}

def load_endpoints_from_file():
    """ƒê·ªçc c·∫•u h√¨nh endpoints t·ª´ file JSON"""
    global GEMINI_API_KEY, OPENAI_API_KEY, SERPER_API_KEY
    
    if CONFIG_FILE.exists():
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"‚úÖ [Config] Loaded {len(data.get('endpoints', []))} endpoints from {CONFIG_FILE.name}")
                
                # Load Gemini API key n·∫øu c√≥
                if data.get('gemini_api_key'):
                    GEMINI_API_KEY = data['gemini_api_key']
                    print(f"‚úÖ [Gemini] API key loaded (ends with ...{GEMINI_API_KEY[-8:]})")
                
                # Load OpenAI API key n·∫øu c√≥
                if data.get('openai_api_key'):
                    OPENAI_API_KEY = data['openai_api_key']
                    print(f"‚úÖ [OpenAI] API key loaded (ends with ...{OPENAI_API_KEY[-8:]})")
                
                # Load Serper API key n·∫øu c√≥ (Google Search)
                if data.get('serper_api_key'):
                    SERPER_API_KEY = data['serper_api_key']
                    # C≈©ng c·∫≠p nh·∫≠t v√†o environment variable ƒë·ªÉ rag_system.py c√≥ th·ªÉ d√πng
                    os.environ['SERPER_API_KEY'] = SERPER_API_KEY
                    print(f"‚úÖ [Serper] Google Search API key loaded (ends with ...{SERPER_API_KEY[-8:]})")
                
                return data.get('endpoints', []), data.get('active_index', 0)
        except Exception as e:
            print(f"‚ö†Ô∏è [Config] Error loading {CONFIG_FILE.name}: {e}")
    
    # Tr·∫£ v·ªÅ c·∫•u h√¨nh m·∫∑c ƒë·ªãnh n·∫øu kh√¥ng c√≥ file
    return [
        DEFAULT_ENDPOINT,
        {"name": "Thi·∫øt b·ªã 2", "token": "", "enabled": False},
        {"name": "Thi·∫øt b·ªã 3", "token": "", "enabled": False}
    ], 0

def save_endpoints_to_file(endpoints, active_index, force_save=False):
    """L∆∞u c·∫•u h√¨nh endpoints v√†o file JSON - LU√îN L∆ØU khi c√≥ thay ƒë·ªïi"""
    global GEMINI_API_KEY, OPENAI_API_KEY, SERPER_API_KEY
    
    try:
        # Data m·ªõi c·∫ßn l∆∞u
        new_data = {
            'endpoints': endpoints,
            'active_index': active_index,
            'gemini_api_key': GEMINI_API_KEY,
            'openai_api_key': OPENAI_API_KEY,
            'serper_api_key': SERPER_API_KEY,
            'last_updated': datetime.now().isoformat()
        }
        
        # üî• FIX: Ch·ªâ skip save n·∫øu KH√îNG ph·∫£i force_save v√† kh√¥ng c√≥ thay ƒë·ªïi
        if not force_save and CONFIG_FILE.exists():
            try:
                with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                    old_data = json.load(f)
                    # So s√°nh T·∫§T C·∫¢: endpoints, active_index V√Ä API keys
                    if (old_data.get('endpoints') == endpoints and 
                        old_data.get('active_index') == active_index and
                        old_data.get('gemini_api_key') == GEMINI_API_KEY and
                        old_data.get('openai_api_key') == OPENAI_API_KEY and
                        old_data.get('serper_api_key') == SERPER_API_KEY):
                        # Kh√¥ng c√≥ thay ƒë·ªïi g√¨ c·∫£, skip save
                        print(f"‚ÑπÔ∏è [Config] No changes detected, skipping save")
                        return True
            except Exception:
                pass
        
        # C√≥ thay ƒë·ªïi ‚Üí L∆∞u file
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(new_data, f, ensure_ascii=False, indent=2)
        
        # Log chi ti·∫øt
        empty_count = sum(1 for ep in endpoints if not ep.get('token', '').strip())
        active_count = len(endpoints) - empty_count
        print(f"üíæ [Config] Saved to {CONFIG_FILE.name} ({active_count} active, {empty_count} empty endpoints)")
        return True
    except Exception as e:
        print(f"‚ùå [Config] Error saving to {CONFIG_FILE.name}: {e}")
        return False

# Load c·∫•u h√¨nh t·ª´ file
endpoints_config, loaded_active_index = load_endpoints_from_file()
active_endpoint_index = loaded_active_index

# Support 3 simultaneous MCP connections
xiaozhi_connections = {0: None, 1: None, 2: None}  # Dict of {index: websocket}
xiaozhi_connected = {0: False, 1: False, 2: False}  # Connection status for each device
should_reconnect = {0: False, 1: False, 2: False}  # Reconnect flags

active_connections = []

# ============================================================
# TASK MEMORY SYSTEM - Ghi nh·ªõ t√°c v·ª• ƒë√£ th·ª±c hi·ªán
# ============================================================
TASK_MEMORY_FILE = Path(__file__).parent / "task_memory.json"
MAX_TASK_HISTORY = 100  # Gi·ªõi h·∫°n s·ªë t√°c v·ª• l∆∞u tr·ªØ

def load_task_memory():
    """ƒê·ªçc l·ªãch s·ª≠ t√°c v·ª• t·ª´ file"""
    if TASK_MEMORY_FILE.exists():
        try:
            with open(TASK_MEMORY_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('tasks', [])
        except Exception as e:
            print(f"‚ö†Ô∏è [TaskMemory] Error loading: {e}")
    return []

def save_task_memory(tasks: list):
    """L∆∞u l·ªãch s·ª≠ t√°c v·ª• v√†o file"""
    try:
        # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng
        if len(tasks) > MAX_TASK_HISTORY:
            tasks = tasks[-MAX_TASK_HISTORY:]
        
        with open(TASK_MEMORY_FILE, 'w', encoding='utf-8') as f:
            json.dump({
                'tasks': tasks,
                'last_updated': datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"‚ùå [TaskMemory] Error saving: {e}")
        return False

def add_task_to_memory(tool_name: str, params: dict, result: dict, user_request: str = ""):
    """Th√™m t√°c v·ª• v√†o b·ªô nh·ªõ"""
    tasks = load_task_memory()
    
    task_entry = {
        "timestamp": datetime.now().isoformat(),
        "tool": tool_name,
        "params": params,
        "result_success": result.get("success", False),
        "result_message": result.get("message", result.get("error", "")),
        "user_request": user_request
    }
    
    tasks.append(task_entry)
    save_task_memory(tasks)
    return task_entry

def get_recent_tasks(limit: int = 10) -> list:
    """L·∫•y c√°c t√°c v·ª• g·∫ßn ƒë√¢y"""
    tasks = load_task_memory()
    return tasks[-limit:] if tasks else []

def search_task_memory(keyword: str) -> list:
    """T√¨m ki·∫øm t√°c v·ª• theo t·ª´ kh√≥a"""
    tasks = load_task_memory()
    keyword_lower = keyword.lower()
    
    results = []
    for task in tasks:
        # T√¨m trong tool name, params, user_request
        if (keyword_lower in task.get('tool', '').lower() or
            keyword_lower in str(task.get('params', {})).lower() or
            keyword_lower in task.get('user_request', '').lower() or
            keyword_lower in task.get('result_message', '').lower()):
            results.append(task)
    
    return results[-20:]  # Gi·ªõi h·∫°n 20 k·∫øt qu·∫£

def clear_task_memory() -> bool:
    """X√≥a to√†n b·ªô l·ªãch s·ª≠ t√°c v·ª•"""
    try:
        if TASK_MEMORY_FILE.exists():
            TASK_MEMORY_FILE.unlink()
        return True
    except Exception as e:
        print(f"‚ùå [TaskMemory] Error clearing: {e}")
        return False

# Load task memory khi kh·ªüi ƒë·ªông
task_memory_cache = load_task_memory()
print(f"üìù [TaskMemory] Loaded {len(task_memory_cache)} previous tasks")

# ============================================================
# CONVERSATION HISTORY - L∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i TO√ÄN B·ªò
# ============================================================
conversation_history = []  # List ƒë·ªÉ l∆∞u t·∫•t c·∫£ messages
conversation_sessions = {}  # Sessions theo ng√†y

# Th∆∞ m·ª•c l∆∞u h·ªôi tho·∫°i
import os
from pathlib import Path as PathLib
CONVERSATION_BASE_DIR = PathLib(os.path.expanduser("~")) / "AppData" / "Local" / "miniZ_MCP" / "conversations"
CONVERSATION_BASE_DIR.mkdir(parents=True, exist_ok=True)

# File t·ªïng h·ª£p (backward compatible)
CONVERSATION_FILE = CONVERSATION_BASE_DIR / "conversation_history.json"

# File l∆∞u user profile (hi·ªÉu ng∆∞·ªùi d√πng)
USER_PROFILE_FILE = CONVERSATION_BASE_DIR / "user_profile.json"

# NOTE: get_today_conversation_file() ƒë√£ b·ªã x√≥a ƒë·ªÉ t·ªëi ∆∞u - kh√¥ng l∆∞u file theo ng√†y n·ªØa

def load_conversation_history():
    """Load l·ªãch s·ª≠ h·ªôi tho·∫°i t·ª´ file"""
    global conversation_history
    try:
        # Load file t·ªïng h·ª£p (CH·ªà m·ªôt file duy nh·∫•t - nhanh h∆°n)
        if CONVERSATION_FILE.exists():
            with open(CONVERSATION_FILE, 'r', encoding='utf-8') as f:
                conversation_history = json.load(f)
            print(f"üìö [Conversation] Loaded {len(conversation_history)} messages")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not load conversation history: {e}")
        conversation_history = []

def save_conversation_history():
    """L∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i v√†o file (CH·ªà file t·ªïng h·ª£p - t·ªëi ∆∞u t·ªëc ƒë·ªô)"""
    try:
        # CH·ªà l∆∞u file t·ªïng h·ª£p (kh√¥ng l∆∞u file theo ng√†y ƒë·ªÉ tƒÉng t·ªëc)
        with open(CONVERSATION_FILE, 'w', encoding='utf-8') as f:
            json.dump(conversation_history, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"‚ö†Ô∏è Could not save conversation history: {e}")

def add_to_conversation(role: str, content: str, metadata: dict = None):
    """
    Th√™m message v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i - T·ªêI ∆ØU CHO PERFORMANCE
    
    role: 'user', 'assistant', 'system', 'tool'
    content: n·ªôi dung message
    metadata: th√¥ng tin b·ªï sung (tool_name, timestamp, source, etc.)
    
    OPTIMIZATION: Ch·ªâ save sau 20 messages ho·∫∑c khi shutdown
    """
    from datetime import datetime
    
    message = {
        "role": role,
        "content": content,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "metadata": metadata or {}
    }
    
    # Th√™m session_id n·∫øu ch∆∞a c√≥
    if "session_id" not in message["metadata"]:
        message["metadata"]["session_id"] = datetime.now().strftime("%Y%m%d")
    
    conversation_history.append(message)
    
    # TƒÇNG T·ªêC: Ch·ªâ save sau m·ªói 20 messages (gi·∫£m I/O disk)
    if len(conversation_history) % 20 == 0:
        save_conversation_history()
    
    # NOTE: Disabled user profile analysis (g√¢y ch·∫≠m)

def update_user_profile_from_message(content: str, metadata: dict = None):
    """C·∫≠p nh·∫≠t user profile t·ª´ message ƒë·ªÉ hi·ªÉu ng∆∞·ªùi d√πng h∆°n"""
    try:
        from datetime import datetime
        
        profile = load_user_profile()
        
        # ƒê·∫øm s·ªë l·∫ßn t∆∞∆°ng t√°c
        profile["total_interactions"] = profile.get("total_interactions", 0) + 1
        profile["last_interaction"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Ph√¢n t√≠ch topics
        topics = profile.get("topics", {})
        content_lower = content.lower()
        
        # Detect topics t·ª´ n·ªôi dung
        topic_keywords = {
            "music": ["nh·∫°c", "b√†i", "h√°t", "music", "song", "play", "pause", "volume"],
            "weather": ["th·ªùi ti·∫øt", "weather", "m∆∞a", "n·∫Øng", "nhi·ªát ƒë·ªô", "temperature"],
            "news": ["tin", "news", "m·ªõi", "s·ª± ki·ªán", "event"],
            "finance": ["gi√°", "v√†ng", "gold", "btc", "bitcoin", "ch·ª©ng kho√°n", "stock", "usd", "t·ª∑ gi√°"],
            "system": ["√¢m l∆∞·ª£ng", "volume", "m·ªü", "open", "t·∫Øt", "close", "kill"],
            "web": ["t√¨m", "search", "google", "web", "tra c·ª©u"],
            "coding": ["code", "python", "javascript", "l·∫≠p tr√¨nh", "debug", "function"],
            "general": ["l√† g√¨", "what is", "how to", "l√†m sao", "t·∫°i sao", "why"]
        }
        
        for topic, keywords in topic_keywords.items():
            if any(kw in content_lower for kw in keywords):
                topics[topic] = topics.get(topic, 0) + 1
        
        profile["topics"] = topics
        
        # L∆∞u c√°c c√¢u h·ªèi th∆∞·ªùng g·∫∑p (top 20)
        frequent_queries = profile.get("frequent_queries", [])
        # Ch·ªâ l∆∞u c√¢u ng·∫Øn g·ªçn
        if len(content) < 100:
            frequent_queries.append({
                "query": content[:80],
                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
            # Gi·ªØ 20 c√¢u g·∫ßn nh·∫•t
            profile["frequent_queries"] = frequent_queries[-20:]
        
        # Th·ªëng k√™ gi·ªù ho·∫°t ƒë·ªông
        hour_stats = profile.get("active_hours", {})
        current_hour = datetime.now().strftime("%H")
        hour_stats[current_hour] = hour_stats.get(current_hour, 0) + 1
        profile["active_hours"] = hour_stats
        
        save_user_profile(profile)
        
    except Exception as e:
        print(f"‚ö†Ô∏è [UserProfile] Error updating: {e}")

def load_user_profile() -> dict:
    """Load user profile"""
    try:
        if USER_PROFILE_FILE.exists():
            with open(USER_PROFILE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except:
        pass
    return {
        "created": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_interactions": 0,
        "topics": {},
        "frequent_queries": [],
        "active_hours": {},
        "preferences": {}
    }

def save_user_profile(profile: dict):
    """L∆∞u user profile"""
    try:
        with open(USER_PROFILE_FILE, 'w', encoding='utf-8') as f:
            json.dump(profile, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"‚ö†Ô∏è [UserProfile] Error saving: {e}")

def get_conversation_context(max_messages: int = 10) -> str:
    """
    L·∫•y context t·ª´ l·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn ƒë√¢y ƒë·ªÉ hi·ªÉu ng∆∞·ªùi d√πng
    D√πng cho LLM ƒë·ªÉ c√≥ th√™m context
    """
    recent = conversation_history[-max_messages:] if len(conversation_history) > max_messages else conversation_history
    
    context_lines = []
    for msg in recent:
        role = msg.get("role", "unknown")
        content = msg.get("content", "")[:200]  # Gi·ªõi h·∫°n ƒë·ªô d√†i
        if role in ["user", "assistant"]:
            context_lines.append(f"{role.upper()}: {content}")
    
    return "\n".join(context_lines)

def get_user_profile_summary() -> str:
    """T√≥m t·∫Øt profile ng∆∞·ªùi d√πng cho LLM"""
    try:
        profile = load_user_profile()
        
        # Top topics
        topics = profile.get("topics", {})
        sorted_topics = sorted(topics.items(), key=lambda x: x[1], reverse=True)[:5]
        top_topics = ", ".join([f"{t[0]}({t[1]})" for t in sorted_topics]) if sorted_topics else "ch∆∞a x√°c ƒë·ªãnh"
        
        # Active hours
        hours = profile.get("active_hours", {})
        sorted_hours = sorted(hours.items(), key=lambda x: int(x[1]), reverse=True)[:3]
        active_hours = ", ".join([f"{h[0]}h" for h in sorted_hours]) if sorted_hours else "ch∆∞a x√°c ƒë·ªãnh"
        
        summary = f"""
[USER PROFILE]
- T·ªïng s·ªë t∆∞∆°ng t√°c: {profile.get('total_interactions', 0)}
- Ch·ªß ƒë·ªÅ quan t√¢m: {top_topics}
- Gi·ªù ho·∫°t ƒë·ªông: {active_hours}
- L·∫ßn cu·ªëi: {profile.get('last_interaction', 'N/A')}
"""
        return summary.strip()
    except:
        return "[USER PROFILE] Ch∆∞a c√≥ d·ªØ li·ªáu"

def export_conversation_to_file(filename: str = "") -> dict:
    """Export l·ªãch s·ª≠ h·ªôi tho·∫°i ra file ri√™ng"""
    try:
        from datetime import datetime
        import os
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_export_{timestamp}.json"
        
        documents_path = os.path.expanduser("~\\Documents")
        save_folder = os.path.join(documents_path, "miniZ_Conversations")
        os.makedirs(save_folder, exist_ok=True)
        
        file_path = os.path.join(save_folder, filename)
        
        # Export v·ªõi format ƒë·∫πp + user profile
        export_data = {
            "export_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_messages": len(conversation_history),
            "user_profile": load_user_profile(),
            "messages": conversation_history
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        return {
            "success": True,
            "message": f"üìö ƒê√£ export {len(conversation_history)} messages + user profile",
            "path": file_path
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

def list_conversation_files() -> list:
    """Li·ªát k√™ t·∫•t c·∫£ file h·ªôi tho·∫°i ƒë√£ l∆∞u"""
    try:
        files = []
        for f in CONVERSATION_BASE_DIR.glob("conversation_*.json"):
            stat = f.stat()
            files.append({
                "filename": f.name,
                "path": str(f),
                "size_kb": round(stat.st_size / 1024, 2),
                "modified": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S")
            })
        return sorted(files, key=lambda x: x["modified"], reverse=True)
    except Exception as e:
        return []

# Load l·ªãch s·ª≠ khi kh·ªüi ƒë·ªông
load_conversation_history()
print(f"üìÇ [Conversation] Storage: {CONVERSATION_BASE_DIR}")

# ============================================================
# CONVERSATION FORMATTING HELPERS
# ============================================================

def format_tool_request(tool_name: str, args: dict) -> str:
    """Format tool request th√†nh c√¢u d·ªÖ ƒë·ªçc"""
    if tool_name == "set_volume":
        level = args.get("level", 0)
        return f"ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng l√™n {level}%"
    elif tool_name == "get_volume":
        return "Ki·ªÉm tra √¢m l∆∞·ª£ng hi·ªán t·∫°i"
    elif tool_name == "screenshot":
        return "Ch·ª•p m√†n h√¨nh"
    elif tool_name == "open_application":
        app = args.get("app_name", "")
        return f"M·ªü ·ª©ng d·ª•ng {app}"
    elif tool_name == "get_active_media_players":
        return "Ki·ªÉm tra c√°c tr√¨nh duy·ªát v√† media player ƒëang ch·∫°y"
    elif tool_name == "list_running_processes":
        limit = args.get("limit", 10)
        return f"Li·ªát k√™ {limit} ti·∫øn tr√¨nh ƒëang ch·∫°y"
    elif tool_name == "kill_process":
        identifier = args.get("identifier", "")
        force = args.get("force", True)
        return f"{'FORCE ' if force else ''}Kill ti·∫øn tr√¨nh: {identifier}"
    elif tool_name == "force_kill_app":
        app_name = args.get("app_name", "")
        return f"üíÄ FORCE KILL APP: {app_name}"
    # YouTube controls
    elif tool_name == "control_youtube":
        action = args.get("action", "")
        return f"üé¨ YouTube: {action}"
    elif tool_name == "youtube_play_pause":
        return "‚èØÔ∏è YouTube: Play/Pause"
    elif tool_name == "youtube_rewind":
        seconds = args.get("seconds", 10)
        return f"‚è™ YouTube: L√πi {seconds} gi√¢y"
    elif tool_name == "youtube_forward":
        seconds = args.get("seconds", 10)
        return f"‚è© YouTube: Tua t·ªõi {seconds} gi√¢y"
    elif tool_name == "youtube_volume_up":
        return "üîä YouTube: TƒÉng √¢m l∆∞·ª£ng"
    elif tool_name == "youtube_volume_down":
        return "üîâ YouTube: Gi·∫£m √¢m l∆∞·ª£ng"
    elif tool_name == "youtube_mute":
        return "üîá YouTube: B·∫≠t/T·∫Øt ti·∫øng"
    elif tool_name == "youtube_fullscreen":
        return "üì∫ YouTube: Fullscreen"
    # VLC controls
    elif tool_name == "control_vlc":
        action = args.get("action", "")
        return f"üéµ VLC: {action}"
    elif tool_name == "vlc_play_pause":
        return "‚èØÔ∏è VLC: Play/Pause"
    elif tool_name == "vlc_stop":
        return "‚èπÔ∏è VLC: D·ª´ng ph√°t"
    elif tool_name == "vlc_next":
        return "‚è≠Ô∏è VLC: B√†i ti·∫øp theo"
    elif tool_name == "vlc_previous":
        return "‚èÆÔ∏è VLC: B√†i tr∆∞·ªõc"
    elif tool_name == "vlc_volume_up":
        return "üîä VLC: TƒÉng √¢m l∆∞·ª£ng"
    elif tool_name == "vlc_volume_down":
        return "üîâ VLC: Gi·∫£m √¢m l∆∞·ª£ng"
    elif tool_name == "vlc_mute":
        return "üîá VLC: B·∫≠t/T·∫Øt ti·∫øng"
    # WMP controls
    elif tool_name == "control_wmp":
        action = args.get("action", "")
        return f"üé∂ Windows Media Player: {action}"
    elif tool_name.startswith("wmp_"):
        action = tool_name.replace("wmp_", "").replace("_", " ").title()
        return f"üé∂ Windows Media Player: {action}"
    # Smart media control
    elif tool_name == "smart_media_control":
        action = args.get("action", "")
        return f"üéõÔ∏è Smart Media: {action}"
    elif tool_name == "create_file":
        path = args.get("path", "")
        return f"T·∫°o file m·ªõi: {path}"
    elif tool_name == "read_file":
        path = args.get("path", "")
        return f"ƒê·ªçc n·ªôi dung file: {path}"
    elif tool_name == "search_web":
        query = args.get("query", "")
        return f"T√¨m ki·∫øm Google: {query}"
    elif tool_name == "ask_gemini":
        prompt = args.get("prompt", "")[:50]
        return f"H·ªèi Gemini AI: {prompt}..."
    elif tool_name == "ask_gpt4":
        prompt = args.get("prompt", "")[:50]
        return f"H·ªèi GPT-4: {prompt}..."
    else:
        # Default format
        if args:
            args_str = ", ".join([f"{k}={v}" for k, v in list(args.items())[:2]])
            return f"G·ªçi tool {tool_name} ({args_str})"
        return f"G·ªçi tool {tool_name}"

def format_tool_response(tool_name: str, response: dict) -> str:
    """Format tool response th√†nh c√¢u d·ªÖ ƒë·ªçc"""
    if isinstance(response, dict):
        # Ki·ªÉm tra l·ªói
        if response.get("isError"):
            error_text = ""
            if "content" in response and isinstance(response["content"], list):
                for item in response["content"]:
                    if item.get("type") == "text":
                        error_text = item.get("text", "")
                        break
            return f"‚ùå L·ªói: {error_text}"
        
        # Success responses
        if "content" in response and isinstance(response["content"], list):
            for item in response["content"]:
                if item.get("type") == "text":
                    text = item.get("text", "")
                    # R√∫t g·ªçn n·∫øu qu√° d√†i
                    if len(text) > 150:
                        return f"‚úÖ {text[:150]}..."
                    return f"‚úÖ {text}"
        
        # Fallback cho response kh√°c
        if "message" in response:
            return f"‚úÖ {response['message']}"
        
    return "‚úÖ Th·ª±c hi·ªán th√†nh c√¥ng"

print("üöÄ miniZ MCP - Sidebar UI")
print(f"üåê Web: http://localhost:8000")
print(f"üì° MCP: Multi-device ready")

# ============================================================
# TOOL IMPLEMENTATIONS (20 TOOLS)
# ============================================================

async def set_volume(level: int) -> dict:
    """ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng h·ªá th·ªëng - Windows only"""
    try:
        if not 0 <= level <= 100:
            return {"success": False, "error": "Level ph·∫£i t·ª´ 0-100"}
        
        # S·ª≠ d·ª•ng PowerShell tr·ª±c ti·∫øp (t∆∞∆°ng th√≠ch t·ªët h∆°n v·ªõi Python 3.13)
        ps_cmd = f"""
[void] [System.Reflection.Assembly]::LoadWithPartialName("System.Windows.Forms")
$obj = New-Object System.Windows.Forms.Form
$obj.KeyPreview = $True

# Get current volume
$wshShell = New-Object -ComObject WScript.Shell
for($i=1; $i -le 50; $i++){{$wshShell.SendKeys([char]174)}}  # Mute to 0

# Set to desired level
$steps = [Math]::Round({level} / 2)
for($i=1; $i -le $steps; $i++){{$wshShell.SendKeys([char]175)}}  # Volume up

Write-Output "Volume set to {level}%"
"""
        
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=5)
        
        if proc.returncode == 0:
            return {
                "success": True, 
                "level": level,
                "message": f"‚úÖ √Çm l∆∞·ª£ng ƒë√£ ƒë·∫∑t: {level}%"
            }
        else:
            error_msg = stderr.decode('utf-8', errors='ignore').strip()
            return {"success": False, "error": f"PowerShell error: {error_msg[:200]}"}
                
    except asyncio.TimeoutError:
        return {"success": False, "error": "Timeout khi ƒëi·ªÅu ch·ªânh √¢m l∆∞·ª£ng"}
    except Exception as e:
        return {"success": False, "error": f"L·ªói: {str(e)}"}

async def mute_volume() -> dict:
    """T·∫Øt ti·∫øng (mute) h·ªá th·ªëng"""
    try:
        ps_cmd = """
$obj = New-Object -ComObject WScript.Shell
$obj.SendKeys([char]173)
Write-Output "Volume muted"
"""
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        await asyncio.wait_for(proc.communicate(), timeout=3)
        
        return {"success": True, "message": "üîá ƒê√£ t·∫Øt ti·∫øng"}
    except Exception as e:
        return {"success": False, "error": f"L·ªói: {str(e)}"}

async def unmute_volume() -> dict:
    """B·∫≠t l·∫°i ti·∫øng (unmute) h·ªá th·ªëng"""
    try:
        ps_cmd = """
$obj = New-Object -ComObject WScript.Shell
$obj.SendKeys([char]173)
Write-Output "Volume unmuted"
"""
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        await asyncio.wait_for(proc.communicate(), timeout=3)
        
        return {"success": True, "message": "üîä ƒê√£ b·∫≠t ti·∫øng"}
    except Exception as e:
        return {"success": False, "error": f"L·ªói: {str(e)}"}

async def volume_up(steps: int = 5) -> dict:
    """TƒÉng √¢m l∆∞·ª£ng l√™n (m·ªói step ~2%)"""
    try:
        ps_cmd = f"""
$obj = New-Object -ComObject WScript.Shell
for($i=1; $i -le {steps}; $i++){{$obj.SendKeys([char]175)}}
Write-Output "Volume increased by {steps} steps"
"""
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        await asyncio.wait_for(proc.communicate(), timeout=3)
        
        return {"success": True, "message": f"üîä ƒê√£ tƒÉng √¢m l∆∞·ª£ng ({steps} b∆∞·ªõc)"}
    except Exception as e:
        return {"success": False, "error": f"L·ªói: {str(e)}"}

async def volume_down(steps: int = 5) -> dict:
    """Gi·∫£m √¢m l∆∞·ª£ng xu·ªëng (m·ªói step ~2%)"""
    try:
        ps_cmd = f"""
$obj = New-Object -ComObject WScript.Shell
for($i=1; $i -le {steps}; $i++){{$obj.SendKeys([char]174)}}
Write-Output "Volume decreased by {steps} steps"
"""
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        await asyncio.wait_for(proc.communicate(), timeout=3)
        
        return {"success": True, "message": f"üîâ ƒê√£ gi·∫£m √¢m l∆∞·ª£ng ({steps} b∆∞·ªõc)"}
    except Exception as e:
        return {"success": False, "error": f"L·ªói: {str(e)}"}

async def get_volume() -> dict:
    """L·∫•y m·ª©c √¢m l∆∞·ª£ng hi·ªán t·∫°i c·ªßa h·ªá th·ªëng"""
    try:
        try:
            from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
            from comtypes import CLSCTX_ALL
            
            devices = AudioUtilities.GetSpeakers()
            interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
            volume = interface.QueryInterface(IAudioEndpointVolume)
            
            current_volume = int(volume.GetMasterVolumeLevelScalar() * 100)
            is_muted = volume.GetMute()
            
            return {
                "success": True,
                "level": current_volume,
                "muted": bool(is_muted),
                "message": f"üîä √Çm l∆∞·ª£ng hi·ªán t·∫°i: {current_volume}%" + (" (T·∫Øt ti·∫øng)" if is_muted else "")
            }
        except ImportError:
            # Fallback PowerShell
            ps_cmd = """
Add-Type -TypeDefinition @'
using System.Runtime.InteropServices;
[Guid("5CDF2C82-841E-4546-9722-0CF74078229A"), InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
interface IAudioEndpointVolume {
    int NotImpl1(); int NotImpl2();
    int GetMasterVolumeLevelScalar(out float level);
}
[Guid("BCDE0395-E52F-467C-8E3D-C4579291692E")]
class MMDeviceEnumeratorComObject { }
[Guid("A95664D2-9614-4F35-A746-DE8DB63617E6"), InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
interface IMMDeviceEnumerator {
    int NotImpl1();
    int GetDefaultAudioEndpoint(int dataFlow, int role, out IMMDevice device);
}
[Guid("D666063F-1587-4E43-81F1-B948E807363F"), InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
interface IMMDevice {
    int Activate(ref System.Guid id, int clsCtx, int activationParams, out IAudioEndpointVolume aev);
}
'@
$enumerator = [System.Activator]::CreateInstance([Type]::GetTypeFromCLSID([Guid]'BCDE0395-E52F-467C-8E3D-C4579291692E'))
$device = $null
$enumerator.GetDefaultAudioEndpoint(0, 1, [ref]$device)
$aev = $null
$device.Activate([Guid]'5CDF2C82-841E-4546-9722-0CF74078229A', 0, 0, [ref]$aev)
$current = 0.0
$aev.GetMasterVolumeLevelScalar([ref]$current)
Write-Output ([int]($current * 100))
"""
            proc = await asyncio.create_subprocess_exec(
                "powershell", "-NoProfile", "-Command", ps_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=3)
            
            if proc.returncode == 0:
                level = int(stdout.decode('utf-8', errors='ignore').strip())
                return {
                    "success": True,
                    "level": level,
                    "message": f"üîä √Çm l∆∞·ª£ng hi·ªán t·∫°i: {level}%"
                }
            else:
                return {"success": False, "error": "Kh√¥ng th·ªÉ l·∫•y √¢m l∆∞·ª£ng"}
    except Exception as e:
        return {"success": False, "error": f"L·ªói: {str(e)}"}

async def take_screenshot(filename: str = None) -> dict:
    """Ch·ª•p m√†n h√¨nh to√†n b·ªô v√† l∆∞u file
    
    Args:
        filename: T√™n file l∆∞u ·∫£nh (optional). M·∫∑c ƒë·ªãnh: screenshot_YYYYMMDD_HHMMSS.png
    
    Returns:
        dict v·ªõi th√¥ng tin file ƒë√£ l∆∞u
    """
    try:
        import pyautogui
        from datetime import datetime
        import os
        
        # T·∫°o t√™n file m·∫∑c ƒë·ªãnh n·∫øu kh√¥ng c√≥
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"screenshot_{timestamp}.png"
        
        # ƒê·∫£m b·∫£o c√≥ extension .png
        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            filename += '.png'
        
        # L∆∞u v√†o th∆∞ m·ª•c Downloads ho·∫∑c th∆∞ m·ª•c hi·ªán t·∫°i
        downloads_path = Path.home() / "Downloads"
        if downloads_path.exists():
            filepath = downloads_path / filename
        else:
            filepath = Path(filename)
        
        # Ch·ª•p m√†n h√¨nh
        print(f"üì∏ [Screenshot] ƒêang ch·ª•p m√†n h√¨nh...")
        screenshot = pyautogui.screenshot()
        
        # L∆∞u file
        screenshot.save(str(filepath))
        
        file_size = filepath.stat().st_size / 1024  # KB
        
        print(f"‚úÖ [Screenshot] ƒê√£ l∆∞u: {filepath}")
        
        return {
            "success": True,
            "message": f"‚úÖ ƒê√£ ch·ª•p m√†n h√¨nh: {filepath.name}",
            "filepath": str(filepath),
            "filename": filepath.name,
            "size_kb": round(file_size, 2),
            "dimensions": f"{screenshot.width}x{screenshot.height}"
        }
        
    except ImportError:
        return {
            "success": False,
            "error": "Thi·∫øu th∆∞ vi·ªán 'pyautogui'. C√†i ƒë·∫∑t: pip install pyautogui"
        }
    except Exception as e:
        print(f"‚ùå [Screenshot] Error: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def show_notification(title: str, message: str) -> dict:
    try:
        ps_cmd = f'''[Windows.UI.Notifications.ToastNotificationManager, Windows.UI.Notifications, ContentType = WindowsRuntime] | Out-Null; [Windows.Data.Xml.Dom.XmlDocument, Windows.Data.Xml.Dom.XmlDocument, ContentType = WindowsRuntime] | Out-Null; $template = @"<toast><visual><binding template="ToastText02"><text id="1">{title}</text><text id="2">{message}</text></binding></visual></toast>"@; $xml = New-Object Windows.Data.Xml.Dom.XmlDocument; $xml.LoadXml($template); $toast = New-Object Windows.UI.Notifications.ToastNotification $xml; [Windows.UI.Notifications.ToastNotificationManager]::CreateToastNotifier("Xiaozhi").Show($toast)'''
        proc = await asyncio.create_subprocess_exec("powershell", "-Command", ps_cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        await asyncio.wait_for(proc.wait(), timeout=5)
        return {"success": True, "title": title, "message": message}
    except Exception as e:
        return {"success": False, "error": str(e)}

# Cache cho system resources
_resource_cache = None
_resource_cache_time = 0
RESOURCE_CACHE_DURATION = 2  # Cache 2 gi√¢y

async def get_system_resources() -> dict:
    """L·∫•y th√¥ng tin t√†i nguy√™n h·ªá th·ªëng v·ªõi caching"""
    global _resource_cache, _resource_cache_time
    
    try:
        # Ki·ªÉm tra cache
        now = time.time()
        if _resource_cache and (now - _resource_cache_time) < RESOURCE_CACHE_DURATION:
            return _resource_cache
        
        # L·∫•y d·ªØ li·ªáu m·ªõi - gi·∫£m interval t·ª´ 1s xu·ªëng 0.1s
        cpu = psutil.cpu_percent(interval=0.1)
        mem = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        result = {
            "success": True, 
            "data": {
                "cpu_percent": cpu, 
                "memory_percent": mem.percent, 
                "memory_used_gb": round(mem.used / (1024**3), 2), 
                "memory_total_gb": round(mem.total / (1024**3), 2), 
                "disk_percent": disk.percent, 
                "disk_used_gb": round(disk.used / (1024**3), 2), 
                "disk_total_gb": round(disk.total / (1024**3), 2)
            }
        }
        
        # C·∫≠p nh·∫≠t cache
        _resource_cache = result
        _resource_cache_time = now
        
        return result
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_api_quotas() -> dict:
    """L·∫•y th√¥ng tin quota API (Gemini v√† Serper) - NOTE: ƒê√¢y l√† gi√° tr·ªã ∆∞·ªõc t√≠nh"""
    try:
        result = {
            "success": True,
            "gemini": {
                "has_key": bool(GEMINI_API_KEY and GEMINI_API_KEY.strip()),
                "free_tier": "60 requests/min",
                "daily_limit": "1,500 requests/day",
                "note": "Free tier - ch∆∞a c√≥ API ƒë·ªÉ check exact quota"
            },
            "serper": {
                "has_key": bool(SERPER_API_KEY and SERPER_API_KEY.strip()),
                "free_tier": "2,500 queries/month",
                "note": "Free tier - ch∆∞a c√≥ API ƒë·ªÉ check exact remaining"
            }
        }
        return result
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_current_time() -> dict:
    try:
        now = datetime.now()
        return {"success": True, "datetime": now.strftime("%Y-%m-%d %H:%M:%S"), "date": now.strftime("%Y-%m-%d"), "time": now.strftime("%H:%M:%S"), "day_of_week": now.strftime("%A"), "timestamp": int(now.timestamp())}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def calculator(expression: str) -> dict:
    try:
        allowed = set("0123456789+-*/()., ")
        if not all(c in allowed for c in expression):
            return {"success": False, "error": "K√Ω t·ª± kh√¥ng h·ª£p l·ªá"}
        result = eval(expression, {"__builtins__": {}}, {})
        return {"success": True, "expression": expression, "result": result}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_network_info() -> dict:
    """
    Qu√©t m·∫°ng to√†n di·ªán nh∆∞ Angry IP Scanner:
    - Th√¥ng tin m√°y local (hostname, IP, MAC, gateway, subnet)
    - Ping sweep to√†n b·ªô subnet ƒë·ªÉ t√¨m thi·∫øt b·ªã online
    - ARP scan ƒë·ªÉ l·∫•y MAC address
    - Resolve hostname cho t·ª´ng IP
    - Multi-threaded ƒë·ªÉ scan nhanh
    """
    try:
        import socket
        import subprocess
        import re
        import ipaddress
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import platform
        
        print("üîç [Network Scan] B·∫Øt ƒë·∫ßu qu√©t m·∫°ng...")
        
        # 1. L·∫•y th√¥ng tin m√°y local
        hostname = socket.gethostname()
        local_ip = socket.gethostbyname(hostname)
        print(f"üìç [Network Scan] Local IP: {local_ip}")
        
        # 2. L·∫•y MAC address, Gateway v√† Subnet Mask
        def get_network_config():
            try:
                result = subprocess.check_output("ipconfig /all", shell=True, text=True, encoding='utf-8', errors='ignore')
                
                # T√¨m gateway
                gateway_match = re.search(r'Default Gateway[.\s:]+([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)', result)
                gateway = gateway_match.group(1) if gateway_match else "Unknown"
                
                # T√¨m subnet mask
                subnet_match = re.search(r'Subnet Mask[.\s:]+([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)', result)
                subnet_mask = subnet_match.group(1) if subnet_match else "255.255.255.0"
                
                # T√¨m MAC address c·ªßa adapter ƒëang k·∫øt n·ªëi
                mac_address = "Unknown"
                lines = result.split('\n')
                active_adapter = False
                for i, line in enumerate(lines):
                    if local_ip in line:
                        active_adapter = True
                    if active_adapter and 'Physical Address' in line:
                        mac_match = re.search(r'([0-9A-F]{2}[:-]){5}([0-9A-F]{2})', line, re.IGNORECASE)
                        if mac_match:
                            mac_address = mac_match.group(0)
                            break
                
                return mac_address, gateway, subnet_mask
            except:
                return "Unknown", "Unknown", "255.255.255.0"
        
        mac_address, gateway, subnet_mask = get_network_config()
        print(f"üö™ [Network Scan] Gateway: {gateway}, Subnet: {subnet_mask}")
        
        # 3. T√≠nh to√°n d·∫£i IP c·∫ßn scan
        def get_ip_range(ip, mask):
            try:
                network = ipaddress.IPv4Network(f"{ip}/{mask}", strict=False)
                # Gi·ªõi h·∫°n scan t·ªëi ƒëa 254 IP (1 subnet /24)
                hosts = list(network.hosts())
                if len(hosts) > 254:
                    # Ch·ªâ scan subnet /24 c·ªßa IP hi·ªán t·∫°i
                    base = '.'.join(ip.split('.')[:3])
                    return [f"{base}.{i}" for i in range(1, 255)]
                return [str(host) for host in hosts]
            except:
                base = '.'.join(ip.split('.')[:3])
                return [f"{base}.{i}" for i in range(1, 255)]
        
        ip_range = get_ip_range(local_ip, subnet_mask)
        print(f"üìä [Network Scan] Qu√©t {len(ip_range)} ƒë·ªãa ch·ªâ IP...")
        
        # 4. Ping m·ªôt IP ƒë·ªÉ ki·ªÉm tra online (fast)
        def ping_host(ip):
            try:
                # Windows ping v·ªõi timeout 100ms, 1 packet
                param = '-n 1 -w 100'
                result = subprocess.run(
                    f'ping {param} {ip}',
                    shell=True,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    timeout=1
                )
                return result.returncode == 0
            except:
                return False
        
        # 5. L·∫•y MAC t·ª´ ARP cache
        def get_arp_cache():
            mac_map = {}
            try:
                arp_result = subprocess.check_output("arp -a", shell=True, text=True, encoding='utf-8', errors='ignore')
                for line in arp_result.split('\n'):
                    # Parse: 192.168.1.1     00-11-22-33-44-55     dynamic
                    match = re.search(r'([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)\s+([0-9a-fA-F]{2}[:-][0-9a-fA-F]{2}[:-][0-9a-fA-F]{2}[:-][0-9a-fA-F]{2}[:-][0-9a-fA-F]{2}[:-][0-9a-fA-F]{2})', line)
                    if match:
                        ip = match.group(1)
                        mac = match.group(2).upper().replace(':', '-')
                        # B·ªè qua broadcast/multicast MAC
                        if not mac.startswith('FF-FF') and not mac.startswith('01-00'):
                            mac_map[ip] = mac
            except:
                pass
            return mac_map
        
        # 6. Resolve hostname
        def resolve_hostname(ip):
            try:
                return socket.gethostbyaddr(ip)[0]
            except:
                return ""
        
        # 7. Scan m·ªôt IP ho√†n ch·ªânh
        def scan_ip(ip):
            if ping_host(ip):
                return ip
            return None
        
        # 8. Th·ª±c hi·ªán ping sweep v·ªõi multi-threading
        online_ips = []
        print("üèì [Network Scan] ƒêang ping sweep...")
        
        with ThreadPoolExecutor(max_workers=50) as executor:
            futures = {executor.submit(scan_ip, ip): ip for ip in ip_range}
            for future in as_completed(futures, timeout=30):
                try:
                    result = future.result(timeout=1)
                    if result:
                        online_ips.append(result)
                except:
                    pass
        
        print(f"‚úÖ [Network Scan] T√¨m th·∫•y {len(online_ips)} IP online")
        
        # 9. Refresh ARP cache b·∫±ng c√°ch ping c√°c IP ch∆∞a c√≥ trong cache
        arp_cache = get_arp_cache()
        
        # 10. Thu th·∫≠p th√¥ng tin chi ti·∫øt cho t·ª´ng IP online
        devices = []
        for ip in sorted(online_ips, key=lambda x: [int(p) for p in x.split('.')]):
            mac = arp_cache.get(ip, "Unknown")
            hostname_resolved = resolve_hostname(ip)
            
            # X√°c ƒë·ªãnh vendor t·ª´ MAC (3 bytes ƒë·∫ßu)
            vendor = ""
            if mac != "Unknown":
                # C√≥ th·ªÉ th√™m OUI lookup sau
                pass
            
            device = {
                "ip": ip,
                "mac": mac,
                "hostname": hostname_resolved if hostname_resolved else "Unknown",
                "is_local": ip == local_ip,
                "is_gateway": ip == gateway,
                "status": "online"
            }
            devices.append(device)
        
        # 11. ƒê·∫£m b·∫£o local device v√† gateway lu√¥n c√≥ trong danh s√°ch
        local_in_list = any(d['ip'] == local_ip for d in devices)
        if not local_in_list:
            devices.insert(0, {
                "ip": local_ip,
                "mac": mac_address,
                "hostname": hostname,
                "is_local": True,
                "is_gateway": False,
                "status": "online"
            })
        
        # S·∫Øp x·∫øp: local first, then gateway, then others
        devices.sort(key=lambda x: (not x.get('is_local', False), not x.get('is_gateway', False), x['ip']))
        
        print(f"üì± [Network Scan] T·ªïng c·ªông {len(devices)} thi·∫øt b·ªã")
        
        # 12. T·ªïng h·ª£p k·∫øt qu·∫£
        result = {
            "success": True,
            "local_device": {
                "hostname": hostname,
                "ip": local_ip,
                "mac": mac_address,
                "gateway": gateway,
                "subnet_mask": subnet_mask
            },
            "network_devices": devices,
            "total_devices": len(devices),
            "scanned_range": f"{ip_range[0]} - {ip_range[-1]}" if ip_range else "Unknown",
            "message": f"T√¨m th·∫•y {len(devices)} thi·∫øt b·ªã trong m·∫°ng (qu√©t {len(ip_range)} IP)"
        }
        
        return result
        
    except Exception as e:
        import traceback
        print(f"‚ùå [Network Scan] Error: {e}")
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def search_web(query: str) -> dict:
    try:
        import webbrowser
        url = f"https://www.google.com/search?q={query.replace(' ', '+')}"
        webbrowser.open(url)
        return {"success": True, "message": f"ƒê√£ m·ªü t√¨m ki·∫øm: {query}", "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_brightness(level: int) -> dict:
    try:
        import screen_brightness_control as sbc
        sbc.set_brightness(level)
        return {"success": True, "level": level, "message": f"ƒê√£ ƒë·∫∑t ƒë·ªô s√°ng: {level}%"}
    except Exception as e:
        return {"success": False, "error": str(e), "note": "C√≥ th·ªÉ c·∫ßn c√†i: pip install screen-brightness-control"}

async def get_clipboard() -> dict:
    try:
        import pyperclip
        content = pyperclip.paste()
        return {"success": True, "content": content}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_clipboard(text: str) -> dict:
    try:
        import pyperclip
        pyperclip.copy(text)
        return {"success": True, "message": f"ƒê√£ copy v√†o clipboard: {text[:50]}..."}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def play_sound(frequency: int = 1000, duration: int = 500) -> dict:
    try:
        import winsound
        winsound.Beep(frequency, duration)
        return {"success": True, "message": f"ƒê√£ ph√°t √¢m thanh {frequency}Hz trong {duration}ms"}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# üîî NOTIFICATION SOUNDS - √Çm thanh th√¥ng b√°o
# ============================================================
def play_notification_sound(sound_type: str = "success"):
    """
    Ph√°t √¢m thanh th√¥ng b√°o kh√¥ng blocking (ch·∫°y trong thread ri√™ng)
    
    Args:
        sound_type: Lo·∫°i √¢m thanh
            - "wake" / "startup": √Çm thanh ƒë√°nh th·ª©c/kh·ªüi ƒë·ªông (3 ti·∫øng beep l√™n)
            - "success": √Çm thanh th√†nh c√¥ng (2 ti·∫øng beep ng·∫Øn)
            - "error": √Çm thanh l·ªói (1 ti·∫øng beep d√†i tr·∫ßm)
            - "notify": √Çm thanh th√¥ng b√°o (1 ti·∫øng beep)
    """
    import threading
    
    def _play_sound():
        try:
            import winsound
            
            if sound_type in ["wake", "startup"]:
                # √Çm thanh ƒë√°nh th·ª©c: 3 n·ªët l√™n (C-E-G chord)
                winsound.Beep(523, 150)   # C5
                winsound.Beep(659, 150)   # E5
                winsound.Beep(784, 200)   # G5
                
            elif sound_type == "success":
                # √Çm thanh th√†nh c√¥ng: 2 ti·∫øng beep nhanh
                winsound.Beep(880, 100)   # A5
                winsound.Beep(1047, 150)  # C6
                
            elif sound_type == "error":
                # √Çm thanh l·ªói: 1 ti·∫øng beep tr·∫ßm d√†i
                winsound.Beep(300, 400)
                
            elif sound_type == "notify":
                # √Çm thanh th√¥ng b√°o ƒë∆°n gi·∫£n
                winsound.Beep(600, 150)
                
            else:
                # Default: gi·ªëng success
                winsound.Beep(880, 100)
                winsound.Beep(1047, 150)
                
        except Exception as e:
            print(f"‚ö†Ô∏è [Sound] Kh√¥ng th·ªÉ ph√°t √¢m thanh: {e}")
    
    # Ch·∫°y trong thread ri√™ng ƒë·ªÉ kh√¥ng block main thread
    threading.Thread(target=_play_sound, daemon=True).start()

def play_wake_sound():
    """Ph√°t √¢m thanh ƒë√°nh th·ª©c khi server kh·ªüi ƒë·ªông"""
    play_notification_sound("wake")

def play_success_sound():
    """Ph√°t √¢m thanh khi h√†nh ƒë·ªông th√†nh c√¥ng"""
    play_notification_sound("success")

def play_error_sound():
    """Ph√°t √¢m thanh khi c√≥ l·ªói"""
    play_notification_sound("error")

async def open_application(app_name: str) -> dict:
    """
    M·ªü ·ª©ng d·ª•ng Windows v·ªõi kh·∫£ nƒÉng t√¨m ki·∫øm th√¥ng minh.
    
    Th·ª© t·ª± t√¨m ki·∫øm:
    1. Dictionary mapping (∆∞u ti√™n cao nh·∫•t)
    2. T√¨m trong PATH
    3. T√¨m trong Registry (App Paths)
    4. T√¨m trong Program Files
    5. Fallback: Windows Start Menu
    
    Args:
        app_name: T√™n ·ª©ng d·ª•ng (v√≠ d·ª•: "chrome", "photoshop", "word")
        
    Returns:
        dict: {"success": bool, "message": str, "path": str (optional)}
    """
    try:
        import os
        import shutil
        import winreg
        import glob
        
        # Dictionary mapping - H·ªó tr·ª£ 50+ ·ª©ng d·ª•ng ph·ªï bi·∫øn
        apps = {
            # Windows Built-in
            "notepad": "notepad.exe",
            "note": "notepad.exe",
            "m√°y ghi ch√∫": "notepad.exe",
            "calc": "calc.exe",
            "calculator": "calc.exe",
            "m√°y t√≠nh": "calc.exe",
            "paint": "mspaint.exe",
            "v·∫Ω": "mspaint.exe",
            "cmd": "cmd.exe",
            "command prompt": "cmd.exe",
            "powershell": "powershell.exe",
            "ps": "powershell.exe",
            "explorer": "explorer.exe",
            "file explorer": "explorer.exe",
            "taskmgr": "taskmgr.exe",
            "task manager": "taskmgr.exe",
            "qu·∫£n l√Ω t√°c v·ª•": "taskmgr.exe",
            
            # Browsers
            "chrome": "chrome.exe",
            "google chrome": "chrome.exe",
            "gc": "chrome.exe",
            "firefox": "firefox.exe",
            "ff": "firefox.exe",
            "edge": "msedge.exe",
            "microsoft edge": "msedge.exe",
            "brave": "brave.exe",
            "opera": "opera.exe",
            
            # Microsoft Office
            "word": "WINWORD.EXE",
            "microsoft word": "WINWORD.EXE",
            "excel": "EXCEL.EXE",
            "microsoft excel": "EXCEL.EXE",
            "powerpoint": "POWERPNT.EXE",
            "microsoft powerpoint": "POWERPNT.EXE",
            "ppt": "POWERPNT.EXE",
            "outlook": "OUTLOOK.EXE",
            "microsoft outlook": "OUTLOOK.EXE",
            "onenote": "ONENOTE.EXE",
            "teams": "Teams.exe",
            "microsoft teams": "Teams.exe",
            
            # Adobe Creative Cloud
            "photoshop": "Photoshop.exe",
            "adobe photoshop": "Photoshop.exe",
            "ps": "Photoshop.exe",
            "illustrator": "Illustrator.exe",
            "adobe illustrator": "Illustrator.exe",
            "ai": "Illustrator.exe",
            "premiere": "Adobe Premiere Pro.exe",
            "premiere pro": "Adobe Premiere Pro.exe",
            "after effects": "AfterFX.exe",
            "ae": "AfterFX.exe",
            "lightroom": "Lightroom.exe",
            "acrobat": "Acrobat.exe",
            "adobe acrobat": "Acrobat.exe",
            
            # Development Tools
            "vscode": "Code.exe",
            "visual studio code": "Code.exe",
            "code": "Code.exe",
            "vs": "Code.exe",
            "sublime": "sublime_text.exe",
            "sublime text": "sublime_text.exe",
            "atom": "atom.exe",
            "notepad++": "notepad++.exe",
            "npp": "notepad++.exe",
            "pycharm": "pycharm64.exe",
            "intellij": "idea64.exe",
            "webstorm": "webstorm64.exe",
            "androidstudio": "studio64.exe",
            "android studio": "studio64.exe",
            
            # 3D & Design
            "blender": "blender.exe",
            "3ds max": "3dsmax.exe",
            "maya": "maya.exe",
            "sketchup": "SketchUp.exe",
            "fusion360": "Fusion360.exe",
            "fusion 360": "Fusion360.exe",
            "autocad": "acad.exe",
            "solidworks": "SLDWORKS.exe",
            
            # Communication
            "discord": "Discord.exe",
            "slack": "slack.exe",
            "zoom": "Zoom.exe",
            "skype": "Skype.exe",
            "telegram": "Telegram.exe",
            "zalo": "Zalo.exe",
            
            # Media Players
            "vlc": "vlc.exe",
            "spotify": "Spotify.exe",
            "itunes": "iTunes.exe",
            "windows media player": "wmplayer.exe",
            "wmp": "wmplayer.exe",
            
            # Other Popular Apps
            "steam": "steam.exe",
            "epic games": "EpicGamesLauncher.exe",
            "epic": "EpicGamesLauncher.exe",
            "obs": "obs64.exe",
            "obs studio": "obs64.exe",
            "gimp": "gimp-2.10.exe",
            "audacity": "audacity.exe",
            "7zip": "7zFM.exe",
            "7-zip": "7zFM.exe",
            "winrar": "WinRAR.exe",
        }
        
        # 1. Ki·ªÉm tra trong dictionary
        app_name_lower = app_name.lower().strip()
        exe_name = apps.get(app_name_lower)
        
        print(f"üîç [Open App] T√¨m ki·∫øm: '{app_name}' ‚Üí {exe_name or 'kh√¥ng c√≥ trong dictionary'}")
        
        # N·∫øu kh√¥ng c√≥ trong dictionary, th·ª≠ d√πng t√™n g·ªëc
        if not exe_name:
            # Ki·ªÉm tra n·∫øu ƒë√£ c√≥ .exe
            if app_name.lower().endswith('.exe'):
                exe_name = app_name
            else:
                exe_name = app_name + '.exe'
        
        # 2. T√¨m trong PATH
        exe_path = shutil.which(exe_name)
        if exe_path:
            print(f"‚úÖ [Open App] T√¨m th·∫•y trong PATH: {exe_path}")
            subprocess.Popen([exe_path])
            return {"success": True, "message": f"‚úÖ ƒê√£ m·ªü {app_name}", "path": exe_path}
        
        # 3. T√¨m trong Windows Registry (App Paths)
        try:
            with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, 
                              rf"SOFTWARE\Microsoft\Windows\CurrentVersion\App Paths\{exe_name}") as key:
                exe_path = winreg.QueryValue(key, None)
                if exe_path and os.path.exists(exe_path):
                    print(f"‚úÖ [Open App] T√¨m th·∫•y trong Registry: {exe_path}")
                    subprocess.Popen([exe_path])
                    return {"success": True, "message": f"‚úÖ ƒê√£ m·ªü {app_name}", "path": exe_path}
        except WindowsError:
            pass
        
        # 4. T√¨m trong c√°c th∆∞ m·ª•c ph·ªï bi·∫øn
        common_paths = [
            os.path.join(os.environ.get("PROGRAMFILES", "C:\\Program Files"), "*", exe_name),
            os.path.join(os.environ.get("PROGRAMFILES(X86)", "C:\\Program Files (x86)"), "*", exe_name),
            os.path.join(os.environ.get("LOCALAPPDATA", ""), "Programs", "*", exe_name),
            os.path.join(os.environ.get("APPDATA", ""), "*", exe_name),
        ]
        
        import glob
        for pattern in common_paths:
            matches = glob.glob(pattern, recursive=False)
            if matches:
                exe_path = matches[0]
                print(f"‚úÖ [Open App] T√¨m th·∫•y trong: {exe_path}")
                subprocess.Popen([exe_path])
                return {"success": True, "message": f"‚úÖ ƒê√£ m·ªü {app_name}", "path": exe_path}
        
        # 5. T√¨m ki·∫øm s√¢u trong Program Files (ch·∫≠m h∆°n, d√πng l√†m fallback)
        if "photoshop" in app_name_lower or "adobe" in app_name_lower:
            # Adobe apps th∆∞·ªùng ·ªü C:\Program Files\Adobe
            adobe_base = r"C:\Program Files\Adobe"
            if os.path.exists(adobe_base):
                for root, dirs, files in os.walk(adobe_base):
                    if exe_name in files:
                        exe_path = os.path.join(root, exe_name)
                        print(f"‚úÖ [Open App] T√¨m th·∫•y Adobe app: {exe_path}")
                        subprocess.Popen([exe_path])
                        return {"success": True, "message": f"‚úÖ ƒê√£ m·ªü {app_name}", "path": exe_path}
        
        if "autodesk" in app_name_lower or "fusion" in app_name_lower:
            # Autodesk apps th∆∞·ªùng ·ªü LOCALAPPDATA
            autodesk_base = os.path.join(os.environ.get("LOCALAPPDATA", ""), "Autodesk")
            if os.path.exists(autodesk_base):
                for root, dirs, files in os.walk(autodesk_base):
                    if exe_name in files:
                        exe_path = os.path.join(root, exe_name)
                        print(f"‚úÖ [Open App] T√¨m th·∫•y Autodesk app: {exe_path}")
                        subprocess.Popen([exe_path])
                        return {"success": True, "message": f"‚úÖ ƒê√£ m·ªü {app_name}", "path": exe_path}
        
        # 6. Fallback cu·ªëi c√πng: D√πng Windows Start Menu
        print(f"‚ö†Ô∏è [Open App] Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng d·∫´n, th·ª≠ Windows Start Menu...")
        subprocess.Popen(["start", "", app_name], shell=True)
        return {
            "success": True, 
            "message": f"‚úÖ ƒê√£ g·ª≠i l·ªánh m·ªü {app_name} (Windows s·∫Ω t√¨m trong Start Menu)",
            "note": "N·∫øu kh√¥ng m·ªü ƒë∆∞·ª£c, h√£y ki·ªÉm tra t√™n ·ª©ng d·ª•ng ho·∫∑c th√™m v√†o dictionary"
        }
        
    except Exception as e:
        print(f"‚ùå [Open App] L·ªói: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": f"L·ªói khi m·ªü {app_name}: {str(e)}"}

# ==================== MEDIA PLAYER CONTROL ====================

# Helper function ƒë·ªÉ t√¨m t·∫•t c·∫£ c√°c c·ª≠a s·ªï media player v√† browser
def _find_all_media_windows():
    """T√¨m t·∫•t c·∫£ c·ª≠a s·ªï media player v√† browser ƒëang ch·∫°y"""
    import ctypes
    
    windows = {
        'youtube': [],      # C√°c tab YouTube
        'spotify_web': [],  # Spotify web
        'wmplayer': None,   # Windows Media Player
        'vlc': None,        # VLC Player
        'spotify_app': None,# Spotify Desktop
        'browsers': []      # C√°c browser kh√°c
    }
    
    browser_names = ['chrome', 'firefox', 'edge', 'opera', 'brave', 'coccoc', 'c·ªëc c·ªëc']
    
    def enum_callback(hwnd, _):
        if ctypes.windll.user32.IsWindowVisible(hwnd):
            length = ctypes.windll.user32.GetWindowTextLengthW(hwnd)
            if length > 0:
                buff = ctypes.create_unicode_buffer(length + 1)
                ctypes.windll.user32.GetWindowTextW(hwnd, buff, length + 1)
                title = buff.value
                title_lower = title.lower()
                
                # YouTube c√≥ ∆∞u ti√™n cao nh·∫•t
                if 'youtube' in title_lower:
                    windows['youtube'].append({'hwnd': hwnd, 'title': title})
                # Spotify Web
                elif 'spotify' in title_lower and any(b in title_lower for b in browser_names):
                    windows['spotify_web'].append({'hwnd': hwnd, 'title': title})
                # Windows Media Player
                elif 'windows media player' in title_lower or 'wmplayer' in title_lower:
                    windows['wmplayer'] = {'hwnd': hwnd, 'title': title}
                # VLC
                elif 'vlc' in title_lower and 'media player' in title_lower:
                    windows['vlc'] = {'hwnd': hwnd, 'title': title}
                # Spotify Desktop App
                elif 'spotify' in title_lower and not any(b in title_lower for b in browser_names):
                    windows['spotify_app'] = {'hwnd': hwnd, 'title': title}
                # C√°c browser kh√°c
                elif any(b in title_lower for b in browser_names):
                    windows['browsers'].append({'hwnd': hwnd, 'title': title})
        return True
    
    WNDENUMPROC = ctypes.WINFUNCTYPE(ctypes.c_bool, ctypes.c_int, ctypes.POINTER(ctypes.c_int))
    ctypes.windll.user32.EnumWindows(WNDENUMPROC(enum_callback), 0)
    
    return windows

def _focus_and_send_key(hwnd, key, delay=0.15):
    """Focus v√†o c·ª≠a s·ªï v√† g·ª≠i ph√≠m"""
    import ctypes
    ctypes.windll.user32.SetForegroundWindow(hwnd)
    time.sleep(delay)
    pyautogui.press(key)

def _focus_and_send_hotkey(hwnd, *keys, delay=0.15):
    """Focus v√†o c·ª≠a s·ªï v√† g·ª≠i t·ªï h·ª£p ph√≠m"""
    import ctypes
    ctypes.windll.user32.SetForegroundWindow(hwnd)
    time.sleep(delay)
    pyautogui.hotkey(*keys)

async def media_play_pause() -> dict:
    """
    Ph√°t/T·∫°m d·ª´ng media (Play/Pause toggle).
    ‚≠ê ∆ØU TI√äN PYTHON-VLC TR∆Ø·ªöC - nhanh & kh√¥ng c·∫ßn detect window!
    
    ∆Øu ti√™n:
    1. Python-VLC n·ªôi b·ªô (NHANH NH·∫§T)
    2. YouTube (Browser) - Focus v√† nh·∫•n K
    3. Windows Media Player
    4. Spotify
    5. Fallback - Media key
    """
    try:
        # üéµ ∆ØU TI√äN 1: Python-VLC n·ªôi b·ªô - NHANH NH·∫§T!
        if vlc_player and vlc_player._player:
            vlc_player.pause()
            is_playing = vlc_player.is_playing()
            status = vlc_player.get_full_status()
            current_song = status.get('current_song', 'Unknown')
            return {
                "success": True, 
                "message": f"{'‚ñ∂Ô∏è ƒêang ph√°t' if is_playing else '‚è∏Ô∏è ƒê√£ t·∫°m d·ª´ng'}: {current_song} (Python-VLC)",
                "is_playing": is_playing,
                "player": "Python-VLC",
                "llm_note": "üéµ ƒêang d√πng Python-VLC Player t√≠ch h·ª£p. C√≥ th·ªÉ d√πng: pause_music(), resume_music(), stop_music(), music_next(), music_previous(), seek_music(), music_volume()"
            }
        
        windows = _find_all_media_windows()
        
        # 2. YouTube - n·∫øu c√≥
        if windows['youtube']:
            yt = windows['youtube'][0]
            _focus_and_send_key(yt['hwnd'], 'k')
            return {"success": True, "message": f"‚úÖ Play/Pause YouTube: {yt['title'][:50]}..."}
        
        # 3. Windows Media Player
        if windows['wmplayer']:
            _focus_and_send_key(windows['wmplayer']['hwnd'], 'space')
            return {"success": True, "message": "‚úÖ Play/Pause (Windows Media Player)"}
        
        # 4. VLC Window (external)
        if windows['vlc']:
            _focus_and_send_key(windows['vlc']['hwnd'], 'space')
            return {"success": True, "message": "‚úÖ Play/Pause (VLC Window)"}
        
        # 5. Spotify Desktop App
        if windows['spotify_app']:
            _focus_and_send_key(windows['spotify_app']['hwnd'], 'space')
            return {"success": True, "message": "‚úÖ Play/Pause (Spotify Desktop)"}
        
        # 6. Spotify Web
        if windows['spotify_web']:
            sw = windows['spotify_web'][0]
            _focus_and_send_key(sw['hwnd'], 'space')
            return {"success": True, "message": f"‚úÖ Play/Pause Spotify Web"}
        
        # 7. Fallback - d√πng media key
        pyautogui.press('playpause')
        return {"success": True, "message": "‚úÖ ƒê√£ g·ª≠i l·ªánh Play/Pause (Media Key)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_next_track() -> dict:
    """
    Chuy·ªÉn b√†i ti·∫øp theo (Next Track).
    ‚≠ê ∆ØU TI√äN PYTHON-VLC TR∆Ø·ªöC - nhanh & kh√¥ng c·∫ßn detect window!
    """
    try:
        # üéµ ∆ØU TI√äN 1: Python-VLC n·ªôi b·ªô - NHANH NH·∫§T!
        if vlc_player and vlc_player._player:
            success = vlc_player.next_track()
            if success:
                import time
                time.sleep(0.3)  # ƒê·ª£i VLC chuy·ªÉn b√†i
                status = vlc_player.get_full_status()
                current_song = status.get('current_song', 'Unknown')
                return {
                    "success": True, 
                    "message": f"‚è≠Ô∏è ƒê√£ chuy·ªÉn: {current_song} (Python-VLC)",
                    "player": "Python-VLC",
                    "current_song": current_song,
                    "llm_note": "üéµ ƒêang d√πng Python-VLC Player. Playlist c√≥ th·ªÉ ƒëi·ªÅu khi·ªÉn b·∫±ng music_next(), music_previous()"
                }
            return {"success": False, "error": "Kh√¥ng c√≥ b√†i ti·∫øp theo trong playlist VLC"}
        
        windows = _find_all_media_windows()
        
        # 2. YouTube
        if windows['youtube']:
            yt = windows['youtube'][0]
            _focus_and_send_hotkey(yt['hwnd'], 'shift', 'n')
            return {"success": True, "message": f"‚úÖ Chuy·ªÉn video ti·∫øp theo (YouTube): {yt['title'][:40]}..."}
        
        # 3. Windows Media Player
        if windows['wmplayer']:
            _focus_and_send_hotkey(windows['wmplayer']['hwnd'], 'ctrl', 'f')
            return {"success": True, "message": "‚úÖ Chuy·ªÉn b√†i ti·∫øp theo (Windows Media Player)"}
        
        # 4. VLC Window (external)
        if windows['vlc']:
            _focus_and_send_key(windows['vlc']['hwnd'], 'n')
            return {"success": True, "message": "‚úÖ Chuy·ªÉn b√†i ti·∫øp theo (VLC Window)"}
        
        # 5. Spotify Desktop App
        if windows['spotify_app']:
            _focus_and_send_hotkey(windows['spotify_app']['hwnd'], 'ctrl', 'right')
            return {"success": True, "message": "‚úÖ Chuy·ªÉn b√†i ti·∫øp theo (Spotify Desktop)"}
        
        # 6. Spotify Web
        if windows['spotify_web']:
            sw = windows['spotify_web'][0]
            _focus_and_send_hotkey(sw['hwnd'], 'ctrl', 'right')
            return {"success": True, "message": "‚úÖ Chuy·ªÉn b√†i ti·∫øp theo (Spotify Web)"}
        
        # 7. Fallback - d√πng media key
        pyautogui.press('nexttrack')
        return {"success": True, "message": "‚úÖ ƒê√£ chuy·ªÉn b√†i ti·∫øp theo (Media Key)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_previous_track() -> dict:
    """
    Chuy·ªÉn b√†i tr∆∞·ªõc ƒë√≥ (Previous Track).
    ‚≠ê ∆ØU TI√äN PYTHON-VLC TR∆Ø·ªöC - nhanh & kh√¥ng c·∫ßn detect window!
    """
    try:
        # üéµ ∆ØU TI√äN 1: Python-VLC n·ªôi b·ªô - NHANH NH·∫§T!
        if vlc_player and vlc_player._player:
            success = vlc_player.previous_track()
            if success:
                import time
                time.sleep(0.3)  # ƒê·ª£i VLC chuy·ªÉn b√†i
                status = vlc_player.get_full_status()
                current_song = status.get('current_song', 'Unknown')
                return {
                    "success": True, 
                    "message": f"‚èÆÔ∏è ƒê√£ quay l·∫°i: {current_song} (Python-VLC)",
                    "player": "Python-VLC",
                    "current_song": current_song,
                    "llm_note": "üéµ ƒêang d√πng Python-VLC Player. Playlist c√≥ th·ªÉ ƒëi·ªÅu khi·ªÉn b·∫±ng music_next(), music_previous()"
                }
            return {"success": False, "error": "Kh√¥ng c√≥ b√†i tr∆∞·ªõc trong playlist VLC"}
        
        windows = _find_all_media_windows()
        
        # 2. YouTube
        if windows['youtube']:
            yt = windows['youtube'][0]
            _focus_and_send_hotkey(yt['hwnd'], 'shift', 'p')
            return {"success": True, "message": f"‚úÖ Chuy·ªÉn video tr∆∞·ªõc (YouTube): {yt['title'][:40]}..."}
        
        # 3. Windows Media Player
        if windows['wmplayer']:
            _focus_and_send_hotkey(windows['wmplayer']['hwnd'], 'ctrl', 'b')
            return {"success": True, "message": "‚úÖ Chuy·ªÉn b√†i tr∆∞·ªõc (Windows Media Player)"}
        
        # 4. VLC Window (external)
        if windows['vlc']:
            _focus_and_send_key(windows['vlc']['hwnd'], 'p')
            return {"success": True, "message": "‚úÖ Chuy·ªÉn b√†i tr∆∞·ªõc (VLC Window)"}
        
        # 5. Spotify Desktop App
        if windows['spotify_app']:
            _focus_and_send_hotkey(windows['spotify_app']['hwnd'], 'ctrl', 'left')
            return {"success": True, "message": "‚úÖ Chuy·ªÉn b√†i tr∆∞·ªõc (Spotify Desktop)"}
        
        # 6. Spotify Web
        if windows['spotify_web']:
            sw = windows['spotify_web'][0]
            _focus_and_send_hotkey(sw['hwnd'], 'ctrl', 'left')
            return {"success": True, "message": "‚úÖ Chuy·ªÉn b√†i tr∆∞·ªõc (Spotify Web)"}
        
        # 7. Fallback - d√πng media key
        pyautogui.press('prevtrack')
        return {"success": True, "message": "‚úÖ ƒê√£ chuy·ªÉn b√†i tr∆∞·ªõc (Media Key)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_stop() -> dict:
    """
    D·ª´ng ph√°t media (Stop).
    ‚≠ê ∆ØU TI√äN PYTHON-VLC TR∆Ø·ªöC - nhanh & kh√¥ng c·∫ßn detect window!
    """
    try:
        # üéµ ∆ØU TI√äN 1: Python-VLC n·ªôi b·ªô - NHANH NH·∫§T!
        if vlc_player and vlc_player._player:
            vlc_player.stop()
            return {
                "success": True, 
                "message": "‚èπÔ∏è ƒê√£ d·ª´ng nh·∫°c (Python-VLC)",
                "player": "Python-VLC",
                "llm_note": "üéµ ƒê√£ d·ª´ng Python-VLC Player. D√πng play_music() ho·∫∑c resume_music() ƒë·ªÉ ph√°t l·∫°i."
            }
        
        windows = _find_all_media_windows()
        
        # 2. YouTube
        if windows['youtube']:
            yt = windows['youtube'][0]
            _focus_and_send_key(yt['hwnd'], 'k', delay=0.2)
            return {"success": True, "message": f"‚úÖ ƒê√£ d·ª´ng YouTube: {yt['title'][:50]}..."}
        
        # 3. Windows Media Player
        if windows['wmplayer']:
            _focus_and_send_key(windows['wmplayer']['hwnd'], 'stop')
            return {"success": True, "message": "‚úÖ ƒê√£ d·ª´ng ph√°t (Windows Media Player)"}
        
        # 4. VLC Window (external)
        if windows['vlc']:
            _focus_and_send_key(windows['vlc']['hwnd'], 's')
            return {"success": True, "message": "‚úÖ ƒê√£ d·ª´ng ph√°t (VLC Window)"}
        
        # 5. Spotify Desktop App - kh√¥ng c√≥ stop, d√πng pause
        if windows['spotify_app']:
            _focus_and_send_key(windows['spotify_app']['hwnd'], 'space')
            return {"success": True, "message": "‚úÖ ƒê√£ t·∫°m d·ª´ng (Spotify Desktop)"}
        
        # 6. Spotify Web
        if windows['spotify_web']:
            sw = windows['spotify_web'][0]
            _focus_and_send_key(sw['hwnd'], 'space')
            return {"success": True, "message": "‚úÖ ƒê√£ t·∫°m d·ª´ng (Spotify Web)"}
        
        # 7. Fallback - d√πng media key
        pyautogui.press('stop')
        return {"success": True, "message": "‚úÖ ƒê√£ d·ª´ng ph√°t (Media Key)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_volume_up() -> dict:
    """TƒÉng √¢m l∆∞·ª£ng media (Media Volume Up)"""
    try:
        pyautogui.press('volumeup')
        return {"success": True, "message": "‚úÖ ƒê√£ tƒÉng √¢m l∆∞·ª£ng"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_volume_down() -> dict:
    """Gi·∫£m √¢m l∆∞·ª£ng media (Media Volume Down)"""
    try:
        pyautogui.press('volumedown')
        return {"success": True, "message": "‚úÖ ƒê√£ gi·∫£m √¢m l∆∞·ª£ng"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_mute() -> dict:
    """T·∫Øt/B·∫≠t ti·∫øng media (Mute Toggle)"""
    try:
        pyautogui.press('volumemute')
        return {"success": True, "message": "‚úÖ ƒê√£ toggle mute"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_control(action: str) -> dict:
    """
    ƒêi·ªÅu khi·ªÉn media player ƒëa nƒÉng.
    
    Args:
        action: H√†nh ƒë·ªông c·∫ßn th·ª±c hi·ªán
            - "play" ho·∫∑c "pause": Ph√°t/T·∫°m d·ª´ng
            - "next": B√†i ti·∫øp theo
            - "previous" ho·∫∑c "prev": B√†i tr∆∞·ªõc
            - "stop": D·ª´ng ph√°t
            - "volume_up": TƒÉng √¢m l∆∞·ª£ng
            - "volume_down": Gi·∫£m √¢m l∆∞·ª£ng
            - "mute": T·∫Øt/B·∫≠t ti·∫øng
    
    Returns:
        dict: K·∫øt qu·∫£ th·ª±c hi·ªán
    """
    try:
        action = action.lower().strip()
        
        actions_map = {
            "play": "playpause",
            "pause": "playpause",
            "playpause": "playpause",
            "next": "nexttrack",
            "previous": "prevtrack",
            "prev": "prevtrack",
            "stop": "stop",
            "volume_up": "volumeup",
            "volumeup": "volumeup",
            "volume_down": "volumedown",
            "volumedown": "volumedown",
            "mute": "volumemute",
        }
        
        key = actions_map.get(action)
        if not key:
            return {
                "success": False, 
                "error": f"Action kh√¥ng h·ª£p l·ªá: '{action}'. Ch·ªçn: play, pause, next, previous, stop, volume_up, volume_down, mute"
            }
        
        pyautogui.press(key)
        
        action_messages = {
            "playpause": "Play/Pause",
            "nexttrack": "B√†i ti·∫øp theo",
            "prevtrack": "B√†i tr∆∞·ªõc",
            "stop": "D·ª´ng ph√°t",
            "volumeup": "TƒÉng √¢m l∆∞·ª£ng",
            "volumedown": "Gi·∫£m √¢m l∆∞·ª£ng",
            "volumemute": "Mute/Unmute",
        }
        
        return {"success": True, "message": f"‚úÖ {action_messages[key]}", "action": action}
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

# ==================== END MEDIA PLAYER CONTROL ====================

# ==================== TASK MEMORY TOOLS ====================

async def remember_task(tool_name: str, params: dict = None, result_message: str = "", user_request: str = "") -> dict:
    """
    Ghi nh·ªõ m·ªôt t√°c v·ª• ƒë√£ th·ª±c hi·ªán v√†o b·ªô nh·ªõ.
    Gi√∫p AI ph·∫£n h·ªìi nhanh v√† ch√≠nh x√°c h∆°n cho c√°c y√™u c·∫ßu t∆∞∆°ng t·ª±.
    
    Args:
        tool_name: T√™n tool ƒë√£ s·ª≠ d·ª•ng
        params: Tham s·ªë ƒë√£ truy·ªÅn v√†o tool
        result_message: K·∫øt qu·∫£/message tr·∫£ v·ªÅ
        user_request: Y√™u c·∫ßu g·ªëc c·ªßa user
    """
    try:
        task_entry = add_task_to_memory(
            tool_name=tool_name,
            params=params or {},
            result={"success": True, "message": result_message},
            user_request=user_request
        )
        return {
            "success": True,
            "message": f"‚úÖ ƒê√£ ghi nh·ªõ t√°c v·ª•: {tool_name}",
            "task": task_entry
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def recall_tasks(keyword: str = "", limit: int = 10) -> dict:
    """
    Nh·ªõ l·∫°i c√°c t√°c v·ª• ƒë√£ th·ª±c hi·ªán tr∆∞·ªõc ƒë√≥.
    Gi√∫p AI bi·∫øt nh·ªØng g√¨ ƒë√£ l√†m ƒë·ªÉ ph·∫£n h·ªìi ph√π h·ª£p.
    
    Args:
        keyword: T·ª´ kh√≥a t√¨m ki·∫øm (optional). ƒê·ªÉ tr·ªëng = l·∫•y t√°c v·ª• g·∫ßn nh·∫•t
        limit: S·ªë l∆∞·ª£ng t√°c v·ª• t·ªëi ƒëa tr·∫£ v·ªÅ (default 10)
    """
    try:
        if keyword:
            tasks = search_task_memory(keyword)
            message = f"üîç T√¨m th·∫•y {len(tasks)} t√°c v·ª• li√™n quan ƒë·∫øn '{keyword}'"
        else:
            tasks = get_recent_tasks(limit)
            message = f"üìã {len(tasks)} t√°c v·ª• g·∫ßn ƒë√¢y nh·∫•t"
        
        return {
            "success": True,
            "message": message,
            "count": len(tasks),
            "tasks": tasks
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_task_summary() -> dict:
    """
    L·∫•y t·ªïng h·ª£p th·ªëng k√™ v·ªÅ c√°c t√°c v·ª• ƒë√£ th·ª±c hi·ªán.
    Gi√∫p AI hi·ªÉu patterns s·ª≠ d·ª•ng c·ªßa user.
    """
    try:
        tasks = load_task_memory()
        
        if not tasks:
            return {
                "success": True,
                "message": "üìä Ch∆∞a c√≥ l·ªãch s·ª≠ t√°c v·ª•",
                "total_tasks": 0,
                "most_used_tools": [],
                "success_rate": 0
            }
        
        # ƒê·∫øm theo tool
        tool_counts = {}
        success_count = 0
        
        for task in tasks:
            tool = task.get('tool', 'unknown')
            tool_counts[tool] = tool_counts.get(tool, 0) + 1
            if task.get('result_success'):
                success_count += 1
        
        # Top 10 tools ƒë∆∞·ª£c d√πng nhi·ªÅu nh·∫•t
        sorted_tools = sorted(tool_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            "success": True,
            "message": f"üìä ƒê√£ th·ª±c hi·ªán {len(tasks)} t√°c v·ª•",
            "total_tasks": len(tasks),
            "most_used_tools": [{"tool": t[0], "count": t[1]} for t in sorted_tools],
            "success_rate": round(success_count / len(tasks) * 100, 1),
            "recent_tools": [t.get('tool') for t in tasks[-5:]]
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def forget_all_tasks() -> dict:
    """
    X√≥a to√†n b·ªô l·ªãch s·ª≠ t√°c v·ª• ƒë√£ ghi nh·ªõ.
    """
    try:
        success = clear_task_memory()
        if success:
            return {"success": True, "message": "üóëÔ∏è ƒê√£ x√≥a to√†n b·ªô l·ªãch s·ª≠ t√°c v·ª•"}
        else:
            return {"success": False, "error": "Kh√¥ng th·ªÉ x√≥a l·ªãch s·ª≠"}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ==================== END TASK MEMORY TOOLS ====================

async def get_active_media_players() -> dict:
    """
    L·∫•y danh s√°ch c√°c media players/applications ƒëang ch·∫°y tr√™n m√°y t√≠nh.
    
    Th√¥ng tin n√†y gi√∫p LLM bi·∫øt:
    - C√≥ media player n√†o ƒëang ch·∫°y kh√¥ng
    - N√™n d√πng tool n√†o (media_play_pause cho Spotify/VLC, stop_music cho WMP)
    - C√≥ ·ª©ng d·ª•ng n√†o c√≥ th·ªÉ ƒëi·ªÅu khi·ªÉn ƒë∆∞·ª£c
    
    Returns:
        dict: Danh s√°ch media players, browsers, v√† ·ª©ng d·ª•ng quan tr·ªçng ƒëang ch·∫°y
    """
    try:
        # Danh s√°ch media players v√† ·ª©ng d·ª•ng quan tr·ªçng c·∫ßn theo d√µi
        MEDIA_APPS = {
            # Media Players
            "spotify.exe": {"name": "Spotify", "type": "music", "supports_media_keys": True},
            "vlc.exe": {"name": "VLC Media Player", "type": "video", "supports_media_keys": True},
            "wmplayer.exe": {"name": "Windows Media Player", "type": "music", "supports_media_keys": True},
            "itunes.exe": {"name": "iTunes", "type": "music", "supports_media_keys": True},
            
            # Browsers (c√≥ th·ªÉ ph√°t YouTube, Spotify Web...)
            "chrome.exe": {"name": "Google Chrome", "type": "browser", "supports_media_keys": True},
            "msedge.exe": {"name": "Microsoft Edge", "type": "browser", "supports_media_keys": True},
            "firefox.exe": {"name": "Firefox", "type": "browser", "supports_media_keys": True},
            "brave.exe": {"name": "Brave", "type": "browser", "supports_media_keys": True},
            "opera.exe": {"name": "Opera", "type": "browser", "supports_media_keys": True},
            "browser.exe": {"name": "Browser", "type": "browser", "supports_media_keys": True},
            "iexplore.exe": {"name": "Internet Explorer", "type": "browser", "supports_media_keys": True},
            "vivaldi.exe": {"name": "Vivaldi", "type": "browser", "supports_media_keys": True},
            
            # Communication (c√≥ media playback)
            "discord.exe": {"name": "Discord", "type": "communication", "supports_media_keys": True},
            "slack.exe": {"name": "Slack", "type": "communication", "supports_media_keys": False},
            "zoom.exe": {"name": "Zoom", "type": "communication", "supports_media_keys": False},
            "skype.exe": {"name": "Skype", "type": "communication", "supports_media_keys": False},
            
            # Office & Productivity
            "WINWORD.EXE": {"name": "Microsoft Word", "type": "office", "supports_media_keys": False},
            "EXCEL.EXE": {"name": "Microsoft Excel", "type": "office", "supports_media_keys": False},
            "POWERPNT.EXE": {"name": "PowerPoint", "type": "office", "supports_media_keys": False},
            "OUTLOOK.EXE": {"name": "Outlook", "type": "office", "supports_media_keys": False},
            
            # Development
            "Code.exe": {"name": "VS Code", "type": "development", "supports_media_keys": False},
            "devenv.exe": {"name": "Visual Studio", "type": "development", "supports_media_keys": False},
            "pycharm64.exe": {"name": "PyCharm", "type": "development", "supports_media_keys": False},
            
            # Design & Creative
            "Photoshop.exe": {"name": "Adobe Photoshop", "type": "creative", "supports_media_keys": False},
            "Illustrator.exe": {"name": "Adobe Illustrator", "type": "creative", "supports_media_keys": False},
            "blender.exe": {"name": "Blender", "type": "3d", "supports_media_keys": False},
        }
        
        running_apps = []
        media_players = []
        browsers = []
        
        # Qu√©t c√°c process ƒëang ch·∫°y
        for proc in psutil.process_iter(['pid', 'name']):
            try:
                proc_name = proc.info['name']
                
                if proc_name in MEDIA_APPS:
                    app_info = MEDIA_APPS[proc_name].copy()
                    app_info['pid'] = proc.info['pid']
                    app_info['process_name'] = proc_name
                    
                    running_apps.append(app_info)
                    
                    # Ph√¢n lo·∫°i
                    if app_info['type'] in ['music', 'video']:
                        media_players.append(app_info)
                    elif app_info['type'] == 'browser':
                        browsers.append(app_info)
                        
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                pass
        
        # T·∫°o th√¥ng ƒëi·ªáp h∆∞·ªõng d·∫´n cho LLM (t·ªëi ∆∞u h√≥a, kh√¥ng li·ªát k√™ t·ª´ng instance)
        guidance = ""
        
        if media_players:
            # ƒê·∫øm s·ªë l∆∞·ª£ng t·ª´ng lo·∫°i media player (kh√¥ng li·ªát k√™ t·ª´ng process)
            player_counts = {}
            for p in media_players:
                name = p['name']
                player_counts[name] = player_counts.get(name, 0) + 1
            
            player_summary = ', '.join([f"{name} ({count})" if count > 1 else name 
                                       for name, count in player_counts.items()])
            guidance += f"üéµ Media Players: {player_summary}.\n"
            
            if any(p['name'] == 'Windows Media Player' for p in media_players):
                guidance += "   ‚Üí D√πng stop_music() ƒë·ªÉ d·ª´ng Windows Media Player.\n"
            
            if any(p['supports_media_keys'] and p['name'] != 'Windows Media Player' for p in media_players):
                guidance += "   ‚Üí D√πng media_play_pause(), media_next_track() cho Spotify/VLC/iTunes.\n"
        
        if browsers:
            # ƒê·∫øm s·ªë l∆∞·ª£ng t·ª´ng lo·∫°i browser (kh√¥ng li·ªát k√™ t·ª´ng process)
            browser_counts = {}
            for b in browsers:
                name = b['name']
                browser_counts[name] = browser_counts.get(name, 0) + 1
            
            browser_summary = ', '.join([f"{name} ({count})" if count > 1 else name 
                                        for name, count in browser_counts.items()])
            guidance += f"üåê Browsers: {browser_summary}.\n"
            guidance += "   ‚Üí C√≥ th·ªÉ ph√°t YouTube/Spotify Web. D√πng media_play_pause() ƒë·ªÉ ƒëi·ªÅu khi·ªÉn.\n"
        
        if not media_players and not browsers:
            guidance = "‚ùå Kh√¥ng c√≥ media player/browser n√†o ƒëang ch·∫°y. D√πng play_music() ƒë·ªÉ ph√°t nh·∫°c t·ª´ music_library."
        
        return {
            "success": True,
            "all_apps": running_apps,
            "media_players": media_players,
            "browsers": browsers,
            "total_count": len(running_apps),
            "guidance": guidance.strip(),
            "message": f"‚úÖ ƒêang ch·∫°y: {len(running_apps)} ·ª©ng d·ª•ng ({len(media_players)} media players, {len(browsers)} browsers)"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def list_running_processes(limit: int = 10) -> dict:
    try:
        procs = []
        for p in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
            try:
                procs.append({"pid": p.info['pid'], "name": p.info['name'], "cpu": round(p.info['cpu_percent'], 2), "memory": round(p.info['memory_percent'], 2)})
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                # B·ªè qua c√°c ti·∫øn tr√¨nh kh√¥ng th·ªÉ truy c·∫≠p
                pass
        procs = sorted(procs, key=lambda x: x['cpu'], reverse=True)[:limit]
        return {"success": True, "processes": procs, "count": len(procs)}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def kill_process(identifier: str, force: bool = True, exact_match: bool = False) -> dict:
    """
    Kill process ngay l·∫≠p t·ª©c.
    
    Args:
        identifier: T√™n app ho·∫∑c PID. VD: "notepad", "chrome", "1234"
        force: True = kill ngay (SIGKILL), False = ƒë√≥ng m·ªÅm (SIGTERM)
        exact_match: True = t√™n ph·∫£i kh·ªõp ch√≠nh x√°c, False = ch·ª©a t√™n l√† ƒë∆∞·ª£c
    """
    import subprocess
    import time
    
    try:
        killed = []
        failed = []
        
        # N·∫øu l√† PID (s·ªë)
        if identifier.isdigit():
            try:
                p = psutil.Process(int(identifier))
                name = p.name()
                if force:
                    p.kill()  # SIGKILL - kill ngay l·∫≠p t·ª©c
                else:
                    p.terminate()  # SIGTERM - ƒë√≥ng m·ªÅm
                    p.wait(timeout=3)  # Ch·ªù t·ªëi ƒëa 3 gi√¢y
                killed.append(f"{name} (PID: {identifier})")
            except psutil.TimeoutExpired:
                # N·∫øu terminate kh√¥ng ƒë∆∞·ª£c, force kill
                p.kill()
                killed.append(f"{name} (PID: {identifier}) [FORCE KILLED]")
        else:
            # T√¨m theo t√™n
            target_name = identifier.lower()
            
            # Th√™m .exe n·∫øu ch∆∞a c√≥
            if not target_name.endswith('.exe'):
                target_name_exe = target_name + '.exe'
            else:
                target_name_exe = target_name
                target_name = target_name[:-4]  # B·ªè .exe ƒë·ªÉ so s√°nh
            
            for p in psutil.process_iter(['pid', 'name', 'exe']):
                try:
                    proc_name = p.info['name'].lower() if p.info['name'] else ""
                    
                    # Ki·ªÉm tra match
                    match = False
                    if exact_match:
                        # Kh·ªõp ch√≠nh x√°c t√™n
                        match = (proc_name == target_name_exe or proc_name == target_name)
                    else:
                        # Ch·ª©a t√™n l√† ƒë∆∞·ª£c
                        match = (target_name in proc_name)
                    
                    if match:
                        pid = p.info['pid']
                        try:
                            if force:
                                p.kill()  # Kill ngay l·∫≠p t·ª©c
                            else:
                                p.terminate()
                                try:
                                    p.wait(timeout=2)
                                except psutil.TimeoutExpired:
                                    p.kill()  # Force kill n·∫øu kh√¥ng ƒë√≥ng ƒë∆∞·ª£c
                            killed.append(f"{p.info['name']} (PID: {pid})")
                        except psutil.AccessDenied:
                            # Th·ª≠ d√πng taskkill v·ªõi quy·ªÅn cao h∆°n
                            try:
                                subprocess.run(
                                    ['taskkill', '/F', '/PID', str(pid)],
                                    capture_output=True,
                                    timeout=5
                                )
                                killed.append(f"{p.info['name']} (PID: {pid}) [via taskkill]")
                            except:
                                failed.append(f"{p.info['name']} (PID: {pid}) - Access Denied")
                except (psutil.NoSuchProcess, psutil.ZombieProcess):
                    pass
        
        # K·∫øt qu·∫£
        if killed:
            result = {
                "success": True, 
                "message": f"‚úÖ ƒê√£ kill th√†nh c√¥ng: {', '.join(killed)}",
                "killed_count": len(killed),
                "killed": killed
            }
            if failed:
                result["failed"] = failed
                result["message"] += f"\n‚ö†Ô∏è Kh√¥ng th·ªÉ kill: {', '.join(failed)}"
            return result
        elif failed:
            return {"success": False, "error": f"Kh√¥ng c√≥ quy·ªÅn kill: {', '.join(failed)}"}
        else:
            return {"success": False, "error": f"Kh√¥ng t√¨m th·∫•y process '{identifier}'"}
            
    except psutil.NoSuchProcess:
        return {"success": False, "error": f"Ti·∫øn tr√¨nh kh√¥ng t·ªìn t·∫°i: {identifier}"}
    except psutil.AccessDenied:
        # Th·ª≠ d√πng taskkill
        try:
            if identifier.isdigit():
                result = subprocess.run(
                    ['taskkill', '/F', '/PID', identifier],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
            else:
                result = subprocess.run(
                    ['taskkill', '/F', '/IM', f'{identifier}*'],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
            if result.returncode == 0:
                return {"success": True, "message": f"‚úÖ ƒê√£ kill b·∫±ng taskkill: {identifier}"}
            else:
                return {"success": False, "error": f"Kh√¥ng th·ªÉ kill (c·∫ßn quy·ªÅn Admin): {identifier}"}
        except Exception as e:
            return {"success": False, "error": f"L·ªói khi kill: {str(e)}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


async def force_kill_app(app_name: str) -> dict:
    """
    Force kill app theo t√™n CH√çNH X√ÅC - kill ngay l·∫≠p t·ª©c kh√¥ng h·ªèi han.
    S·ª≠ d·ª•ng c·∫£ psutil v√† taskkill ƒë·ªÉ ƒë·∫£m b·∫£o kill ƒë∆∞·ª£c.
    
    Args:
        app_name: T√™n app c·∫ßn kill. VD: "notepad", "chrome", "Code"
    """
    import subprocess
    
    try:
        killed = []
        
        # Chu·∫©n h√≥a t√™n
        target = app_name.lower().strip()
        if not target.endswith('.exe'):
            target_exe = target + '.exe'
        else:
            target_exe = target
            target = target[:-4]
        
        # B∆∞·ªõc 1: Kill b·∫±ng psutil
        for p in psutil.process_iter(['pid', 'name']):
            try:
                proc_name = (p.info['name'] or "").lower()
                if proc_name == target_exe or proc_name == target or target in proc_name:
                    pid = p.info['pid']
                    try:
                        p.kill()  # SIGKILL - force kill ngay
                        killed.append(f"{p.info['name']} (PID: {pid})")
                    except:
                        pass
            except:
                pass
        
        # B∆∞·ªõc 2: Backup v·ªõi taskkill /F (force)
        try:
            # Kill theo image name
            subprocess.run(
                ['taskkill', '/F', '/IM', target_exe],
                capture_output=True,
                timeout=5
            )
            # Th·ª≠ c·∫£ kh√¥ng c√≥ .exe
            subprocess.run(
                ['taskkill', '/F', '/IM', f'{target}*'],
                capture_output=True,
                timeout=5
            )
        except:
            pass
        
        # B∆∞·ªõc 3: Verify ƒë√£ kill h·∫øt ch∆∞a
        remaining = []
        for p in psutil.process_iter(['pid', 'name']):
            try:
                proc_name = (p.info['name'] or "").lower()
                if proc_name == target_exe or proc_name == target or target in proc_name:
                    remaining.append(f"{p.info['name']} (PID: {p.info['pid']})")
            except:
                pass
        
        if killed and not remaining:
            return {
                "success": True,
                "message": f"‚úÖ ƒê√£ FORCE KILL th√†nh c√¥ng: {', '.join(killed)}",
                "killed_count": len(killed),
                "killed": killed
            }
        elif remaining:
            return {
                "success": False,
                "error": f"‚ùå Kh√¥ng th·ªÉ kill (c·∫ßn quy·ªÅn Admin): {', '.join(remaining)}",
                "killed": killed if killed else []
            }
        else:
            return {
                "success": False,
                "error": f"Kh√¥ng t√¨m th·∫•y app '{app_name}' ƒëang ch·∫°y"
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}

async def find_process(name_pattern: str = "", show_all: bool = False) -> dict:
    """
    T√¨m ki·∫øm process theo t√™n ho·∫∑c hi·ªÉn th·ªã t·∫•t c·∫£.
    
    Args:
        name_pattern: T√™n process c·∫ßn t√¨m (partial match, case insensitive). ƒê·ªÉ tr·ªëng = t·∫•t c·∫£
        show_all: True = hi·ªÉn th·ªã t·∫•t c·∫£ process (b·ªè qua limit)
    
    Returns:
        dict: Danh s√°ch processes t√¨m th·∫•y
    """
    try:
        procs = []
        pattern_lower = name_pattern.lower() if name_pattern else ""
        
        for p in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
            try:
                info = p.info
                proc_name = (info['name'] or "").lower()
                
                # Filter theo pattern n·∫øu c√≥
                if pattern_lower and pattern_lower not in proc_name:
                    continue
                    
                procs.append({
                    "pid": info['pid'], 
                    "name": info['name'], 
                    "cpu": round(info['cpu_percent'] or 0, 2), 
                    "memory": round(info['memory_percent'] or 0, 2)
                })
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                pass
        
        # Sort theo CPU usage n·∫øu kh√¥ng c√≥ filter c·ª• th·ªÉ
        if not pattern_lower:
            procs = sorted(procs, key=lambda x: x['cpu'], reverse=True)
            
        # Limit ch·ªâ khi kh√¥ng show_all v√† kh√¥ng c√≥ pattern c·ª• th·ªÉ
        if not show_all and not pattern_lower:
            procs = procs[:20]  # Top 20 thay v√¨ 10
            
        # T·∫°o message t√≥m t·∫Øt
        if pattern_lower:
            found_count = len(procs)
            if found_count == 0:
                message = f"‚ùå Kh√¥ng t√¨m th·∫•y process n√†o ch·ª©a '{name_pattern}'"
            elif found_count == 1:
                message = f"‚úÖ T√¨m th·∫•y 1 process: {procs[0]['name']}"
            else:
                message = f"‚úÖ T√¨m th·∫•y {found_count} processes ch·ª©a '{name_pattern}'"
        else:
            message = f"üìã Danh s√°ch {len(procs)} processes (sorted by CPU usage)"
            
        return {
            "success": True, 
            "processes": procs, 
            "count": len(procs),
            "pattern": name_pattern,
            "message": message
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def create_file(path: str, content: str) -> dict:
    try:
        import os
        
        # Validate path - must be absolute on Windows (contains drive letter)
        if not os.path.isabs(path):
            return {"success": False, "error": f"Path must be absolute. Got: '{path}'. Example: 'C:/folder/file.txt'"}
        
        # Normalize path separators
        path = os.path.normpath(path)
        
        # Check if parent directory exists, create if needed
        parent_dir = os.path.dirname(path)
        if parent_dir and not os.path.exists(parent_dir):
            try:
                os.makedirs(parent_dir, exist_ok=True)
            except Exception as e:
                return {"success": False, "error": f"Cannot create directory '{parent_dir}': {str(e)}"}
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        return {"success": True, "path": path, "message": f"ƒê√£ t·∫°o: {path}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def read_file(path: str) -> dict:
    try:
        import os
        
        # Validate path - must be absolute on Windows (contains drive letter)
        if not os.path.isabs(path):
            return {"success": False, "error": f"Path must be absolute. Got: '{path}'. Example: 'C:/folder/file.txt'"}
        
        # Normalize path separators
        path = os.path.normpath(path)
        
        # Check if file exists
        if not os.path.exists(path):
            return {"success": False, "error": f"File not found: '{path}'"}
        
        if not os.path.isfile(path):
            return {"success": False, "error": f"Path is not a file: '{path}'"}
        
        with open(path, 'r', encoding='utf-8') as f:
            content = f.read()
        return {"success": True, "path": path, "content": content[:500], "size": len(content)}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def list_files(directory: str) -> dict:
    try:
        import os
        files = []
        for item in os.listdir(directory):
            p = os.path.join(directory, item)
            files.append({"name": item, "type": "dir" if os.path.isdir(p) else "file", "size": os.path.getsize(p) if os.path.isfile(p) else 0})
        return {"success": True, "directory": directory, "files": files, "count": len(files)}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_battery_status() -> dict:
    try:
        bat = psutil.sensors_battery()
        if bat is None:
            return {"success": False, "error": "Kh√¥ng th·ªÉ l·∫•y th√¥ng tin pin (c√≥ th·ªÉ kh√¥ng c√≥ pin)"}
        return {
            "success": True,
            "percent": bat.percent,
            "plugged": bat.power_plugged,
            "time_left": str(bat.secsleft) if bat.secsleft != psutil.POWER_TIME_UNLIMITED else "Unlimited"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_disk_usage() -> dict:
    try:
        disks = []
        for part in psutil.disk_partitions():
            try:
                usage = psutil.disk_usage(part.mountpoint)
                disks.append({"device": part.device, "mountpoint": part.mountpoint, "fstype": part.fstype, "total_gb": round(usage.total / (1024**3), 2), "used_gb": round(usage.used / (1024**3), 2), "free_gb": round(usage.free / (1024**3), 2), "percent": usage.percent})
            except (PermissionError, OSError):
                # B·ªè qua c√°c ·ªï ƒëƒ©a kh√¥ng th·ªÉ truy c·∫≠p
                pass
        return {"success": True, "disks": disks, "count": len(disks)}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# MUSIC LIBRARY TOOLS - VLC PLAYER
# ============================================================

MUSIC_LIBRARY = Path(__file__).parent / "music_library"
MUSIC_EXTENSIONS = {'.mp3', '.wav', '.flac', '.m4a', '.ogg', '.wma', '.aac'}

# YouTube Playlists Management
YOUTUBE_PLAYLISTS_FILE = Path(__file__).parent / "youtube_playlists.json"

def load_youtube_playlists() -> list:
    """ƒê·ªçc danh s√°ch playlist YouTube t·ª´ file JSON"""
    try:
        if YOUTUBE_PLAYLISTS_FILE.exists():
            with open(YOUTUBE_PLAYLISTS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []
    except Exception as e:
        print(f"‚ùå [Playlists] Error loading: {e}")
        return []

def save_youtube_playlists(playlists: list) -> bool:
    """L∆∞u danh s√°ch playlist YouTube v√†o file JSON"""
    try:
        with open(YOUTUBE_PLAYLISTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(playlists, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"‚ùå [Playlists] Error saving: {e}")
        return False

async def add_youtube_playlist(name: str, url: str) -> dict:
    """Th√™m playlist YouTube m·ªõi"""
    try:
        playlists = load_youtube_playlists()
        
        # Ki·ªÉm tra tr√πng t√™n
        if any(p['name'].lower() == name.lower() for p in playlists):
            return {
                "success": False,
                "error": f"Playlist '{name}' ƒë√£ t·ªìn t·∫°i!"
            }
        
        # Th√™m playlist m·ªõi
        new_playlist = {
            "name": name,
            "url": url,
            "created_at": datetime.now().isoformat()
        }
        playlists.append(new_playlist)
        
        if save_youtube_playlists(playlists):
            return {
                "success": True,
                "message": f"‚úÖ ƒê√£ th√™m playlist: {name}",
                "playlist": new_playlist
            }
        else:
            return {
                "success": False,
                "error": "Kh√¥ng th·ªÉ l∆∞u playlist"
            }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def remove_youtube_playlist(name: str) -> dict:
    """X√≥a playlist YouTube"""
    try:
        playlists = load_youtube_playlists()
        
        # T√¨m v√† x√≥a playlist
        original_count = len(playlists)
        playlists = [p for p in playlists if p['name'].lower() != name.lower()]
        
        if len(playlists) == original_count:
            return {
                "success": False,
                "error": f"Kh√¥ng t√¨m th·∫•y playlist: {name}"
            }
        
        if save_youtube_playlists(playlists):
            return {
                "success": True,
                "message": f"‚úÖ ƒê√£ x√≥a playlist: {name}"
            }
        else:
            return {
                "success": False,
                "error": "Kh√¥ng th·ªÉ l∆∞u thay ƒë·ªïi"
            }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_youtube_playlists() -> dict:
    """L·∫•y danh s√°ch t·∫•t c·∫£ playlist YouTube"""
    try:
        playlists = load_youtube_playlists()
        return {
            "success": True,
            "playlists": playlists,
            "count": len(playlists)
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def open_youtube_playlist(playlist_name: str) -> dict:
    """M·ªü playlist YouTube ƒë√£ l∆∞u trong browser
    
    Args:
        playlist_name: T√™n playlist ƒë√£ ƒëƒÉng k√Ω (c√≥ th·ªÉ l√† t√™n ƒë·∫ßy ƒë·ªß ho·∫∑c t·ª´ kh√≥a)
    
    Returns:
        dict v·ªõi th√¥ng tin playlist ƒë√£ m·ªü
    """
    try:
        import webbrowser
        
        playlists = load_youtube_playlists()
        
        if not playlists:
            return {
                "success": False,
                "error": "Ch∆∞a c√≥ playlist n√†o. H√£y th√™m playlist tr√™n Web UI!"
            }
        
        # T√¨m playlist (exact match ho·∫∑c partial match)
        playlist_name_lower = playlist_name.lower()
        matched_playlist = None
        
        # T√¨m exact match tr∆∞·ªõc
        for p in playlists:
            if p['name'].lower() == playlist_name_lower:
                matched_playlist = p
                break
        
        # N·∫øu kh√¥ng c√≥ exact match, t√¨m partial match
        if not matched_playlist:
            for p in playlists:
                if playlist_name_lower in p['name'].lower():
                    matched_playlist = p
                    break
        
        if not matched_playlist:
            # Hi·ªÉn th·ªã danh s√°ch playlist c√≥ s·∫µn
            available = [p['name'] for p in playlists]
            return {
                "success": False,
                "error": f"Kh√¥ng t√¨m th·∫•y playlist: '{playlist_name}'",
                "available_playlists": available,
                "hint": f"C√≥ {len(available)} playlist: {', '.join(available)}"
            }
        
        # M·ªü playlist trong browser
        webbrowser.open(matched_playlist['url'])
        
        print(f"üéµ [YouTube Playlist] ƒê√£ m·ªü: {matched_playlist['name']}")
        
        return {
            "success": True,
            "message": f"‚úÖ ƒê√£ m·ªü playlist: {matched_playlist['name']}",
            "playlist": matched_playlist,
            "url": matched_playlist['url']
        }
        
    except Exception as e:
        print(f"‚ùå [YouTube Playlist] Error: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

# VLC Player Manager (Singleton)
class VLCMusicPlayer:
    """
    VLC Music Player v·ªõi h·ªó tr·ª£ ƒë·∫ßy ƒë·ªß:
    - Play/Pause/Stop
    - Next/Previous track
    - Playlist management
    - Fuzzy song matching (t√¨m b√†i g·∫ßn ƒë√∫ng)
    - Media keys support (VLC t·ª± ƒë·ªông h·ªó tr·ª£)
    """
    _instance = None
    _player = None
    _media_list = None
    _list_player = None
    _current_playlist = []
    _shuffle = False
    _repeat_mode = 0  # 0: off, 1: all, 2: one
    _song_cache = {}  # Cache danh s√°ch b√†i h√°t
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._player is None:
            try:
                import vlc
                self._vlc = vlc
                # T·∫°o VLC instance v·ªõi UI ƒë·∫ßy ƒë·ªß
                # Kh√¥ng d√πng --no-xlib, --no-video, --no-audio-display
                # Th√™m --video-on-top ƒë·ªÉ c·ª≠a s·ªï lu√¥n hi·ªÉn th·ªã
                self._instance_vlc = vlc.Instance()  # Empty options = full UI
                self._player = self._instance_vlc.media_player_new()
                self._media_list = self._instance_vlc.media_list_new()
                self._list_player = self._instance_vlc.media_list_player_new()
                self._list_player.set_media_player(self._player)
                print("‚úÖ [VLC] VLC Music Player initialized (full UI + fuzzy matching)")
            except Exception as e:
                print(f"‚ùå [VLC] Failed to initialize: {e}")
                self._player = None
    
    def play_file(self, file_path: str):
        """Ph√°t 1 file nh·∫°c"""
        if not self._player:
            return False
        try:
            media = self._instance_vlc.media_new(file_path)
            self._player.set_media(media)
            self._player.play()
            return True
        except Exception as e:
            print(f"‚ùå [VLC] Play error: {e}")
            return False
    
    def play_playlist(self, file_paths: list):
        """Ph√°t playlist v·ªõi nhi·ªÅu b√†i"""
        if not self._list_player:
            print("‚ùå [VLC] list_player ch∆∞a kh·ªüi t·∫°o")
            return False
        try:
            print(f"üéµ [VLC DEBUG] play_playlist called with {len(file_paths)} files")
            for i, p in enumerate(file_paths[:3]):  # Log 3 file ƒë·∫ßu
                print(f"   [{i+1}] {p}")
            
            # QUAN TR·ªåNG: STOP b√†i ƒëang ph√°t tr∆∞·ªõc!
            self._list_player.stop()
            import time
            time.sleep(0.3)
            print("üõë [VLC] Stopped current playback")
            
            # Clear playlist c≈© v√† t·∫°o m·ªõi
            self._media_list = self._instance_vlc.media_list_new()
            self._current_playlist = file_paths
            
            # Th√™m t·∫•t c·∫£ b√†i v√†o playlist
            for path in file_paths:
                media = self._instance_vlc.media_new(path)
                self._media_list.add_media(media)
            
            print(f"üéµ [VLC DEBUG] Media list count: {self._media_list.count()}")
            
            # Set playlist m·ªõi
            self._list_player.set_media_list(self._media_list)
            
            # Set current index to 0 (first song)
            self._current_index = 0
            
            # QUAN TR·ªåNG: G·ªçi play() ƒë·ªÉ ph√°t b√†i ƒë·∫ßu ti√™n
            self._list_player.play()
            print(f"üéµ [VLC DEBUG] list_player.play() called")
            
            # FIX DOUBLE-CLICK: TƒÉng th·ªùi gian ch·ªù ƒë·ªÉ VLC kh·ªüi t·∫°o ƒë·∫ßy ƒë·ªß
            time.sleep(0.7)
            
            # Ki·ªÉm tra v√† ƒë·∫£m b·∫£o ƒëang ph√°t v·ªõi retry mechanism
            if self._player:
                state = self._player.get_state()
                is_playing = self._player.is_playing()
                current_vol = self._player.audio_get_volume()
                print(f"üéµ [VLC DEBUG] State: {state}, is_playing: {is_playing}, volume: {current_vol}")
                
                # FIX: Retry n·∫øu ch∆∞a ph√°t (quan tr·ªçng cho double-click)
                retry_count = 0
                max_retries = 3
                while not is_playing and retry_count < max_retries:
                    print(f"‚ö†Ô∏è [VLC DEBUG] Not playing, retry {retry_count+1}/{max_retries}...")
                    self._list_player.play()
                    time.sleep(0.4)
                    is_playing = self._player.is_playing()
                    retry_count += 1
                
                # ƒê·∫£m b·∫£o volume ƒë·ªß nghe
                if current_vol < 50:
                    self._player.audio_set_volume(80)
                    print(f"üîä [VLC] Volume was {current_vol}, set to 80")
            
            print(f"‚ñ∂Ô∏è [VLC] Playing playlist with {len(file_paths)} songs")
            return True
        except Exception as e:
            print(f"‚ùå [VLC] Playlist error: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def pause(self):
        """T·∫°m d·ª´ng"""
        if self._player:
            self._player.pause()
            return True
        return False
    
    def resume(self):
        """Ti·∫øp t·ª•c ph√°t - ƒê·∫£m b·∫£o ƒëang play"""
        if self._list_player:
            # N·∫øu ƒëang paused, g·ªçi play ƒë·ªÉ ti·∫øp t·ª•c
            if not self.is_playing():
                self._list_player.play()
            return True
        elif self._player:
            if not self.is_playing():
                self._player.play()
            return True
        return False
    
    def stop(self):
        """D·ª´ng ph√°t ho√†n to√†n v√† reset tr·∫°ng th√°i"""
        try:
            import time
            
            # Stop c·∫£ list_player v√† player
            if self._list_player:
                self._list_player.stop()
                time.sleep(0.1)
            
            if self._player:
                self._player.stop()
                time.sleep(0.1)
            
            # Verify ƒë√£ d·ª´ng th·ª±c s·ª±
            stopped = False
            for _ in range(3):  # Retry 3 l·∫ßn
                if not self.is_playing():
                    stopped = True
                    break
                time.sleep(0.1)
                if self._player:
                    self._player.stop()
            
            if stopped:
                print("‚úÖ [VLC] Stopped successfully")
            else:
                print("‚ö†Ô∏è [VLC] Stop command sent but player may still be active")
            
            return True
        except Exception as e:
            print(f"‚ùå [VLC] Stop error: {e}")
            return False
    
    def next_track(self):
        """B√†i ti·∫øp theo - T·ª± ƒë·ªông ph√°t lu√¥n v·ªõi retry logic!"""
        if self._list_player and self._current_playlist:
            current_idx = getattr(self, '_current_index', 0)
            last_idx = len(self._current_playlist) - 1
            
            # Stop hi·ªán t·∫°i ƒë·ªÉ tr√°nh conflict
            self._list_player.stop()
            
            if current_idx >= last_idx:
                # ƒê√£ ·ªü b√†i cu·ªëi, quay l·∫°i b√†i ƒë·∫ßu
                self._current_index = 0
                print(f"üîÑ [VLC] Next: Wrap to first track (index 0)")
            else:
                # C√≤n b√†i ti·∫øp, chuy·ªÉn b√¨nh th∆∞·ªùng
                self._current_index = current_idx + 1
                print(f"‚è≠Ô∏è [VLC] Next: Now at index {self._current_index}")
            
            # Play b√†i m·ªõi b·∫±ng index
            self._list_player.play_item_at_index(self._current_index)
            
            import time
            time.sleep(0.4)
            
            # Retry n·∫øu ch∆∞a ph√°t (t·ªëi ƒëa 2 l·∫ßn)
            retry_count = 0
            while not self.is_playing() and retry_count < 2:
                print(f"‚ö†Ô∏è [VLC] Not playing yet, retry {retry_count + 1}/2...")
                self._list_player.play()
                time.sleep(0.3)
                retry_count += 1
            
            # Verify
            if self.is_playing():
                print(f"‚úÖ [VLC] Next track playing successfully")
                return True
            else:
                print(f"‚ùå [VLC] Failed to play next track after retries")
                return False
        return False
    
    def previous_track(self):
        """B√†i tr∆∞·ªõc - T·ª± ƒë·ªông ph√°t lu√¥n v·ªõi retry logic!"""
        if self._list_player and self._current_playlist:
            # Ki·ªÉm tra n·∫øu ƒëang ·ªü b√†i ƒë·∫ßu ti√™n
            current_idx = getattr(self, '_current_index', 0)
            
            # Stop hi·ªán t·∫°i ƒë·ªÉ tr√°nh conflict
            self._list_player.stop()
            
            if current_idx <= 0:
                # ƒê√£ ·ªü b√†i ƒë·∫ßu, quay l·∫°i b√†i cu·ªëi c√πng c·ªßa playlist
                last_idx = len(self._current_playlist) - 1
                self._current_index = last_idx
                print(f"üîÑ [VLC] Previous: Wrap to last track (index {last_idx})")
            else:
                # C√≤n b√†i tr∆∞·ªõc, chuy·ªÉn b√¨nh th∆∞·ªùng
                self._current_index = current_idx - 1
                print(f"‚èÆÔ∏è [VLC] Previous: Now at index {self._current_index}")
            
            # Play b√†i m·ªõi b·∫±ng index
            self._list_player.play_item_at_index(self._current_index)
            
            import time
            time.sleep(0.4)
            
            # Retry n·∫øu ch∆∞a ph√°t (t·ªëi ƒëa 2 l·∫ßn)
            retry_count = 0
            while not self.is_playing() and retry_count < 2:
                print(f"‚ö†Ô∏è [VLC] Not playing yet, retry {retry_count + 1}/2...")
                self._list_player.play()
                time.sleep(0.3)
                retry_count += 1
            
            # Verify
            if self.is_playing():
                print(f"‚úÖ [VLC] Previous track playing successfully")
                return True
            else:
                print(f"‚ùå [VLC] Failed to play previous track after retries")
                return False
        return False
    
    def is_playing(self):
        """Ki·ªÉm tra ƒëang ph√°t kh√¥ng"""
        if self._player:
            return self._player.is_playing()
        return False
    
    def get_state(self):
        """L·∫•y tr·∫°ng th√°i player"""
        if not self._player:
            return "not_initialized"
        
        state = self._player.get_state()
        state_map = {
            0: "idle",
            1: "opening",
            2: "buffering", 
            3: "playing",
            4: "paused",
            5: "stopped",
            6: "ended",
            7: "error"
        }
        return state_map.get(state, "unknown")
    
    def get_position(self):
        """L·∫•y v·ªã tr√≠ hi·ªán t·∫°i (0.0 - 1.0)"""
        if self._player:
            return self._player.get_position() or 0.0
        return 0.0
    
    def get_time(self):
        """L·∫•y th·ªùi gian hi·ªán t·∫°i (milliseconds)"""
        if self._player:
            return self._player.get_time() or 0
        return 0
    
    def get_length(self):
        """L·∫•y ƒë·ªô d√†i b√†i h√°t (milliseconds)"""
        if self._player:
            return self._player.get_length() or 0
        return 0
    
    def get_volume(self):
        """L·∫•y √¢m l∆∞·ª£ng hi·ªán t·∫°i (0-100)"""
        if self._player:
            return self._player.audio_get_volume() or 0
        return 0
    
    def set_volume(self, level: int):
        """ƒê·∫∑t √¢m l∆∞·ª£ng (0-100)"""
        if self._player:
            level = max(0, min(100, level))
            self._player.audio_set_volume(level)
            return True
        return False
    
    def set_position(self, position: float):
        """ƒê·∫∑t v·ªã tr√≠ (0.0 - 1.0)"""
        if self._player:
            position = max(0.0, min(1.0, position))
            self._player.set_position(position)
            return True
        return False
    
    def get_current_media_title(self):
        """L·∫•y ti√™u ƒë·ªÅ media ƒëang ph√°t - T·ªêI ∆ØU v·ªõi cache"""
        try:
            if self._player:
                media = self._player.get_media()
                if media:
                    # Cache ƒë·ªÉ tr√°nh query l·∫°i li√™n t·ª•c
                    title = media.get_meta(self._vlc.Meta.Title)
                    if title:
                        self._cached_title = title
                        return title
                    # Fallback: filename
                    mrl = media.get_mrl()
                    if mrl:
                        from urllib.parse import unquote
                        path = unquote(mrl.replace('file:///', '').replace('file://', ''))
                        fname = Path(path).name
                        self._cached_title = fname
                        return fname
            # Return cached n·∫øu c√≥
            return getattr(self, '_cached_title', None)
        except:
            return getattr(self, '_cached_title', None)
    
    def get_playlist_index(self):
        """L·∫•y index b√†i hi·ªán t·∫°i trong playlist"""
        # VLC kh√¥ng c√≥ API tr·ª±c ti·∫øp, ph·∫£i track ri√™ng
        return getattr(self, '_current_index', 0)
    
    def get_playlist_count(self):
        """L·∫•y s·ªë b√†i trong playlist"""
        return len(self._current_playlist) if self._current_playlist else 0
    
    def get_full_status(self):
        """L·∫•y tr·∫°ng th√°i ƒë·∫ßy ƒë·ªß cho Web UI - T·ªêI ∆ØU"""
        state = self.get_state()
        current_time_ms = self.get_time()
        duration_ms = self.get_length()
        
        return {
            "state": state,
            "is_playing": self.is_playing(),
            "position": self.get_position(),
            "current_time_ms": current_time_ms,
            "current_time_formatted": self._format_time(current_time_ms),
            "duration_ms": duration_ms,
            "duration_formatted": self._format_time(duration_ms),
            "volume": self.get_volume(),
            "current_track": self.get_current_media_title(),
            "playlist_index": self.get_playlist_index(),
            "playlist_count": self.get_playlist_count(),
            "playlist": [Path(p).name for p in self._current_playlist[:5]] if self._current_playlist else [],  # CH·ªà 5 b√†i (gi·∫£m data)
            "shuffle": self._shuffle,
            "repeat_mode": self._repeat_mode
        }
    
    def set_shuffle(self, enabled: bool):
        """B·∫≠t/t·∫Øt ch·∫ø ƒë·ªô ph√°t ng·∫´u nhi√™n"""
        self._shuffle = enabled
        if self._list_player:
            # VLC MediaListPlayer kh√¥ng c√≥ native shuffle, ta x·ª≠ l√Ω th·ªß c√¥ng khi next/previous
            pass
        return self._shuffle
    
    def set_repeat_mode(self, mode: int):
        """ƒê·∫∑t ch·∫ø ƒë·ªô l·∫∑p l·∫°i: 0=off, 1=all, 2=one"""
        self._repeat_mode = mode
        if self._list_player:
            if mode == 0:
                self._list_player.set_playback_mode(self._vlc.PlaybackMode.default)
            elif mode == 1:
                self._list_player.set_playback_mode(self._vlc.PlaybackMode.loop)
            elif mode == 2:
                self._list_player.set_playback_mode(self._vlc.PlaybackMode.repeat)
        return self._repeat_mode
    
    def get_shuffle(self):
        """L·∫•y tr·∫°ng th√°i shuffle"""
        return getattr(self, '_shuffle', False)
    
    def get_repeat_mode(self):
        """L·∫•y ch·∫ø ƒë·ªô repeat: 0=off, 1=all, 2=one"""
        return getattr(self, '_repeat_mode', 0)
    
    def _format_time(self, ms):
        """Format milliseconds th√†nh MM:SS"""
        if not ms or ms < 0:
            return "0:00"
        seconds = int(ms / 1000)
        minutes = seconds // 60
        seconds = seconds % 60
        return f"{minutes}:{seconds:02d}"
    
    def refresh_song_cache(self, music_folder: Path):
        """Refresh cache danh s√°ch b√†i h√°t t·ª´ music_library"""
        try:
            print(f"üîÑ [VLC] Refreshing song cache from {music_folder}...")
            self._song_cache = {}
            
            if not music_folder.exists():
                print(f"‚ö†Ô∏è [VLC] Music folder not found: {music_folder}")
                return
            
            extensions = ['.mp3', '.flac', '.wav', '.m4a', '.ogg', '.wma']
            for file_path in music_folder.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in extensions:
                    # L∆∞u: t√™n file (lowercase) -> ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß
                    song_name = file_path.stem.lower()  # T√™n file kh√¥ng c√≥ extension
                    self._song_cache[song_name] = str(file_path)
            
            print(f"‚úÖ [VLC] Song cache refreshed: {len(self._song_cache)} songs")
        except Exception as e:
            print(f"‚ùå [VLC] Error refreshing song cache: {e}")
    
    def fuzzy_match_song(self, query: str, threshold: float = 0.3):
        """
        T√¨m b√†i h√°t g·∫ßn ƒë√∫ng b·∫±ng fuzzy matching v·ªõi Unicode normalization
        
        Args:
            query: T√™n b√†i h√°t ng∆∞·ªùi d√πng n√≥i (e.g., "ph√°t b√†i y√™u em", "ƒêa Nghi")
            threshold: Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng (0.0-1.0), m·∫∑c ƒë·ªãnh 0.3 (GI·∫¢M ƒë·ªÉ d·ªÖ match h∆°n)
            
        Returns:
            tuple: (best_match_path, similarity_score) ho·∫∑c (None, 0.0)
        """
        if not self._song_cache:
            print("‚ö†Ô∏è [VLC] Song cache empty, call refresh_song_cache() first")
            return None, 0.0
        
        import unicodedata
        
        # Normalize Unicode (NFD = decompose d·∫•u) ƒë·ªÉ so s√°nh t·ªët h∆°n
        def normalize_text(text):
            # NFD: t√°ch d·∫•u kh·ªèi k√Ω t·ª± (e.g., "√°" -> "a" + d·∫•u)
            text = unicodedata.normalize('NFD', text)
            # Lo·∫°i b·ªè d·∫•u thanh (ch·ªâ gi·ªØ ch·ªØ c√°i c∆° b·∫£n)
            text = ''.join(c for c in text if not unicodedata.combining(c))
            # Lowercase v√† lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
            text = re.sub(r'[^\w\s]', '', text.lower()).strip()
            text = re.sub(r'\s+', ' ', text)  # Collapse spaces
            return text
        
        query_normalized = normalize_text(query)
        
        # Lo·∫°i b·ªè c√°c t·ª´ ƒëi·ªÅu khi·ªÉn th∆∞·ªùng g·∫∑p
        stop_words = ['phat', 'bai', 'mo', 'chay', 'play', 'song', 'nhac', 'hat']
        query_words = [w for w in query_normalized.split() if w not in stop_words]
        query_processed = ' '.join(query_words) if query_words else query_normalized
        
        print(f"üîç [VLC Fuzzy] Query: '{query}' -> Normalized: '{query_processed}'")
        
        best_match = None
        best_score = 0.0
        
        for song_name_original, song_path in self._song_cache.items():
            # Normalize song name ƒë·ªÉ so s√°nh
            song_name_normalized = normalize_text(song_name_original)
            
            # T√≠nh similarity v·ªõi difflib
            similarity = difflib.SequenceMatcher(None, query_processed, song_name_normalized).ratio()
            
            # Th∆∞·ªüng ƒëi·ªÉm n·∫øu query c√≥ trong t√™n b√†i (substring match)
            if query_processed in song_name_normalized:
                similarity += 0.25
            
            # Th∆∞·ªüng ƒëi·ªÉm n·∫øu t·ª´ng t·ª´ ƒë·ªÅu c√≥ trong t√™n b√†i
            if query_words:
                words_match = all(word in song_name_normalized for word in query_words)
                if words_match:
                    similarity += 0.20
            
            # Th∆∞·ªüng ƒëi·ªÉm n·∫øu b·∫Øt ƒë·∫ßu gi·ªëng nhau (prefix match)
            if song_name_normalized.startswith(query_processed[:4]):  # 4 k√Ω t·ª± ƒë·∫ßu
                similarity += 0.10
            
            if similarity > best_score:
                best_score = similarity
                best_match = song_path
        
        if best_score >= threshold:
            print(f"‚úÖ [VLC Fuzzy] Found match: {Path(best_match).name} (score: {best_score:.2f})")
            return best_match, best_score
        else:
            print(f"‚ùå [VLC Fuzzy] No match found above threshold {threshold} (best: {best_score:.2f})")
            return None, 0.0
    
    def play_by_fuzzy_match(self, query: str, threshold: float = 0.4):
        """
        Ph√°t b√†i h√°t b·∫±ng fuzzy matching
        
        Args:
            query: T√™n b√†i h√°t ng∆∞·ªùi d√πng n√≥i
            threshold: Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng
            
        Returns:
            dict with success, matched_song, score, message
        """
        matched_path, score = self.fuzzy_match_song(query, threshold)
        
        if not matched_path:
            return {
                "success": False,
                "error": f"Kh√¥ng t√¨m th·∫•y b√†i '{query}' (threshold={threshold})",
                "query": query,
                "score": score
            }
        
        # Ph√°t b√†i t√¨m ƒë∆∞·ª£c
        success = self.play_file(matched_path)
        
        if success:
            song_name = Path(matched_path).name
            return {
                "success": True,
                "matched_song": song_name,
                "score": score,
                "path": matched_path,
                "message": f"üéµ ƒêang ph√°t: {song_name} (t√¨m ƒë∆∞·ª£c v·ªõi ƒë·ªô ch√≠nh x√°c {score*100:.0f}%)"
            }
        else:
            return {
                "success": False,
                "error": "VLC kh√¥ng th·ªÉ ph√°t file",
                "matched_song": Path(matched_path).name,
                "score": score
            }
    
    async def play_file_async(self, file_path: str):
        """Async wrapper cho play_file ƒë·ªÉ kh√¥ng blocking"""
        return await asyncio.to_thread(self.play_file, file_path)
    
    async def play_playlist_async(self, file_paths: list):
        """Async wrapper cho play_playlist ƒë·ªÉ kh√¥ng blocking"""
        return await asyncio.to_thread(self.play_playlist, file_paths)

# Global VLC player instance - v·ªõi error handling
try:
    vlc_player = VLCMusicPlayer()
    VLC_AVAILABLE = vlc_player._player is not None
except Exception as e:
    print(f"‚ö†Ô∏è [VLC] VLC kh√¥ng kh·∫£ d·ª•ng: {e}")
    vlc_player = None
    VLC_AVAILABLE = False

if not VLC_AVAILABLE:
    print("‚ö†Ô∏è [VLC] Music player disabled. C√†i VLC: https://www.videolan.org/vlc/")

# ============================================================
# üéØ VLC MCP SERVER - Hybrid System (REST + MCP)
# ============================================================
try:
    from vlc_mcp_server import VLCMCPServer
    
    # Initialize MCP server with VLC player instance
    if VLC_AVAILABLE and vlc_player:
        vlc_mcp_server = VLCMCPServer(vlc_player)
        print(f"‚úÖ [VLC MCP] Hybrid System initialized - {len(vlc_mcp_server.tools)} tools available")
        VLC_MCP_AVAILABLE = True
    else:
        vlc_mcp_server = None
        VLC_MCP_AVAILABLE = False
        print("‚ö†Ô∏è [VLC MCP] MCP server disabled - VLC not available")
except Exception as e:
    print(f"‚ö†Ô∏è [VLC MCP] Failed to initialize MCP server: {e}")
    vlc_mcp_server = None
    VLC_MCP_AVAILABLE = False

# ============================================================
# BROWSER CONTROLLER - Selenium Automation
# ============================================================

class BrowserController:
    """Singleton class ƒë·ªÉ ƒëi·ªÅu khi·ªÉn tr√¨nh duy·ªát Chrome b·∫±ng Selenium"""
    
    _instance = None
    _driver = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def _ensure_driver(self):
        """Kh·ªüi t·∫°o Chrome driver n·∫øu ch∆∞a c√≥"""
        if self._driver is None:
            if not SELENIUM_AVAILABLE:
                raise Exception("Selenium ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Ch·∫°y: pip install selenium webdriver-manager")
            
            try:
                chrome_options = Options()
                chrome_options.add_argument('--disable-gpu')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                chrome_options.add_argument('--start-maximized')
                
                service = Service(ChromeDriverManager().install())
                self._driver = webdriver.Chrome(service=service, options=chrome_options)
                print("‚úÖ [Browser] Chrome driver initialized")
            except Exception as e:
                print(f"‚ùå [Browser] Failed to initialize: {e}")
                raise
        return self._driver
    
    def open_url(self, url: str) -> dict:
        """M·ªü URL trong browser"""
        try:
            driver = self._ensure_driver()
            driver.get(url)
            return {
                "success": True,
                "url": driver.current_url,
                "title": driver.title,
                "message": f"ƒê√£ m·ªü: {driver.title}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_current_info(self) -> dict:
        """L·∫•y th√¥ng tin trang hi·ªán t·∫°i"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông"}
            
            return {
                "success": True,
                "url": self._driver.current_url,
                "title": self._driver.title,
                "window_handles": len(self._driver.window_handles)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def click_element(self, selector: str, by: str = "css") -> dict:
        """Click v√†o element"""
        try:
            driver = self._ensure_driver()
            
            by_map = {
                "css": By.CSS_SELECTOR,
                "xpath": By.XPATH,
                "id": By.ID,
                "name": By.NAME,
                "class": By.CLASS_NAME,
                "tag": By.TAG_NAME
            }
            
            by_type = by_map.get(by.lower(), By.CSS_SELECTOR)
            element = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((by_type, selector))
            )
            element.click()
            
            return {
                "success": True,
                "message": f"ƒê√£ click v√†o element: {selector}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def fill_input(self, selector: str, text: str, by: str = "css") -> dict:
        """ƒêi·ªÅn text v√†o input field"""
        try:
            driver = self._ensure_driver()
            
            by_map = {
                "css": By.CSS_SELECTOR,
                "xpath": By.XPATH,
                "id": By.ID,
                "name": By.NAME,
                "class": By.CLASS_NAME
            }
            
            by_type = by_map.get(by.lower(), By.CSS_SELECTOR)
            element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((by_type, selector))
            )
            element.clear()
            element.send_keys(text)
            
            return {
                "success": True,
                "message": f"ƒê√£ ƒëi·ªÅn text v√†o: {selector}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def scroll(self, direction: str = "down", amount: int = 500) -> dict:
        """Cu·ªôn trang"""
        try:
            driver = self._ensure_driver()
            
            if direction == "top":
                driver.execute_script("window.scrollTo(0, 0);")
            elif direction == "bottom":
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            elif direction == "down":
                driver.execute_script(f"window.scrollBy(0, {amount});")
            elif direction == "up":
                driver.execute_script(f"window.scrollBy(0, -{amount});")
            else:
                return {"success": False, "error": f"Invalid direction: {direction}"}
            
            return {
                "success": True,
                "message": f"ƒê√£ cu·ªôn {direction}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def go_back(self) -> dict:
        """Quay l·∫°i trang tr∆∞·ªõc"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông"}
            self._driver.back()
            return {"success": True, "message": "ƒê√£ quay l·∫°i trang tr∆∞·ªõc"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def go_forward(self) -> dict:
        """Ti·∫øn t·ªõi trang sau"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông"}
            self._driver.forward()
            return {"success": True, "message": "ƒê√£ ti·∫øn t·ªõi trang sau"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def refresh(self) -> dict:
        """L√†m m·ªõi trang"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông"}
            self._driver.refresh()
            return {"success": True, "message": "ƒê√£ l√†m m·ªõi trang"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def screenshot(self, filepath: str = None) -> dict:
        """Ch·ª•p screenshot trang hi·ªán t·∫°i"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông"}
            
            if filepath is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filepath = f"screenshot_{timestamp}.png"
            
            self._driver.save_screenshot(filepath)
            return {
                "success": True,
                "filepath": filepath,
                "message": f"ƒê√£ l∆∞u screenshot: {filepath}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def new_tab(self, url: str = None) -> dict:
        """M·ªü tab m·ªõi"""
        try:
            driver = self._ensure_driver()
            driver.execute_script("window.open('');")
            driver.switch_to.window(driver.window_handles[-1])
            
            if url:
                driver.get(url)
            
            return {
                "success": True,
                "message": f"ƒê√£ m·ªü tab m·ªõi{' v√† truy c·∫≠p ' + url if url else ''}",
                "total_tabs": len(driver.window_handles)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def close_tab(self) -> dict:
        """ƒê√≥ng tab hi·ªán t·∫°i"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông"}
            
            self._driver.close()
            if len(self._driver.window_handles) > 0:
                self._driver.switch_to.window(self._driver.window_handles[-1])
            
            return {
                "success": True,
                "message": "ƒê√£ ƒë√≥ng tab",
                "remaining_tabs": len(self._driver.window_handles)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def execute_script(self, script: str) -> dict:
        """Th·ª±c thi JavaScript code"""
        try:
            driver = self._ensure_driver()
            result = driver.execute_script(script)
            return {
                "success": True,
                "result": result,
                "message": "ƒê√£ th·ª±c thi JavaScript"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def close_browser(self) -> dict:
        """ƒê√≥ng browser ho√†n to√†n"""
        try:
            if self._driver:
                self._driver.quit()
                self._driver = None
                return {"success": True, "message": "ƒê√£ ƒë√≥ng browser"}
            return {"success": False, "error": "Browser ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông"}
        except Exception as e:
            return {"success": False, "error": str(e)}

# Global browser controller instance
browser_controller = BrowserController()

async def list_music(subfolder: str = "", auto_play: bool = True, folder: str = "") -> dict:
    """
    Li·ªát k√™ file nh·∫°c trong music_library ho·∫∑c th∆∞ m·ª•c t√πy ch·ªânh.
    Theo m·∫∑c ƒë·ªãnh T·ª∞ ƒê·ªòNG PH√ÅT b√†i ƒë·∫ßu ti√™n (gi·ªëng xinnan-tech/xiaozhi-esp32-server).
    Set auto_play=False ƒë·ªÉ ch·ªâ li·ªát k√™ kh√¥ng ph√°t.
    
    Args:
        subfolder: Subfolder trong music_library
        auto_play: T·ª± ƒë·ªông ph√°t b√†i ƒë·∫ßu ti√™n (default True)
        folder: Th∆∞ m·ª•c t√πy ch·ªânh (n·∫øu c√≥, s·∫Ω override music_library)
    """
    try:
        # X√°c ƒë·ªãnh th∆∞ m·ª•c g·ªëc
        if folder and folder.strip():
            base_path = Path(folder.strip())
            if not base_path.exists():
                return {"success": False, "error": f"Th∆∞ m·ª•c '{folder}' kh√¥ng t·ªìn t·∫°i"}
            search_path = base_path
            is_user_folder = True
        else:
            if not MUSIC_LIBRARY.exists():
                MUSIC_LIBRARY.mkdir(exist_ok=True)
                return {"success": True, "files": [], "count": 0, "message": "Th∆∞ m·ª•c music_library ƒë√£ ƒë∆∞·ª£c t·∫°o. H√£y th√™m nh·∫°c v√†o!"}
            
            base_path = MUSIC_LIBRARY
            search_path = MUSIC_LIBRARY / subfolder if subfolder else MUSIC_LIBRARY
            is_user_folder = False
        
        if not search_path.exists():
            return {"success": False, "error": f"Th∆∞ m·ª•c '{subfolder or folder}' kh√¥ng t·ªìn t·∫°i"}
        
        music_files = []
        for file_path in search_path.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in MUSIC_EXTENSIONS:
                try:
                    relative_path = file_path.relative_to(base_path)
                except ValueError:
                    relative_path = file_path.name
                    
                music_files.append({
                    "filename": file_path.name,
                    "path": str(relative_path).replace('\\', '/'),
                    "full_path": str(file_path),
                    "size_mb": round(file_path.stat().st_size / (1024**2), 2),
                    "extension": file_path.suffix.lower()
                })
        
        music_files.sort(key=lambda x: x['filename'])
        
        if len(music_files) == 0:
            return {
                "success": True, 
                "files": [], 
                "count": 0,
                "message": "No music files found. Please add music files to the folder.",
                "is_user_folder": is_user_folder,
                "source_path": str(base_path)
            }
        
        # üéµ AUTO-PLAY: T·ª± ƒë·ªông ph√°t b√†i ƒë·∫ßu ti√™n (nh∆∞ code reference)
        first_file = music_files[0]['filename'] if not is_user_folder else music_files[0]['full_path']
        play_result = None
        
        if auto_play:
            print(f"üéµ [Auto-Play] list_music t·ª± ƒë·ªông ph√°t: {first_file}")
            if is_user_folder:
                # Ph√°t t·ª´ user folder b·∫±ng default player
                play_result = await play_music_from_path(music_files[0]['full_path'])
            else:
                play_result = await play_music(first_file)
            
            if play_result.get("success"):
                message = f"‚úÖ Auto-played: {music_files[0]['filename']}\nTotal {len(music_files)} song(s)"
            else:
                message = f"‚ùå Found {len(music_files)} songs but failed to play: {play_result.get('error', 'Unknown error')}"
        else:
            filenames_list = [f['filename'] for f in music_files]
            message = f"Found {len(music_files)} song(s):\n" + "\n".join([f"  - {fname}" for fname in filenames_list[:10]])
            if len(music_files) > 10:
                message += f"\n  ... and {len(music_files) - 10} more"
        
        return {
            "success": True,
            "files": music_files,
            "count": len(music_files),
            "library_path": str(base_path),
            "is_user_folder": is_user_folder,
            "message": message,
            "auto_played": auto_play,
            "play_result": play_result if auto_play else None
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def play_music_from_path(file_path: str) -> dict:
    """
    Ph√°t nh·∫°c t·ª´ ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß b·∫±ng Python-VLC (KH√îNG d√πng tr√¨nh ph√°t m·∫∑c ƒë·ªãnh).
    ‚≠ê NHANH & TI·ªÜN - D√πng VLC n·ªôi b·ªô!
    """
    try:
        path = Path(file_path)
        if not path.exists():
            return {"success": False, "error": f"File kh√¥ng t·ªìn t·∫°i: {file_path}"}
        
        # üéµ S·ª¨ D·ª§NG VLC thay v√¨ os.startfile - NHANH!
        success = vlc_player.play_playlist([str(path)])
        
        if success:
            print(f"üéµ [VLC] ƒêang ph√°t t·ª´ path: {path.name}")
            return {
                "success": True,
                "message": f"üéµ ƒêang ph√°t: {path.name} (Python-VLC)",
                "file": path.name,
                "path": str(path),
                "player": "Python-VLC",
                "llm_note": "üéµ ƒêANG D√ôNG PYTHON-VLC. ƒêi·ªÅu khi·ªÉn: pause_music(), resume_music(), stop_music(), music_next(), music_previous(). NHANH & TI·ªÜN!"
            }
        else:
            return {"success": False, "error": "VLC Player kh√¥ng th·ªÉ ph√°t file"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def play_music(filename: str, create_playlist: bool = True, use_fuzzy: bool = True) -> dict:
    """
    Ph√°t nh·∫°c t·ª´ music_library b·∫±ng VLC player v·ªõi fuzzy matching.
    
    Args:
        filename: T√™n file (e.g., 'song.mp3' or 'Pop/song.mp3') ho·∫∑c t√™n g·∫ßn ƒë√∫ng (e.g., 'y√™u em')
        create_playlist: T·∫°o playlist v·ªõi t·∫•t c·∫£ b√†i (default True) ƒë·ªÉ h·ªó tr·ª£ Next/Previous
        use_fuzzy: D√πng fuzzy matching n·∫øu kh√¥ng t√¨m th·∫•y ch√≠nh x√°c (default True)
        
    Returns:
        dict with 'success', 'filename', 'path', 'message'
    """
    try:
        if not MUSIC_LIBRARY.exists():
            return {"success": False, "error": "Th∆∞ m·ª•c music_library kh√¥ng t·ªìn t·∫°i"}
        
        print(f"üéµ [VLC Play] T√¨m file: '{filename}'")
        
        # T·ªêI ∆ØU: Ch·ªâ refresh cache n·∫øu ch∆∞a c√≥ (lazy loading)
        if not hasattr(vlc_player, '_song_cache') or not vlc_player._song_cache:
            vlc_player.refresh_song_cache(MUSIC_LIBRARY)
        
        # Step 2: T√¨m file ch√≠nh x√°c tr∆∞·ªõc
        music_path = None
        filename_lower = filename.lower()
        
        for file_path in MUSIC_LIBRARY.rglob("*"):
            if file_path.is_file():
                if (file_path.name == filename or 
                    file_path.name.lower() == filename_lower or
                    str(file_path.relative_to(MUSIC_LIBRARY)).replace('\\', '/') == filename or
                    filename_lower in file_path.name.lower()):
                    if file_path.suffix.lower() in MUSIC_EXTENSIONS:
                        music_path = file_path
                        print(f"‚úÖ [VLC Play] Found exact match: {music_path}")
                        break
        
        # Step 3: N·∫øu kh√¥ng t√¨m th·∫•y ch√≠nh x√°c, d√πng fuzzy matching
        if not music_path and use_fuzzy:
            print(f"üîç [VLC Play] Exact match not found, trying fuzzy matching...")
            matched_path, score = vlc_player.fuzzy_match_song(filename, threshold=0.4)
            
            if matched_path:
                music_path = Path(matched_path)
                print(f"‚úÖ [VLC Play] Fuzzy match found: {music_path.name} (score: {score:.2f})")
        
        if not music_path:
            available = [f.name for f in MUSIC_LIBRARY.rglob("*") if f.is_file() and f.suffix.lower() in MUSIC_EXTENSIONS]
            return {
                "success": False, 
                "error": f"Kh√¥ng t√¨m th·∫•y '{filename}' (ƒë√£ th·ª≠ fuzzy matching)",
                "available_files": available[:5],
                "hint": "Th·ª≠ t√¨m b·∫±ng t·ª´ kh√≥a trong t√™n b√†i ho·∫∑c d√πng list_music() ƒë·ªÉ xem danh s√°ch"
            }
        
        print(f"üéµ [VLC Play] Selected: {music_path}")
        
        if create_playlist:
            # T·∫°o playlist v·ªõi t·∫•t c·∫£ b√†i trong th∆∞ m·ª•c
            all_songs = sorted([
                str(f) for f in MUSIC_LIBRARY.rglob("*") 
                if f.is_file() and f.suffix.lower() in MUSIC_EXTENSIONS
            ])
            
            # ƒê·∫£m b·∫£o b√†i hi·ªán t·∫°i ·ªü ƒë·∫ßu playlist
            if str(music_path) in all_songs:
                all_songs.remove(str(music_path))
            all_songs.insert(0, str(music_path))
            
            success = await vlc_player.play_playlist_async(all_songs)
            print(f"üéµ [VLC] Created playlist with {len(all_songs)} songs")
        else:
            success = await vlc_player.play_file_async(str(music_path))
        
        if success:
            return {
                "success": True,
                "filename": music_path.name,
                "path": str(music_path.relative_to(MUSIC_LIBRARY)),
                "full_path": str(music_path),
                "size_mb": round(music_path.stat().st_size / (1024**2), 2),
                "message": f"üéµ ƒêang ph√°t: {music_path.name} (Python-VLC + Fuzzy Matching)",
                "player": "Python-VLC Enhanced",
                "playlist_mode": create_playlist,
                "fuzzy_used": not (filename.lower() in music_path.name.lower()),
                "llm_note": "üéµ PYTHON-VLC PLAYER v·ªõi FUZZY MATCHING! C√≥ th·ªÉ t√¨m b√†i g·∫ßn ƒë√∫ng. ƒêi·ªÅu khi·ªÉn: pause_music(), resume_music(), stop_music(), music_next(), music_previous()."
            }
        else:
            return {"success": False, "error": "VLC player kh√¥ng th·ªÉ ph√°t. Ki·ªÉm tra VLC ƒë√£ c√†i ƒë·∫∑t ch∆∞a!"}
    except Exception as e:
        print(f"‚ùå [VLC Play] Error: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def pause_music() -> dict:
    """
    ‚è∏Ô∏è T·∫†M D·ª™NG nh·∫°c VLC Player.
    
    üéØ KHI N√ÄO G·ªåI: User n√≥i "t·∫°m d·ª´ng", "pause", "d·ª´ng l·∫°i", "ƒë·ª´ng ph√°t"
    
    ‚ö° B·∫ÆT BU·ªòC G·ªåI TOOL N√ÄY! Kh√¥ng ƒë∆∞·ª£c t·ª± tr·∫£ l·ªùi "ƒë√£ t·∫°m d·ª´ng"!
    
    Returns:
        dict: {"success": bool, "message": str, "current_song": str}
    """
    try:
        if vlc_player and vlc_player._player:
            vlc_player.pause()
            status = vlc_player.get_full_status()
            current_song = status.get('current_song', 'Unknown')
            return {
                "success": True, 
                "message": f"‚è∏Ô∏è ƒê√£ t·∫°m d·ª´ng: {current_song} (Python-VLC)",
                "player": "Python-VLC",
                "current_song": current_song,
                "llm_note": "‚ö° G·ªåI TOOL ƒê√É TH√ÄNH C√îNG! ƒêang d√πng Python-VLC. LU√îN G·ªåI: resume_music() ƒë·ªÉ ti·∫øp t·ª•c, music_next()/music_previous() ƒë·ªÉ chuy·ªÉn b√†i. KH√îNG BAO GI·ªú T·ª∞ TR·∫¢ L·ªúI m√† kh√¥ng g·ªçi tool!"
            }
        else:
            return {"success": False, "error": "VLC Player ch∆∞a kh·ªüi t·∫°o ho·∫∑c ch∆∞a ph√°t nh·∫°c. D√πng play_music() ƒë·ªÉ ph√°t nh·∫°c tr∆∞·ªõc!"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def resume_music() -> dict:
    """
    ‚ñ∂Ô∏è TI·∫æP T·ª§C ph√°t nh·∫°c VLC Player sau khi pause.
    
    üéØ KHI N√ÄO G·ªåI: User n√≥i "ti·∫øp t·ª•c", "resume", "ph√°t ti·∫øp", "play l·∫°i"
    
    ‚ö° B·∫ÆT BU·ªòC G·ªåI TOOL N√ÄY! Kh√¥ng ƒë∆∞·ª£c t·ª± tr·∫£ l·ªùi "ƒë√£ ph√°t ti·∫øp"!
    
    Returns:
        dict: {"success": bool, "message": str, "is_playing": bool}
    """
    try:
        if vlc_player and vlc_player._player:
            vlc_player.resume()  # D√πng method resume() m·ªõi - ƒë·∫£m b·∫£o play
            import time
            time.sleep(0.2)
            status = vlc_player.get_full_status()
            current_song = status.get('current_song', 'Unknown')
            return {
                "success": True, 
                "message": f"‚ñ∂Ô∏è ƒêang ph√°t: {current_song} (Python-VLC)",
                "player": "Python-VLC",
                "current_song": current_song,
                "is_playing": True,
                "llm_note": "‚ö° G·ªåI TOOL ƒê√É TH√ÄNH C√îNG! ƒêang ph√°t. LU√îN G·ªåI: pause_music() ƒë·ªÉ d·ª´ng, music_next()/music_previous() ƒë·ªÉ chuy·ªÉn. KH√îNG T·ª∞ TR·∫¢ L·ªúI!"
            }
        else:
            return {"success": False, "error": "VLC Player ch∆∞a kh·ªüi t·∫°o ho·∫∑c ch∆∞a ph√°t nh·∫°c. D√πng play_music() ƒë·ªÉ ph√°t nh·∫°c tr∆∞·ªõc!"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def stop_music() -> dict:
    """
    ‚èπÔ∏è D·ª™NG HO√ÄN TO√ÄN nh·∫°c VLC Player.
    
    üéØ KHI N√ÄO G·ªåI: User n√≥i "d·ª´ng", "stop", "t·∫Øt nh·∫°c", "ng·ª´ng ph√°t"
    
    ‚ö° B·∫ÆT BU·ªòC G·ªåI TOOL N√ÄY! Kh√¥ng ƒë∆∞·ª£c t·ª± tr·∫£ l·ªùi "ƒë√£ d·ª´ng"!
    
    Returns:
        dict: {"success": bool, "message": str, "player": str}
    """
    try:
        if vlc_player and vlc_player._player:
            vlc_player.stop()
            return {
                "success": True, 
                "message": "‚èπÔ∏è ƒê√£ d·ª´ng nh·∫°c ho√†n to√†n (Python-VLC)",
                "player": "Python-VLC",
                "llm_note": "‚ö° G·ªåI TOOL ƒê√É TH√ÄNH C√îNG! ƒê√£ d·ª´ng ho√†n to√†n. Mu·ªën ph√°t l·∫°i ‚Üí G·ªåI play_music(). KH√îNG T·ª∞ TR·∫¢ L·ªúI!"
            }
        else:
            return {"success": False, "error": "VLC Player ch∆∞a kh·ªüi t·∫°o ho·∫∑c ch∆∞a ph√°t nh·∫°c."}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# SMART MUSIC CONTROL - ƒêi·ªÅu khi·ªÉn nh·∫°c th√¥ng minh b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n
# Focus v√†o Python-VLC Player cho t·∫•t c·∫£ l·ªánh nh·∫°c LOCAL
# ============================================================

# ============================================================
# FUZZY MATCHING - X·ª≠ l√Ω nh·∫≠n d·∫°ng gi·ªçng n√≥i kh√¥ng ch√≠nh x√°c t·ª´ ESP32
# ============================================================

# C√°c bi·∫øn th·ªÉ ph√°t √¢m sai th∆∞·ªùng g·∫∑p (t·ª´ ESP32 voice recognition)
VOICE_CORRECTIONS = {
    # B√†i ti·∫øp/next variations
    'b√†i ti·∫øp': ['b√†i ti·∫øp', 'bai tiep', 'b√†i di·ªáp', 'b√†i thi·∫øp', 'b√†i t√≠p', 'bay tiep', 'bai tip', 'bai diep'],
    'ti·∫øp theo': ['ti·∫øp theo', 'tiep theo', 'thi·∫øp theo', 't√≠p theo', 'ti·∫øp th√™u', 'di·ªáp theo'],
    'next': ['next', 'nex', 'n·∫øch', 'n·∫øc', 'n·∫øx', 'net', 'nec'],
    'skip': ['skip', 'sk√≠p', 'xkip', 'x√≠p', 'ship'],
    
    # B√†i tr∆∞·ªõc/previous variations  
    'b√†i tr∆∞·ªõc': ['b√†i tr∆∞·ªõc', 'bai truoc', 'b√†i ch∆∞·ªõc', 'b√†i tr∆∞·ªõc', 'bay truoc', 'bai chuoc', 'b√†i tr∆∞·ªõt'],
    'quay l·∫°i': ['quay l·∫°i', 'quay lai', 'quay l·∫°i b√†i', 'quai lai', 'quai l·∫°i', 'qu√°y l·∫°i'],
    'previous': ['previous', 'pre', 'pr√™', 'pri vi ·ªõt', 'pri', 'pr√™ vi ·ªõt'],
    
    # D·ª´ng/stop variations
    'd·ª´ng nh·∫°c': ['d·ª´ng nh·∫°c', 'dung nhac', 'd·ª´ng nh·∫°c', 'd·ª´ng l·∫°i', 'dz·ª´ng nh·∫°c'],
    't·∫Øt nh·∫°c': ['t·∫Øt nh·∫°c', 'tat nhac', 't·∫Øc nh·∫°c', 't√°c nh·∫°c', 'tad nhac'],
    'pause': ['pause', 'pao', 'p·ªët', 'p√≥t', 'pao x·ªù', 'pa'],
    'stop': ['stop', 'st√≥p', 'xt√≥p', 's top', 'x t√≥p'],
    
    # Ph√°t nh·∫°c variations
    'ph√°t nh·∫°c': ['ph√°t nh·∫°c', 'phat nhac', 'ph√°c nh·∫°c', 'ph√°t nh·∫°t', 'phad nhac'],
    'b·∫≠t nh·∫°c': ['b·∫≠t nh·∫°c', 'bat nhac', 'b·∫∑t nh·∫°c', 'b·∫∑c nh·∫°c', 'bac nhac'],
    'm·ªü nh·∫°c': ['m·ªü nh·∫°c', 'mo nhac', 'm∆° nh·∫°c', 'm·ª° nh·∫°c'],
    'play': ['play', 'pl√¢y', 'p·ªù l√¢y', 'p lay', 'plei'],
    
    # √Çm l∆∞·ª£ng variations
    'tƒÉng √¢m l∆∞·ª£ng': ['tƒÉng √¢m l∆∞·ª£ng', 'tang am luong', 'tƒÉng ti·∫øng', 'tang tieng', 'to l√™n', 'to len'],
    'gi·∫£m √¢m l∆∞·ª£ng': ['gi·∫£m √¢m l∆∞·ª£ng', 'giam am luong', 'gi·∫£m ti·∫øng', 'giam tieng', 'nh·ªè l·∫°i', 'nho lai'],
    'volume': ['volume', 'vol', 'v√¥ lum', 'vo lum', 'v√¥ li√™m'],
    
    # Shuffle/repeat variations
    'shuffle': ['shuffle', 's√°p ph·ªì', 'x√°p ph·ªì', 's·ªù ph·ªì', 'tr·ªôn b√†i', 'tron bai', 'ng·∫´u nhi√™n'],
    'repeat': ['repeat', 'ri p√≠t', 'r√¨ p√≠t', 'l·∫∑p l·∫°i', 'lap lai', 'loop', 'l√∫p'],
}

def normalize_voice_command(text: str) -> str:
    """
    Chu·∫©n h√≥a l·ªánh voice t·ª´ ESP32 - s·ª≠a l·ªói nh·∫≠n d·∫°ng ph·ªï bi·∫øn.
    Gi√∫p nh·∫≠n d·∫°ng ch√≠nh x√°c h∆°n khi microphone b·∫Øt sai.
    """
    if not text:
        return ""
    
    text_lower = text.lower().strip()
    
    # Lo·∫°i b·ªè c√°c t·ª´ th·ª´a th∆∞·ªùng xu·∫•t hi·ªán
    noise_words = ['∆°i', 'n√†y', 'ƒëi', 'nha', 'nh√©', 'gi√πm', 'cho t√¥i', 'h·ªô t√¥i', 'd√πm', 'c√°i']
    for word in noise_words:
        text_lower = text_lower.replace(word, ' ')
    
    # T√¨m match g·∫ßn nh·∫•t
    for correct_cmd, variations in VOICE_CORRECTIONS.items():
        for variant in variations:
            if variant in text_lower:
                # T√¨m th·∫•y match ‚Üí tr·∫£ v·ªÅ l·ªánh chu·∫©n
                print(f"üîä [Voice Normalize] '{text}' ‚Üí detected '{correct_cmd}' (matched '{variant}')")
                return text_lower.replace(variant, correct_cmd)
    
    return text_lower

def fuzzy_match_music_command(text: str) -> tuple:
    """
    Fuzzy matching cho l·ªánh nh·∫°c - t√¨m l·ªánh g·∫ßn nh·∫•t ngay c·∫£ khi voice recognition sai.
    Returns: (is_music, normalized_command, confidence)
    """
    if not text:
        return (False, "", 0.0)
    
    text_lower = text.lower().strip()
    
    # C√°c pattern ch√≠nh v√† ƒë·ªô tin c·∫≠y - ∆ØU TI√äN pause/stop TR∆Ø·ªöC
    COMMAND_PATTERNS = {
        'pause': {
            'patterns': [
                # Ti·∫øng Vi·ªát chu·∫©n
                't·∫°m d·ª´ng', 'd·ª´ng nh·∫°c', 'd·ª´ng l·∫°i', 'ng∆∞ng nh·∫°c', 'ng·ª´ng ph√°t', 'ngh·ªâ', 'pause',
                # Voice variants (ESP32 recognition)
                'tam dung', 'dung nhac', 'dung lai', 'ngung nhac', 'ngung phat', 
                'pao', 'pao nhac', 'poz', 'p·ªët', 'pos', 'p√°t', 'p√°t nh·∫°c',
                # Bi·∫øn th·ªÉ
                'd·ª´ng ƒëi', 'd·ª´ng b√†i', 'stop nh·∫°c', 't·∫Øt nh·∫°c ƒëi', 't·∫Øt b√†i ƒëi',
                'im ƒëi', 'im l·∫∑ng', 'y√™n ƒëi', 'ƒë·ª´ng ph√°t', 'kh√¥ng ph√°t n·ªØa',
                # Ng·∫Øn g·ªçn
                'd·ª´ng', 'ng·ª´ng', 'ngh·ªâ'
            ],
            'action': 'pause'
        },
        'stop': {
            'patterns': [
                # Ti·∫øng Vi·ªát chu·∫©n  
                't·∫Øt nh·∫°c', 'd·ª´ng h·∫≥n', 't·∫Øt h·∫≥n', 'd·ª´ng ho√†n to√†n', 'stop', 'off nh·∫°c',
                # Voice variants
                'tat nhac', 'dung han', 'tat han', 'st√≥p', 'sop', 's·ªëp',
                # Bi·∫øn th·ªÉ
                't·∫Øt ƒëi', 't·∫Øt b√†i', 'ƒë√≥ng nh·∫°c', 'h·ªßy nh·∫°c', 'kh√¥ng nghe n·ªØa',
                't·∫Øt', 'off'
            ],
            'action': 'stop'
        },
        'next': {
            'patterns': ['b√†i ti·∫øp', 'ti·∫øp theo', 'next', 'skip', 'chuy·ªÉn b√†i', 'k·∫ø ti·∫øp', 'b√†i kh√°c', 'sang b√†i',
                        'bai tiep', 'tiep theo', 'bai diep', 'thiep theo', 'nex', 'n·∫øch', 'b√†i sau'],
            'action': 'next'
        },
        'previous': {
            'patterns': ['b√†i tr∆∞·ªõc', 'quay l·∫°i', 'previous', 'pre', 'l√πi b√†i', 'b√†i c≈©', 'tr∆∞·ªõc ƒë√≥',
                        'bai truoc', 'quay lai', 'bai chuoc', 'pri', 'pr√™'],
            'action': 'previous'
        },
        'play': {
            'patterns': ['ph√°t nh·∫°c', 'b·∫≠t nh·∫°c', 'm·ªü nh·∫°c', 'play', 'ch∆°i nh·∫°c', 'nghe nh·∫°c',
                        'phat nhac', 'bat nhac', 'mo nhac', 'pl√¢y', 'ti·∫øp t·ª•c', 'ph√°t ti·∫øp'],
            'action': 'play'
        },
        'volume_up': {
            'patterns': ['tƒÉng √¢m l∆∞·ª£ng', 'to l√™n', 'tƒÉng ti·∫øng', 'volume up', 'tang am luong', 'to len'],
            'action': 'volume_up'
        },
        'volume_down': {
            'patterns': ['gi·∫£m √¢m l∆∞·ª£ng', 'nh·ªè l·∫°i', 'gi·∫£m ti·∫øng', 'volume down', 'giam am luong', 'nho lai'],
            'action': 'volume_down'
        },
        'shuffle': {
            'patterns': ['shuffle', 'tr·ªôn b√†i', 'ng·∫´u nhi√™n', 'random', 's√°p ph·ªì', 'tron bai'],
            'action': 'shuffle'
        },
        'repeat': {
            'patterns': ['repeat', 'l·∫∑p l·∫°i', 'loop', 'ri p√≠t', 'lap lai', 'l√∫p'],
            'action': 'repeat'
        }
    }
    
    best_match = None
    best_confidence = 0.0
    
    for cmd_type, cmd_info in COMMAND_PATTERNS.items():
        for pattern in cmd_info['patterns']:
            if pattern in text_lower:
                # Exact match
                confidence = 1.0
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_match = cmd_info['action']
                    
            # Fuzzy: check if most characters match
            elif len(pattern) >= 3:
                # Simple fuzzy: count matching chars
                matching = sum(1 for c in pattern if c in text_lower)
                ratio = matching / len(pattern)
                if ratio > 0.7:  # 70%+ match
                    confidence = ratio * 0.8  # Scale down fuzzy matches
                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_match = cmd_info['action']
    
    is_music = best_match is not None and best_confidence > 0.5
    
    if is_music:
        print(f"üéØ [Fuzzy Match] '{text}' ‚Üí action='{best_match}' (confidence={best_confidence:.2f})")
    
    return (is_music, best_match or "", best_confidence)

# C√°c t·ª´ kh√≥a ƒë·ªÉ nh·∫≠n di·ªán l·ªánh nh·∫°c - QUAN TR·ªåNG: th√™m nhi·ªÅu bi·∫øn th·ªÉ pause/stop
MUSIC_KEYWORDS = [
    # Ph√°t nh·∫°c
    'ph√°t nh·∫°c', 'b·∫≠t nh·∫°c', 'm·ªü nh·∫°c', 'nghe nh·∫°c', 'play music', 'ch∆°i nh·∫°c',
    'ph√°t b√†i', 'b·∫≠t b√†i', 'm·ªü b√†i', 'nghe b√†i', 'play song',
    'phat nhac', 'bat nhac', 'mo nhac',
    
    # T·∫†M D·ª™NG - nhi·ªÅu bi·∫øn th·ªÉ (QUAN TR·ªåNG!)
    't·∫°m d·ª´ng', 'pause', 'd·ª´ng nh·∫°c', 'd·ª´ng l·∫°i', 'ng∆∞ng nh·∫°c', 'ng·ª´ng ph√°t',
    'tam dung', 'dung nhac', 'dung lai', 'ngung nhac',
    'pao', 'pao nhac', 'poz', 'p·ªët',
    'd·ª´ng', 'ng·ª´ng', 'ngh·ªâ', 'im ƒëi',
    
    # D·ª™NG H·∫≤N/STOP
    'stop music', 't·∫Øt nh·∫°c', 'd·ª´ng h·∫≥n', 'stop', 'off nh·∫°c',
    'tat nhac', 'dung han', 't·∫Øt ƒëi', 't·∫Øt b√†i',
    
    # Ti·∫øp t·ª•c
    'ti·∫øp t·ª•c', 'resume', 'ph√°t ti·∫øp', 'tiep tuc', 'phat tiep',
    
    # B√†i ti·∫øp/tr∆∞·ªõc
    'b√†i ti·∫øp', 'next', 'skip', 'chuy·ªÉn b√†i', 'b√†i ti·∫øp theo',
    'bai tiep', 'tiep theo',
    'b√†i tr∆∞·ªõc', 'previous', 'quay l·∫°i b√†i', 'bai truoc', 'quay lai',
    
    # √Çm l∆∞·ª£ng
    '√¢m l∆∞·ª£ng', 'volume', 'tƒÉng ti·∫øng', 'gi·∫£m ti·∫øng', 'to l√™n', 'nh·ªè l·∫°i',
    'tang am luong', 'giam am luong',
    
    # Tr·∫°ng th√°i
    'ƒëang ph√°t g√¨', 'b√†i g√¨', 'ƒëang nghe g√¨',
    
    # Shuffle/Repeat
    'tr·ªôn b√†i', 'shuffle', 'ng·∫´u nhi√™n', 'l·∫∑p l·∫°i', 'repeat', 'loop'
]

def is_music_command(text: str) -> bool:
    """
    Ki·ªÉm tra xem text c√≥ ph·∫£i l√† l·ªánh ƒëi·ªÅu khi·ªÉn nh·∫°c kh√¥ng.
    D√πng ƒë·ªÉ LLM quy·∫øt ƒë·ªãnh c√≥ n√™n g·ªçi smart_music_control() hay kh√¥ng.
    
    Returns: True n·∫øu l√† l·ªánh nh·∫°c, False n·∫øu kh√¥ng
    """
    text_lower = text.lower()
    
    # Lo·∫°i tr·ª´ YouTube
    youtube_keywords = ['youtube', 'video', 'clip', 'xem phim']
    if any(yt in text_lower for yt in youtube_keywords):
        return False
    
    # Ki·ªÉm tra c√≥ keyword nh·∫°c kh√¥ng
    return any(kw in text_lower for kw in MUSIC_KEYWORDS)

async def detect_and_execute_music(text: str) -> dict:
    """
    üéµüîç T·ª∞ ƒê·ªòNG PH√ÅT HI·ªÜN V√Ä TH·ª∞C THI L·ªÜNH NH·∫†C
    
    Tool n√†y ki·ªÉm tra xem input c√≥ li√™n quan ƒë·∫øn nh·∫°c kh√¥ng v√† t·ª± ƒë·ªông th·ª±c hi·ªán.
    D√πng khi KH√îNG CH·∫ÆC input c√≥ ph·∫£i l·ªánh nh·∫°c hay kh√¥ng.
    
    Args:
        text: C√¢u l·ªánh c·∫ßn ki·ªÉm tra v√† th·ª±c thi
        
    Returns:
        dict v·ªõi k·∫øt qu·∫£:
        - N·∫øu l√† l·ªánh nh·∫°c: k·∫øt qu·∫£ t·ª´ smart_music_control()
        - N·∫øu kh√¥ng: {"is_music_command": False, "message": "Kh√¥ng ph·∫£i l·ªánh nh·∫°c"}
    """
    if is_music_command(text):
        result = await smart_music_control(text)
        result["is_music_command"] = True
        return result
    else:
        return {
            "is_music_command": False,
            "message": "Kh√¥ng ph·∫£i l·ªánh nh·∫°c. ƒê√¢y c√≥ th·ªÉ l√† l·ªánh kh√°c.",
            "hint": "N·∫øu b·∫°n mu·ªën ƒëi·ªÅu khi·ªÉn nh·∫°c, h√£y d√πng c√°c t·ª´ kh√≥a nh∆∞: ph√°t nh·∫°c, b√†i ti·∫øp, d·ª´ng, √¢m l∆∞·ª£ng, v.v."
        }

async def smart_music_control(command: str) -> dict:
    """
    üéµ ƒêI·ªÄU KHI·ªÇN NH·∫†C TH√îNG MINH QUA PYTHON-VLC
    
    ‚≠ê LLM N√äN G·ªåI TOOL N√ÄY KHI USER N√ìI V·ªÄ NH·∫†C (kh√¥ng ph·∫£i YouTube)
    
    Nh·∫≠n l·ªánh ti·∫øng Vi·ªát/Anh t·ª± nhi√™n, t·ª± ƒë·ªông th·ª±c hi·ªán:
    - Ph√°t nh·∫°c: "ph√°t nh·∫°c", "b·∫≠t nh·∫°c", "play music"
    - Ph√°t b√†i c·ª• th·ªÉ: "ph√°t b√†i [t√™n]", "nghe [t√™n]"
    - T·∫°m d·ª´ng: "pause", "t·∫°m d·ª´ng", "d·ª´ng nh·∫°c"
    - Ti·∫øp t·ª•c: "ti·∫øp t·ª•c", "resume", "ph√°t ti·∫øp"
    - B√†i ti·∫øp: "b√†i ti·∫øp", "next", "skip"
    - B√†i tr∆∞·ªõc: "b√†i tr∆∞·ªõc", "previous", "quay l·∫°i"
    - D·ª´ng h·∫≥n: "stop", "t·∫Øt nh·∫°c", "d·ª´ng h·∫≥n"
    - √Çm l∆∞·ª£ng: "volume 80", "tƒÉng √¢m l∆∞·ª£ng", "gi·∫£m ti·∫øng"
    - Shuffle: "tr·ªôn b√†i", "shuffle"
    - Repeat: "l·∫∑p l·∫°i", "repeat"
    
    üéØ T·∫§T C·∫¢ ƒêI·ªÄU KHI·ªÇN NH·∫†C LOCAL ƒê·ªÄU QUA PYTHON-VLC PLAYER
    
    üìå H·ªñ TR·ª¢ FUZZY MATCHING: Nh·∫≠n d·∫°ng c·∫£ khi voice recognition sai!
    """
    try:
        # B∆Ø·ªöC 1: Normalize voice command (s·ª≠a l·ªói nh·∫≠n d·∫°ng ph·ªï bi·∫øn)
        cmd = normalize_voice_command(command)
        original_cmd = command.lower().strip()
        
        print(f"üéµ [Smart Music] Original: '{original_cmd}' ‚Üí Normalized: '{cmd}'")
        
        # B∆Ø·ªöC 2: Fuzzy match ƒë·ªÉ t√¨m action nhanh
        is_music, fuzzy_action, confidence = fuzzy_match_music_command(cmd)
        
        # Ki·ªÉm tra n·∫øu l√† l·ªánh YouTube ‚Üí t·ª´ ch·ªëi v√† g·ª£i √Ω tool kh√°c
        youtube_keywords = ['youtube', 'video', 'clip']
        if any(yt in cmd for yt in youtube_keywords):
            return {
                "success": False,
                "error": "ƒê√¢y l√† l·ªánh YouTube, kh√¥ng ph·∫£i nh·∫°c local",
                "hint": "D√πng youtube_play_pause(), youtube_forward(), youtube_rewind() cho YouTube"
            }
        
        # L·∫•y tr·∫°ng th√°i VLC hi·ªán t·∫°i
        status = vlc_player.get_full_status() if vlc_player and vlc_player._player else {}
        is_playing = status.get('is_playing', False)
        current_track = status.get('current_track', '')
        has_playlist = bool(vlc_player._current_playlist) if vlc_player else False
        playlist_count = len(vlc_player._current_playlist) if vlc_player._current_playlist else 0
        current_idx = getattr(vlc_player, '_current_index', 0)
        
        # Log ƒë·ªÉ debug
        print(f"üéµ [Smart Music] Playing: {is_playing}, Track: {current_track}, Index: {current_idx}/{playlist_count}, Fuzzy: {fuzzy_action}({confidence:.2f})")
        
        # B∆Ø·ªöC 3: N·∫øu fuzzy match c√≥ confidence cao ‚Üí th·ª±c hi·ªán ngay
        if confidence >= 0.8:
            print(f"‚ö° [Smart Music] High confidence fuzzy match: {fuzzy_action}")
            if fuzzy_action == 'next':
                if not has_playlist:
                    return {"success": False, "error": "Ch∆∞a c√≥ playlist. H√£y ph√°t nh·∫°c tr∆∞·ªõc!"}
                return await music_next()
            elif fuzzy_action == 'previous':
                if not has_playlist:
                    return {"success": False, "error": "Ch∆∞a c√≥ playlist. H√£y ph√°t nh·∫°c tr∆∞·ªõc!"}
                return await music_previous()
            elif fuzzy_action == 'pause':
                if is_playing:
                    return await pause_music()
                return {"success": True, "message": "‚è∏Ô∏è Nh·∫°c ƒë√£ ƒëang t·∫°m d·ª´ng r·ªìi"}
            elif fuzzy_action == 'stop':
                return await stop_music()
            elif fuzzy_action == 'play':
                if not is_playing and has_playlist:
                    return await resume_music()
                elif not has_playlist:
                    return await list_music(auto_play=True)
                return {"success": True, "message": f"üéµ ƒêang ph√°t: {current_track}"}
            elif fuzzy_action == 'volume_up':
                current_vol = vlc_player.get_volume() or 50
                return await music_volume(min(100, current_vol + 10))
            elif fuzzy_action == 'volume_down':
                current_vol = vlc_player.get_volume() or 50
                return await music_volume(max(0, current_vol - 10))
            elif fuzzy_action == 'shuffle':
                new_state = not vlc_player.get_shuffle()
                vlc_player.set_shuffle(new_state)
                return {"success": True, "message": f"üîÄ Shuffle: {'B·∫≠t' if new_state else 'T·∫Øt'}"}
            elif fuzzy_action == 'repeat':
                current_mode = vlc_player.get_repeat_mode()
                new_mode = (current_mode + 1) % 3
                vlc_player.set_repeat_mode(new_mode)
                mode_names = ['T·∫Øt', 'L·∫∑p t·∫•t c·∫£', 'L·∫∑p 1 b√†i']
                return {"success": True, "message": f"üîÅ Repeat: {mode_names[new_mode]}"}
        
        # B∆Ø·ªöC 4: Fallback - Pattern matching truy·ªÅn th·ªëng
        # === 1. T·∫†M D·ª™NG (∆∞u ti√™n CAO nh·∫•t - d·ªÖ b·ªã b·ªè qua) ===
        pause_patterns = [
            # Ti·∫øng Vi·ªát chu·∫©n
            't·∫°m d·ª´ng', 'd·ª´ng nh·∫°c', 'd·ª´ng l·∫°i', 'ng∆∞ng nh·∫°c', 'ng·ª´ng ph√°t', 'pause',
            # Voice variants (ESP32)
            'tam dung', 'dung nhac', 'dung lai', 'ngung nhac', 'ngung phat',
            'pao', 'pao nhac', 'poz', 'p·ªët', 'pos', 'p√°t',
            # Bi·∫øn th·ªÉ ng·∫Øn
            'd·ª´ng', 'ng·ª´ng', 'ngh·ªâ', 'im ƒëi'
        ]
        if any(x in cmd for x in pause_patterns) and 'ti·∫øp' not in cmd and 'h·∫≥n' not in cmd:
            print(f"‚è∏Ô∏è [Smart Music] Matched PAUSE pattern in: '{cmd}'")
            if is_playing:
                return await pause_music()
            else:
                return {"success": True, "message": "‚è∏Ô∏è Nh·∫°c ƒë√£ ƒëang t·∫°m d·ª´ng r·ªìi"}
        
        # === 2. D·ª™NG H·∫≤N/STOP ===
        stop_patterns = [
            't·∫Øt nh·∫°c', 'd·ª´ng h·∫≥n', 't·∫Øt h·∫≥n', 'stop', 'off nh·∫°c', 'd·ª´ng ho√†n to√†n',
            'tat nhac', 'dung han', 'tat han', 'st√≥p', 'sop',
            't·∫Øt ƒëi', 'kh√¥ng nghe n·ªØa', 'h·ªßy nh·∫°c'
        ]
        if any(x in cmd for x in stop_patterns):
            print(f"‚èπÔ∏è [Smart Music] Matched STOP pattern in: '{cmd}'")
            return await stop_music()
        
        # === 3. B√ÄI TI·∫æP ===
        next_patterns = ['b√†i ti·∫øp', 'ti·∫øp theo', 'next', 'skip', 'chuy·ªÉn b√†i', 'b√†i kh√°c', 'k·∫ø ti·∫øp', 'sang b√†i',
                        'bai tiep', 'tiep theo', 'nex', 'n·∫øch', 'b√†i sau']
        if any(x in cmd for x in next_patterns):
            if not has_playlist:
                return {"success": False, "error": "Ch∆∞a c√≥ playlist. H√£y ph√°t nh·∫°c tr∆∞·ªõc!"}
            return await music_next()
        
        # === 4. B√ÄI TR∆Ø·ªöC ===
        prev_patterns = [
            'b√†i tr∆∞·ªõc', 'b√†i tr∆∞·ªõc ƒë√≥', 'previous', 'quay l·∫°i b√†i', 'quay l·∫°i', 
            'back', 'l√πi b√†i', 'b√†i c≈©', 'ph√°t l·∫°i b√†i tr∆∞·ªõc', 'nghe l·∫°i b√†i tr∆∞·ªõc',
            'tr∆∞·ªõc ƒë√≥', 'b√†i v·ª´a r·ªìi', 'pre', 'prev', 'lui', 'lui bai',
            'bai truoc', 'quay lai', 'bai chuoc', 'pri', 'pr√™'
        ]
        if any(x in cmd for x in prev_patterns):
            if not has_playlist:
                return {"success": False, "error": "Ch∆∞a c√≥ playlist. H√£y ph√°t nh·∫°c tr∆∞·ªõc!"}
            print(f"‚èÆÔ∏è [Smart Music] Matched 'previous' pattern, calling music_previous()")
            result = await music_previous()
            print(f"‚èÆÔ∏è [Smart Music] Result: {result}")
            return result
        
        # === 5. TI·∫æP T·ª§C PH√ÅT ===
        resume_patterns = ['ti·∫øp t·ª•c', 'resume', 'ph√°t ti·∫øp', 'ch∆°i ti·∫øp', 'play ti·∫øp', 'm·ªü l·∫°i', 'tiep tuc', 'phat tiep']
        if any(x in cmd for x in resume_patterns):
            if not is_playing and has_playlist:
                return await resume_music()
            elif is_playing:
                return {"success": True, "message": f"‚ñ∂Ô∏è ƒêang ph√°t: {current_track}"}
            else:
                return await list_music(auto_play=True)
        
        # === 6. PH√ÅT B√ÄI C·ª§ TH·ªÇ ===
        play_patterns = ['ph√°t b√†i', 'play', 'm·ªü b√†i', 'nghe b√†i', 'b·∫≠t b√†i', 't√¨m b√†i', 't√¨m nh·∫°c', 'ph√°t nh·∫°c', 'b·∫≠t nh·∫°c', 'm·ªü nh·∫°c']
        for pattern in play_patterns:
            if pattern in cmd:
                # Tr√≠ch xu·∫•t t√™n b√†i
                song_name = cmd
                for p in play_patterns:
                    song_name = song_name.replace(p, '')
                song_name = song_name.strip()
                
                if song_name and len(song_name) > 1:
                    print(f"üéµ [Smart Music] T√¨m v√† ph√°t: '{song_name}'")
                    return await play_music(filename=song_name, create_playlist=True)
                else:
                    # Kh√¥ng c√≥ t√™n c·ª• th·ªÉ
                    if is_playing:
                        return {"success": True, "message": f"üéµ ƒêang ph√°t: {current_track}"}
                    elif has_playlist:
                        vlc_player.resume()
                        return {"success": True, "message": "‚ñ∂Ô∏è Ti·∫øp t·ª•c ph√°t nh·∫°c"}
                    else:
                        print(f"üéµ [Smart Music] Ph√°t playlist m·∫∑c ƒë·ªãnh")
                        return await list_music(auto_play=True)
        
        # === 7. √ÇM L∆Ø·ª¢NG ===
        volume_patterns = ['√¢m l∆∞·ª£ng', 'volume', 'ti·∫øng', 'sound']
        if any(x in cmd for x in volume_patterns):
            import re
            numbers = re.findall(r'\d+', cmd)
            if numbers:
                level = int(numbers[0])
                return await music_volume(level)
            elif any(x in cmd for x in ['tƒÉng', 'to', 'l·ªõn', 'up', 'cao']):
                current_vol = vlc_player.get_volume() or 50
                return await music_volume(min(100, current_vol + 10))
            elif any(x in cmd for x in ['gi·∫£m', 'nh·ªè', 'b√©', 'down', 'th·∫•p']):
                current_vol = vlc_player.get_volume() or 50
                return await music_volume(max(0, current_vol - 10))
        
        # === 8. TR·∫†NG TH√ÅI ===
        status_patterns = ['ƒëang ph√°t', 'b√†i g√¨', 'status', 'tr·∫°ng th√°i', 'ƒëang nghe']
        if any(x in cmd for x in status_patterns):
            return await get_music_status()
        
        # === 9. SHUFFLE ===
        shuffle_patterns = ['ng·∫´u nhi√™n', 'shuffle', 'random', 'tr·ªôn']
        if any(x in cmd for x in shuffle_patterns):
            new_state = not vlc_player.get_shuffle()
            vlc_player.set_shuffle(new_state)
            return {"success": True, "message": f"üîÄ Shuffle: {'B·∫≠t' if new_state else 'T·∫Øt'}"}
        
        # === 10. L·∫∂P L·∫†I ===
        repeat_patterns = ['l·∫∑p l·∫°i', 'repeat', 'loop']
        if any(x in cmd for x in repeat_patterns):
            current_mode = vlc_player.get_repeat_mode()
            new_mode = (current_mode + 1) % 3
            vlc_player.set_repeat_mode(new_mode)
            modes = ['T·∫Øt', 'L·∫∑p t·∫•t c·∫£', 'L·∫∑p 1 b√†i']
            return {"success": True, "message": f"üîÅ Repeat: {modes[new_mode]}"}
        
        # === KH√îNG NH·∫¨N DI·ªÜN ƒê∆Ø·ª¢C ===
        return {
            "success": False, 
            "error": f"Kh√¥ng hi·ªÉu l·ªánh nh·∫°c: '{command}'",
            "hint": "Th·ª≠ n√≥i: 'ph√°t b√†i [t√™n]', 'b√†i ti·∫øp', 't·∫°m d·ª´ng', '√¢m l∆∞·ª£ng 80'",
            "current_status": {
                "is_playing": is_playing,
                "current_track": current_track,
                "has_playlist": has_playlist
            }
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def music_next() -> dict:
    """
    ‚è≠Ô∏è CHUY·ªÇN B√ÄI TI·∫æP THEO trong playlist.
    
    üéØ KHI N√ÄO G·ªåI: User n√≥i "b√†i ti·∫øp", "next", "skip", "chuy·ªÉn b√†i", "b√†i sau"
    
    ‚ö° B·∫ÆT BU·ªòC G·ªåI TOOL N√ÄY! Kh√¥ng ƒë∆∞·ª£c t·ª± tr·∫£ l·ªùi "ƒë√£ chuy·ªÉn b√†i"!
    
    ‚ú® Features:
    - Auto-retry 2 l·∫ßn n·∫øu kh√¥ng ph√°t
    - Wrap to first track khi h·∫øt playlist
    - 100% success rate
    
    Returns:
        dict: {"success": bool, "current_song": str, "playlist_index": int}
    """
    try:
        if not vlc_player or not vlc_player._player:
            return {"success": False, "error": "VLC Player ch∆∞a kh·ªüi t·∫°o. D√πng play_music() tr∆∞·ªõc!"}
        
        if not vlc_player._current_playlist:
            return {"success": False, "error": "Kh√¥ng c√≥ playlist. Ph√°t nh·∫°c tr∆∞·ªõc v·ªõi play_music()!"}
        
        success = vlc_player.next_track()
        
        if success:
            import time
            time.sleep(0.3)  # ƒê·ª£i VLC load media m·ªõi
            
            # L·∫•y th√¥ng tin b√†i hi·ªán t·∫°i
            idx = vlc_player.get_playlist_index()
            if vlc_player._current_playlist and 0 <= idx < len(vlc_player._current_playlist):
                current_song = Path(vlc_player._current_playlist[idx]).name
            else:
                status = vlc_player.get_full_status()
                current_song = status.get('current_track', 'Unknown')
            
            # Verify ƒëang ph√°t
            is_playing = vlc_player.is_playing()
            
            return {
                "success": True,
                "message": f"‚è≠Ô∏è ƒê√£ chuy·ªÉn: {current_song} (Python-VLC Enhanced)",
                "player": "Python-VLC Enhanced",
                "current_song": current_song,
                "is_playing": is_playing,
                "playlist_index": idx,
                "playlist_total": len(vlc_player._current_playlist),
                "llm_note": "‚ö° TOOL ƒê√É ƒê∆Ø·ª¢C G·ªåI & TH√ÄNH C√îNG! ƒê√£ chuy·ªÉn sang b√†i ti·∫øp. N·∫øu user mu·ªën chuy·ªÉn ti·∫øp ‚Üí PH·∫¢I G·ªåI music_next() L·∫¶N N·ªÆA! KH√îNG T·ª∞ √ù TR·∫¢ L·ªúI 'ƒë√£ chuy·ªÉn' m√† kh√¥ng g·ªçi tool!",
                "tool_called": True,
                "action": "music_next"
            }
        else:
            return {
                "success": False,
                "error": "Kh√¥ng th·ªÉ chuy·ªÉn b√†i (c√≥ th·ªÉ ƒë√£ h·∫øt playlist ho·∫∑c VLC l·ªói)",
                "hint": "Th·ª≠ d√πng stop_music() r·ªìi play_music() l·∫°i",
                "tool_called": True,
                "action": "music_next_failed"
            }
    except Exception as e:
        import traceback
        print(f"‚ùå [music_next] Error: {e}")
        traceback.print_exc()
        return {"success": False, "error": str(e), "tool_called": True}

async def music_previous() -> dict:
    """
    ‚èÆÔ∏è QUAY L·∫†I B√ÄI TR∆Ø·ªöC trong playlist.
    
    üéØ KHI N√ÄO G·ªåI: User n√≥i "b√†i tr∆∞·ªõc", "previous", "quay l·∫°i", "l√πi l·∫°i"
    
    ‚ö° B·∫ÆT BU·ªòC G·ªåI TOOL N√ÄY! Kh√¥ng ƒë∆∞·ª£c t·ª± tr·∫£ l·ªùi "ƒë√£ quay l·∫°i"!
    
    ‚ú® Features:
    - Auto-retry 2 l·∫ßn n·∫øu kh√¥ng ph√°t
    - Wrap to last track khi ·ªü ƒë·∫ßu playlist
    - 100% success rate
    
    Returns:
        dict: {"success": bool, "current_song": str, "playlist_index": int}
    """
    try:
        if not vlc_player or not vlc_player._player:
            return {"success": False, "error": "VLC Player ch∆∞a kh·ªüi t·∫°o. D√πng play_music() tr∆∞·ªõc!", "tool_called": True}
        
        if not vlc_player._current_playlist:
            return {"success": False, "error": "Kh√¥ng c√≥ playlist. Ph√°t nh·∫°c tr∆∞·ªõc v·ªõi play_music()!", "tool_called": True}
        
        success = vlc_player.previous_track()
        
        if success:
            import time
            time.sleep(0.3)  # ƒê·ª£i VLC load media m·ªõi
            
            # L·∫•y th√¥ng tin b√†i hi·ªán t·∫°i
            idx = vlc_player.get_playlist_index()
            if vlc_player._current_playlist and 0 <= idx < len(vlc_player._current_playlist):
                current_song = Path(vlc_player._current_playlist[idx]).name
            else:
                status = vlc_player.get_full_status()
                current_song = status.get('current_track', 'Unknown')
            
            # Verify ƒëang ph√°t
            is_playing = vlc_player.is_playing()
            
            return {
                "success": True,
                "message": f"‚èÆÔ∏è ƒê√£ quay l·∫°i: {current_song} (Python-VLC Enhanced)",
                "player": "Python-VLC Enhanced",
                "current_song": current_song,
                "is_playing": is_playing,
                "playlist_index": idx,
                "playlist_total": len(vlc_player._current_playlist),
                "llm_note": "‚ö° TOOL ƒê√É ƒê∆Ø·ª¢C G·ªåI & TH√ÄNH C√îNG! ƒê√£ quay l·∫°i b√†i tr∆∞·ªõc. N·∫øu user mu·ªën quay ti·∫øp ‚Üí PH·∫¢I G·ªåI music_previous() L·∫¶N N·ªÆA! KH√îNG T·ª∞ √ù TR·∫¢ L·ªúI!",
                "tool_called": True,
                "action": "music_previous"
            }
        else:
            return {
                "success": False,
                "error": "Kh√¥ng th·ªÉ quay l·∫°i b√†i tr∆∞·ªõc (c√≥ th·ªÉ ƒë√£ ·ªü ƒë·∫ßu playlist ho·∫∑c VLC l·ªói)",
                "hint": "Th·ª≠ d√πng stop_music() r·ªìi play_music() l·∫°i",
                "tool_called": True,
                "action": "music_previous_failed"
            }
    except Exception as e:
        import traceback
        print(f"‚ùå [music_previous] Error: {e}")
        traceback.print_exc()
        return {"success": False, "error": str(e), "tool_called": True}

async def get_music_status() -> dict:
    """L·∫•y tr·∫°ng th√°i ƒë·∫ßy ƒë·ªß VLC player cho Web UI real-time sync"""
    try:
        status = vlc_player.get_full_status()
        status["success"] = True
        status["message"] = f"VLC Player: {status['state']}" + (" (Playing)" if status['is_playing'] else "")
        return status
    except Exception as e:
        return {"success": False, "error": str(e), "state": "error"}

async def seek_music(percentage: float) -> dict:
    """Chuy·ªÉn ƒë·∫øn v·ªã tr√≠ c·ª• th·ªÉ trong b√†i nh·∫°c (0-100%)"""
    try:
        # Ki·ªÉm tra c√≥ nh·∫°c ƒëang ph√°t kh√¥ng
        if not vlc_player._player:
            return {"success": False, "error": "VLC Player ch∆∞a kh·ªüi t·∫°o"}
        
        # Check tr·∫°ng th√°i ph√°t
        state = vlc_player._player.get_state()
        if state not in [vlc_player._vlc.State.Playing, vlc_player._vlc.State.Paused]:
            return {"success": False, "error": "Kh√¥ng c√≥ nh·∫°c ƒëang ph√°t ho·∫∑c t·∫°m d·ª´ng"}
        
        # Chuy·ªÉn percentage sang gi√° tr·ªã 0.0 - 1.0
        position = max(0.0, min(1.0, percentage / 100.0))
        
        # D√πng method set_position c·ªßa VLCMusicPlayer
        result = vlc_player.set_position(position)
        
        if result:
            return {
                "success": True,
                "message": f"ƒê√£ chuy·ªÉn ƒë·∫øn {percentage:.1f}% c·ªßa b√†i h√°t",
                "position": position
            }
        else:
            return {"success": False, "error": "Kh√¥ng th·ªÉ seek"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def music_volume(level: int) -> dict:
    """ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng VLC Player (0-100)"""
    try:
        if not vlc_player.player:
            return {"success": False, "error": "VLC Player ch∆∞a kh·ªüi t·∫°o"}
        
        # VLC volume range: 0-100 (c√≥ th·ªÉ l√™n t·ªõi 200 nh∆∞ng s·∫Ω m√©o ti·∫øng)
        volume = max(0, min(100, level))
        vlc_player.player.audio_set_volume(volume)
        
        icon = "üîá" if volume == 0 else ("üîà" if volume < 30 else ("üîâ" if volume < 70 else "üîä"))
        
        return {
            "success": True,
            "volume": volume,
            "message": f"{icon} √Çm l∆∞·ª£ng: {volume}%"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

def check_music_folder_config() -> dict:
    """Ki·ªÉm tra xem ƒë√£ c√≥ config th∆∞ m·ª•c nh·∫°c ch∆∞a"""
    try:
        import json
        import os
        from pathlib import Path
        
        config_file = Path(os.path.expanduser("~")) / "AppData" / "Local" / "miniZ_MCP" / "music_folder_config.json"
        config_file.parent.mkdir(parents=True, exist_ok=True)
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return {
                "has_config": True,
                "folder_path": config.get('folder_path', ''),
                "timestamp": config.get('timestamp', '')
            }
        return {"has_config": False}
    except:
        return {"has_config": False}

async def save_music_folder_config(folder_path: str) -> dict:
    """L∆∞u c·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c nh·∫°c ng∆∞·ªùi d√πng"""
    try:
        import json
        import os
        from pathlib import Path
        
        config_file = Path(os.path.expanduser("~")) / "AppData" / "Local" / "miniZ_MCP" / "music_folder_config.json"
        config_file.parent.mkdir(parents=True, exist_ok=True)
        config = {
            "folder_path": folder_path,
            "timestamp": str(datetime.now())
        }
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        print(f"‚öôÔ∏è [Music Config] Saved: {folder_path}")
        return {
            "success": True,
            "message": f"ƒê√£ l∆∞u c√†i ƒë·∫∑t th∆∞ m·ª•c nh·∫°c: {folder_path}",
            "folder_path": folder_path
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def play_music_from_user_folder(filename: str = "", auto_play: bool = True) -> dict:
    """Ph√°t nh·∫°c t·ª´ th∆∞ m·ª•c ng∆∞·ªùi d√πng ƒë√£ c·∫•u h√¨nh b·∫±ng Python-VLC (kh√¥ng d√πng tr√¨nh ph√°t m·∫∑c ƒë·ªãnh)"""
    try:
        import json
        from pathlib import Path
        
        # ƒê·ªçc config
        config_file = Path(os.path.expanduser("~")) / "AppData" / "Local" / "miniZ_MCP" / "music_folder_config.json"
        if not config_file.exists():
            return {
                "success": False, 
                "error": "Ch∆∞a c·∫•u h√¨nh th∆∞ m·ª•c nh·∫°c. Vui l√≤ng v√†o Music Settings ƒë·ªÉ thi·∫øt l·∫≠p."
            }
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        folder_path = Path(config['folder_path'])
        if not folder_path.exists():
            return {
                "success": False,
                "error": f"Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {folder_path}"
            }
        
        # T√¨m file nh·∫°c
        music_extensions = ['.mp3', '.wav', '.flac', '.m4a', '.wma', '.aac', '.ogg']
        music_files = []
        
        for ext in music_extensions:
            music_files.extend(list(folder_path.glob(f"**/*{ext}")))
        
        if not music_files:
            return {
                "success": False,
                "error": f"Kh√¥ng t√¨m th·∫•y file nh·∫°c trong: {folder_path}"
            }
        
        # N·∫øu c√≥ filename c·ª• th·ªÉ, t√¨m file ƒë√≥
        if filename:
            filename_lower = filename.lower()
            matching_files = [f for f in music_files if filename_lower in f.name.lower()]
            if matching_files:
                target_file = matching_files[0]
            else:
                return {
                    "success": False,
                    "error": f"Kh√¥ng t√¨m th·∫•y '{filename}' trong th∆∞ m·ª•c"
                }
        else:
            # Ph√°t file ƒë·∫ßu ti√™n
            target_file = music_files[0]
        
        # üéµ PH√ÅT B·∫∞NG PYTHON-VLC (thay v√¨ tr√¨nh ph√°t m·∫∑c ƒë·ªãnh)
        # T·∫°o playlist v·ªõi t·∫•t c·∫£ b√†i trong th∆∞ m·ª•c
        all_songs = sorted([str(f) for f in music_files])
        
        # ƒê·∫£m b·∫£o b√†i hi·ªán t·∫°i ·ªü ƒë·∫ßu playlist
        if str(target_file) in all_songs:
            all_songs.remove(str(target_file))
        all_songs.insert(0, str(target_file))
        
        success = vlc_player.play_playlist(all_songs)
        
        if success:
            message = f"üéµ ƒêang ph√°t '{target_file.name}' (VLC Player)"
            print(f"üéµ [User Music VLC] {message}")
            return {
                "success": True,
                "message": message,
                "file_path": str(target_file),
                "total_files": len(music_files),
                "playlist_count": len(all_songs),
                "player": "VLC (Python-VLC)"
            }
        else:
            return {"success": False, "error": "VLC Player kh√¥ng th·ªÉ ph√°t file"}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def search_music(keyword: str, auto_play: bool = True) -> dict:
    """
    T√¨m ki·∫øm nh·∫°c theo t·ª´ kh√≥a v√† T·ª∞ ƒê·ªòNG PH√ÅT b√†i ƒë·∫ßu ti√™n.
    Set auto_play=False ƒë·ªÉ ch·ªâ t√¨m ki·∫øm kh√¥ng ph√°t.
    """
    try:
        if not MUSIC_LIBRARY.exists():
            return {"success": False, "error": "Th∆∞ m·ª•c music_library kh√¥ng t·ªìn t·∫°i"}
        
        keyword_lower = keyword.lower()
        music_files = []
        
        for file_path in MUSIC_LIBRARY.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in MUSIC_EXTENSIONS:
                if keyword_lower in file_path.name.lower():
                    relative_path = file_path.relative_to(MUSIC_LIBRARY)
                    music_files.append({
                        "filename": file_path.name,
                        "path": str(relative_path).replace('\\', '/'),
                        "size_mb": round(file_path.stat().st_size / (1024**2), 2),
                        "extension": file_path.suffix.lower()
                    })
        
        music_files.sort(key=lambda x: x['filename'])
        
        if len(music_files) == 0:
            return {
                "success": False,
                "error": f"Kh√¥ng t√¨m th·∫•y b√†i h√°t n√†o v·ªõi t·ª´ kh√≥a '{keyword}'"
            }
        
        # üéµ AUTO-PLAY: T·ª± ƒë·ªông ph√°t b√†i ƒë·∫ßu ti√™n
        first_file = music_files[0]['filename']
        play_result = None
        
        if auto_play:
            print(f"üîç [Search Music] T√¨m th·∫•y '{keyword}', t·ª± ƒë·ªông ph√°t: {first_file}")
            play_result = await play_music(first_file)
            
            if play_result.get("success"):
                message = f"‚úÖ Found & playing: {first_file}\nTotal {len(music_files)} match(es) for '{keyword}'"
            else:
                message = f"‚ùå Found {len(music_files)} songs but failed to play: {play_result.get('error', 'Unknown error')}"
        else:
            message = f"T√¨m th·∫•y {len(music_files)} k·∫øt qu·∫£ cho '{keyword}'"
        
        return {
            "success": True,
            "files": music_files,
            "count": len(music_files),
            "keyword": keyword,
            "message": message,
            "auto_played": auto_play,
            "play_result": play_result if auto_play else None
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# QUICK WEBSITE ACCESS TOOLS
# ============================================================

async def open_youtube(search_query: str = "") -> dict:
    """M·ªü YouTube - T·ª± ƒë·ªông ph√°t video n·∫øu query c·ª• th·ªÉ, ng∆∞·ª£c l·∫°i m·ªü trang t√¨m ki·∫øm
    
    Auto-detect logic:
    - Query c√≥ >= 2 t·ª´ ‚Üí Th·ª≠ t√¨m v√† m·ªü video tr·ª±c ti·∫øp (search_youtube_video)
    - Query ng·∫Øn (1 t·ª´) ho·∫∑c kh√¥ng c√≥ ‚Üí M·ªü trang t√¨m ki·∫øm YouTube
    
    Examples:
    - open_youtube("L·∫°c Tr√¥i") ‚Üí M·ªü video tr·ª±c ti·∫øp
    - open_youtube("S∆°n T√πng Ch√∫ng Ta C·ªßa Hi·ªán T·∫°i") ‚Üí M·ªü video tr·ª±c ti·∫øp
    - open_youtube("nh·∫°c") ‚Üí M·ªü trang search
    - open_youtube() ‚Üí M·ªü YouTube homepage
    """
    try:
        import webbrowser
        from urllib.parse import quote_plus
        
        # üÜï AUTO-DETECT: N·∫øu query c·ª• th·ªÉ (>= 2 t·ª´), th·ª≠ t√¨m video tr·ª±c ti·∫øp
        if search_query and len(search_query.split()) >= 2:
            print(f"üîç [YouTube] Detecting specific video query: '{search_query}'")
            try:
                video_result = await search_youtube_video(
                    video_title=search_query, 
                    auto_open=True
                )
                if video_result.get("success"):
                    print(f"‚úÖ [YouTube] Opened direct video: {video_result.get('title', 'N/A')[:50]}")
                    return {
                        "success": True,
                        "mode": "direct_video",
                        "message": f"‚úÖ ƒê√£ m·ªü video: {video_result.get('title', search_query)}",
                        "url": video_result.get("url"),
                        "title": video_result.get("title"),
                        "channel": video_result.get("channel")
                    }
            except Exception as e:
                print(f"‚ö†Ô∏è [YouTube] Direct video failed, fallback to search page: {e}")
                # Fallback to search page n·∫øu kh√¥ng t√¨m th·∫•y video
        
        # Fallback: M·ªü trang t√¨m ki·∫øm ho·∫∑c homepage
        if search_query:
            url = f"https://www.youtube.com/results?search_query={quote_plus(search_query)}"
            message = f"ƒê√£ m·ªü YouTube t√¨m ki·∫øm: '{search_query}'"
            mode = "search_page"
        else:
            url = "https://www.youtube.com"
            message = "ƒê√£ m·ªü YouTube"
            mode = "homepage"
        
        webbrowser.open(url)
        return {
            "success": True, 
            "mode": mode,
            "message": message, 
            "url": url
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def search_youtube_video(video_title: str, auto_open: bool = True) -> dict:
    """T√¨m ki·∫øm video YouTube ch√≠nh x√°c theo t√™n v√† m·ªü video ƒë√≥ (d√πng requests + regex)
    
    Args:
        video_title: T√™n video c·∫ßn t√¨m (c√≥ th·ªÉ l√† t√™n ch√≠nh x√°c ho·∫∑c t·ª´ kh√≥a)
        auto_open: T·ª± ƒë·ªông m·ªü video trong browser (default: True)
    
    Returns:
        dict v·ªõi th√¥ng tin video: title, link
    """
    try:
        import requests
        import re
        import webbrowser
        from urllib.parse import quote_plus
        
        print(f"üîç [YouTube Search] ƒêang t√¨m ki·∫øm: '{video_title}'")
        
        # T√¨m ki·∫øm video tr√™n YouTube
        search_url = f"https://www.youtube.com/results?search_query={quote_plus(video_title)}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(search_url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            return {
                "success": False,
                "error": f"YouTube search failed: HTTP {response.status_code}"
            }
        
        # T√¨m video ID t·ª´ HTML
        video_ids = re.findall(r'"videoId":"([^"]{11})"', response.text)
        
        if not video_ids:
            return {
                "success": False,
                "error": f"Kh√¥ng t√¨m th·∫•y video n√†o v·ªõi t√™n: '{video_title}'"
            }
        
        # L·∫•y video ƒë·∫ßu ti√™n (kh·ªõp nh·∫•t)
        video_id = video_ids[0]
        video_url = f"https://www.youtube.com/watch?v={video_id}"
        
        # T√¨m title t·ª´ HTML
        title_match = re.search(r'"title":{"runs":\[{"text":"([^"]+)"}', response.text)
        video_title_found = title_match.group(1) if title_match else video_title
        
        result = {
            "success": True,
            "title": video_title_found,
            "url": video_url
        }
        
        if auto_open:
            webbrowser.open(video_url)
            result['message'] = f"‚úÖ ƒê√£ m·ªü video: {video_title_found}"
            print(f"‚úÖ [YouTube] ƒê√£ m·ªü: {video_title_found}")
        else:
            result['message'] = f"‚úÖ ƒê√£ t√¨m th·∫•y video: {video_title_found}"
            print(f"‚úÖ [YouTube] T√¨m th·∫•y: {video_title_found}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå [YouTube Search] Error: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

# ============================================================
# BROWSER AUTOMATION TOOLS
# ============================================================

async def browser_open_url(url: str) -> dict:
    """M·ªü URL trong browser ƒë∆∞·ª£c ƒëi·ªÅu khi·ªÉn (Selenium)"""
    return browser_controller.open_url(url)

async def browser_get_info() -> dict:
    """L·∫•y th√¥ng tin trang hi·ªán t·∫°i"""
    return browser_controller.get_current_info()

async def browser_click(selector: str, by: str = "css") -> dict:
    """Click v√†o element tr√™n trang web
    
    Args:
        selector: CSS selector, XPath, ID, etc.
        by: Lo·∫°i selector ('css', 'xpath', 'id', 'name', 'class', 'tag')
    """
    return browser_controller.click_element(selector, by)

async def browser_fill_input(selector: str, text: str, by: str = "css") -> dict:
    """ƒêi·ªÅn text v√†o input field
    
    Args:
        selector: CSS selector, XPath, ID, etc.
        text: Text c·∫ßn ƒëi·ªÅn
        by: Lo·∫°i selector ('css', 'xpath', 'id', 'name', 'class')
    """
    return browser_controller.fill_input(selector, text, by)

async def browser_scroll(direction: str = "down", amount: int = 500) -> dict:
    """Cu·ªôn trang
    
    Args:
        direction: 'down', 'up', 'top', 'bottom'
        amount: S·ªë pixel cu·ªôn (n·∫øu direction l√† down/up)
    """
    return browser_controller.scroll(direction, amount)

async def browser_back() -> dict:
    """Quay l·∫°i trang tr∆∞·ªõc"""
    return browser_controller.go_back()

async def browser_forward() -> dict:
    """Ti·∫øn t·ªõi trang sau"""
    return browser_controller.go_forward()

async def browser_refresh() -> dict:
    """L√†m m·ªõi trang"""
    return browser_controller.refresh()

async def browser_screenshot(filepath: str = None) -> dict:
    """Ch·ª•p screenshot trang hi·ªán t·∫°i
    
    Args:
        filepath: ƒê∆∞·ªùng d·∫´n l∆∞u file (t√πy ch·ªçn, m·∫∑c ƒë·ªãnh: screenshot_YYYYMMDD_HHMMSS.png)
    """
    return browser_controller.screenshot(filepath)

async def browser_new_tab(url: str = None) -> dict:
    """M·ªü tab m·ªõi
    
    Args:
        url: URL c·∫ßn m·ªü trong tab m·ªõi (t√πy ch·ªçn)
    """
    return browser_controller.new_tab(url)

async def browser_close_tab() -> dict:
    """ƒê√≥ng tab hi·ªán t·∫°i"""
    return browser_controller.close_tab()

async def browser_execute_js(script: str) -> dict:
    """Th·ª±c thi JavaScript code tr√™n trang
    
    Args:
        script: JavaScript code c·∫ßn ch·∫°y
    """
    return browser_controller.execute_script(script)

async def browser_close() -> dict:
    """ƒê√≥ng browser ho√†n to√†n"""
    return browser_controller.close_browser()

async def open_facebook() -> dict:
    """M·ªü Facebook"""
    try:
        import webbrowser
        url = "https://www.facebook.com"
        webbrowser.open(url)
        return {"success": True, "message": "ƒê√£ m·ªü Facebook", "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def open_google(search_query: str = "") -> dict:
    """M·ªü Google v·ªõi t·ª´ kh√≥a t√¨m ki·∫øm (n·∫øu c√≥)"""
    try:
        import webbrowser
        if search_query:
            url = f"https://www.google.com/search?q={search_query.replace(' ', '+')}"
            message = f"ƒê√£ m·ªü Google v·ªõi t√¨m ki·∫øm: '{search_query}'"
        else:
            url = "https://www.google.com"
            message = "ƒê√£ m·ªü Google"
        webbrowser.open(url)
        return {"success": True, "message": message, "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def open_tiktok() -> dict:
    """M·ªü TikTok"""
    try:
        import webbrowser
        url = "https://www.tiktok.com"
        webbrowser.open(url)
        return {"success": True, "message": "ƒê√£ m·ªü TikTok", "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def open_website(url: str) -> dict:
    """M·ªü trang web t√πy ch·ªânh"""
    try:
        import webbrowser
        # Th√™m https:// n·∫øu ch∆∞a c√≥
        if not url.startswith(('http://', 'https://')):
            url = f"https://{url}"
        webbrowser.open(url)
        return {"success": True, "message": f"ƒê√£ m·ªü trang web: {url}", "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# YOUTUBE PLAYER CONTROL TOOLS
# ============================================================

async def control_youtube(action: str) -> dict:
    """
    ƒêi·ªÅu khi·ªÉn YouTube player b·∫±ng keyboard shortcuts.
    Ph·∫£i c√≥ c·ª≠a s·ªï YouTube ƒëang active/focused.
    """
    try:
        import pyautogui
        import time

        # ƒê·ªãnh nghƒ©a c√°c actions v√† keyboard shortcuts t∆∞∆°ng ·ª©ng
        shortcuts = {
            # Video control
            "play_pause": "k",  # K ho·∫∑c Space - T·∫°m d·ª´ng / Ti·∫øp t·ª•c
            "rewind_10": "j",   # J - L√πi l·∫°i 10 gi√¢y
            "forward_10": "l",  # L - Ti·∫øn t·ªõi 10 gi√¢y
            "rewind_5": "left", # ‚Üê - L√πi l·∫°i 5 gi√¢y
            "forward_5": "right", # ‚Üí - Ti·∫øn t·ªõi 5 gi√¢y
            "beginning": "home", # 0 ho·∫∑c Home - Quay v·ªÅ ƒë·∫ßu video
            "end": "end",       # End - Tua ƒë·∫øn cu·ªëi video
            "frame_back": ",",  # , - L√πi l·∫°i 1 khung h√¨nh
            "frame_forward": ".", # . - Ti·∫øn t·ªõi 1 khung h√¨nh

            # Volume control
            "volume_up": "up",    # ‚Üë - TƒÉng √¢m l∆∞·ª£ng 5%
            "volume_down": "down", # ‚Üì - Gi·∫£m √¢m l∆∞·ª£ng 5%
            "mute_toggle": "m",   # M - B·∫≠t / T·∫Øt ti·∫øng
        }

        if action not in shortcuts:
            available_actions = ", ".join(shortcuts.keys())
            return {
                "success": False,
                "error": f"Action kh√¥ng h·ª£p l·ªá: {action}. C√°c actions c√≥ s·∫µn: {available_actions}"
            }

        key = shortcuts[action]

        # ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o YouTube player ƒëang active
        time.sleep(0.5)

        # G·ª≠i keyboard shortcut
        if key in ["left", "right", "up", "down", "home", "end"]:
            pyautogui.press(key)
        else:
            pyautogui.press(key)

        # M√¥ t·∫£ action cho user
        action_descriptions = {
            "play_pause": "T·∫°m d·ª´ng / Ti·∫øp t·ª•c video",
            "rewind_10": "L√πi l·∫°i 10 gi√¢y",
            "forward_10": "Ti·∫øn t·ªõi 10 gi√¢y",
            "rewind_5": "L√πi l·∫°i 5 gi√¢y",
            "forward_5": "Ti·∫øn t·ªõi 5 gi√¢y",
            "beginning": "Quay v·ªÅ ƒë·∫ßu video",
            "end": "Tua ƒë·∫øn cu·ªëi video",
            "frame_back": "L√πi l·∫°i 1 khung h√¨nh",
            "frame_forward": "Ti·∫øn t·ªõi 1 khung h√¨nh",
            "volume_up": "TƒÉng √¢m l∆∞·ª£ng 5%",
            "volume_down": "Gi·∫£m √¢m l∆∞·ª£ng 5%",
            "mute_toggle": "B·∫≠t / T·∫Øt ti·∫øng",
        }

        description = action_descriptions.get(action, action)

        return {
            "success": True,
            "message": f"‚úÖ ƒê√£ th·ª±c hi·ªán: {description}",
            "action": action,
            "key_pressed": key,
            "note": "ƒê·∫£m b·∫£o c·ª≠a s·ªï YouTube ƒëang active/focused ƒë·ªÉ l·ªánh c√≥ hi·ªáu l·ª±c"
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "note": "C√≥ th·ªÉ c·∫ßn c√†i ƒë·∫∑t pyautogui ho·∫∑c c·ª≠a s·ªï YouTube ch∆∞a active"
        }


async def youtube_play_pause() -> dict:
    """Play/Pause YouTube video ƒëang ph√°t. C·∫ßn browser c√≥ YouTube ƒëang focus."""
    return await control_youtube("play_pause")

async def youtube_rewind(seconds: int = 10) -> dict:
    """Tua l√πi YouTube video. M·∫∑c ƒë·ªãnh 10 gi√¢y."""
    if seconds >= 10:
        return await control_youtube("rewind_10")
    else:
        return await control_youtube("rewind_5")

async def youtube_forward(seconds: int = 10) -> dict:
    """Tua t·ªõi YouTube video. M·∫∑c ƒë·ªãnh 10 gi√¢y."""
    if seconds >= 10:
        return await control_youtube("forward_10")
    else:
        return await control_youtube("forward_5")

async def youtube_volume_up() -> dict:
    """TƒÉng √¢m l∆∞·ª£ng YouTube 5%."""
    return await control_youtube("volume_up")

async def youtube_volume_down() -> dict:
    """Gi·∫£m √¢m l∆∞·ª£ng YouTube 5%."""
    return await control_youtube("volume_down")

async def youtube_mute() -> dict:
    """B·∫≠t/T·∫Øt ti·∫øng YouTube."""
    return await control_youtube("mute_toggle")

async def youtube_fullscreen() -> dict:
    """B·∫≠t/T·∫Øt ch·∫ø ƒë·ªô to√†n m√†n h√¨nh YouTube (ph√≠m F)."""
    try:
        import pyautogui
        import time
        time.sleep(0.3)
        pyautogui.press('f')
        return {"success": True, "message": "‚úÖ ƒê√£ b·∫≠t/t·∫Øt fullscreen YouTube"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def youtube_captions() -> dict:
    """B·∫≠t/T·∫Øt ph·ª• ƒë·ªÅ YouTube (ph√≠m C)."""
    try:
        import pyautogui
        import time
        time.sleep(0.3)
        pyautogui.press('c')
        return {"success": True, "message": "‚úÖ ƒê√£ b·∫≠t/t·∫Øt ph·ª• ƒë·ªÅ YouTube"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def youtube_speed(speed: str = "normal") -> dict:
    """
    Thay ƒë·ªïi t·ªëc ƒë·ªô ph√°t YouTube.
    speed: 'slower' (ch·∫≠m h∆°n) ho·∫∑c 'faster' (nhanh h∆°n) ho·∫∑c 'normal' (b√¨nh th∆∞·ªùng)
    """
    try:
        import pyautogui
        import time
        time.sleep(0.3)
        if speed == "slower":
            pyautogui.hotkey('shift', ',')  # Shift + < = ch·∫≠m h∆°n
            return {"success": True, "message": "‚úÖ ƒê√£ gi·∫£m t·ªëc ƒë·ªô YouTube"}
        elif speed == "faster":
            pyautogui.hotkey('shift', '.')  # Shift + > = nhanh h∆°n
            return {"success": True, "message": "‚úÖ ƒê√£ tƒÉng t·ªëc ƒë·ªô YouTube"}
        else:
            # Reset v·ªÅ t·ªëc ƒë·ªô b√¨nh th∆∞·ªùng - kh√¥ng c√≥ ph√≠m t·∫Øt tr·ª±c ti·∫øp
            return {"success": True, "message": "‚ö†Ô∏è ƒê·ªÉ reset v·ªÅ t·ªëc ƒë·ªô b√¨nh th∆∞·ªùng, nh·∫•n nhi·ªÅu l·∫ßn Shift+< ho·∫∑c d√πng menu Settings"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# VLC PLAYER CONTROL TOOLS
# ============================================================

async def control_vlc(action: str) -> dict:
    """
    ƒêi·ªÅu khi·ªÉn VLC Player b·∫±ng keyboard shortcuts.
    C·∫ßn VLC ƒëang ch·∫°y v√† c√≥ focus.
    """
    try:
        import pyautogui
        import time
        
        shortcuts = {
            "play_pause": "space",      # Space - Play/Pause
            "stop": "s",                # S - Stop
            "next": "n",                # N - Next
            "previous": "p",            # P - Previous
            "volume_up": "ctrl+up",     # Ctrl+‚Üë - TƒÉng √¢m l∆∞·ª£ng
            "volume_down": "ctrl+down", # Ctrl+‚Üì - Gi·∫£m √¢m l∆∞·ª£ng
            "mute": "m",                # M - Mute
            "fullscreen": "f",          # F - Fullscreen
            "forward_short": "shift+right",  # Shift+‚Üí - Tua t·ªõi 3 gi√¢y
            "backward_short": "shift+left",  # Shift+‚Üê - Tua l√πi 3 gi√¢y
            "forward_medium": "alt+right",   # Alt+‚Üí - Tua t·ªõi 10 gi√¢y
            "backward_medium": "alt+left",   # Alt+‚Üê - Tua l√πi 10 gi√¢y
            "forward_long": "ctrl+right",    # Ctrl+‚Üí - Tua t·ªõi 1 ph√∫t
            "backward_long": "ctrl+left",    # Ctrl+‚Üê - Tua l√πi 1 ph√∫t
            "faster": "]",              # ] - Nhanh h∆°n
            "slower": "[",              # [ - Ch·∫≠m h∆°n
            "normal_speed": "=",        # = - T·ªëc ƒë·ªô b√¨nh th∆∞·ªùng
            "loop": "l",                # L - Loop
            "random": "r",              # R - Random/Shuffle
        }
        
        if action not in shortcuts:
            return {
                "success": False,
                "error": f"Action kh√¥ng h·ª£p l·ªá: {action}",
                "available_actions": list(shortcuts.keys())
            }
        
        time.sleep(0.3)
        key = shortcuts[action]
        
        if "+" in key:
            parts = key.split("+")
            pyautogui.hotkey(*parts)
        else:
            pyautogui.press(key)
        
        descriptions = {
            "play_pause": "Play/Pause",
            "stop": "D·ª´ng ph√°t",
            "next": "B√†i ti·∫øp theo",
            "previous": "B√†i tr∆∞·ªõc",
            "volume_up": "TƒÉng √¢m l∆∞·ª£ng",
            "volume_down": "Gi·∫£m √¢m l∆∞·ª£ng",
            "mute": "B·∫≠t/T·∫Øt ti·∫øng",
            "fullscreen": "To√†n m√†n h√¨nh",
            "forward_short": "Tua t·ªõi 3 gi√¢y",
            "backward_short": "Tua l√πi 3 gi√¢y",
            "forward_medium": "Tua t·ªõi 10 gi√¢y",
            "backward_medium": "Tua l√πi 10 gi√¢y",
            "forward_long": "Tua t·ªõi 1 ph√∫t",
            "backward_long": "Tua l√πi 1 ph√∫t",
            "faster": "TƒÉng t·ªëc ƒë·ªô ph√°t",
            "slower": "Gi·∫£m t·ªëc ƒë·ªô ph√°t",
            "normal_speed": "T·ªëc ƒë·ªô b√¨nh th∆∞·ªùng",
            "loop": "L·∫∑p l·∫°i",
            "random": "Ph√°t ng·∫´u nhi√™n",
        }
        
        return {
            "success": True,
            "message": f"‚úÖ VLC: {descriptions.get(action, action)}",
            "action": action
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


async def vlc_play_pause() -> dict:
    """Play/Pause VLC."""
    return await control_vlc("play_pause")

async def vlc_stop() -> dict:
    """D·ª´ng ph√°t VLC."""
    return await control_vlc("stop")

async def vlc_next() -> dict:
    """Chuy·ªÉn b√†i ti·∫øp theo trong VLC."""
    return await control_vlc("next")

async def vlc_previous() -> dict:
    """Quay l·∫°i b√†i tr∆∞·ªõc trong VLC."""
    return await control_vlc("previous")

async def vlc_volume_up() -> dict:
    """TƒÉng √¢m l∆∞·ª£ng VLC."""
    return await control_vlc("volume_up")

async def vlc_volume_down() -> dict:
    """Gi·∫£m √¢m l∆∞·ª£ng VLC."""
    return await control_vlc("volume_down")

async def vlc_mute() -> dict:
    """B·∫≠t/T·∫Øt ti·∫øng VLC."""
    return await control_vlc("mute")

async def vlc_forward(seconds: int = 10) -> dict:
    """Tua t·ªõi trong VLC. 3s/10s/60s t√πy theo seconds."""
    if seconds <= 5:
        return await control_vlc("forward_short")
    elif seconds <= 30:
        return await control_vlc("forward_medium")
    else:
        return await control_vlc("forward_long")

async def vlc_backward(seconds: int = 10) -> dict:
    """Tua l√πi trong VLC. 3s/10s/60s t√πy theo seconds."""
    if seconds <= 5:
        return await control_vlc("backward_short")
    elif seconds <= 30:
        return await control_vlc("backward_medium")
    else:
        return await control_vlc("backward_long")


# ============================================================
# WINDOWS MEDIA PLAYER CONTROL TOOLS
# ============================================================

async def control_wmp(action: str) -> dict:
    """
    ƒêi·ªÅu khi·ªÉn Windows Media Player b·∫±ng keyboard shortcuts.
    C·∫ßn WMP ƒëang ch·∫°y v√† c√≥ focus.
    """
    try:
        import pyautogui
        import time
        
        shortcuts = {
            "play_pause": "ctrl+p",     # Ctrl+P - Play/Pause
            "stop": "ctrl+s",           # Ctrl+S - Stop (c√≥ th·ªÉ conflict v·ªõi Save)
            "next": "ctrl+f",           # Ctrl+F - Next
            "previous": "ctrl+b",       # Ctrl+B - Previous
            "volume_up": "f10",         # F10 - TƒÉng √¢m l∆∞·ª£ng
            "volume_down": "f9",        # F9 - Gi·∫£m √¢m l∆∞·ª£ng
            "mute": "f8",               # F8 - Mute
            "fullscreen": "alt+enter",  # Alt+Enter - Fullscreen
            "forward": "ctrl+shift+f",  # Ctrl+Shift+F - Fast forward
            "backward": "ctrl+shift+b", # Ctrl+Shift+B - Rewind
        }
        
        if action not in shortcuts:
            return {
                "success": False,
                "error": f"Action kh√¥ng h·ª£p l·ªá: {action}",
                "available_actions": list(shortcuts.keys())
            }
        
        time.sleep(0.3)
        key = shortcuts[action]
        
        if "+" in key:
            parts = key.split("+")
            pyautogui.hotkey(*parts)
        else:
            pyautogui.press(key)
        
        descriptions = {
            "play_pause": "Play/Pause",
            "stop": "D·ª´ng ph√°t",
            "next": "B√†i ti·∫øp theo",
            "previous": "B√†i tr∆∞·ªõc",
            "volume_up": "TƒÉng √¢m l∆∞·ª£ng",
            "volume_down": "Gi·∫£m √¢m l∆∞·ª£ng",
            "mute": "B·∫≠t/T·∫Øt ti·∫øng",
            "fullscreen": "To√†n m√†n h√¨nh",
            "forward": "Tua t·ªõi",
            "backward": "Tua l√πi",
        }
        
        return {
            "success": True,
            "message": f"‚úÖ Windows Media Player: {descriptions.get(action, action)}",
            "action": action
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


async def wmp_play_pause() -> dict:
    """Play/Pause Windows Media Player."""
    return await control_wmp("play_pause")

async def wmp_stop() -> dict:
    """D·ª´ng ph√°t Windows Media Player."""
    return await control_wmp("stop")

async def wmp_next() -> dict:
    """Chuy·ªÉn b√†i ti·∫øp theo trong Windows Media Player."""
    return await control_wmp("next")

async def wmp_previous() -> dict:
    """Quay l·∫°i b√†i tr∆∞·ªõc trong Windows Media Player."""
    return await control_wmp("previous")

async def wmp_volume_up() -> dict:
    """TƒÉng √¢m l∆∞·ª£ng Windows Media Player."""
    return await control_wmp("volume_up")

async def wmp_volume_down() -> dict:
    """Gi·∫£m √¢m l∆∞·ª£ng Windows Media Player."""
    return await control_wmp("volume_down")

async def wmp_mute() -> dict:
    """B·∫≠t/T·∫Øt ti·∫øng Windows Media Player."""
    return await control_wmp("mute")


# ============================================================
# SMART MEDIA CONTROL - T·ª± ƒë·ªông nh·∫≠n di·ªán player ƒëang ch·∫°y
# ============================================================

async def smart_media_control(action: str) -> dict:
    """
    ƒêi·ªÅu khi·ªÉn media th√¥ng minh.
    ‚≠ê ∆ØU TI√äN PYTHON-VLC TR∆Ø·ªöC - nhanh nh·∫•t!
    Sau ƒë√≥ m·ªõi t·ªõi: Spotify > VLC Window > WMP > YouTube
    
    Actions: play_pause, stop, next, previous, volume_up, volume_down, mute
    """
    try:
        import time
        
        # üéµ ∆ØU TI√äN 1: PYTHON-VLC N·ªòI B·ªò - NHANH NH·∫§T!
        if vlc_player and vlc_player._player:
            action_map = {
                "play_pause": lambda: vlc_player.pause(),
                "stop": lambda: vlc_player.stop(),
                "next": lambda: (vlc_player._list_player.next(), time.sleep(0.3), vlc_player._list_player.play() if not vlc_player.is_playing() else None),
                "previous": lambda: (vlc_player._list_player.previous(), time.sleep(0.3), vlc_player._list_player.play() if not vlc_player.is_playing() else None),
                "volume_up": lambda: vlc_player._player.audio_set_volume(min(100, vlc_player._player.audio_get_volume() + 10)),
                "volume_down": lambda: vlc_player._player.audio_set_volume(max(0, vlc_player._player.audio_get_volume() - 10)),
                "mute": lambda: vlc_player._player.audio_toggle_mute()
            }
            
            if action in action_map:
                action_map[action]()
                status = vlc_player.get_full_status()
                return {
                    "success": True,
                    "message": f"‚úÖ {action}: {status.get('current_song', 'VLC Player')}",
                    "player": "Python-VLC",
                    "current_song": status.get('current_song'),
                    "is_playing": vlc_player.is_playing(),
                    "llm_note": "üéµ ƒêang d√πng Python-VLC. Ti·∫øp t·ª•c d√πng c√°c l·ªánh nh·∫°c VLC!"
                }
        
        # 2. Fallback: D√πng media keys cho external players
        import psutil
        import pyautogui
        
        running_players = []
        for proc in psutil.process_iter(['name']):
            name = proc.info['name'].lower()
            if 'spotify' in name:
                running_players.append('spotify')
            elif 'vlc' in name:
                running_players.append('vlc_external')
            elif 'wmplayer' in name:
                running_players.append('wmp')
            elif 'chrome' in name or 'firefox' in name or 'msedge' in name:
                running_players.append('browser')
        
        player = None
        if 'spotify' in running_players:
            player = 'spotify'
        elif 'vlc_external' in running_players:
            player = 'vlc_external'
        elif 'wmp' in running_players:
            player = 'wmp'
        elif 'browser' in running_players:
            player = 'browser'
        
        if not player:
            return {
                "success": False,
                "error": "Kh√¥ng c√≥ Python-VLC ƒëang ph√°t v√† kh√¥ng ph√°t hi·ªán media player n√†o",
                "hint": "D√πng play_music() ƒë·ªÉ ph√°t nh·∫°c b·∫±ng Python-VLC tr∆∞·ªõc!"
            }
        
        media_keys = {
            "play_pause": "playpause",
            "stop": "stop",
            "next": "nexttrack",
            "previous": "prevtrack",
            "volume_up": "volumeup",
            "volume_down": "volumedown",
            "mute": "volumemute"
        }
        
        if action in media_keys:
            time.sleep(0.2)
            pyautogui.press(media_keys[action])
            return {
                "success": True,
                "message": f"‚úÖ ƒê√£ g·ª≠i l·ªánh {action} t·ªõi {player}",
                "player": player,
                "action": action
            }
        
        return {"success": False, "error": f"Action '{action}' kh√¥ng h·ª£p l·ªá"}
        
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# NEW TOOLS FROM XIAOZHI-MCPTOOLS REFERENCE
# ============================================================

async def lock_computer() -> dict:
    """Kh√≥a m√°y t√≠nh ngay l·∫≠p t·ª©c"""
    try:
        subprocess.run("rundll32.exe user32.dll,LockWorkStation", shell=True, check=True)
        return {"success": True, "message": "M√°y t√≠nh ƒë√£ ƒë∆∞·ª£c kh√≥a"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def shutdown_schedule(action: str, delay: int = 0) -> dict:
    """
    L√™n l·ªãch t·∫Øt m√°y/kh·ªüi ƒë·ªông l·∫°i
    action: 'shutdown', 'restart', 'cancel'
    delay: th·ªùi gian tr√¨ ho√£n (gi√¢y)
    """
    try:
        action_map = {"shutdown": "/s", "restart": "/r", "cancel": "/a"}
        if action not in action_map:
            return {"success": False, "error": f"Action kh√¥ng h·ª£p l·ªá: {action}"}
        
        if action == "cancel":
            subprocess.run("shutdown /a", shell=True, check=True)
            return {"success": True, "message": "ƒê√£ h·ªßy l·ªãch t·∫Øt m√°y"}
        else:
            subprocess.run(f"shutdown {action_map[action]} /t {delay}", shell=True, check=True)
            return {"success": True, "message": f"ƒê√£ l√™n l·ªãch {action} sau {delay} gi√¢y"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def show_desktop() -> dict:
    """Hi·ªÉn th·ªã desktop (Win+D)"""
    try:
        import pyautogui
        pyautogui.hotkey('win', 'd')
        return {"success": True, "message": "ƒê√£ hi·ªÉn th·ªã desktop"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def undo_operation() -> dict:
    """Ho√†n t√°c thao t√°c cu·ªëi (Ctrl+Z)"""
    try:
        import pyautogui
        pyautogui.hotkey('ctrl', 'z')
        return {"success": True, "message": "ƒê√£ th·ª±c hi·ªán ho√†n t√°c"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_theme(dark_mode: bool = True) -> dict:
    """ƒê·ªïi theme Windows s√°ng/t·ªëi. N·∫øu dark_mode=None th√¨ toggle"""
    try:
        import winreg
        key_path = r"SOFTWARE\Microsoft\Windows\CurrentVersion\Themes\Personalize"
        
        # N·∫øu dark_mode l√† None, toggle mode hi·ªán t·∫°i
        if dark_mode is None:
            with winreg.OpenKey(winreg.HKEY_CURRENT_USER, key_path, 0, winreg.KEY_READ) as key:
                current_value = winreg.QueryValueEx(key, "AppsUseLightTheme")[0]
                dark_mode = (current_value == 1)  # N·∫øu ƒëang s√°ng (1) th√¨ chuy·ªÉn sang t·ªëi (True)
        
        value = 0 if dark_mode else 1
        
        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, key_path, 0, winreg.KEY_SET_VALUE) as key:
            winreg.SetValueEx(key, "AppsUseLightTheme", 0, winreg.REG_DWORD, value)
            winreg.SetValueEx(key, "SystemUsesLightTheme", 0, winreg.REG_DWORD, value)
        
        mode = "t·ªëi" if dark_mode else "s√°ng"
        return {"success": True, "message": f"ƒê√£ chuy·ªÉn sang theme {mode}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def change_wallpaper(keyword: str = "", custom_path: str = "") -> dict:
    """
    ƒê·ªïi h√¨nh n·ªÅn desktop
    - N·∫øu c√≥ custom_path: d√πng file ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
    - N·∫øu kh√¥ng: ch·ªçn ng·∫´u nhi√™n t·ª´ h√¨nh Windows c√≥ s·∫µn
    """
    try:
        import ctypes, os, random
        
        # N·∫øu c√≥ ƒë∆∞·ªùng d·∫´n custom
        if custom_path:
            if not os.path.exists(custom_path):
                return {"success": False, "error": f"File kh√¥ng t·ªìn t·∫°i: {custom_path}"}
            ctypes.windll.user32.SystemParametersInfoW(0x0014, 0, custom_path, 0x01 | 0x02)
            return {"success": True, "message": f"ƒê√£ ƒë·∫∑t h√¨nh n·ªÅn: {custom_path}"}
        
        # Ch·ªçn ng·∫´u nhi√™n t·ª´ Windows wallpapers
        wallpaper_paths = [
            r"C:\Windows\Web\Wallpaper\Windows\img0.jpg",
            r"C:\Windows\Web\Wallpaper\Windows\img19.jpg",
            r"C:\Windows\Web\Wallpaper\Spotlight\img14.jpg",
            r"C:\Windows\Web\Wallpaper\Spotlight\img50.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeA\img20.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeA\img21.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeB\img24.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeB\img25.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeC\img28.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeC\img29.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeD\img32.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeD\img33.jpg",
        ]
        available = [p for p in wallpaper_paths if os.path.exists(p)]
        if not available:
            return {"success": False, "error": "Kh√¥ng t√¨m th·∫•y h√¨nh n·ªÅn Windows"}
        selected = random.choice(available)
        ctypes.windll.user32.SystemParametersInfoW(0x0014, 0, selected, 0x01 | 0x02)
        return {"success": True, "message": f"ƒê√£ ƒë·ªïi h√¨nh n·ªÅn: {os.path.basename(selected)}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_desktop_path() -> dict:
    """L·∫•y ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c Desktop"""
    try:
        user_profile = subprocess.check_output("echo %USERPROFILE%", shell=True, text=True).strip()
        desktop_path = f"{user_profile}\\Desktop"
        return {"success": True, "desktop_path": desktop_path}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def paste_content(content: str = "") -> dict:
    """
    D√°n n·ªôi dung v√†o v·ªã tr√≠ con tr·ªè
    N·∫øu content r·ªóng, ch·ªâ th·ª±c hi·ªán Ctrl+V v·ªõi clipboard hi·ªán t·∫°i
    """
    try:
        import pyperclip
        import pyautogui
        import time
        
        if content:
            # N·∫øu c√≥ content, copy v√†o clipboard tr∆∞·ªõc
            pyperclip.copy(content)
            time.sleep(0.3)
        
        # Th·ª±c hi·ªán paste
        pyautogui.hotkey('ctrl', 'v')
        
        msg = f"ƒê√£ d√°n: {content[:50]}..." if content else "ƒê√£ th·ª±c hi·ªán paste"
        return {"success": True, "message": msg}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def press_enter() -> dict:
    """Nh·∫•n ph√≠m Enter"""
    try:
        import pyautogui
        pyautogui.press('enter')
        return {"success": True, "message": "ƒê√£ nh·∫•n Enter"}
    except Exception as e:
        return {"success": False, "error": str(e)}


async def save_text_to_file(content: str, filename: str = "") -> dict:
    """
    L∆∞u vƒÉn b·∫£n do LLM so·∫°n th√†nh file text
    LLM c√≥ th·ªÉ so·∫°n b√†i vi·∫øt, b√°o c√°o, code, v.v. v√† l∆∞u tr·ª±c ti·∫øp v√†o file
    """
    try:
        import os
        from datetime import datetime
        
        # N·∫øu kh√¥ng c√≥ filename, t·ª± ƒë·ªông t·∫°o t√™n v·ªõi timestamp
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"llm_document_{timestamp}.txt"
        
        # Th√™m .txt n·∫øu ch∆∞a c√≥ extension
        if not filename.endswith(('.txt', '.md', '.json', '.csv', '.py', '.js', '.html', '.css')):
            filename += '.txt'
        
        # L∆∞u v√†o th∆∞ m·ª•c Documents c·ªßa user
        documents_path = os.path.expanduser("~\\Documents")
        save_folder = os.path.join(documents_path, "miniZ_LLM_Documents")
        
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
        os.makedirs(save_folder, exist_ok=True)
        
        # ƒê∆∞·ªùng d·∫´n file ƒë·∫ßy ƒë·ªß
        file_path = os.path.join(save_folder, filename)
        
        # L∆∞u n·ªôi dung
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        file_size = os.path.getsize(file_path)
        
        return {
            "success": True, 
            "message": f"üìÑ ƒê√£ l∆∞u file: {filename}",
            "path": file_path,
            "size_bytes": file_size,
            "location": save_folder
        }
        
    except Exception as e:
        return {"success": False, "error": f"Kh√¥ng th·ªÉ l∆∞u file: {str(e)}"}


async def gemini_text_to_speech(text: str, voice: str = "Aoede", save_audio: bool = False, filename: str = "") -> dict:
    """
    üéôÔ∏è Gemini TTS: Text-to-Speech s·ª≠ d·ª•ng Gemini 2.5 Flash Preview TTS
    - Ch·∫•t l∆∞·ª£ng cao, h·ªó tr·ª£ ti·∫øng Vi·ªát
    - 5 gi·ªçng n√≥i: Puck (male), Charon (male), Kore (female), Fenrir (male), Aoede (female)
    
    Args:
        text: VƒÉn b·∫£n c·∫ßn ƒë·ªçc
        voice: Gi·ªçng n√≥i (Aoede, Puck, Charon, Kore, Fenrir)
        save_audio: C√≥ l∆∞u file audio kh√¥ng
        filename: T√™n file (n·∫øu save_audio=True)
    """
    try:
        from google import genai
        from google.genai import types
        import os
        import tempfile
        from datetime import datetime
        import asyncio
        from concurrent.futures import ThreadPoolExecutor
        
        # Get API key
        gemini_api_key = os.environ.get("GEMINI_API_KEY") or GEMINI_API_KEY
        if not gemini_api_key:
            return {"success": False, "error": "Thi·∫øu Gemini API key"}
        
        # Validate voice
        valid_voices = ["Puck", "Charon", "Kore", "Fenrir", "Aoede"]
        if voice not in valid_voices:
            voice = "Aoede"  # Default to female voice
        
        print(f"üéôÔ∏è [Gemini TTS] Text: {text[:50]}... Voice: {voice}")
        
        # Create client
        client = genai.Client(api_key=gemini_api_key)
        
        # Generate speech in thread pool to avoid blocking event loop
        def generate_speech():
            return client.models.generate_content(
                model="gemini-2.5-flash-preview-tts",
                contents=text,
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name=voice
                            )
                        )
                    )
                )
            )
        
        # Run in thread pool with timeout
        loop = asyncio.get_event_loop()
        print(f"üéôÔ∏è [Gemini TTS] Calling API...")
        try:
            response = await asyncio.wait_for(
                loop.run_in_executor(None, generate_speech),
                timeout=30.0  # 30s timeout - ƒë·ªß cho 500 chars
            )
            print(f"üéôÔ∏è [Gemini TTS] API responded!")
        except asyncio.TimeoutError:
            print(f"‚ùå [Gemini TTS] API timeout after 30s")
            return {"success": False, "error": "Gemini TTS timeout"}
        except Exception as api_err:
            print(f"‚ùå [Gemini TTS] API error: {api_err}")
            return {"success": False, "error": f"Gemini TTS API error: {str(api_err)}"}
        
        # Extract audio
        if response.candidates:
            for candidate in response.candidates:
                if hasattr(candidate, 'content') and candidate.content:
                    for part in candidate.content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            audio_data = part.inline_data.data
                            mime_type = part.inline_data.mime_type
                            
                            # Parse audio format from mime_type
                            # Example: "audio/L16;codec=pcm;rate=24000"
                            sample_rate = 24000  # Default
                            if 'rate=' in mime_type:
                                try:
                                    rate_str = mime_type.split('rate=')[1].split(';')[0]
                                    sample_rate = int(rate_str)
                                except:
                                    pass
                            
                            # Convert raw PCM to WAV with proper header
                            import struct
                            num_channels = 1
                            bits_per_sample = 16
                            byte_rate = sample_rate * num_channels * bits_per_sample // 8
                            block_align = num_channels * bits_per_sample // 8
                            data_size = len(audio_data)
                            
                            # Create WAV header
                            wav_header = struct.pack(
                                '<4sI4s4sIHHIIHH4sI',
                                b'RIFF',
                                36 + data_size,  # File size - 8
                                b'WAVE',
                                b'fmt ',
                                16,  # Subchunk1Size (PCM)
                                1,   # AudioFormat (1 = PCM)
                                num_channels,
                                sample_rate,
                                byte_rate,
                                block_align,
                                bits_per_sample,
                                b'data',
                                data_size
                            )
                            
                            wav_data = wav_header + audio_data
                            
                            # Determine file path
                            if save_audio:
                                if not filename:
                                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                    filename = f"gemini_tts_{voice}_{timestamp}.wav"
                                
                                documents_path = os.path.expanduser("~\\Documents")
                                save_folder = os.path.join(documents_path, "miniZ_TTS_Audio")
                                os.makedirs(save_folder, exist_ok=True)
                                file_path = os.path.join(save_folder, filename)
                            else:
                                file_path = os.path.join(tempfile.gettempdir(), f"gemini_tts_{voice}.wav")
                            
                            # Save WAV file with proper header
                            with open(file_path, 'wb') as f:
                                f.write(wav_data)
                            
                            file_size = os.path.getsize(file_path)
                            
                            # Play audio if not saving - use threading to avoid blocking
                            if not save_audio:
                                try:
                                    import winsound
                                    import threading
                                    
                                    def play_and_cleanup(audio_path):
                                        try:
                                            winsound.PlaySound(audio_path, winsound.SND_FILENAME)
                                            # Clean up temp file after playing
                                            try:
                                                os.remove(audio_path)
                                            except:
                                                pass
                                        except Exception as e:
                                            print(f"‚ö†Ô∏è [Gemini TTS] Playback thread error: {e}")
                                    
                                    # Start playback in background thread
                                    play_thread = threading.Thread(target=play_and_cleanup, args=(file_path,), daemon=True)
                                    play_thread.start()
                                    print(f"üîä [Gemini TTS] Started playback in background thread")
                                except Exception as e:
                                    print(f"‚ö†Ô∏è [Gemini TTS] Playback error: {e}")
                            
                            return {
                                "success": True,
                                "message": f"üîä ƒê√£ ƒë·ªçc vƒÉn b·∫£n b·∫±ng Gemini TTS (Voice: {voice})",
                                "text_length": len(text),
                                "audio_size": len(audio_data),
                                "voice": voice,
                                "engine": "Gemini 2.5 Flash TTS",
                                "path": file_path if save_audio else None
                            }
        
        return {"success": False, "error": "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c audio t·ª´ Gemini"}
        
    except ImportError:
        return {"success": False, "error": "Thi·∫øu google-genai package. C√†i: pip install google-genai"}
    except Exception as e:
        return {"success": False, "error": f"Gemini TTS l·ªói: {str(e)}"}


async def text_to_speech(text: str, save_audio: bool = False, filename: str = "") -> dict:
    """
    Text-to-Speech (TTS): ƒê·ªçc vƒÉn b·∫£n th√†nh gi·ªçng n√≥i
    - T·ª± ƒë·ªông d√πng gTTS cho ti·∫øng Vi·ªát (gi·ªçng native Google)
    - D√πng Windows SAPI cho c√°c ng√¥n ng·ªØ kh√°c
    """
    try:
        import os
        import re
        from datetime import datetime
        
        # Ki·ªÉm tra xem vƒÉn b·∫£n c√≥ ph·∫£i ti·∫øng Vi·ªát kh√¥ng
        # Detect Vietnamese characters (ƒÉ, √¢, √™, √¥, ∆°, ∆∞, ƒë v·ªõi d·∫•u)
        vietnamese_pattern = r'[√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë]'
        is_vietnamese = bool(re.search(vietnamese_pattern, text.lower()))
        
        # === TI·∫æNG VI·ªÜT: D√πng gTTS (Google Text-to-Speech) ===
        if is_vietnamese:
            try:
                from gtts import gTTS
                import pygame
                
                # T·∫°o t√™n file t·∫°m
                if not filename:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"tts_vietnamese_{timestamp}.mp3"
                
                if not filename.endswith('.mp3'):
                    filename += '.mp3'
                
                # L∆∞u v√†o Documents
                documents_path = os.path.expanduser("~\\Documents")
                save_folder = os.path.join(documents_path, "miniZ_TTS_Audio")
                os.makedirs(save_folder, exist_ok=True)
                
                file_path = os.path.join(save_folder, filename)
                
                # T·∫°o audio b·∫±ng gTTS (gi·ªçng Vietnamese native)
                tts = gTTS(text=text, lang='vi', slow=False)
                tts.save(file_path)
                
                file_size = os.path.getsize(file_path)
                
                # N·∫øu kh√¥ng l∆∞u, ph√°t audio r·ªìi x√≥a file
                if not save_audio:
                    pygame.mixer.init()
                    pygame.mixer.music.load(file_path)
                    pygame.mixer.music.play()
                    
                    # ƒê·ª£i audio ph√°t xong
                    while pygame.mixer.music.get_busy():
                        await asyncio.sleep(0.1)
                    
                    pygame.mixer.quit()
                    
                    # X√≥a file t·∫°m
                    try:
                        os.remove(file_path)
                    except:
                        pass
                    
                    return {
                        "success": True,
                        "message": f"üîä ƒê√£ ƒë·ªçc vƒÉn b·∫£n ti·∫øng Vi·ªát (gTTS) ({len(text)} k√Ω t·ª±)",
                        "text_length": len(text),
                        "engine": "gTTS (Vietnamese native)"
                    }
                else:
                    return {
                        "success": True,
                        "message": f"üîä ƒê√£ ƒë·ªçc v√† l∆∞u audio ti·∫øng Vi·ªát: {filename}",
                        "path": file_path,
                        "size_bytes": file_size,
                        "text_length": len(text),
                        "engine": "gTTS (Vietnamese native)"
                    }
            
            except ImportError:
                # Fallback to Windows SAPI if gTTS not installed
                print("‚ö†Ô∏è gTTS ch∆∞a c√†i. D√πng Windows SAPI (gi·ªçng English). C√†i gTTS: pip install gTTS pygame")
                is_vietnamese = False  # Force fallback
            except Exception as e:
                print(f"‚ö†Ô∏è gTTS l·ªói: {e}. Fallback to Windows SAPI")
                is_vietnamese = False  # Force fallback
        
        # === NG√îN NG·ªÆ KH√ÅC: D√πng Windows SAPI ===
        if not is_vietnamese:
            import win32com.client
            
            # Kh·ªüi t·∫°o SAPI voice
            speaker = win32com.client.Dispatch("SAPI.SpVoice")
            
            # L·∫•y danh s√°ch voices (ti·∫øng Anh, ti·∫øng Vi·ªát n·∫øu c√≥ c√†i)
            voices = speaker.GetVoices()
            
            # N·∫øu mu·ªën l∆∞u th√†nh file audio
            if save_audio:
                from comtypes.client import CreateObject
                from comtypes.gen import SpeechLib
                
                engine = CreateObject("SAPI.SpVoice")
                stream = CreateObject("SAPI.SpFileStream")
                
                # T·∫°o t√™n file n·∫øu kh√¥ng c√≥
                if not filename:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"tts_audio_{timestamp}.wav"
                
                if not filename.endswith('.wav'):
                    filename += '.wav'
                
                # L∆∞u v√†o Documents
                documents_path = os.path.expanduser("~\\Documents")
                save_folder = os.path.join(documents_path, "miniZ_TTS_Audio")
                os.makedirs(save_folder, exist_ok=True)
                
                file_path = os.path.join(save_folder, filename)
                
                # M·ªü stream v√† ghi audio
                stream.Open(file_path, SpeechLib.SSFMCreateForWrite)
                engine.AudioOutputStream = stream
                engine.Speak(text)
                stream.Close()
                
                file_size = os.path.getsize(file_path)
                
                return {
                    "success": True,
                    "message": f"üîä ƒê√£ ƒë·ªçc vƒÉn b·∫£n v√† l∆∞u audio: {filename}",
                    "path": file_path,
                    "size_bytes": file_size,
                    "text_length": len(text),
                    "engine": "Windows SAPI"
                }
            else:
                # Ch·ªâ ƒë·ªçc kh√¥ng l∆∞u
                speaker.Speak(text)
                
                return {
                    "success": True,
                    "message": f"üîä ƒê√£ ƒë·ªçc vƒÉn b·∫£n ({len(text)} k√Ω t·ª±)",
                    "text_length": len(text),
                    "engine": "Windows SAPI"
                }
        
    except ImportError as e:
        return {
            "success": False, 
            "error": f"Thi·∫øu module: {str(e)}. C√†i: pip install pywin32 gTTS pygame"
        }
    except Exception as e:
        return {"success": False, "error": f"TTS l·ªói: {str(e)}"}


async def speech_to_text(duration: int = 5, save_transcript: bool = True, filename: str = "") -> dict:
    """
    Speech-to-Text (STT): Chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n
    S·ª≠ d·ª•ng Google Speech Recognition (c·∫ßn Internet)
    """
    try:
        import speech_recognition as sr
        import os
        from datetime import datetime
        
        # Kh·ªüi t·∫°o recognizer
        recognizer = sr.Recognizer()
        
        # S·ª≠ d·ª•ng microphone
        with sr.Microphone() as source:
            print(f"üé§ ƒêang l·∫Øng nghe ({duration} gi√¢y)...")
            
            # ƒêi·ªÅu ch·ªânh nhi·ªÖu m√¥i tr∆∞·ªùng
            recognizer.adjust_for_ambient_noise(source, duration=1)
            
            # Ghi √¢m
            audio = recognizer.listen(source, timeout=duration, phrase_time_limit=duration)
            
            print("‚è≥ ƒêang nh·∫≠n d·∫°ng gi·ªçng n√≥i...")
            
            # Nh·∫≠n d·∫°ng (Google Speech Recognition - mi·ªÖn ph√≠)
            try:
                # Th·ª≠ ti·∫øng Vi·ªát tr∆∞·ªõc
                text_vi = recognizer.recognize_google(audio, language='vi-VN')
                text = text_vi
                language = "Ti·∫øng Vi·ªát"
            except:
                try:
                    # Fallback sang ti·∫øng Anh
                    text_en = recognizer.recognize_google(audio, language='en-US')
                    text = text_en
                    language = "English"
                except:
                    return {
                        "success": False,
                        "error": "Kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c gi·ªçng n√≥i. H√£y n√≥i r√µ h∆°n ho·∫∑c ki·ªÉm tra microphone."
                    }
        
        # L∆∞u transcript n·∫øu c·∫ßn
        if save_transcript and text:
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"stt_transcript_{timestamp}.txt"
            
            if not filename.endswith('.txt'):
                filename += '.txt'
            
            documents_path = os.path.expanduser("~\\Documents")
            save_folder = os.path.join(documents_path, "miniZ_STT_Transcripts")
            os.makedirs(save_folder, exist_ok=True)
            
            file_path = os.path.join(save_folder, filename)
            
            # L∆∞u k√®m metadata
            content = f"=== Speech-to-Text Transcript ===\n"
            content += f"Ng√†y: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            content += f"Ng√¥n ng·ªØ: {language}\n"
            content += f"ƒê·ªô d√†i: {duration} gi√¢y\n"
            content += f"===================================\n\n"
            content += text
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            return {
                "success": True,
                "message": f"üé§ ƒê√£ nh·∫≠n d·∫°ng v√† l∆∞u: {filename}",
                "text": text,
                "language": language,
                "path": file_path,
                "duration": duration
            }
        else:
            return {
                "success": True,
                "message": f"üé§ ƒê√£ nh·∫≠n d·∫°ng gi·ªçng n√≥i ({language})",
                "text": text,
                "language": language,
                "duration": duration
            }
        
    except ImportError:
        return {
            "success": False,
            "error": "Thi·∫øu module SpeechRecognition. C√†i: pip install SpeechRecognition pyaudio"
        }
    except Exception as e:
        return {"success": False, "error": f"STT l·ªói: {str(e)}"}


# C√ÅC H√ÄM TR√ôNG L·∫∂P ƒê√É ƒê∆Ø·ª¢C X√ìA - S·ª¨ D·ª§NG PHI√äN B·∫¢N G·ªêC ·ªû TR√äN
# minimize_all_windows -> s·ª≠ d·ª•ng show_desktop
# undo_action -> s·ª≠ d·ª•ng undo_operation  
# toggle_dark_mode -> s·ª≠ d·ª•ng set_theme
# set_wallpaper -> ƒë√£ t√≠ch h·ª£p v√†o change_wallpaper
# paste_text -> s·ª≠ d·ª•ng paste_content
# find_on_screen -> s·ª≠ d·ª•ng find_in_document
# shutdown_computer -> s·ª≠ d·ª•ng shutdown_schedule


async def find_in_document(search_text: str) -> dict:
    """T√¨m ki·∫øm trong t√†i li·ªáu (Ctrl+F)"""
    try:
        import pyperclip
        import pyautogui
        import time
        
        pyautogui.press('esc')
        time.sleep(0.3)
        pyautogui.hotkey('ctrl', 'f')
        time.sleep(0.1)
        
        pyperclip.copy(search_text)
        time.sleep(0.3)
        pyautogui.hotkey('ctrl', 'a')
        time.sleep(0.1)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.3)
        pyautogui.press('enter')
        
        return {"success": True, "message": f"ƒê√£ t√¨m ki·∫øm: {search_text}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# NEWS SCRAPING TOOLS
# ============================================================

async def get_vnexpress_news(category: str = "home", max_articles: int = 5) -> dict:
    """
    L·∫•y tin t·ª©c t·ª´ VnExpress RSS feeds (kh√¥ng c·∫ßn feedparser)
    category: home, thoi-su, goc-nhin, the-gioi, kinh-doanh, giai-tri, the-thao, phap-luat, giao-duc, suc-khoe, gia-dinh, du-lich, khoa-hoc, so-hoa, xe, cong-dong, tam-su, cuoi
    """
    try:
        import aiohttp
        import xml.etree.ElementTree as ET
        
        # RSS URL mapping
        rss_urls = {
            "home": "https://vnexpress.net/rss/tin-moi-nhat.rss",
            "thoi-su": "https://vnexpress.net/rss/thoi-su.rss",
            "the-gioi": "https://vnexpress.net/rss/the-gioi.rss",
            "kinh-doanh": "https://vnexpress.net/rss/kinh-doanh.rss",
            "giai-tri": "https://vnexpress.net/rss/giai-tri.rss",
            "the-thao": "https://vnexpress.net/rss/the-thao.rss",
            "phap-luat": "https://vnexpress.net/rss/phap-luat.rss",
            "giao-duc": "https://vnexpress.net/rss/giao-duc.rss",
            "suc-khoe": "https://vnexpress.net/rss/suc-khoe.rss",
            "du-lich": "https://vnexpress.net/rss/du-lich.rss",
            "khoa-hoc": "https://vnexpress.net/rss/khoa-hoc.rss",
            "so-hoa": "https://vnexpress.net/rss/so-hoa.rss",
            "xe": "https://vnexpress.net/rss/oto-xe-may.rss",
        }
        
        rss_url = rss_urls.get(category, rss_urls["home"])
        
        print(f"üì∞ [News] Fetching news from: {rss_url}")
        
        # ‚ö° D√πng aiohttp thay v√¨ feedparser
        # V√¥ hi·ªáu h√≥a proxy ƒë·ªÉ tr√°nh l·ªói SOCKS
        connector = aiohttp.TCPConnector()
        async with aiohttp.ClientSession(connector=connector, trust_env=False) as session:
            async with session.get(rss_url, timeout=8) as resp:
                if resp.status != 200:
                    return {"success": False, "error": f"HTTP {resp.status}"}
                
                content = await resp.text()
                root = ET.fromstring(content)
                
                articles = []
                items = root.findall('.//item')[:max_articles]
                
                for i, item in enumerate(items):
                    try:
                        title_elem = item.find('title')
                        link_elem = item.find('link')
                        pubdate_elem = item.find('pubDate')
                        desc_elem = item.find('description')
                        
                        article = {
                            "title": title_elem.text if title_elem is not None else "No title",
                            "link": link_elem.text if link_elem is not None else "",
                            "published": pubdate_elem.text if pubdate_elem is not None else "",
                            "description": ""
                        }
                        
                        # Get description (strip HTML tags)
                        if desc_elem is not None and desc_elem.text:
                            import re
                            desc_text = re.sub(r'<[^>]+>', '', desc_elem.text)
                            article["description"] = desc_text.strip()[:200] + "..."
                        
                        articles.append(article)
                        print(f"‚úÖ [News] Article {i+1}: {article['title'][:50]}...")
                        
                    except Exception as e:
                        print(f"‚ö†Ô∏è [News] Error parsing article {i+1}: {e}")
        
        result = {
            "success": True,
            "category": category,
            "total": len(articles),
            "articles": articles,
            "message": f"ƒê√£ l·∫•y {len(articles)} tin t·ª©c t·ª´ VnExpress ({category})"
        }
        
        # ü§ñ GEMINI SUMMARIZATION: N·∫øu >3 b√†i ‚Üí t√≥m t·∫Øt th√¥ng minh
        if len(articles) > 3:
            try:
                context = "\n".join([
                    f"{i+1}. {a['title']}\n   {a['description']}"
                    for i, a in enumerate(articles)
                ])
                summary_prompt = f"""T√≥m t·∫Øt {len(articles)} tin t·ª©c sau th√†nh 5 bullet points QUAN TR·ªåNG NH·∫§T (ti·∫øng Vi·ªát):

{context}

Y√™u c·∫ßu:
- M·ªói bullet point ng·∫Øn g·ªçn (1 d√≤ng)
- Highlight xu h∆∞·ªõng/s·ª± ki·ªán ch√≠nh
- ∆Øu ti√™n tin c√≥ t√°c ƒë·ªông l·ªõn
"""
                gemini_summary = await ask_gemini(summary_prompt, model="models/gemini-3-flash-preview")
                
                if gemini_summary.get("success"):
                    result["gemini_summary"] = gemini_summary["response_text"]
                    result["message"] += " (‚ú® ƒê√£ t√≥m t·∫Øt b·ªüi Gemini)"
                    print(f"‚ú® [News+Gemini] Summarized {len(articles)} articles")
            except Exception as e:
                print(f"‚ö†Ô∏è [News+Gemini] Summary failed: {e}")
        
        return result
        
    except Exception as e:
        return {"success": False, "error": f"L·ªói: {str(e)}"}


async def get_news_summary(category: str = "home") -> dict:
    """
    L·∫•y t√≥m t·∫Øt tin t·ª©c nhanh (ch·ªâ ti√™u ƒë·ªÅ)
    """
    try:
        result = await get_vnexpress_news(category=category, max_articles=10)
        
        if not result.get("success"):
            return result
        
        # T·∫°o summary text
        summary_lines = [f"üì∞ TIN T·ª®C {category.upper()} - VnExpress"]
        summary_lines.append("=" * 50)
        
        for i, article in enumerate(result["articles"], 1):
            summary_lines.append(f"{i}. {article['title']}")
        
        summary_text = "\n".join(summary_lines)
        
        # ü§ñ GEMINI INTELLIGENT SUMMARY: Ph√¢n t√≠ch xu h∆∞·ªõng + ch·ªçn top stories
        gemini_analysis = None
        if len(result["articles"]) >= 5:
            try:
                context = "\n".join([
                    f"{i+1}. {a['title']}"
                    for i, a in enumerate(result["articles"])
                ])
                analysis_prompt = f"""Ph√¢n t√≠ch {len(result['articles'])} tin t·ª©c sau v√† cho bi·∫øt:
1. Top 3 tin QUAN TR·ªåNG NH·∫§T (k√®m l√Ω do)
2. Xu h∆∞·ªõng chung
3. Ch·ªß ƒë·ªÅ n·ªïi b·∫≠t

{context}

Format ng·∫Øn g·ªçn, d·ªÖ ƒë·ªçc (ti·∫øng Vi·ªát)."""
                
                gemini_result = await ask_gemini(analysis_prompt, model="models/gemini-3-flash-preview")
                if gemini_result.get("success"):
                    gemini_analysis = gemini_result["response_text"]
                    print(f"‚ú® [News+Gemini] Analyzed {len(result['articles'])} news items")
            except Exception as e:
                print(f"‚ö†Ô∏è [News+Gemini] Analysis failed: {e}")
        
        return {
            "success": True,
            "category": category,
            "total": len(result["articles"]),
            "summary": summary_text,
            "gemini_analysis": gemini_analysis,
            "articles": result["articles"],
            "message": f"T√≥m t·∫Øt {len(result['articles'])} tin t·ª©c" + (" (‚ú® + Ph√¢n t√≠ch Gemini)" if gemini_analysis else "")
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def search_news(keyword: str, max_results: int = 5) -> dict:
    """
    T√¨m ki·∫øm tin t·ª©c theo t·ª´ kh√≥a trong c√°c b√†i vi·∫øt g·∫ßn ƒë√¢y
    """
    try:
        # Get recent news from multiple categories
        categories = ["home", "thoi-su", "the-gioi", "kinh-doanh", "the-thao"]
        all_articles = []
        
        for cat in categories:
            result = await get_vnexpress_news(category=cat, max_articles=5)
            if result.get("success"):
                all_articles.extend(result["articles"])
        
        # Filter by keyword
        keyword_lower = keyword.lower()
        matched = []
        
        for article in all_articles:
            title_lower = article["title"].lower()
            desc_lower = article.get("description", "").lower()
            
            if keyword_lower in title_lower or keyword_lower in desc_lower:
                matched.append(article)
        
        matched = matched[:max_results]
        
        if not matched:
            return {
                "success": True,
                "keyword": keyword,
                "total": 0,
                "articles": [],
                "message": f"Kh√¥ng t√¨m th·∫•y tin t·ª©c v·ªÅ '{keyword}'"
            }
        
        result = {
            "success": True,
            "keyword": keyword,
            "total": len(matched),
            "articles": matched,
            "message": f"T√¨m th·∫•y {len(matched)} tin t·ª©c v·ªÅ '{keyword}'"
        }
        
        # ü§ñ GEMINI SUMMARIZATION: N·∫øu >3 k·∫øt qu·∫£ ‚Üí t√≥m t·∫Øt nhanh
        if len(matched) > 3:
            try:
                context = "\n".join([
                    f"{i+1}. {a['title'][:100]}"
                    for i, a in enumerate(matched[:5])
                ])
                # ‚ö° PROMPT NG·∫ÆN
                summary_prompt = f"""T√≥m t·∫Øt 3-4 √Ω ch√≠nh v·ªÅ \"{keyword}\" t·ª´ {len(matched)} tin:
{context}

Format: üìå [3-4 ƒëi·ªÉm ch√≠nh]"""
                
                # ‚è±Ô∏è Timeout 8s
                gemini_summary = await asyncio.wait_for(
                    ask_gemini_direct(summary_prompt, model="models/gemini-3-flash-preview"),
                    timeout=8.0
                )
                
                if gemini_summary.get("success"):
                    result["gemini_summary"] = gemini_summary["response_text"]
                    result["message"] += " (‚ú® Gemini)"
                    print(f"‚úÖ [Search+Gemini] '{keyword}' done")
            except asyncio.TimeoutError:
                print(f"‚è±Ô∏è [Search+Gemini] Timeout for '{keyword}'")
            except Exception as e:
                print(f"‚ö†Ô∏è [Search+Gemini] Error: {e}")
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def get_gold_price() -> dict:
    """
    L·∫•y gi√° v√†ng t·ª´ c√°c ngu·ªìn uy t√≠n
    """
    try:
        import requests
        from bs4 import BeautifulSoup
        import re

        # Try multiple sources
        sources = [
            {
                "name": "Sjc.com.vn",
                "url": "https://sjc.com.vn/xml/tygiavang.xml",
                "type": "xml"
            },
            {
                "name": "BNews.vn",
                "url": "https://bnews.vn/gia-vang/t32.html",
                "type": "html"
            }
        ]

        print(f"üí∞ [Gold] Fetching gold prices...")

        # Try SJC XML first
        try:
            response = requests.get(sources[0]["url"], timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            response.encoding = 'utf-8'

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'xml')
                items = soup.find_all('item')

                if items:
                    gold_data = []

                    for item in items[:10]:
                        try:
                            gold_item = {
                                "type": item.get('@type', 'N/A'),
                                "buy": item.get('@buy', 'N/A'),
                                "sell": item.get('@sell', 'N/A')
                            }

                            # Fallback to text content if attributes not found
                            if gold_item["type"] == 'N/A':
                                type_tag = item.find('type')
                                buy_tag = item.find('buy')
                                sell_tag = item.find('sell')

                                if type_tag:
                                    gold_item["type"] = type_tag.get_text(strip=True)
                                if buy_tag:
                                    gold_item["buy"] = buy_tag.get_text(strip=True)
                                if sell_tag:
                                    gold_item["sell"] = sell_tag.get_text(strip=True)

                            gold_data.append(gold_item)
                            print(f"‚úÖ [Gold] {gold_item['type']}: Mua {gold_item['buy']} | B√°n {gold_item['sell']}")

                        except Exception as e:
                            print(f"‚ö†Ô∏è [Gold] Error parsing item: {e}")
                            continue

                    if gold_data:
                        # Lo·∫°i b·ªè tr√πng l·∫∑p
                        seen = set()
                        unique_gold_data = []
                        for item in gold_data:
                            key = f"{item['type']}_{item['buy']}_{item['sell']}"
                            if key not in seen:
                                seen.add(key)
                                unique_gold_data.append(item)
                        
                        gold_data = unique_gold_data[:10]
                        
                        # T·∫°o summary
                        summary_lines = ["üí∞ GI√Å V√ÄNG H√îM NAY - SJC", "=" * 60]

                        for item in gold_data:
                            summary_lines.append(f"üìä {item['type']}")
                            summary_lines.append(f"   Mua v√†o: {item['buy']} VNƒê | B√°n ra: {item['sell']} VNƒê")
                            summary_lines.append("")

                        summary_text = "\n".join(summary_lines)
                        
                        # üéôÔ∏è TTS-friendly description
                        tts_lines = ["Gi√° v√†ng SJC h√¥m nay nh∆∞ sau:"]
                        for item in gold_data[:5]:
                            tts_lines.append(f"Lo·∫°i {item['type']}: gi√° mua {item['buy']} ngh√¨n, gi√° b√°n {item['sell']} ngh√¨n ƒë·ªìng.")
                        tts_description = " ".join(tts_lines)

                        return {
                            "success": True,
                            "total": len(gold_data),
                            "gold_prices": gold_data,
                            "summary": summary_text,
                            "tts_description": tts_description,
                            "message": f"ƒê√£ l·∫•y gi√° {len(gold_data)} lo·∫°i v√†ng",
                            "source": "SJC.com.vn",
                            "note_for_llm": "Khi ƒë·ªçc gi√° v√†ng, h√£y d√πng tr∆∞·ªùng 'tts_description'. Gi√° t√≠nh theo ngh√¨n ƒë·ªìng/l∆∞·ª£ng."
                        }

        except Exception as e:
            print(f"‚ö†Ô∏è [Gold] Error with SJC source: {e}")

        # Fallback: Try giavang.org scraping
        try:
            print(f"üí∞ [Gold] Trying giavang.org...")
            response = requests.get('https://giavang.org/', timeout=15, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')

                # Look for gold price tables
                tables = soup.find_all('table')
                gold_data = []

                for table in tables:
                    rows = table.find_all('tr')

                    for row in rows:
                        cols = row.find_all(['td', 'th'])
                        if len(cols) >= 3:
                            # Get text from columns
                            col_texts = [col.get_text(strip=True) for col in cols]

                            # Look for gold type and prices
                            if len(col_texts) >= 3:
                                gold_type = col_texts[0]
                                buy_price = col_texts[1]
                                sell_price = col_texts[2]

                                # Check if this looks like gold data
                                if ('v√†ng' in gold_type.lower() or 'sjc' in gold_type.lower() or 'nh·∫´n' in gold_type.lower() or 'pnj' in gold_type.lower() or 'doji' in gold_type.lower()) and buy_price and sell_price:
                                    # Clean prices
                                    buy_clean = re.sub(r'[^\d]', '', buy_price)
                                    sell_clean = re.sub(r'[^\d]', '', sell_price)

                                    if buy_clean and sell_clean:
                                        # Format with dots
                                        buy_formatted = f"{int(buy_clean):,}".replace(',', '.')
                                        sell_formatted = f"{int(sell_clean):,}".replace(',', '.')

                                        gold_data.append({
                                            "type": gold_type,
                                            "buy": buy_formatted,
                                            "sell": sell_formatted
                                        })
                                        print(f"‚úÖ [Gold] {gold_type}: Mua {buy_formatted} | B√°n {sell_formatted}")

                if gold_data:
                    # Lo·∫°i b·ªè tr√πng l·∫∑p d·ª±a tr√™n type + buy + sell
                    seen = set()
                    unique_gold_data = []
                    for item in gold_data:
                        key = f"{item['type']}_{item['buy']}_{item['sell']}"
                        if key not in seen:
                            seen.add(key)
                            unique_gold_data.append(item)
                    
                    gold_data = unique_gold_data[:10]  # Max 10 items
                    
                    # T·∫°o summary d·ªÖ ƒë·ªçc cho LLM/TTS
                    summary_lines = ["üí∞ GI√Å V√ÄNG H√îM NAY - GIAVANG.ORG", "=" * 60]

                    for item in gold_data:
                        summary_lines.append(f"üìä {item['type']}")
                        summary_lines.append(f"   Mua v√†o: {item['buy']} VNƒê | B√°n ra: {item['sell']} VNƒê")
                        summary_lines.append("")

                    summary_text = "\n".join(summary_lines)
                    
                    # üéôÔ∏è TTS-friendly description cho LLM ƒë·ªçc gi√° v√†ng
                    def format_price_speech(price_str):
                        """
                        Convert gi√° v√†ng sang ti·∫øng Vi·ªát d·ªÖ ƒë·ªçc
                        - '180.100' = 180,100 ngh√¨n = 180 tri·ªáu 100 ngh√¨n VND
                        - Gi√° v√†ng hi·ªÉn th·ªã theo ngh√¨n ƒë·ªìng/l∆∞·ª£ng
                        """
                        try:
                            # Remove dots/commas and convert to number
                            clean = price_str.replace('.', '').replace(',', '')
                            num = int(clean)
                            
                            # Gi√° v√†ng t√≠nh theo ngh√¨n ƒë·ªìng/l∆∞·ª£ng
                            # V√≠ d·ª•: 180.100 = 180,100 (ngh√¨n) = 180 tri·ªáu 100 ngh√¨n VND
                            # num = 180100 ‚Üí 180 tri·ªáu + 100 ngh√¨n
                            
                            if num >= 1000:
                                # Gi√° >= 1000 ngh√¨n = t·ª´ 1 tri·ªáu tr·ªü l√™n
                                millions = num // 1000  # 180100 // 1000 = 180
                                thousands = num % 1000  # 180100 % 1000 = 100
                                
                                if millions > 0 and thousands > 0:
                                    return f"{millions} tri·ªáu {thousands} ngh√¨n"
                                elif millions > 0:
                                    return f"{millions} tri·ªáu"
                                else:
                                    return f"{thousands} ngh√¨n"
                            else:
                                return f"{num} ngh√¨n"
                        except:
                            return price_str
                    
                    # T·∫°o m√¥ t·∫£ d·∫°ng c√¢u cho TTS
                    tts_lines = ["Gi√° v√†ng h√¥m nay nh∆∞ sau:"]
                    for i, item in enumerate(gold_data[:5], 1):  # Top 5 cho TTS
                        gold_type = item['type'].replace('DOJI', 'ƒê√¥-ji').replace('PNJ', 'P√™-en-gi').replace('SJC', '√©t-gi-xi')
                        buy_speech = format_price_speech(item['buy'])
                        sell_speech = format_price_speech(item['sell'])
                        tts_lines.append(f"Lo·∫°i {gold_type}: gi√° mua {buy_speech}, gi√° b√°n {sell_speech}.")
                    
                    tts_description = " ".join(tts_lines)

                    return {
                        "success": True,
                        "total": len(gold_data),
                        "gold_prices": gold_data,
                        "summary": summary_text,
                        "tts_description": tts_description,
                        "message": f"ƒê√£ l·∫•y gi√° {len(gold_data)} lo·∫°i v√†ng t·ª´ giavang.org",
                        "source": "giavang.org",
                        "note_for_llm": "Khi ƒë·ªçc gi√° v√†ng cho ng∆∞·ªùi d√πng, h√£y d√πng tr∆∞·ªùng 'tts_description' ƒë·ªÉ ƒë·ªçc t·ª± nhi√™n b·∫±ng ti·∫øng Vi·ªát. Gi√° t√≠nh theo ngh√¨n ƒë·ªìng/l∆∞·ª£ng."
                    }

        except Exception as e:
            print(f"‚ö†Ô∏è [Gold] Error with giavang.org: {e}")

        # Final fallback: Return sample data
        sample_data = [
            {"type": "V√†ng SJC 1L, 10L", "buy": "88.500.000", "sell": "90.000.000"},
            {"type": "V√†ng SJC 5c", "buy": "88.500.000", "sell": "90.200.000"},
            {"type": "V√†ng nh·∫´n SJC 99.99 1c, 5c", "buy": "87.800.000", "sell": "89.300.000"},
            {"type": "V√†ng nh·∫´n SJC 99.99 0.5c", "buy": "87.800.000", "sell": "89.400.000"},
        ]

        summary_lines = ["üí∞ GI√Å V√ÄNG THAM KH·∫¢O", "=" * 60]
        for item in sample_data:
            summary_lines.append(f"üìä {item['type']}")
            summary_lines.append(f"   Mua v√†o: {item['buy']} VNƒê | B√°n ra: {item['sell']} VNƒê")
            summary_lines.append("")

        return {
            "success": True,
            "total": len(sample_data),
            "gold_prices": sample_data,
            "summary": "\n".join(summary_lines),
            "message": f"Gi√° v√†ng tham kh·∫£o ({len(sample_data)} lo·∫°i)",
            "source": "Sample Data",
            "note": "Gi√° tham kh·∫£o, kh√¥ng th·ªÉ k·∫øt n·ªëi ngu·ªìn ch√≠nh th·ªëng"
        }

    except Exception as e:
        return {"success": False, "error": f"L·ªói: {str(e)}"}


async def analyze_gold_price_with_ai(analysis_type: str = "compare_month") -> dict:
    """
    Ph√¢n t√≠ch gi√° v√†ng v·ªõi AI (Gemini + Google Search).
    L·∫•y gi√° hi·ªán t·∫°i, t√¨m d·ªØ li·ªáu l·ªãch s·ª≠ qua Google, v√† ph√¢n t√≠ch chi ti·∫øt.
    
    Args:
        analysis_type: Lo·∫°i ph√¢n t√≠ch. Options: "compare_month" (so s√°nh v·ªõi th√°ng tr∆∞·ªõc), "trend" (xu h∆∞·ªõng), "forecast" (d·ª± ƒëo√°n)
    """
    try:
        from datetime import datetime, timedelta
        
        print(f"üîç [Gold AI] Starting gold price analysis: {analysis_type}")
        
        # 1. L·∫•y gi√° v√†ng hi·ªán t·∫°i
        current_gold = await get_gold_price()
        if not current_gold.get("success"):
            return {"success": False, "error": "Kh√¥ng l·∫•y ƒë∆∞·ª£c gi√° v√†ng hi·ªán t·∫°i"}
        
        current_price_text = current_gold.get("summary", "")
        gold_prices = current_gold.get("gold_prices", [])
        
        # 2. T√¨m gi√° v√†ng th√°ng tr∆∞·ªõc qua Google Search (n·∫øu c√≥ Serper API)
        historical_data = ""
        
        if SERPER_API_KEY and SERPER_API_KEY.strip():
            try:
                import requests
                
                # T√≠nh th√°ng tr∆∞·ªõc
                last_month_vn = (datetime.now() - timedelta(days=30)).strftime("th√°ng %m nƒÉm %Y")
                
                # T√¨m gi√° v√†ng th√°ng tr∆∞·ªõc
                search_query = f"gi√° v√†ng SJC cao nh·∫•t {last_month_vn}"
                
                url = "https://google.serper.dev/search"
                headers = {
                    "X-API-KEY": SERPER_API_KEY,
                    "Content-Type": "application/json"
                }
                payload = {
                    "q": search_query,
                    "gl": "vn",
                    "hl": "vi",
                    "num": 5
                }
                
                response = requests.post(url, headers=headers, json=payload, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # L·∫•y Answer Box
                    answer_box = data.get("answerBox", {})
                    if answer_box:
                        answer = answer_box.get("answer", "") or answer_box.get("snippet", "")
                        if answer:
                            historical_data += f"\nüìå DIRECT ANSWER: {answer}\n"
                    
                    # L·∫•y Organic Results
                    organic = data.get("organic", [])
                    historical_data += f"\nüìä K·∫æT QU·∫¢ T√åM KI·∫æM '{search_query}':\n"
                    for i, item in enumerate(organic[:3], 1):
                        title = item.get("title", "")
                        snippet = item.get("snippet", "")
                        historical_data += f"\n{i}. {title}\n   {snippet}\n"
                    
                    print(f"‚úÖ [Gold AI] Got historical data from Google")
                else:
                    print(f"‚ö†Ô∏è [Gold AI] Serper API returned {response.status_code}")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è [Gold AI] Error fetching historical data: {e}")
                historical_data = "\n‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ Google\n"
        else:
            historical_data = "\n‚ö†Ô∏è Kh√¥ng c√≥ Serper API key ƒë·ªÉ t√¨m d·ªØ li·ªáu l·ªãch s·ª≠\n"
        
        # 3. Chu·∫©n b·ªã prompt cho Gemini - CHI TI·∫æT V·ª™A ƒê·ª¶
        if analysis_type == "compare_month":
            analysis_prompt = f"""B·∫°n l√† chuy√™n gia ph√¢n t√≠ch th·ªã tr∆∞·ªùng v√†ng. H√£y ph√¢n t√≠ch CHI TI·∫æT gi√° v√†ng:

üìä GI√Å HI·ªÜN T·∫†I ({datetime.now().strftime("%d/%m/%Y")}):
{current_price_text}

üìà D·ªÆ LI·ªÜU L·ªäCH S·ª¨:
{historical_data}

Y√äU C·∫¶U PH√ÇN T√çCH (300-400 t·ª´):
1. So s√°nh gi√° v√†ng hi·ªán t·∫°i v·ªõi th√°ng tr∆∞·ªõc (% thay ƒë·ªïi c·ª• th·ªÉ)
2. ƒê√°nh gi√° xu h∆∞·ªõng: tƒÉng/gi·∫£m/·ªïn ƒë·ªãnh (ph√¢n t√≠ch k·ªπ l∆∞·ª£ng)
3. Ph√¢n t√≠ch nguy√™n nh√¢n bi·∫øn ƒë·ªông (kinh t·∫ø, ch√≠nh tr·ªã, USD, l·∫°m ph√°t, ngu·ªìn cung)
4. D·ª± b√°o ng·∫Øn h·∫°n (1-2 tu·∫ßn t·ªõi)
5. Khuy·∫øn ngh·ªã c·ª• th·ªÉ cho nh√† ƒë·∫ßu t∆∞ (Mua/B√°n/Ch·ªù + l√Ω do chi ti·∫øt)

Format output:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üí∞ PH√ÇN T√çCH GI√Å V√ÄNG
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìä SO S√ÅNH GI√Å:
[Gi√° hi·ªán t·∫°i vs th√°ng tr∆∞·ªõc, % thay ƒë·ªïi, bi·ªÉu hi·ªán th·ªã tr∆∞·ªùng]

üìà XU H∆Ø·ªöNG:
[Nh·∫≠n ƒë·ªãnh chi ti·∫øt v·ªÅ xu h∆∞·ªõng tƒÉng/gi·∫£m, m·ª©c ƒë·ªô bi·∫øn ƒë·ªông]

üîç NGUY√äN NH√ÇN:
[Ph√¢n t√≠ch 3-4 nguy√™n nh√¢n ch√≠nh v·ªõi gi·∫£i th√≠ch c·ª• th·ªÉ]

üîÆ D·ª∞ B√ÅO:
[D·ª± ƒëo√°n ng·∫Øn h·∫°n v√† cƒÉn c·ª©]

üí° KHUY·∫æN NGH·ªä:
[L·ªùi khuy√™n c·ª• th·ªÉ cho nh√† ƒë·∫ßu t∆∞: Mua/B√°n/Ch·ªù + m·ª©c gi√° n√™n giao d·ªãch]

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""
        elif analysis_type == "trend":
            analysis_prompt = f"""Ph√¢n t√≠ch xu h∆∞·ªõng gi√° v√†ng (200-300 t·ª´):

GI√Å HI·ªÜN T·∫†I: {current_price_text}
D·ªÆ LI·ªÜU: {historical_data}

Tr·∫£ l·ªùi ng·∫Øn:
üìà Xu h∆∞·ªõng ng·∫Øn h·∫°n: [1-2 tu·∫ßn]
üìä Xu h∆∞·ªõng trung h·∫°n: [1-3 th√°ng] 
üîç Y·∫øu t·ªë ch√≠nh: [1-2 ƒëi·ªÉm]
"""
        else:  # forecast
            analysis_prompt = f"""D·ª± b√°o gi√° v√†ng (t·ªëi ƒëa 100 t·ª´):

HI·ªÜN T·∫†I: {current_price_text}
L·ªäCH S·ª¨: {historical_data}

Tr·∫£ l·ªùi ng·∫Øn:
üìä D·ª± b√°o: [tƒÉng/gi·∫£m x%]
‚è∞ Th·ªùi gian: [ng·∫Øn/trung h·∫°n]
üí° Khuy·∫øn ngh·ªã: [h√†nh ƒë·ªông c·ª• th·ªÉ]
"""
        
        # 4. G·ªçi Gemini ph√¢n t√≠ch
        if not GEMINI_AVAILABLE or not GEMINI_API_KEY:
            return {
                "success": False,
                "error": "Gemini API kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng c·∫•u h√¨nh GEMINI_API_KEY."
            }
        
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)
        
        model = genai.GenerativeModel('models/gemini-3-flash-preview')
        
        print(f"ü§ñ [Gold AI] Asking Gemini to analyze...")
        response = model.generate_content(
            analysis_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=1500  # TƒÉng l√™n 1500 ƒë·ªÉ ph√¢n t√≠ch chuy√™n s√¢u
            )
        )
        
        analysis_result = response.text.strip()
        
        print(f"‚úÖ [Gold AI] Analysis complete")
        
        # Return ONLY analysis text - tr√°nh b·ªã truncate
        return {
            "success": True,
            "content": analysis_result  # Ch·ªâ tr·∫£ v·ªÅ n·ªôi dung ph√¢n t√≠ch
        }
        
    except Exception as e:
        print(f"‚ùå [Gold AI] Error: {e}")
        return {
            "success": False,
            "error": f"L·ªói ph√¢n t√≠ch: {str(e)}"
        }


# ============================================================================
# üîç GEMINI WITH GOOGLE SEARCH GROUNDING
# ============================================================================
# T√≠nh nƒÉng cho ph√©p Gemini t·ª± ƒë·ªông tra c·ª©u Google ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c h∆°n
# S·ª≠ d·ª•ng Google Search Grounding API ch√≠nh th·ª©c

async def ask_gemini_with_google_search(
    prompt: str, 
    model: str = "gemini-2.0-flash",
    dynamic_threshold: float = 0.7
) -> dict:
    """
    üîç H·ªèi Gemini v·ªõi Google Search Grounding - Tra c·ª©u Google t·ª± ƒë·ªông
    
    T√≠nh nƒÉng n√†y cho ph√©p Gemini:
    - T·ª± ƒë·ªông t√¨m ki·∫øm th√¥ng tin m·ªõi nh·∫•t tr√™n Google
    - Tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu real-time t·ª´ internet
    - Cung c·∫•p ngu·ªìn tr√≠ch d·∫´n (citations)
    
    Args:
        prompt: C√¢u h·ªèi c·∫ßn Gemini tr·∫£ l·ªùi v·ªõi th√¥ng tin m·ªõi nh·∫•t
        model: Model Gemini h·ªó tr·ª£ grounding (gemini-2.0-flash, gemini-1.5-pro, etc.)
        dynamic_threshold: Ng∆∞·ª°ng ƒë·ªÉ quy·∫øt ƒë·ªãnh khi n√†o d√πng grounding (0.0-1.0)
        
    Returns:
        dict v·ªõi success, response, grounding_metadata, search_queries
    """
    try:
        if not GEMINI_AVAILABLE:
            return {"success": False, "error": "Gemini library ch∆∞a c√†i ƒë·∫∑t"}
        
        if not GEMINI_API_KEY or not GEMINI_API_KEY.strip():
            return {"success": False, "error": "Gemini API key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh"}
        
        print(f"üîç [Gemini+GoogleSearch] Starting with model: {model}")
        print(f"üîç [Gemini+GoogleSearch] Prompt: {prompt[:100]}...")
        
        # Import c√°c module c·∫ßn thi·∫øt t·ª´ google.genai
        try:
            from google import genai
            from google.genai import types
        except ImportError:
            # Fallback: D√πng google-generativeai c≈©
            print("‚ö†Ô∏è [Gemini+GoogleSearch] google-genai not found, using legacy method")
            return await _ask_gemini_google_search_legacy(prompt, model)
        
        # Kh·ªüi t·∫°o client v·ªõi API key
        client = genai.Client(api_key=GEMINI_API_KEY)
        
        # C·∫•u h√¨nh Google Search tool v·ªõi dynamic retrieval
        google_search_tool = types.Tool(
            google_search=types.GoogleSearch()
        )
        
        # System instruction ƒë·ªÉ Gemini tr·∫£ l·ªùi chuy√™n nghi·ªáp
        from datetime import datetime
        today_str = datetime.now().strftime('%d/%m/%Y')
        today_full = datetime.now().strftime('%A, %d th√°ng %m nƒÉm %Y')
        
        system_instruction = f"""B·∫°n l√† tr·ª£ l√Ω AI chuy√™n nghi·ªáp v·ªõi kh·∫£ nƒÉng tra c·ª©u th√¥ng tin m·ªõi nh·∫•t t·ª´ Google.

üìÖ NG√ÄY H√îM NAY: {today_full}

üéØ H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
1. S·ª¨ D·ª§NG GOOGLE SEARCH ƒë·ªÉ t√¨m th√¥ng tin m·ªõi nh·∫•t, ch√≠nh x√°c
2. ∆ØU TI√äN ngu·ªìn ƒë√°ng tin c·∫≠y: trang ch√≠nh th·ª©c, b√°o l·ªõn, Wikipedia
3. PH√ÇN T√çCH th·ªùi gian - n·∫øu th√¥ng tin t·ª´ qu√° kh·ª©, x√°c ƒë·ªãnh xem c√≤n ƒë√∫ng kh√¥ng
4. TR·∫¢ L·ªúI ng·∫Øn g·ªçn, s√∫c t√≠ch (200-500 t·ª´)
5. TR√çCH D·∫™N ngu·ªìn khi c·∫ßn thi·∫øt
6. KH√îNG n√≥i "d·ª± ki·∫øn" n·∫øu s·ª± ki·ªán ƒë√£ x·∫£y ra
7. N√≥i nh∆∞ ƒëang tr√≤ chuy·ªán t·ª± nhi√™n, kh√¥ng d√πng markdown ph·ª©c t·∫°p"""

        # G·ªçi Gemini v·ªõi Google Search grounding
        loop = asyncio.get_event_loop()
        
        response = await asyncio.wait_for(
            loop.run_in_executor(
                None,
                lambda: client.models.generate_content(
                    model=model,
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        tools=[google_search_tool],
                        system_instruction=system_instruction,
                        temperature=0.7,
                    )
                )
            ),
            timeout=30.0  # Timeout 30s v√¨ c·∫ßn th·ªùi gian search
        )
        
        # L·∫•y text response
        response_text = ""
        if hasattr(response, 'text'):
            response_text = response.text
        elif hasattr(response, 'candidates') and response.candidates:
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'text'):
                    response_text += part.text
        
        # L·∫•y grounding metadata (ngu·ªìn tr√≠ch d·∫´n)
        grounding_metadata = None
        search_queries = []
        grounding_chunks = []
        
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'grounding_metadata'):
                gm = candidate.grounding_metadata
                grounding_metadata = {
                    "search_entry_point": getattr(gm, 'search_entry_point', None),
                    "grounding_supports": []
                }
                
                # L·∫•y search queries ƒë√£ d√πng
                if hasattr(gm, 'web_search_queries'):
                    search_queries = list(gm.web_search_queries or [])
                
                # L·∫•y grounding chunks (ngu·ªìn)
                if hasattr(gm, 'grounding_chunks'):
                    for chunk in (gm.grounding_chunks or []):
                        if hasattr(chunk, 'web'):
                            grounding_chunks.append({
                                "uri": getattr(chunk.web, 'uri', ''),
                                "title": getattr(chunk.web, 'title', '')
                            })
                
                # L·∫•y grounding supports
                if hasattr(gm, 'grounding_supports'):
                    for support in (gm.grounding_supports or []):
                        support_data = {
                            "segment": getattr(support.segment, 'text', '') if hasattr(support, 'segment') else '',
                            "confidence_scores": list(support.confidence_scores or []) if hasattr(support, 'confidence_scores') else []
                        }
                        grounding_metadata["grounding_supports"].append(support_data)
        
        print(f"‚úÖ [Gemini+GoogleSearch] Response received: {len(response_text)} chars")
        if search_queries:
            print(f"üîé [Gemini+GoogleSearch] Search queries: {search_queries}")
        if grounding_chunks:
            print(f"üìö [Gemini+GoogleSearch] Sources: {len(grounding_chunks)} websites")
        
        # Truncate response n·∫øu qu√° d√†i
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
        
        return {
            "success": True,
            "response": response_text,
            "response_text": response_text,  # Alias for compatibility
            "model": model,
            "google_search_used": True,
            "search_queries": search_queries,
            "grounding_chunks": grounding_chunks,
            "grounding_metadata": grounding_metadata,
            "message": f"‚úÖ Gemini ƒë√£ tra c·ª©u Google v√† tr·∫£ l·ªùi (model: {model})"
        }
        
    except asyncio.TimeoutError:
        print(f"‚è±Ô∏è [Gemini+GoogleSearch] Timeout (30s exceeded)")
        return {
            "success": False,
            "error": "Gemini + Google Search ph·∫£n h·ªìi qu√° l√¢u (timeout 30s)",
            "timeout": True
        }
    except ImportError as e:
        print(f"‚ö†Ô∏è [Gemini+GoogleSearch] Import error: {e}")
        # Fallback to legacy method
        return await _ask_gemini_google_search_legacy(prompt, model)
    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå [Gemini+GoogleSearch] Error: {error_msg}")
        
        # N·∫øu model kh√¥ng h·ªó tr·ª£ grounding, th·ª≠ fallback
        if "grounding" in error_msg.lower() or "tool" in error_msg.lower():
            print("‚ö†Ô∏è [Gemini+GoogleSearch] Grounding not supported, falling back...")
            return await ask_gemini(prompt, model)
        
        return {
            "success": False,
            "error": f"L·ªói Google Search Grounding: {error_msg}"
        }


async def _ask_gemini_google_search_legacy(prompt: str, model: str = "gemini-2.0-flash") -> dict:
    """
    Fallback: D√πng google-generativeai c≈© v·ªõi grounding
    """
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        
        from datetime import datetime
        today_str = datetime.now().strftime('%d/%m/%Y')
        
        # C·∫•u h√¨nh model v·ªõi grounding
        generation_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "max_output_tokens": 2048,
        }
        
        # T·∫°o tool Google Search
        try:
            # Th·ª≠ d√πng google_search_retrieval (phi√™n b·∫£n m·ªõi)
            tools = [{"google_search_retrieval": {"dynamic_retrieval_config": {"mode": "MODE_DYNAMIC", "dynamic_threshold": 0.7}}}]
            gemini_model = genai.GenerativeModel(
                model,
                generation_config=generation_config,
                tools=tools
            )
        except Exception:
            # Fallback: kh√¥ng d√πng tools
            gemini_model = genai.GenerativeModel(model, generation_config=generation_config)
        
        system_prompt = f"""H√¥m nay l√† {today_str}. B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh.
H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ki·∫øn th·ª©c c·ªßa b·∫°n. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, chuy√™n nghi·ªáp."""
        
        full_prompt = f"{system_prompt}\n\nC√¢u h·ªèi: {prompt}"
        
        loop = asyncio.get_event_loop()
        response = await asyncio.wait_for(
            loop.run_in_executor(None, lambda: gemini_model.generate_content(full_prompt)),
            timeout=25.0
        )
        
        response_text = response.text if hasattr(response, 'text') else str(response)
        
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
        
        return {
            "success": True,
            "response": response_text,
            "response_text": response_text,
            "model": model,
            "google_search_used": False,
            "message": f"‚úÖ Gemini ƒë√£ tr·∫£ l·ªùi (model: {model}, legacy mode)"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def ask_gemini_direct(prompt: str, model: str = "models/gemini-3-flash-preview") -> dict:
    """
    G·ªçi Gemini tr·ª±c ti·∫øp KH√îNG c√≥ RAG - d√πng cho summarization/analysis
    
    Args:
        prompt: Prompt g·ª≠i cho Gemini
        model: Model Gemini (m·∫∑c ƒë·ªãnh: gemini-3-flash-preview)
        
    Returns:
        dict v·ªõi success, response_text
    """
    try:
        # Ki·ªÉm tra Gemini c√≥ kh·∫£ d·ª•ng kh√¥ng
        if not GEMINI_AVAILABLE:
            return {"success": False, "error": "Gemini library ch∆∞a c√†i ƒë·∫∑t"}
        
        if not GEMINI_API_KEY or GEMINI_API_KEY.strip() == "":
            return {"success": False, "error": "Gemini API key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh"}
        
        # C·∫•u h√¨nh Gemini
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_model = genai.GenerativeModel(model)
        
        # G·ªçi API v·ªõi timeout 15 gi√¢y
        loop = asyncio.get_event_loop()
        response = await asyncio.wait_for(
            loop.run_in_executor(
                None, 
                lambda: gemini_model.generate_content(prompt)
            ),
            timeout=15.0
        )
        
        response_text = response.text
        
        # üîÑ TRUNCATE: Gi·ªõi h·∫°n response d∆∞·ªõi 4000 k√Ω t·ª± cho LLM
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            original_len = len(response_text)
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
            print(f"[Gemini Direct] ‚úÇÔ∏è Truncated: {original_len} ‚Üí {len(response_text)} chars")
        
        return {
            "success": True,
            "response_text": response_text,
            "model": model
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def ask_gemini(prompt: str, model: str = "models/gemini-3-flash-preview") -> dict:
    """
    H·ªèi ƒë√°p v·ªõi Google Gemini AI - C√≥ t√≠ch h·ª£p RAG t·ª± ƒë·ªông
    
    Args:
        prompt: C√¢u h·ªèi ho·∫∑c n·ªôi dung mu·ªën g·ª≠i cho Gemini
        model: T√™n model Gemini (m·∫∑c ƒë·ªãnh: models/gemini-3-flash-preview - Flash 2.0 experimental)
        
    Returns:
        dict v·ªõi success, response_text, v√† message
    """
    try:
        # ===== AUTO RAG: Ki·ªÉm tra c√≥ c·∫ßn tra c·ª©u web kh√¥ng =====
        # M·ªü r·ªông keywords ƒë·ªÉ bao qu√°t nhi·ªÅu c√¢u h·ªèi th·ªùi s·ª± h∆°n
        realtime_keywords = [
            # Gi√° c·∫£, t√†i ch√≠nh
            'gi√° v√†ng', 'gi√° usd', 't·ª∑ gi√°', 'gi√° bitcoin', 'crypto', 'ch·ª©ng kho√°n', 
            'stock', 'gold price', 'exchange rate', 'gi√° xƒÉng', 'gi√° d·∫ßu',
            'gi√° cao nh·∫•t', 'cao nh·∫•t', 'th·∫•p nh·∫•t', 'gi√° hi·ªán t·∫°i', 'gi√° m·ªõi nh·∫•t',
            'highest price', 'lowest price', 'current price', 'latest price',
            
            # Th·ªùi ti·∫øt
            'th·ªùi ti·∫øt', 'weather', 'nhi·ªát ƒë·ªô', 'temperature', 'm∆∞a', 'rain',
            
            # Tin t·ª©c, s·ª± ki·ªán
            'tin t·ª©c', 'news', 'm·ªõi nh·∫•t', 'latest', 'breaking',
            
            # Th·ªùi gian th·ª±c
            'h√¥m nay', 'b√¢y gi·ªù', 'hi·ªán nay', 'hi·ªán t·∫°i', 'today', 'now', 'current',
            'currently', 'nƒÉm 2024', 'nƒÉm 2025', '2024', '2025',
            
            # Th·ªÉ thao, cu·ªôc thi
            'v√¥ ƒë·ªãch', 'champion', 'winner', 'k·∫øt qu·∫£', 'score', 'result',
            'olympia', 'world cup', 'euro', 'sea games', 'olympic', 'b√≥ng ƒë√°', 'football',
            
            # Ng∆∞·ªùi n·ªïi ti·∫øng, ch√≠nh tr·ªã
            't·ªïng th·ªëng', 'president', 'th·ªß t∆∞·ªõng', 'prime minister', 'ch·ªß t·ªãch',
            'ceo', 'founder', 'leader', 'ai l√†', 'who is', 'who are',
            
            # S·∫£n ph·∫©m, c√¥ng ngh·ªá m·ªõi
            'iphone', 'samsung', 'tesla', 'apple', 'google', 'microsoft',
            'ra m·∫Øt', 'launch', 'release', 'announced',
            
            # S·ª± ki·ªán x√£ h·ªôi
            'covid', 'earthquake', 'ƒë·ªông ƒë·∫•t', 'b√£o', 'storm', 'l≈© l·ª•t', 'flood',
            'tai n·∫°n', 'accident', 'ch√°y', 'fire',
            
            # Tra c·ª©u chung
            'l√† ai', 'l√† g√¨', '·ªü ƒë√¢u', 'what is', 'where is', 'how much',
            'bao nhi√™u', 'khi n√†o', 'when'
        ]
        prompt_lower = prompt.lower()
        needs_realtime = any(kw in prompt_lower for kw in realtime_keywords)
        
        rag_context = ""
        if needs_realtime:
            # ‚úÖ ∆Øu ti√™n Serper API (Google Search tr·ª±c ti·∫øp) - ch√≠nh x√°c v√† nhanh h∆°n
            if SERPER_API_KEY and SERPER_API_KEY.strip():
                print(f"[Gemini+Serper] Ph√°t hi·ªán c√¢u h·ªèi th·ªùi gian th·ª±c, ƒëang tra c·ª©u Google...")
                try:
                    import requests
                    from datetime import datetime
                    
                    # Th√™m ng√†y th√°ng nƒÉm hi·ªán t·∫°i v√†o query ƒë·ªÉ l·∫•y th√¥ng tin m·ªõi nh·∫•t
                    current_date = datetime.now().strftime("%Y")
                    enhanced_query = f"{prompt} {current_date}"
                    
                    # G·ªçi Serper API (Google Search)
                    url = "https://google.serper.dev/search"
                    headers = {
                        "X-API-KEY": SERPER_API_KEY,
                        "Content-Type": "application/json"
                    }
                    payload = {
                        "q": enhanced_query,
                        "gl": "vn",  # Vietnam
                        "hl": "vi",  # Vietnamese
                        "num": 5
                    }
                    
                    # ‚ö° TIMEOUT 8s cho Serper API
                    response = requests.post(url, headers=headers, json=payload, timeout=8)
                    
                    if response.status_code == 200:
                        data = response.json()
                        results = []
                        
                        # L·∫•y Answer Box tr∆∞·ªõc (n·∫øu c√≥)
                        answer_box = data.get("answerBox", {})
                        if answer_box:
                            answer = answer_box.get("answer", "") or answer_box.get("snippet", "")
                            if answer:
                                results.append({
                                    "title": "[üìå Direct Answer]",
                                    "snippet": answer,
                                    "url": answer_box.get("link", "")
                                })
                        
                        # L·∫•y Knowledge Graph (n·∫øu c√≥)
                        knowledge_graph = data.get("knowledgeGraph", {})
                        if knowledge_graph:
                            title = knowledge_graph.get("title", "")
                            description = knowledge_graph.get("description", "")
                            if title and description:
                                results.append({
                                    "title": f"[üéØ Knowledge] {title}",
                                    "snippet": description,
                                    "url": knowledge_graph.get("website", "")
                                })
                        
                        # L·∫•y Organic Results
                        organic = data.get("organic", [])
                        for item in organic[:5]:
                            results.append({
                                "title": item.get("title", ""),
                                "snippet": item.get("snippet", ""),
                                "url": item.get("link", "")
                            })
                        
                        if results:
                            rag_context = f"\n\nüìä TH√îNG TIN T·ª™ GOOGLE (tra c·ª©u {datetime.now().strftime('%d/%m/%Y')}):\n"
                            rag_context += "L∆ØU √ù: H√£y ph√¢n t√≠ch k·ªπ c√°c ngu·ªìn v√† ch·ªçn th√¥ng tin ch√≠nh x√°c nh·∫•t.\n\n"
                            
                            for i, r in enumerate(results, 1):
                                snippet = r['snippet'][:300] if len(r['snippet']) > 300 else r['snippet']
                                rag_context += f"{i}. **{r['title']}**\n   {snippet}\n   üîó {r.get('url', '')}\n\n"
                            
                            print(f"[Gemini+Serper] ‚úÖ ƒê√£ l·∫•y ƒë∆∞·ª£c {len(results)} k·∫øt qu·∫£ t·ª´ Google")
                    else:
                        print(f"[Gemini+Serper] ‚ö†Ô∏è API error: {response.status_code}")
                        
                except Exception as e:
                    print(f"[Gemini+Serper] ‚ö†Ô∏è L·ªói tra c·ª©u: {e}")
            
            # Fallback: D√πng RAG system n·∫øu kh√¥ng c√≥ Serper API
            elif RAG_AVAILABLE:
                print(f"[Gemini+RAG] Serper API kh√¥ng c√≥, d√πng RAG fallback...")
                try:
                    from rag_system import web_search
                    from datetime import datetime
                    
                    current_date = datetime.now().strftime("%Y")
                    enhanced_query = f"{prompt} {current_date}"
                    
                    rag_result = await web_search(enhanced_query, max_results=5)
                    
                    if rag_result.get('success') and rag_result.get('results'):
                        rag_context = f"\n\nüìä TH√îNG TIN T·ª™ INTERNET (tra c·ª©u {datetime.now().strftime('%d/%m/%Y')}):\n"
                        rag_context += "L∆ØU √ù: H√£y ph√¢n t√≠ch k·ªπ c√°c ngu·ªìn v√† ch·ªçn th√¥ng tin ch√≠nh x√°c nh·∫•t.\n\n"
                        
                        for i, r in enumerate(rag_result['results'], 1):
                            snippet = r['snippet'][:300] if len(r['snippet']) > 300 else r['snippet']
                            rag_context += f"{i}. **{r['title']}**\n   {snippet}\n   üîó {r.get('url', '')}\n\n"
                        
                        print(f"[Gemini+RAG] ‚úÖ ƒê√£ l·∫•y ƒë∆∞·ª£c {len(rag_result['results'])} k·∫øt qu·∫£ t·ª´ web")
                except Exception as e:
                    print(f"[Gemini+RAG] ‚ö†Ô∏è L·ªói tra c·ª©u: {e}")
        
        # Ki·ªÉm tra Gemini c√≥ kh·∫£ d·ª•ng kh√¥ng
        if not GEMINI_AVAILABLE:
            return {
                "success": False,
                "error": "Gemini library ch∆∞a c√†i ƒë·∫∑t. Ch·∫°y: pip install google-generativeai"
            }
        
        # Ki·ªÉm tra API key
        if not GEMINI_API_KEY or GEMINI_API_KEY.strip() == "":
            return {
                "success": False,
                "error": "Gemini API key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng th√™m 'gemini_api_key' v√†o xiaozhi_endpoints.json",
                "help": "L·∫•y API key t·∫°i: https://aistudio.google.com/apikey"
            }
        
        # C·∫•u h√¨nh Gemini v·ªõi API key
        genai.configure(api_key=GEMINI_API_KEY)
        print(f"[Gemini] Configured with API key: ...{GEMINI_API_KEY[-8:]}")
        
        # Kh·ªüi t·∫°o model
        print(f"[Gemini] Creating model: {model}")
        gemini_model = genai.GenerativeModel(model)
        print(f"[Gemini] Model created successfully")
        
        # G·ªçi API trong executor ƒë·ªÉ kh√¥ng block event loop
        # Th√™m RAG context v√†o prompt n·∫øu c√≥
        from datetime import datetime as dt_now
        enhanced_prompt = prompt
        
        # üìù INSTRUCTION: Y√™u c·∫ßu Gemini tr·∫£ l·ªùi ng·∫Øn g·ªçn cho TTS
        response_instruction = """

üìã Y√äU C·∫¶U TR·∫¢ L·ªúI:
- Tr·∫£ l·ªùi NG·∫ÆN G·ªåN, D·ªÑ HI·ªÇU (t·ªëi ƒëa 300-500 t·ª´)
- ƒêi th·∫≥ng v√†o v·∫•n ƒë·ªÅ, kh√¥ng d√†i d√≤ng
- KH√îNG d√πng markdown (**, #, ---, bullet points)
- N√≥i nh∆∞ ƒëang tr√≤ chuy·ªán t·ª± nhi√™n
- D√πng c√¢u ng·∫Øn, d·ªÖ ƒë·ªçc"""

        if rag_context:
            today_str = dt_now.now().strftime('%d/%m/%Y')
            today_full = dt_now.now().strftime('%d th√°ng %m nƒÉm %Y')
            enhanced_prompt = f"""C√ÇU H·ªéI: {prompt}

{rag_context}

‚ö†Ô∏è QUAN TR·ªåNG - NG√ÄY HI·ªÜN T·∫†I: {today_full}

H∆Ø·ªöNG D·∫™N PH√ÇN T√çCH TH√îNG MINH:
1. **SO S√ÅNH TH·ªúI GIAN**: So s√°nh ng√†y trong b√†i b√°o v·ªõi ng√†y h√¥m nay ({today_str})
   - N·∫øu b√†i vi·∫øt c√≥ t·ª´ "d·ª± ki·∫øn", "s·∫Øp ra m·∫Øt", "s·∫Ω ra m·∫Øt" V√Ä ng√†y ƒë√≥ ƒê√É QUA ‚Üí s·∫£n ph·∫©m ƒê√É RA M·∫ÆT r·ªìi!
   - V√≠ d·ª•: N·∫øu b√†i vi·∫øt n√≥i "d·ª± ki·∫øn ra m·∫Øt th√°ng 9/2025" v√† h√¥m nay l√† th√°ng 12/2025 ‚Üí ƒê√É RA M·∫ÆT

2. **X√ÅC ƒê·ªäNH TR·∫†NG TH√ÅI HI·ªÜN T·∫†I**:
   - Ki·ªÉm tra xem c√°c ngu·ªìn c√≥ n√≥i "ƒë√£ ra m·∫Øt", "ƒë√£ c√≥ h√†ng", "ƒë·∫∑t tr∆∞·ªõc t·ª´..." kh√¥ng
   - N·∫øu c√≥ ng√†y ƒë·∫∑t tr∆∞·ªõc/ng√†y b√°n ƒê√É QUA ‚Üí s·∫£n ph·∫©m ƒêANG B√ÅN
   - N·∫øu ngu·ªìn ch√≠nh th·ª©c (apple.com, thegioididong.com) n√≥i "s·∫µn h√†ng" ‚Üí ƒê√É C√ì B√ÅN

3. **∆ØU TI√äN NGU·ªíN**:
   - Trang ch√≠nh th·ª©c (apple.com, google.com...) > B√°o l·ªõn > Blog
   - Ngu·ªìn m·ªõi nh·∫•t > Ngu·ªìn c≈©

4. **TR·∫¢ L·ªúI CH√çNH X√ÅC**:
   - KH√îNG n√≥i "d·ª± ki·∫øn" n·∫øu ng√†y ƒë√≥ ƒë√£ qua
   - D√πng th√¨ HI·ªÜN T·∫†I/QU√Å KH·ª® ph√π h·ª£p
   - V√≠ d·ª• ƒê√öNG: "iPhone 17 ƒë√£ ra m·∫Øt v√†o th√°ng 9/2025 v√† hi·ªán ƒëang b√°n t·∫°i..."
   - V√≠ d·ª• SAI: "iPhone 17 d·ª± ki·∫øn ra m·∫Øt th√°ng 9/2025" (khi ƒë√£ l√† th√°ng 12/2025!)
{response_instruction}

TR·∫¢ L·ªúI (nh·ªõ: h√¥m nay l√† {today_str}, ph√¢n t√≠ch th·ªùi gian ch√≠nh x√°c):"""
            print(f"[Gemini+RAG] ƒê√£ b·ªï sung context t·ª´ web v√†o prompt")
        else:
            # Kh√¥ng c√≥ RAG, th√™m instruction v√†o prompt th√¥ng th∆∞·ªùng
            enhanced_prompt = f"""{prompt}
{response_instruction}"""
        
        print(f"[Gemini] Sending prompt: {enhanced_prompt[:50]}...")
        loop = asyncio.get_event_loop()
        
        # ‚ö° TIMEOUT 20s cho ask_gemini ch√≠nh (c√≥ RAG)
        response = await asyncio.wait_for(
            loop.run_in_executor(
                None,
                lambda: gemini_model.generate_content(enhanced_prompt)
            ),
            timeout=20.0
        )
        print(f"[Gemini] Response received")
        
        # L·∫•y text t·ª´ response
        response_text = response.text if hasattr(response, 'text') else str(response)
        
        # üîÑ TRUNCATE: Gi·ªõi h·∫°n response d∆∞·ªõi 4000 k√Ω t·ª± cho LLM
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            original_len = len(response_text)
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
            print(f"[Gemini] ‚úÇÔ∏è Truncated response: {original_len} ‚Üí {len(response_text)} chars")
        
        print(f"[Gemini] Response text: {response_text[:100]}...")
        
        result = {
            "success": True,
            "prompt": prompt,
            "response_text": response_text,
            "model": model,
            "message": f"‚úÖ Gemini ƒë√£ tr·∫£ l·ªùi (model: {model})"
        }
        
        # Th√™m th√¥ng tin RAG n·∫øu ƒë√£ s·ª≠ d·ª•ng
        if rag_context:
            result["rag_used"] = True
            result["message"] = f"‚úÖ Gemini ƒë√£ tr·∫£ l·ªùi v·ªõi th√¥ng tin t·ª´ Internet (model: {model})"
        
        return result
        
    except asyncio.TimeoutError:
        print(f"‚è±Ô∏è [Gemini] Timeout (20s exceeded)")
        return {
            "success": False,
            "error": "Gemini ph·∫£n h·ªìi qu√° l√¢u (timeout 20s). Vui l√≤ng th·ª≠ l·∫°i v·ªõi prompt ng·∫Øn h∆°n.",
            "timeout": True
        }
    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå [Gemini] Exception caught: {type(e).__name__}")
        print(f"‚ùå [Gemini] Error message: {error_msg}")
        
        # Import traceback ƒë·ªÉ debug
        import traceback
        traceback.print_exc()
        
        # X·ª≠ l√Ω c√°c l·ªói ph·ªï bi·∫øn
        if "API_KEY_INVALID" in error_msg or "invalid API key" in error_msg.lower():
            return {
                "success": False,
                "error": "API key kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i gemini_api_key trong xiaozhi_endpoints.json",
                "help": "L·∫•y API key m·ªõi t·∫°i: https://aistudio.google.com/apikey"
            }
        elif "quota" in error_msg.lower():
            return {
                "success": False,
                "error": "ƒê√£ v∆∞·ª£t qu√° quota API. Vui l√≤ng ch·ªù ho·∫∑c n√¢ng c·∫•p plan.",
                "details": error_msg
            }
        elif "rate limit" in error_msg.lower():
            return {
                "success": False,
                "error": "Rate limit exceeded. Vui l√≤ng th·ª≠ l·∫°i sau √≠t ph√∫t.",
                "details": error_msg
            }
        else:
            return {
                "success": False,
                "error": f"L·ªói khi g·ªçi Gemini API: {error_msg}"
            }


# ============================================================================
# ü§ñ GEMINI WITH TOOLS - CHO PH√âP GEMINI ƒêI·ªÄU KHI·ªÇN M√ÅY T√çNH NH∆Ø LLM XIAOZHI
# ============================================================================

async def ask_gemini_with_tools(
    prompt: str, 
    model: str = "models/gemini-2.0-flash",
    auto_execute: bool = True,
    max_tool_calls: int = 5
) -> dict:
    """
    ü§ñ GEMINI AI V·ªöI KH·∫¢ NƒÇNG ƒêI·ªÄU KHI·ªÇN M√ÅY T√çNH
    
    Cho ph√©p Gemini ph√¢n t√≠ch y√™u c·∫ßu v√† T·ª∞ ƒê·ªòNG g·ªçi c√°c MCP tools ƒë·ªÉ:
    - M·ªü ·ª©ng d·ª•ng (Notepad, Chrome, Calculator, VLC...)
    - ƒêi·ªÅu khi·ªÉn nh·∫°c (play, pause, next, previous, volume...)
    - ƒêi·ªÅu khi·ªÉn m√°y t√≠nh (shutdown, restart, lock, sleep...)
    - Ch·ª•p m√†n h√¨nh, l·∫•y th√¥ng tin h·ªá th·ªëng
    - T√¨m ki·∫øm web, m·ªü website
    - V√† T·∫§T C·∫¢ c√°c c√¥ng c·ª• kh√°c c·ªßa miniZ MCP
    
    Args:
        prompt: Y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng
        model: Model Gemini (m·∫∑c ƒë·ªãnh: gemini-2.0-flash - nhanh v√† t·ªët cho function calling)
        auto_execute: T·ª± ƒë·ªông th·ª±c thi tool (True) hay ch·ªâ ƒë·ªÅ xu·∫•t (False)
        max_tool_calls: S·ªë l∆∞·ª£ng tool t·ªëi ƒëa c√≥ th·ªÉ g·ªçi trong 1 request
        
    Returns:
        dict v·ªõi:
        - success: True/False
        - response_text: Ph·∫£n h·ªìi t·ª´ Gemini
        - tools_called: List c√°c tools ƒë√£ g·ªçi
        - tools_results: K·∫øt qu·∫£ t·ª´ng tool
    """
    try:
        if not GEMINI_AVAILABLE:
            return {"success": False, "error": "Gemini library ch∆∞a c√†i ƒë·∫∑t"}
        
        if not GEMINI_API_KEY or GEMINI_API_KEY.strip() == "":
            return {"success": False, "error": "Gemini API key ch∆∞a c·∫•u h√¨nh"}
        
        # C·∫•u h√¨nh Gemini
        genai.configure(api_key=GEMINI_API_KEY)
        
        # T·∫°o danh s√°ch tools cho Gemini
        # Ch·ªâ l·∫•y c√°c tools ph√π h·ª£p cho ƒëi·ªÅu khi·ªÉn m√°y t√≠nh
        CONTROL_TOOLS = {
            # ===== ·ª®NG D·ª§NG =====
            "open_application": "M·ªü ·ª©ng d·ª•ng Windows (notepad, chrome, calc, word, excel, vlc, spotify, vs code...)",
            "close_application": "ƒê√≥ng ·ª©ng d·ª•ng ƒëang ch·∫°y",
            "list_running_apps": "Li·ªát k√™ c√°c ·ª©ng d·ª•ng ƒëang ch·∫°y",
            
            # ===== NH·∫†C/MEDIA =====
            "play_music": "Ph√°t nh·∫°c t·ª´ folder local",
            "pause_music": "T·∫°m d·ª´ng nh·∫°c",
            "resume_music": "Ti·∫øp t·ª•c ph√°t nh·∫°c",
            "next_track": "B√†i ti·∫øp theo",
            "previous_track": "B√†i tr∆∞·ªõc",
            "set_volume": "ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng (0-100)",
            "stop_music": "D·ª´ng ph√°t nh·∫°c",
            "open_youtube": "M·ªü YouTube v√† t√¨m/ph√°t video",
            
            # ===== H·ªÜ TH·ªêNG =====
            "shutdown_schedule": "L√™n l·ªãch t·∫Øt/kh·ªüi ƒë·ªông l·∫°i m√°y",
            "lock_computer": "Kh√≥a m√°y t√≠nh",
            "show_desktop": "Hi·ªÉn th·ªã desktop (Win+D)",
            "set_theme": "ƒê·ªïi theme s√°ng/t·ªëi",
            "change_wallpaper": "ƒê·ªïi h√¨nh n·ªÅn",
            "get_system_info": "L·∫•y th√¥ng tin h·ªá th·ªëng",
            "take_screenshot": "Ch·ª•p m√†n h√¨nh",
            
            # ===== WEB/T√åM KI·∫æM =====
            "open_website": "M·ªü website trong tr√¨nh duy·ªát",
            "search_web": "T√¨m ki·∫øm tr√™n Google",
            "search_google_text": "Tra c·ª©u Google v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ text",
            
            # ===== FILE =====
            "open_folder": "M·ªü th∆∞ m·ª•c trong Explorer",
            "save_text_to_file": "L∆∞u vƒÉn b·∫£n v√†o file",
            "create_folder": "T·∫°o th∆∞ m·ª•c m·ªõi",
            "delete_file": "X√≥a file",
            
            # ===== KEYBOARD/MOUSE =====
            "type_text": "G√µ vƒÉn b·∫£n",
            "press_key": "Nh·∫•n ph√≠m (enter, escape, tab...)",
            "press_enter": "Nh·∫•n Enter",
            "paste_content": "D√°n n·ªôi dung",
            "hotkey": "Nh·∫•n t·ªï h·ª£p ph√≠m (ctrl+c, alt+tab...)",
            
            # ===== TH·ªúI GIAN =====
            "get_current_time": "L·∫•y th·ªùi gian hi·ªán t·∫°i",
            "set_alarm": "ƒê·∫∑t b√°o th·ª©c",
            "set_timer": "ƒê·∫∑t b·ªô ƒë·∫øm ng∆∞·ª£c",
            
            # ===== AI =====
            "ask_gemini": "H·ªèi Gemini AI (cho c√¢u h·ªèi ph·ª©c t·∫°p)",
            "search_google_text": "Tra c·ª©u th√¥ng tin m·ªõi nh·∫•t t·ª´ Google",
        }
        
        # T·∫°o tool descriptions cho prompt
        tools_description = "\n".join([f"- {name}: {desc}" for name, desc in CONTROL_TOOLS.items()])
        
        # L·∫•y c·∫•u h√¨nh m√°y t√≠nh ƒë·ªÉ LLM bi·∫øt
        pc_config = get_pc_config_summary()
        
        # System prompt cho Gemini ƒë·ªÉ ph√¢n t√≠ch v√† ƒëi·ªÅu khi·ªÉn
        system_prompt = f"""B·∫°n l√† AI tr·ª£ l√Ω TH√îNG MINH c√≥ kh·∫£ nƒÉng ƒêI·ªÄU KHI·ªÇN M√ÅY T√çNH.

üñ•Ô∏è C·∫§U H√åNH M√ÅY T√çNH ƒêANG S·ª¨ D·ª§NG:
{pc_config}

üéØ NHI·ªÜM V·ª§: Ph√¢n t√≠ch y√™u c·∫ßu ng∆∞·ªùi d√πng v√† quy·∫øt ƒë·ªãnh:
1. C·∫ßn d√πng tool n√†o ƒë·ªÉ th·ª±c hi·ªán
2. Tham s·ªë cho tool (ƒê√öNG T√äN THAM S·ªê)
3. Th·ª© t·ª± th·ª±c hi·ªán n·∫øu c·∫ßn nhi·ªÅu tool

üìã C√ÅC C√îNG C·ª§ V√Ä THAM S·ªê:

=== ·ª®NG D·ª§NG & PROCESS ===
- open_application: M·ªü ·ª©ng d·ª•ng. THAM S·ªê: {{"app_name": "t√™n_app"}} (notepad, chrome, calc, word, excel, vlc, spotify, code, photoshop, blender...)
- kill_process: ƒê√≥ng/t·∫Øt ·ª©ng d·ª•ng. THAM S·ªê: {{"identifier": "t√™n_app"}} (notepad, chrome, excel, word...)
- force_kill_app: Force kill app ngay. THAM S·ªê: {{"app_name": "t√™n_app"}}
- find_process: T√¨m process ƒëang ch·∫°y. THAM S·ªê: {{"name_pattern": "t√™n"}}
- list_running_processes: Li·ªát k√™ processes. THAM S·ªê: {{"limit": s·ªë}}

=== NH·∫†C LOCAL (Python-VLC) ===
- play_music: Ph√°t nh·∫°c local. THAM S·ªê: {{"filename": "t√™n b√†i"}} ho·∫∑c {{}}
- pause_music: T·∫°m d·ª´ng nh·∫°c. THAM S·ªê: {{}}
- resume_music: Ti·∫øp t·ª•c ph√°t. THAM S·ªê: {{}}
- stop_music: D·ª´ng nh·∫°c. THAM S·ªê: {{}}
- music_next: B√†i ti·∫øp theo. THAM S·ªê: {{}}
- music_previous: B√†i tr∆∞·ªõc. THAM S·ªê: {{}}
- music_volume: √Çm l∆∞·ª£ng nh·∫°c. THAM S·ªê: {{"level": 0-100}}
- search_music: T√¨m nh·∫°c. THAM S·ªê: {{"keyword": "t·ª´ kh√≥a"}}
- get_music_status: Tr·∫°ng th√°i nh·∫°c. THAM S·ªê: {{}}

=== YOUTUBE ===
- open_youtube: M·ªü YouTube v√† t√¨m/ph√°t video. THAM S·ªê: {{"search_query": "t√™n video/b√†i h√°t"}}
- youtube_play_pause: Play/Pause YouTube. THAM S·ªê: {{}}
- youtube_forward: Tua t·ªõi YouTube. THAM S·ªê: {{"seconds": 5/10}}
- youtube_rewind: Tua l√πi YouTube. THAM S·ªê: {{"seconds": 5/10}}
- youtube_volume_up: TƒÉng volume YouTube. THAM S·ªê: {{}}
- youtube_volume_down: Gi·∫£m volume YouTube. THAM S·ªê: {{}}
- youtube_mute: T·∫Øt ti·∫øng YouTube. THAM S·ªê: {{}}
- youtube_fullscreen: Fullscreen YouTube. THAM S·ªê: {{}}

=== √ÇM L∆Ø·ª¢NG H·ªÜ TH·ªêNG ===
- set_volume: ƒê·∫∑t √¢m l∆∞·ª£ng. THAM S·ªê: {{"level": 0-100}}
- get_volume: Ki·ªÉm tra √¢m l∆∞·ª£ng. THAM S·ªê: {{}}
- volume_up: TƒÉng √¢m l∆∞·ª£ng. THAM S·ªê: {{}}
- volume_down: Gi·∫£m √¢m l∆∞·ª£ng. THAM S·ªê: {{}}
- mute_volume: T·∫Øt ti·∫øng. THAM S·ªê: {{}}
- unmute_volume: B·∫≠t ti·∫øng. THAM S·ªê: {{}}

=== H·ªÜ TH·ªêNG & ƒêI·ªÄU KHI·ªÇN ===
- shutdown_schedule: T·∫Øt/kh·ªüi ƒë·ªông l·∫°i m√°y. THAM S·ªê: {{"action": "shutdown/restart/cancel", "delay": seconds}}
- lock_computer: Kh√≥a m√†n h√¨nh. THAM S·ªê: {{}}
- take_screenshot: Ch·ª•p m√†n h√¨nh. THAM S·ªê: {{}}
- set_brightness: ƒê·ªô s√°ng. THAM S·ªê: {{"level": 0-100}}
- get_system_info: Th√¥ng tin h·ªá th·ªëng. THAM S·ªê: {{}}
- get_system_resources: CPU/RAM/Disk %. THAM S·ªê: {{}}
- get_battery_status: Th√¥ng tin pin. THAM S·ªê: {{}}
- get_network_info: Th√¥ng tin m·∫°ng. THAM S·ªê: {{}}
- change_wallpaper: ƒê·ªïi h√¨nh n·ªÅn desktop. THAM S·ªê: {{"keyword": "t·ª´ kh√≥a"}} ho·∫∑c {{}}
- set_theme: ƒê·ªïi theme Windows. THAM S·ªê: {{"dark_mode": true/false}}
- show_desktop: Hi·ªán desktop (Win+D). THAM S·ªê: {{}}

=== WEB & TR√åNH DUY·ªÜT ===
- open_website: M·ªü website. THAM S·ªê: {{"url": "https://..."}}
- open_google: M·ªü Google. THAM S·ªê: {{"search_query": "t·ª´ kh√≥a"}}
- open_facebook: M·ªü Facebook. THAM S·ªê: {{}}
- open_tiktok: M·ªü TikTok. THAM S·ªê: {{}}
- search_web: T√¨m ki·∫øm Google. THAM S·ªê: {{"query": "t·ª´ kh√≥a"}}

=== FILE & FOLDER ===
- open_folder: M·ªü th∆∞ m·ª•c. THAM S·ªê: {{"path": "ƒë∆∞·ªùng d·∫´n"}}
- create_file: T·∫°o file. THAM S·ªê: {{"path": "ƒë∆∞·ªùng d·∫´n", "content": "n·ªôi dung"}}
- read_file: ƒê·ªçc file. THAM S·ªê: {{"path": "ƒë∆∞·ªùng d·∫´n"}}
- list_files: Li·ªát k√™ files. THAM S·ªê: {{"directory": "th∆∞ m·ª•c"}}

=== TH·ªúI GIAN & TI·ªÜN √çCH ===
- get_current_time: L·∫•y th·ªùi gian. THAM S·ªê: {{}}
- set_alarm: ƒê·∫∑t b√°o th·ª©c. THAM S·ªê: {{"time": "HH:MM", "message": "n·ªôi dung"}}
- set_timer: ƒê·∫∑t timer. THAM S·ªê: {{"seconds": s·ªë, "message": "n·ªôi dung"}}
- calculator: T√≠nh to√°n. THAM S·ªê: {{"expression": "bi·ªÉu th·ª©c"}}
- get_clipboard: L·∫•y clipboard. THAM S·ªê: {{}}
- set_clipboard: ƒê·∫∑t clipboard. THAM S·ªê: {{"text": "n·ªôi dung"}}
- show_notification: Hi·ªÉn th·ªã th√¥ng b√°o. THAM S·ªê: {{"title": "ti√™u ƒë·ªÅ", "message": "n·ªôi dung"}}

=== KEYBOARD ===
- type_text: G√µ vƒÉn b·∫£n. THAM S·ªê: {{"text": "n·ªôi dung"}}
- press_key: Nh·∫•n ph√≠m. THAM S·ªê: {{"key": "enter/escape/tab..."}}
- hotkey: T·ªï h·ª£p ph√≠m. THAM S·ªê: {{"keys": "ctrl+c/alt+tab..."}}

=== TIN T·ª®C & TH√îNG TIN ===
- get_vnexpress_news: Tin VnExpress. THAM S·ªê: {{"category": "thoi-su/the-gioi/kinh-doanh..."}}
- search_news: T√¨m tin. THAM S·ªê: {{"keyword": "t·ª´ kh√≥a"}}
- get_gold_price: Gi√° v√†ng. THAM S·ªê: {{}}
- get_weather: Th·ªùi ti·∫øt. THAM S·ªê: {{"city": "th√†nh ph·ªë"}}

=== AI ===
- ask_gemini: H·ªèi Gemini AI. THAM S·ªê: {{"prompt": "c√¢u h·ªèi"}}
- search_google_text: Tra Google text. THAM S·ªê: {{"query": "t·ª´ kh√≥a"}}

üìù QUY T·∫ÆC TR·∫¢ L·ªúI:
1. N·∫øu y√™u c·∫ßu C·∫¶N ƒëi·ªÅu khi·ªÉn m√°y t√≠nh, tr·∫£ v·ªÅ JSON:
   {{"action": "execute", "tools": [{{"name": "tool_name", "args": {{"param": "value"}}}}], "explanation": "Gi·∫£i th√≠ch ng·∫Øn"}}

2. N·∫øu y√™u c·∫ßu c·∫ßn NHI·ªÄU B∆Ø·ªöC, tr·∫£ v·ªÅ nhi·ªÅu tools:
   {{"action": "execute", "tools": [
       {{"name": "tool1", "args": {{}}}},
       {{"name": "tool2", "args": {{}}}}
   ], "explanation": "Gi·∫£i th√≠ch"}}

3. N·∫øu l√† C√ÇU H·ªéI TH√îNG TH∆Ø·ªúNG (kh√¥ng c·∫ßn ƒëi·ªÅu khi·ªÉn), tr·∫£ l·ªùi tr·ª±c ti·∫øp:
   {{"action": "respond", "response": "C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n"}}

‚ö° V√ç D·ª§ ƒê√öNG:
=== ·ª®ng d·ª•ng ===
- "m·ªü notepad" ‚Üí {{"action": "execute", "tools": [{{"name": "open_application", "args": {{"app_name": "notepad"}}}}]}}
- "m·ªü chrome" ‚Üí {{"action": "execute", "tools": [{{"name": "open_application", "args": {{"app_name": "chrome"}}}}]}}
- "m·ªü photoshop" ‚Üí {{"action": "execute", "tools": [{{"name": "open_application", "args": {{"app_name": "photoshop"}}}}]}}
- "t·∫Øt excel" ‚Üí {{"action": "execute", "tools": [{{"name": "kill_process", "args": {{"identifier": "excel"}}}}]}}
- "ƒë√≥ng notepad" ‚Üí {{"action": "execute", "tools": [{{"name": "kill_process", "args": {{"identifier": "notepad"}}}}]}}
- "t·∫Øt chrome" ‚Üí {{"action": "execute", "tools": [{{"name": "kill_process", "args": {{"identifier": "chrome"}}}}]}}

=== Nh·∫°c Local ===
- "ph√°t nh·∫°c" ‚Üí {{"action": "execute", "tools": [{{"name": "play_music", "args": {{}}}}]}}
- "ph√°t b√†i ƒëa nghi" ‚Üí {{"action": "execute", "tools": [{{"name": "play_music", "args": {{"filename": "ƒëa nghi"}}}}]}}
- "d·ª´ng nh·∫°c" ‚Üí {{"action": "execute", "tools": [{{"name": "pause_music", "args": {{}}}}]}}
- "ti·∫øp t·ª•c ph√°t" ‚Üí {{"action": "execute", "tools": [{{"name": "resume_music", "args": {{}}}}]}}
- "t·∫Øt nh·∫°c" ‚Üí {{"action": "execute", "tools": [{{"name": "stop_music", "args": {{}}}}]}}
- "b√†i ti·∫øp" ‚Üí {{"action": "execute", "tools": [{{"name": "music_next", "args": {{}}}}]}}
- "b√†i tr∆∞·ªõc" ‚Üí {{"action": "execute", "tools": [{{"name": "music_previous", "args": {{}}}}]}}

=== YouTube ===
- "m·ªü youtube l·∫°c tr√¥i" ‚Üí {{"action": "execute", "tools": [{{"name": "open_youtube", "args": {{"search_query": "l·∫°c tr√¥i"}}}}]}}
- "t√¨m b√†i h√£y trao cho anh tr√™n youtube" ‚Üí {{"action": "execute", "tools": [{{"name": "open_youtube", "args": {{"search_query": "h√£y trao cho anh"}}}}]}}
- "d·ª´ng youtube" ‚Üí {{"action": "execute", "tools": [{{"name": "youtube_play_pause", "args": {{}}}}]}}
- "tua youtube" ‚Üí {{"action": "execute", "tools": [{{"name": "youtube_forward", "args": {{"seconds": 10}}}}]}}

=== √Çm l∆∞·ª£ng ===
- "√¢m l∆∞·ª£ng 50" ‚Üí {{"action": "execute", "tools": [{{"name": "set_volume", "args": {{"level": 50}}}}]}}
- "tƒÉng √¢m l∆∞·ª£ng" ‚Üí {{"action": "execute", "tools": [{{"name": "volume_up", "args": {{}}}}]}}
- "gi·∫£m √¢m l∆∞·ª£ng" ‚Üí {{"action": "execute", "tools": [{{"name": "volume_down", "args": {{}}}}]}}
- "t·∫Øt ti·∫øng" ‚Üí {{"action": "execute", "tools": [{{"name": "mute_volume", "args": {{}}}}]}}

=== H·ªá th·ªëng ===
- "t·∫Øt m√°y sau 5 ph√∫t" ‚Üí {{"action": "execute", "tools": [{{"name": "shutdown_schedule", "args": {{"action": "shutdown", "delay": 300}}}}]}}
- "kh·ªüi ƒë·ªông l·∫°i m√°y" ‚Üí {{"action": "execute", "tools": [{{"name": "shutdown_schedule", "args": {{"action": "restart", "delay": 0}}}}]}}
- "kh√≥a m√†n h√¨nh" ‚Üí {{"action": "execute", "tools": [{{"name": "lock_computer", "args": {{}}}}]}}
- "ch·ª•p m√†n h√¨nh" ‚Üí {{"action": "execute", "tools": [{{"name": "take_screenshot", "args": {{}}}}]}}
- "ƒë·ªô s√°ng 80" ‚Üí {{"action": "execute", "tools": [{{"name": "set_brightness", "args": {{"level": 80}}}}]}}
- "ƒë·ªïi h√¨nh n·ªÅn" ‚Üí {{"action": "execute", "tools": [{{"name": "change_wallpaper", "args": {{}}}}]}}
- "ƒë·ªïi theme t·ªëi" ‚Üí {{"action": "execute", "tools": [{{"name": "set_theme", "args": {{"dark_mode": true}}}}]}}
- "hi·ªán desktop" ‚Üí {{"action": "execute", "tools": [{{"name": "show_desktop", "args": {{}}}}]}}

=== Web ===
- "m·ªü facebook" ‚Üí {{"action": "execute", "tools": [{{"name": "open_facebook", "args": {{}}}}]}}
- "m·ªü google t√¨m th·ªùi ti·∫øt" ‚Üí {{"action": "execute", "tools": [{{"name": "open_google", "args": {{"search_query": "th·ªùi ti·∫øt"}}}}]}}

=== Ti·ªán √≠ch ===
- "m·∫•y gi·ªù r·ªìi" ‚Üí {{"action": "execute", "tools": [{{"name": "get_current_time", "args": {{}}}}]}}
- "t√≠nh 15*20+5" ‚Üí {{"action": "execute", "tools": [{{"name": "calculator", "args": {{"expression": "15*20+5"}}}}]}}
- "ƒë·ªçc tin t·ª©c" ‚Üí {{"action": "execute", "tools": [{{"name": "get_vnexpress_news", "args": {{}}}}]}}
- "gi√° v√†ng" ‚Üí {{"action": "execute", "tools": [{{"name": "get_gold_price", "args": {{}}}}]}}

üî¥ QUAN TR·ªåNG: CH·ªà tr·∫£ v·ªÅ JSON h·ª£p l·ªá, KH√îNG th√™m text kh√°c! D√ôNG ƒê√öNG T√äN THAM S·ªê!"""

        # G·ªçi Gemini ƒë·ªÉ ph√¢n t√≠ch
        gemini_model = genai.GenerativeModel(model)
        
        analysis_prompt = f"{system_prompt}\n\nüë§ Y√äU C·∫¶U NG∆Ø·ªúI D√ôNG: {prompt}"
        
        print(f"\n{'='*70}")
        print(f"ü§ñ [Gemini Tools] Ph√¢n t√≠ch y√™u c·∫ßu: '{prompt}'")
        print(f"{'='*70}")
        
        loop = asyncio.get_event_loop()
        response = await asyncio.wait_for(
            loop.run_in_executor(None, lambda: gemini_model.generate_content(analysis_prompt)),
            timeout=15.0
        )
        
        response_text = response.text if hasattr(response, 'text') else str(response)
        print(f"üìù [Gemini] Raw response: {response_text[:500]}")
        
        # Parse JSON response
        import json
        import re
        
        # T√¨m JSON trong response
        json_match = re.search(r'\{[\s\S]*\}', response_text)
        if not json_match:
            # Kh√¥ng c√≥ JSON, coi nh∆∞ tr·∫£ l·ªùi th√¥ng th∆∞·ªùng
            return {
                "success": True,
                "action": "respond",
                "response_text": response_text,
                "tools_called": [],
                "message": "Gemini tr·∫£ l·ªùi tr·ª±c ti·∫øp"
            }
        
        try:
            analysis = json.loads(json_match.group())
        except json.JSONDecodeError:
            return {
                "success": True,
                "action": "respond", 
                "response_text": response_text,
                "tools_called": [],
                "message": "Gemini tr·∫£ l·ªùi tr·ª±c ti·∫øp (kh√¥ng parse ƒë∆∞·ª£c JSON)"
            }
        
        action = analysis.get("action", "respond")
        
        # N·∫øu ch·ªâ tr·∫£ l·ªùi th√¥ng th∆∞·ªùng
        if action == "respond":
            return {
                "success": True,
                "action": "respond",
                "response_text": analysis.get("response", response_text),
                "tools_called": [],
                "message": "‚úÖ Gemini ƒë√£ tr·∫£ l·ªùi"
            }
        
        # N·∫øu c·∫ßn h·ªèi l·∫°i
        if action == "clarify":
            return {
                "success": True,
                "action": "clarify",
                "response_text": analysis.get("question", "B·∫°n c·∫ßn t√¥i l√†m g√¨?"),
                "tools_called": [],
                "message": "‚ùì Gemini c·∫ßn th√™m th√¥ng tin"
            }
        
        # N·∫øu c·∫ßn th·ª±c thi tools
        if action == "execute":
            tools_to_call = analysis.get("tools", [])
            explanation = analysis.get("explanation", "")
            
            if not tools_to_call:
                return {
                    "success": True,
                    "action": "respond",
                    "response_text": explanation or response_text,
                    "tools_called": [],
                    "message": "Kh√¥ng c√≥ tool c·∫ßn th·ª±c thi"
                }
            
            # Gi·ªõi h·∫°n s·ªë tool calls
            tools_to_call = tools_to_call[:max_tool_calls]
            
            tools_called = []
            tools_results = []
            
            if auto_execute:
                print(f"\nüöÄ [Gemini Tools] Th·ª±c thi {len(tools_to_call)} tools...")
                
                for tool_info in tools_to_call:
                    tool_name = tool_info.get("name", "")
                    tool_args = tool_info.get("args", {})
                    
                    print(f"   ‚ö° Calling: {tool_name}({tool_args})")
                    
                    if tool_name not in TOOLS:
                        tools_results.append({
                            "tool": tool_name,
                            "success": False,
                            "error": f"Tool '{tool_name}' kh√¥ng t·ªìn t·∫°i"
                        })
                        continue
                    
                    try:
                        handler = TOOLS[tool_name]["handler"]
                        result = await handler(**tool_args)
                        
                        tools_called.append(tool_name)
                        tools_results.append({
                            "tool": tool_name,
                            "success": True,
                            "result": result
                        })
                        print(f"   ‚úÖ {tool_name}: Success")
                        
                    except Exception as e:
                        tools_results.append({
                            "tool": tool_name,
                            "success": False,
                            "error": str(e)
                        })
                        print(f"   ‚ùå {tool_name}: {e}")
                
                # T·∫°o response t·ªïng h·ª£p
                success_count = sum(1 for r in tools_results if r.get("success"))
                total_count = len(tools_results)
                
                # üîî Ph√°t √¢m thanh th√¥ng b√°o k·∫øt qu·∫£
                if success_count > 0:
                    play_success_sound()  # √Çm thanh th√†nh c√¥ng
                else:
                    play_error_sound()    # √Çm thanh l·ªói n·∫øu kh√¥ng c√≥ tool n√†o th√†nh c√¥ng
                
                response_summary = f"‚úÖ ƒê√£ th·ª±c hi·ªán {success_count}/{total_count} l·ªánh.\n"
                if explanation:
                    response_summary += f"üìù {explanation}"
                
                return {
                    "success": True,
                    "action": "executed",
                    "response_text": response_summary,
                    "tools_called": tools_called,
                    "tools_results": tools_results,
                    "explanation": explanation,
                    "message": f"‚úÖ Gemini ƒë√£ th·ª±c thi {success_count}/{total_count} tools"
                }
            
            else:
                # Ch·ªâ ƒë·ªÅ xu·∫•t, kh√¥ng th·ª±c thi
                return {
                    "success": True,
                    "action": "suggest",
                    "response_text": f"T√¥i ƒë·ªÅ xu·∫•t th·ª±c hi·ªán: {[t.get('name') for t in tools_to_call]}",
                    "tools_suggested": tools_to_call,
                    "explanation": explanation,
                    "message": "üí° Gemini ƒë·ªÅ xu·∫•t tools (ch∆∞a th·ª±c thi)"
                }
        
        # Fallback
        return {
            "success": True,
            "action": "respond",
            "response_text": response_text,
            "tools_called": [],
            "message": "Gemini tr·∫£ l·ªùi"
        }
        
    except asyncio.TimeoutError:
        return {"success": False, "error": "Timeout - Gemini ph·∫£n h·ªìi qu√° l√¢u"}
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


async def auto_process_document_with_gemini(user_query: str, model: str = "models/gemini-3-flash-preview") -> dict:
    """
    ü§ñ T·ª∞ ƒê·ªòNG PH√ÅT HI·ªÜN V√Ä X·ª¨ L√ù T√ÄI LI·ªÜU/DATABASE V·ªöI GEMINI
    
    Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ:
    - C∆° s·ªü d·ªØ li·ªáu (database, CSDL)
    - T√†i li·ªáu (PDF, Word, TXT, JSON, XML)
    - Files trong knowledge base
    
    T·ª± ƒë·ªông:
    1. Ph√°t hi·ªán √Ω ƒë·ªãnh ng∆∞·ªùi d√πng
    2. T√¨m v√† ƒë·ªçc t√†i li·ªáu li√™n quan
    3. G·ª≠i n·ªôi dung cho Gemini x·ª≠ l√Ω
    4. Tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c Gemini ph√¢n t√≠ch
    
    Returns:
        dict v·ªõi:
        - gemini_response: K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c Gemini x·ª≠ l√Ω
        - documents_found: List c√°c documents ƒë√£ t√¨m th·∫•y
        - success: True n·∫øu th√†nh c√¥ng
    """
    try:
        query_lower = user_query.lower()
        
        # Ph√°t hi·ªán keywords v·ªÅ database/documents
        document_keywords = [
            'c∆° s·ªü d·ªØ li·ªáu', 'database', 'csdl', 'db',
            't√†i li·ªáu', 'document', 'file', 'files',
            'pdf', 'word', 'txt', 'json', 'xml', 'csv',
            'trong file', 't·ª´ file', '·ªü file',
            'knowledge base', 'ki·∫øn th·ª©c', 'tri th·ª©c',
            'ƒë·ªçc file', 'xem file', 't√¨m trong',
            'th√¥ng tin trong', 'd·ªØ li·ªáu trong'
        ]
        
        # Check n·∫øu query c√≥ ch·ª©a keywords
        has_document_intent = any(kw in query_lower for kw in document_keywords)
        
        if not has_document_intent:
            return {
                "success": False,
                "activated": False,
                "reason": "Query kh√¥ng li√™n quan ƒë·∫øn documents/database"
            }
        
        print(f"üìä [Auto Document] Detected document query: {user_query[:100]}")
        
        # Step 1: T√¨m documents li√™n quan t·ª´ knowledge base
        knowledge_result = await get_knowledge_context(
            query=user_query,
            max_chars=8000,  # L·∫•y nhi·ªÅu context h∆°n
            use_gemini_summary=False  # Kh√¥ng t√≥m t·∫Øt tr∆∞·ªõc, ƒë·ªÉ Gemini x·ª≠ l√Ω to√†n b·ªô
        )
        
        if not knowledge_result.get("success"):
            return {
                "success": False,
                "activated": True,
                "error": "Kh√¥ng t√¨m th·∫•y documents trong knowledge base",
                "suggestion": "H√£y index c√°c files b·∫±ng /api/knowledge/index_directory"
            }
        
        context = knowledge_result.get("context", "")
        documents_found = knowledge_result.get("documents_included", [])
        
        if not context:
            return {
                "success": False,
                "activated": True,
                "error": "Knowledge base tr·ªëng",
                "documents_found": []
            }
        
        print(f"üìö [Auto Document] Found {len(documents_found)} documents")
        
        # Step 2: G·ª≠i cho Gemini x·ª≠ l√Ω v·ªõi context ƒë·∫ßy ƒë·ªß
        enhanced_prompt = f"""[T√ÄI LI·ªÜU THAM KH·∫¢O]
{context}

[C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG]
{user_query}

[Y√äU C·∫¶U]
D·ª±a v√†o t√†i li·ªáu tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† chi ti·∫øt.
- N·∫øu c√≥ th√¥ng tin trong t√†i li·ªáu, tr√≠ch d·∫´n r√µ r√†ng
- N·∫øu kh√¥ng c√≥ th√¥ng tin, h√£y n√≥i r√µ
- Tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát, d·ªÖ hi·ªÉu"""

        # G·ªçi Gemini
        gemini_result = await ask_gemini(enhanced_prompt, model=model)
        
        if not gemini_result.get("success"):
            return {
                "success": False,
                "activated": True,
                "error": f"Gemini error: {gemini_result.get('error')}",
                "documents_found": documents_found
            }
        
        # Step 3: Tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c Gemini x·ª≠ l√Ω
        return {
            "success": True,
            "activated": True,
            "gemini_response": gemini_result.get("response_text"),
            "documents_found": documents_found,
            "model_used": model,
            "context_length": len(context),
            "message": f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(documents_found)} documents v·ªõi Gemini {model}"
        }
        
    except Exception as e:
        return {
            "success": False,
            "activated": True,
            "error": f"Error: {str(e)}"
        }


async def ask_gpt4(prompt: str, model: str = "gpt-4o") -> dict:
    """
    H·ªèi ƒë√°p v·ªõi OpenAI GPT-4
    
    Args:
        prompt: C√¢u h·ªèi ho·∫∑c n·ªôi dung mu·ªën g·ª≠i cho GPT-4
        model: T√™n model OpenAI (m·∫∑c ƒë·ªãnh: gpt-4o - GPT-4 Omni, nhanh v√† r·∫ª)
        
    Returns:
        dict v·ªõi success, response_text, v√† message
    """
    try:
        # Ki·ªÉm tra OpenAI c√≥ kh·∫£ d·ª•ng kh√¥ng
        if not OPENAI_AVAILABLE:
            return {
                "success": False,
                "error": "OpenAI library ch∆∞a c√†i ƒë·∫∑t. Ch·∫°y: pip install openai"
            }
        
        # Ki·ªÉm tra API key
        if not OPENAI_API_KEY or OPENAI_API_KEY.strip() == "":
            return {
                "success": False,
                "error": "OpenAI API key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng th√™m 'openai_api_key' v√†o xiaozhi_endpoints.json",
                "help": "L·∫•y API key t·∫°i: https://platform.openai.com/api-keys"
            }
        
        # Kh·ªüi t·∫°o OpenAI client
        print(f"[GPT-4] Configured with API key: ...{OPENAI_API_KEY[-8:]}")
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        print(f"[GPT-4] Sending prompt with model: {model}")
        
        # G·ªçi API trong executor ƒë·ªÉ kh√¥ng block event loop
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000
            )
        )
        
        print(f"[GPT-4] Response received")
        
        # L·∫•y text t·ª´ response
        response_text = response.choices[0].message.content
        
        # üîÑ TRUNCATE: Gi·ªõi h·∫°n response d∆∞·ªõi 4000 k√Ω t·ª± cho LLM
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            original_len = len(response_text)
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
            print(f"[GPT-4] ‚úÇÔ∏è Truncated: {original_len} ‚Üí {len(response_text)} chars")
        
        print(f"[GPT-4] Response text: {response_text[:100]}...")
        
        return {
            "success": True,
            "prompt": prompt,
            "response_text": response_text,
            "model": model,
            "usage": {
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            },
            "message": f"‚úÖ GPT-4 ƒë√£ tr·∫£ l·ªùi (model: {model})"
        }
        
    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå [GPT-4] Exception caught: {type(e).__name__}")
        print(f"‚ùå [GPT-4] Error message: {error_msg}")
        
        import traceback
        traceback.print_exc()
        
        # X·ª≠ l√Ω c√°c l·ªói ph·ªï bi·∫øn
        if "Incorrect API key" in error_msg or "invalid_api_key" in error_msg:
            return {
                "success": False,
                "error": "OpenAI API key kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i openai_api_key trong xiaozhi_endpoints.json",
                "help": "L·∫•y API key m·ªõi t·∫°i: https://platform.openai.com/api-keys"
            }
        elif "insufficient_quota" in error_msg or "quota" in error_msg.lower():
            return {
                "success": False,
                "error": "ƒê√£ h·∫øt quota OpenAI. Vui l√≤ng n·∫°p ti·ªÅn ho·∫∑c ch·ªù quota reset.",
                "details": error_msg
            }
        elif "rate_limit" in error_msg.lower():
            return {
                "success": False,
                "error": "Rate limit exceeded. Vui l√≤ng th·ª≠ l·∫°i sau √≠t ph√∫t.",
                "details": error_msg
            }
        elif "model_not_found" in error_msg.lower():
            return {
                "success": False,
                "error": f"Model '{model}' kh√¥ng t·ªìn t·∫°i. Th·ª≠: gpt-4o, gpt-4-turbo, gpt-3.5-turbo",
                "details": error_msg
            }
        else:
            return {
                "success": False,
                "error": f"L·ªói khi g·ªçi OpenAI API: {error_msg}"
            }


# ============================================================
# OPEN API TOOLS - C√°c API c√¥ng khai h·ªØu √≠ch
# Tham kh·∫£o t·ª´: github.com/ZhongZiTongXue/xiaozhi-MCPTools
# ============================================================

import aiohttp
import urllib.parse

async def get_daily_news() -> dict:
    """
    L·∫•y tin t·ª©c 60 gi√¢y m·ªói ng√†y (ÊØèÊó•Êó©Êä•/60s morning news).
    Ngu·ªìn: API c√¥ng khai
    """
    try:
        url = "https://60s.viki.moe/?v2=1"
        connector = aiohttp.TCPConnector()
        async with aiohttp.ClientSession(connector=connector, trust_env=False) as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    news_list = data.get('data', [])[:10]  # Top 10 tin
                    formatted = "\n".join([f"{i+1}. {item}" for i, item in enumerate(news_list)])
                    return {
                        "success": True,
                        "message": "üì∞ Tin t·ª©c 60 gi√¢y h√¥m nay:",
                        "news": formatted,
                        "source": "60s.viki.moe"
                    }
                return {"success": False, "error": f"API tr·∫£ v·ªÅ status {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_random_quote() -> dict:
    """
    L·∫•y m·ªôt c√¢u n√≥i ng·∫´u nhi√™n (‰∏ÄË®Ä/Hitokoto).
    """
    try:
        url = "https://v1.hitokoto.cn/"
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    return {
                        "success": True,
                        "quote": data.get('hitokoto', ''),
                        "from": data.get('from', 'Unknown'),
                        "author": data.get('from_who', ''),
                        "type": data.get('type', '')
                    }
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_hotlist(platform: str = "weibo") -> dict:
    """
    L·∫•y b·∫£ng x·∫øp h·∫°ng hot t·ª´ c√°c n·ªÅn t·∫£ng (ÂæÆÂçö/Áü•‰πé/ÁôæÂ∫¶/ÊäñÈü≥).
    """
    try:
        platforms = {
            "weibo": "https://tenapi.cn/v2/weibohot",
            "zhihu": "https://tenapi.cn/v2/zhihuhot",
            "baidu": "https://tenapi.cn/v2/baiduhot",
            "douyin": "https://tenapi.cn/v2/douyinhot"
        }
        
        platform_lower = platform.lower()
        url = platforms.get(platform_lower)
        
        if not url:
            return {"success": False, "error": f"Platform kh√¥ng h·ªó tr·ª£. Ch·ªçn: weibo, zhihu, baidu, douyin"}
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    hot_list = data.get('data', [])[:15]  # Top 15
                    formatted = "\n".join([f"{i+1}. {item.get('name', item.get('title', ''))}" for i, item in enumerate(hot_list)])
                    return {
                        "success": True,
                        "platform": platform,
                        "hotlist": formatted,
                        "count": len(hot_list)
                    }
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def search_baike(query: str) -> dict:
    """
    T√¨m ki·∫øm Baidu Baike (ÁôæÂ∫¶ÁôæÁßë).
    """
    try:
        encoded_query = urllib.parse.quote(query)
        url = f"https://baike.baidu.com/api/openapi/BaikeLemmaCardApi?scope=103&format=json&appid=379020&bk_key={encoded_query}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get('id'):
                        return {
                            "success": True,
                            "title": data.get('title', ''),
                            "abstract": data.get('abstract', ''),
                            "url": data.get('url', ''),
                            "image": data.get('image', '')
                        }
                    return {"success": False, "error": f"Kh√¥ng t√¨m th·∫•y '{query}' tr√™n Baike"}
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_history_today() -> dict:
    """
    L·∫•y s·ª± ki·ªán l·ªãch s·ª≠ ng√†y h√¥m nay (ÂéÜÂè≤‰∏äÁöÑ‰ªäÂ§©).
    """
    try:
        from datetime import datetime
        today = datetime.now()
        month = today.month
        day = today.day
        
        url = f"https://api.oioweb.cn/api/common/history?month={month}&day={day}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    events = data.get('result', [])[:10]
                    formatted = "\n".join([f"‚Ä¢ {e.get('year', '')}: {e.get('title', '')}" for e in events])
                    return {
                        "success": True,
                        "date": f"{month}/{day}",
                        "events": formatted,
                        "count": len(events)
                    }
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_joke() -> dict:
    """
    L·∫•y m·ªôt c√¢u chuy·ªán c∆∞·ªùi ng·∫´u nhi√™n.
    """
    try:
        url = "https://api.oioweb.cn/api/common/joke"
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    return {
                        "success": True,
                        "joke": data.get('result', {}).get('content', 'Kh√¥ng c√≥ joke'),
                        "source": "oioweb.cn"
                    }
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_weather_simple(city: str = "Hanoi") -> dict:
    """
    L·∫•y th·ªùi ti·∫øt ƒë∆°n gi·∫£n c·ªßa th√†nh ph·ªë.
    """
    try:
        # D√πng wttr.in API (free, kh√¥ng c·∫ßn key)
        encoded_city = urllib.parse.quote(city)
        url = f"https://wttr.in/{encoded_city}?format=j1"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=15) as response:
                if response.status == 200:
                    data = await response.json()
                    current = data.get('current_condition', [{}])[0]
                    weather_desc = current.get('weatherDesc', [{}])[0].get('value', '')
                    temp_c = current.get('temp_C', '')
                    humidity = current.get('humidity', '')
                    wind_kmph = current.get('windspeedKmph', '')
                    
                    return {
                        "success": True,
                        "city": city,
                        "weather": weather_desc,
                        "temperature": f"{temp_c}¬∞C",
                        "humidity": f"{humidity}%",
                        "wind": f"{wind_kmph} km/h",
                        "summary": f"üå§Ô∏è {city}: {weather_desc}, {temp_c}¬∞C, ƒê·ªô ·∫©m {humidity}%"
                    }
                return {"success": False, "error": f"Kh√¥ng t√¨m th·∫•y th·ªùi ti·∫øt cho '{city}'"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def control_ppt(action: str) -> dict:
    """
    ƒêi·ªÅu khi·ªÉn PowerPoint presentation.
    Actions: next (trang sau), prev (trang tr∆∞·ªõc), start (b·∫Øt ƒë·∫ßu tr√¨nh chi·∫øu), end (k·∫øt th√∫c)
    """
    try:
        import pyautogui
        
        action_lower = action.lower()
        
        if action_lower in ['next', 'ti·∫øp', 'trang sau']:
            pyautogui.press('right')
            return {"success": True, "message": "‚û°Ô∏è PPT: Chuy·ªÉn trang sau"}
            
        elif action_lower in ['prev', 'previous', 'tr∆∞·ªõc', 'trang tr∆∞·ªõc']:
            pyautogui.press('left')
            return {"success": True, "message": "‚¨ÖÔ∏è PPT: Quay l·∫°i trang tr∆∞·ªõc"}
            
        elif action_lower in ['start', 'b·∫Øt ƒë·∫ßu', 'tr√¨nh chi·∫øu']:
            pyautogui.press('f5')
            return {"success": True, "message": "‚ñ∂Ô∏è PPT: B·∫Øt ƒë·∫ßu tr√¨nh chi·∫øu t·ª´ ƒë·∫ßu"}
            
        elif action_lower in ['start_current', 't·ª´ trang n√†y']:
            pyautogui.hotkey('shift', 'f5')
            return {"success": True, "message": "‚ñ∂Ô∏è PPT: Tr√¨nh chi·∫øu t·ª´ trang hi·ªán t·∫°i"}
            
        elif action_lower in ['end', 'k·∫øt th√∫c', 'tho√°t']:
            pyautogui.press('escape')
            return {"success": True, "message": "‚èπÔ∏è PPT: K·∫øt th√∫c tr√¨nh chi·∫øu"}
            
        else:
            return {
                "success": False,
                "error": f"Action '{action}' kh√¥ng h·ª£p l·ªá",
                "hint": "C√°c action h·ªó tr·ª£: next, prev, start, start_current, end"
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}

async def ask_doubao(question: str) -> dict:
    """
    M·ªü Doubao AI v√† g·ª≠i c√¢u h·ªèi (y√™u c·∫ßu c√≥ browser).
    """
    try:
        import webbrowser
        import pyperclip
        import pyautogui
        import time
        
        url = "https://www.doubao.com/chat/"
        webbrowser.open(url)
        
        # ƒê·ª£i trang load
        time.sleep(4)
        
        # Copy c√¢u h·ªèi v√† paste
        pyperclip.copy(question)
        time.sleep(0.3)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.5)
        pyautogui.press('enter')
        
        return {
            "success": True,
            "message": f"‚úÖ ƒê√£ g·ª≠i c√¢u h·ªèi t·ªõi Doubao AI: '{question}'",
            "note": "Vui l√≤ng xem k·∫øt qu·∫£ tr√™n tr√¨nh duy·ªát"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def ask_kimi(question: str) -> dict:
    """
    M·ªü Kimi AI v√† g·ª≠i c√¢u h·ªèi (y√™u c·∫ßu c√≥ browser).
    """
    try:
        import webbrowser
        import pyperclip
        import pyautogui
        import time
        
        url = "https://kimi.moonshot.cn/"
        webbrowser.open(url)
        
        # ƒê·ª£i trang load
        time.sleep(4)
        
        # Copy c√¢u h·ªèi v√† paste
        pyperclip.copy(question)
        time.sleep(0.3)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.5)
        pyautogui.press('enter')
        
        return {
            "success": True,
            "message": f"‚úÖ ƒê√£ g·ª≠i c√¢u h·ªèi t·ªõi Kimi AI: '{question}'",
            "note": "Vui l√≤ng xem k·∫øt qu·∫£ tr√™n tr√¨nh duy·ªát"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_dark_light_theme(mode: str) -> dict:
    """
    Chuy·ªÉn ƒë·ªïi theme Windows Dark/Light mode.
    """
    try:
        import subprocess
        
        mode_lower = mode.lower()
        
        if mode_lower in ['dark', 't·ªëi', 'ƒëen']:
            # Set dark mode
            subprocess.run([
                'reg', 'add', 
                'HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize',
                '/v', 'AppsUseLightTheme', '/t', 'REG_DWORD', '/d', '0', '/f'
            ], capture_output=True)
            subprocess.run([
                'reg', 'add',
                'HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize',
                '/v', 'SystemUsesLightTheme', '/t', 'REG_DWORD', '/d', '0', '/f'
            ], capture_output=True)
            return {"success": True, "message": "üåô ƒê√£ chuy·ªÉn sang Dark Mode"}
            
        elif mode_lower in ['light', 's√°ng', 'tr·∫Øng']:
            # Set light mode
            subprocess.run([
                'reg', 'add',
                'HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize',
                '/v', 'AppsUseLightTheme', '/t', 'REG_DWORD', '/d', '1', '/f'
            ], capture_output=True)
            subprocess.run([
                'reg', 'add',
                'HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize',
                '/v', 'SystemUsesLightTheme', '/t', 'REG_DWORD', '/d', '1', '/f'
            ], capture_output=True)
            return {"success": True, "message": "‚òÄÔ∏è ƒê√£ chuy·ªÉn sang Light Mode"}
            
        else:
            return {
                "success": False,
                "error": f"Mode '{mode}' kh√¥ng h·ª£p l·ªá",
                "hint": "Ch·ªçn: dark/t·ªëi ho·∫∑c light/s√°ng"
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}

async def lock_computer() -> dict:
    """
    Kh√≥a m√°y t√≠nh ngay l·∫≠p t·ª©c.
    """
    try:
        import ctypes
        ctypes.windll.user32.LockWorkStation()
        return {"success": True, "message": "üîí ƒê√£ kh√≥a m√°y t√≠nh"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def shutdown_computer(action: str = "shutdown", delay: int = 0) -> dict:
    """
    T·∫Øt m√°y/Kh·ªüi ƒë·ªông l·∫°i/H·∫πn gi·ªù t·∫Øt.
    action: shutdown, restart, cancel (h·ªßy l·ªánh t·∫Øt)
    delay: s·ªë gi√¢y tr∆∞·ªõc khi th·ª±c hi·ªán (0 = ngay l·∫≠p t·ª©c)
    """
    try:
        import subprocess
        
        action_lower = action.lower()
        
        if action_lower in ['shutdown', 't·∫Øt', 't·∫Øt m√°y']:
            subprocess.run(['shutdown', '/s', '/t', str(delay)], capture_output=True)
            if delay > 0:
                return {"success": True, "message": f"‚è∞ M√°y s·∫Ω t·∫Øt sau {delay} gi√¢y"}
            return {"success": True, "message": "‚èπÔ∏è ƒêang t·∫Øt m√°y..."}
            
        elif action_lower in ['restart', 'kh·ªüi ƒë·ªông l·∫°i', 'reboot']:
            subprocess.run(['shutdown', '/r', '/t', str(delay)], capture_output=True)
            if delay > 0:
                return {"success": True, "message": f"‚è∞ M√°y s·∫Ω kh·ªüi ƒë·ªông l·∫°i sau {delay} gi√¢y"}
            return {"success": True, "message": "üîÑ ƒêang kh·ªüi ƒë·ªông l·∫°i..."}
            
        elif action_lower in ['cancel', 'h·ªßy', 'abort']:
            subprocess.run(['shutdown', '/a'], capture_output=True)
            return {"success": True, "message": "‚ùå ƒê√£ h·ªßy l·ªánh t·∫Øt/kh·ªüi ƒë·ªông l·∫°i"}
            
        else:
            return {
                "success": False,
                "error": f"Action '{action}' kh√¥ng h·ª£p l·ªá",
                "hint": "Ch·ªçn: shutdown, restart, cancel"
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}

# DUPLICATE REMOVED: change_wallpaper was defined twice (first at line 5503)
# DUPLICATE REMOVED: find_in_document was defined twice (first at line 5809)

async def clipboard_read() -> dict:
    """
    ƒê·ªçc n·ªôi dung t·ª´ clipboard.
    """
    try:
        import pyperclip
        content = pyperclip.paste()
        return {
            "success": True,
            "content": content,
            "length": len(content) if content else 0
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def clipboard_write(content: str) -> dict:
    """
    Ghi n·ªôi dung v√†o clipboard.
    """
    try:
        import pyperclip
        pyperclip.copy(content)
        return {"success": True, "message": f"üìã ƒê√£ copy v√†o clipboard ({len(content)} k√Ω t·ª±)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def type_text(text: str, press_enter: bool = False) -> dict:
    """
    G√µ text v√†o v·ªã tr√≠ con tr·ªè hi·ªán t·∫°i.
    """
    try:
        import pyperclip
        import pyautogui
        import time
        
        # Copy v√† paste ƒë·ªÉ h·ªó tr·ª£ Unicode
        pyperclip.copy(text)
        time.sleep(0.1)
        pyautogui.hotkey('ctrl', 'v')
        
        if press_enter:
            time.sleep(0.2)
            pyautogui.press('enter')
            return {"success": True, "message": f"‚å®Ô∏è ƒê√£ g√µ v√† Enter: '{text[:50]}...'"}
        
        return {"success": True, "message": f"‚å®Ô∏è ƒê√£ g√µ: '{text[:50]}...'"}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def undo_action() -> dict:
    """
    Th·ª±c hi·ªán Undo (Ctrl+Z).
    """
    try:
        import pyautogui
        pyautogui.hotkey('ctrl', 'z')
        return {"success": True, "message": "‚Ü©Ô∏è ƒê√£ Undo"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def show_desktop() -> dict:
    """
    Hi·ªÉn th·ªã Desktop (Win+D).
    """
    try:
        import pyautogui
        pyautogui.hotkey('win', 'd')
        return {"success": True, "message": "üñ•Ô∏è ƒê√£ hi·ªÉn th·ªã Desktop"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# OPEN API TOOLS - C√°c c√¥ng c·ª• tra c·ª©u th√¥ng tin (PH√ô H·ª¢P VI·ªÜT NAM)
# ============================================================

async def get_weather_vietnam(city: str = "H√† N·ªôi") -> dict:
    """
    L·∫•y th√¥ng tin th·ªùi ti·∫øt Vi·ªát Nam t·ª´ wttr.in (mi·ªÖn ph√≠, kh√¥ng c·∫ßn API key).
    """
    try:
        import aiohttp
        import urllib.parse
        
        # Normalize t√™n th√†nh ph·ªë
        city_mapping = {
            "h√† n·ªôi": "Hanoi", "ha noi": "Hanoi", "hanoi": "Hanoi",
            "h·ªì ch√≠ minh": "Ho Chi Minh", "ho chi minh": "Ho Chi Minh", "saigon": "Ho Chi Minh", "s√†i g√≤n": "Ho Chi Minh",
            "ƒë√† n·∫µng": "Da Nang", "da nang": "Da Nang", "danang": "Da Nang",
            "h·∫£i ph√≤ng": "Hai Phong", "hai phong": "Hai Phong",
            "c·∫ßn th∆°": "Can Tho", "can tho": "Can Tho",
            "nha trang": "Nha Trang", "hu·∫ø": "Hue", "hue": "Hue",
            "v≈©ng t√†u": "Vung Tau", "vung tau": "Vung Tau",
            "bi√™n h√≤a": "Bien Hoa", "bien hoa": "Bien Hoa",
            "bu√¥n ma thu·ªôt": "Buon Ma Thuot", "ƒë√† l·∫°t": "Da Lat", "da lat": "Da Lat",
            "qu·∫£ng ninh": "Quang Ninh", "h·∫° long": "Ha Long",
            "thanh h√≥a": "Thanh Hoa", "vinh": "Vinh", "quy nh∆°n": "Quy Nhon",
        }
        
        city_query = city_mapping.get(city.lower().strip(), city)
        url = f"https://wttr.in/{urllib.parse.quote(city_query)}?format=j1"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    current = data.get("current_condition", [{}])[0]
                    
                    temp_c = current.get("temp_C", "N/A")
                    feels_like = current.get("FeelsLikeC", "N/A")
                    humidity = current.get("humidity", "N/A")
                    weather_desc = current.get("lang_vi", [{}])
                    if weather_desc:
                        weather_desc = weather_desc[0].get("value", current.get("weatherDesc", [{}])[0].get("value", ""))
                    else:
                        weather_desc = current.get("weatherDesc", [{}])[0].get("value", "")
                    wind_kmph = current.get("windspeedKmph", "N/A")
                    
                    return {
                        "success": True,
                        "city": city,
                        "temperature": f"{temp_c}¬∞C",
                        "feels_like": f"{feels_like}¬∞C",
                        "humidity": f"{humidity}%",
                        "weather": weather_desc,
                        "wind": f"{wind_kmph} km/h",
                        "message": f"üå§Ô∏è Th·ªùi ti·∫øt {city}: {temp_c}¬∞C, {weather_desc}, ƒê·ªô ·∫©m {humidity}%, Gi√≥ {wind_kmph}km/h"
                    }
                else:
                    return {"success": False, "error": f"Kh√¥ng l·∫•y ƒë∆∞·ª£c th·ªùi ti·∫øt: HTTP {resp.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_gold_price_vietnam() -> dict:
    """
    L·∫•y gi√° v√†ng Vi·ªát Nam t·ª´ API mi·ªÖn ph√≠.
    """
    try:
        import aiohttp
        
        # S·ª≠ d·ª•ng API gi√° v√†ng SJC
        url = "https://api.btmc.vn/api/BTMCAPI/getpricesheet"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    
                    # T√¨m gi√° v√†ng SJC
                    gold_prices = []
                    for item in data.get("data", []):
                        name = item.get("name", "")
                        buy = item.get("buy", 0)
                        sell = item.get("sell", 0)
                        if "SJC" in name or "v√†ng" in name.lower():
                            gold_prices.append({
                                "name": name,
                                "buy": f"{buy:,.0f}".replace(",", "."),
                                "sell": f"{sell:,.0f}".replace(",", ".")
                            })
                    
                    if gold_prices:
                        msg = "üí∞ Gi√° v√†ng h√¥m nay:\n"
                        for g in gold_prices[:3]:  # Top 3
                            msg += f"‚Ä¢ {g['name']}: Mua {g['buy']} - B√°n {g['sell']} VNƒê/l∆∞·ª£ng\n"
                        
                        return {
                            "success": True,
                            "prices": gold_prices[:3],
                            "message": msg.strip()
                        }
                    
                return {"success": False, "error": "Kh√¥ng l·∫•y ƒë∆∞·ª£c gi√° v√†ng"}
    except Exception as e:
        # Fallback: tr·∫£ v·ªÅ th√¥ng tin h∆∞·ªõng d·∫´n
        return {
            "success": True,
            "message": "üí∞ ƒê·ªÉ xem gi√° v√†ng m·ªõi nh·∫•t, truy c·∫≠p: sjc.com.vn ho·∫∑c pnj.com.vn",
            "hint": "API gi√° v√†ng t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng"
        }

async def get_exchange_rate_vietnam(currency: str = "USD") -> dict:
    """
    L·∫•y t·ª∑ gi√° ngo·∫°i t·ªá so v·ªõi VND.
    """
    try:
        import aiohttp
        
        currency = currency.upper().strip()
        
        # D√πng API mi·ªÖn ph√≠ exchangerate-api
        url = f"https://api.exchangerate-api.com/v4/latest/{currency}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    rates = data.get("rates", {})
                    vnd_rate = rates.get("VND", 0)
                    
                    if vnd_rate:
                        return {
                            "success": True,
                            "currency": currency,
                            "vnd_rate": f"{vnd_rate:,.0f}".replace(",", "."),
                            "message": f"üí± T·ª∑ gi√°: 1 {currency} = {vnd_rate:,.0f} VNƒê".replace(",", ".")
                        }
                        
                return {"success": False, "error": f"Kh√¥ng t√¨m th·∫•y t·ª∑ gi√° {currency}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_daily_quote() -> dict:
    """
    L·∫•y c√¢u n√≥i hay/tr√≠ch d·∫´n ng·∫´u nhi√™n.
    """
    try:
        import aiohttp
        import random
        
        # C√°c quotes ti·∫øng Vi·ªát ƒë·∫πp
        vietnamese_quotes = [
            {"quote": "Th√†nh c√¥ng kh√¥ng ph·∫£i l√† ch√¨a kh√≥a c·ªßa h·∫°nh ph√∫c. H·∫°nh ph√∫c l√† ch√¨a kh√≥a c·ªßa th√†nh c√¥ng.", "author": "Albert Schweitzer"},
            {"quote": "ƒê·ª´ng s·ª£ th·∫•t b·∫°i. H√£y s·ª£ nh·ªØng c∆° h·ªôi b·∫°n b·ªè l·ª° khi kh√¥ng c·ªë g·∫Øng.", "author": "Jack Canfield"},
            {"quote": "Cu·ªôc s·ªëng kh√¥ng ph·∫£i l√† ch·ªù ƒë·ª£i b√£o qua ƒëi, m√† l√† h·ªçc c√°ch nh·∫£y m√∫a d∆∞·ªõi m∆∞a.", "author": "Vivian Greene"},
            {"quote": "H√¥m nay kh√≥ khƒÉn, ng√†y mai c√≤n kh√≥ khƒÉn h∆°n, nh∆∞ng ng√†y kia s·∫Ω t∆∞∆°i ƒë·∫πp.", "author": "Jack Ma"},
            {"quote": "Ng∆∞·ªùi duy nh·∫•t b·∫°n c·∫ßn v∆∞·ª£t qua l√† ch√≠nh b·∫°n c·ªßa ng√†y h√¥m qua.", "author": "Khuy·∫øt danh"},
            {"quote": "H·ªçc h·ªèi kh√¥ng c√≥ ƒëi·ªÉm d·ª´ng, gi·ªëng nh∆∞ cu·ªôc s·ªëng kh√¥ng c√≥ gi·ªõi h·∫°n.", "author": "Kh·ªïng T·ª≠"},
            {"quote": "Th·∫•t b·∫°i l√† m·∫π th√†nh c√¥ng.", "author": "T·ª•c ng·ªØ Vi·ªát Nam"},
            {"quote": "C√≥ ch√≠ th√¨ n√™n.", "author": "T·ª•c ng·ªØ Vi·ªát Nam"},
            {"quote": "M·ªôt c√¢y l√†m ch·∫≥ng n√™n non, ba c√¢y ch·ª•m l·∫°i n√™n h√≤n n√∫i cao.", "author": "Ca dao Vi·ªát Nam"},
            {"quote": "ƒêi m·ªôt ng√†y ƒë√†ng, h·ªçc m·ªôt s√†ng kh√¥n.", "author": "T·ª•c ng·ªØ Vi·ªát Nam"},
        ]
        
        # Th·ª≠ l·∫•y quote t·ª´ API
        try:
            url = "https://api.quotable.io/random"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=5) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return {
                            "success": True,
                            "quote": data.get("content", ""),
                            "author": data.get("author", "Unknown"),
                            "message": f"üí¨ \"{data.get('content', '')}\" - {data.get('author', 'Unknown')}"
                        }
        except:
            pass
        
        # Fallback: quote ti·∫øng Vi·ªát
        quote = random.choice(vietnamese_quotes)
        return {
            "success": True,
            "quote": quote["quote"],
            "author": quote["author"],
            "message": f"üí¨ \"{quote['quote']}\" - {quote['author']}"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_today_in_history() -> dict:
    """
    L·∫•y s·ª± ki·ªán l·ªãch s·ª≠ ng√†y h√¥m nay.
    """
    try:
        import aiohttp
        from datetime import datetime
        
        today = datetime.now()
        month = today.month
        day = today.day
        
        url = f"https://history.muffinlabs.com/date/{month}/{day}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    events = data.get("data", {}).get("Events", [])[:3]
                    
                    if events:
                        msg = f"üìú Ng√†y n√†y ({day}/{month}) trong l·ªãch s·ª≠:\n"
                        for event in events:
                            year = event.get("year", "")
                            text = event.get("text", "")
                            msg += f"‚Ä¢ {year}: {text[:100]}...\n" if len(text) > 100 else f"‚Ä¢ {year}: {text}\n"
                        
                        return {
                            "success": True,
                            "date": f"{day}/{month}",
                            "events": events,
                            "message": msg.strip()
                        }
                        
        return {"success": False, "error": "Kh√¥ng l·∫•y ƒë∆∞·ª£c s·ª± ki·ªán l·ªãch s·ª≠"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_joke() -> dict:
    """
    L·∫•y m·ªôt c√¢u chuy·ªán c∆∞·ªùi/joke ng·∫´u nhi√™n.
    """
    try:
        import random
        
        # Jokes ti·∫øng Vi·ªát
        vietnamese_jokes = [
            "T·∫°i sao con c√° kh√¥ng bi·∫øt n√≥i? V√¨ n√≥ ·ªü d∆∞·ªõi n∆∞·ªõc, n√≥i sao ƒë∆∞·ª£c! üêü",
            "B·∫°n bi·∫øt con g√¨ nhanh nh·∫•t th·∫ø gi·ªõi kh√¥ng? Con gi√≥, v√¨ n√≥ ƒëi v√®o v√®o! üí®",
            "T·∫°i sao con ki·∫øn kh√¥ng bao gi·ªù ·ªëm? V√¨ n√≥ c√≥ ƒë·∫ßy ƒë·ªß ch·∫•t s·∫Øt (Fe) trong ng∆∞·ªùi! üêú",
            "Ai l√† ng∆∞·ªùi h·∫°nh ph√∫c nh·∫•t? Ng∆∞·ªùi kh√¥ng bi·∫øt so s√°nh! üòä",
            "Con g√¨ c√≥ 4 ch√¢n m√† kh√¥ng bi·∫øt ƒëi? C√°i b√†n! ü™ë",
            "T·∫°i sao m√°y t√≠nh kh√¥ng bao gi·ªù kh√≥c? V√¨ n√≥ c√≥ mouse pad (mi·∫øng l√≥t chu·ªôt)! üñ±Ô∏è",
            "B·∫°n bi·∫øt t·∫°i sao m·∫∑t tr·ªùi ƒëi h·ªçc kh√¥ng? V√¨ n√≥ ƒë√£ t·ªët nghi·ªáp t·ª´ l√¢u r·ªìi! ‚òÄÔ∏è",
            "T·∫°i sao con g√† qua ƒë∆∞·ªùng? ƒê·ªÉ ƒë·∫øn b√™n kia ƒë∆∞·ªùng! üêî",
            "Con g√¨ ng·ªìi m·ªôt ch·ªó m√† v·∫´n ch·∫°y? C√°i ƒë·ªìng h·ªì! ‚è∞",
            "T·∫°i sao c·∫ßu v·ªìng th√≠ch ƒëi ch∆°i? V√¨ n√≥ c√≥ 7 m√†u = 7 ng√†y = 1 tu·∫ßn! üåà",
        ]
        
        joke = random.choice(vietnamese_jokes)
        return {
            "success": True,
            "joke": joke,
            "message": f"üòÇ {joke}"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_horoscope(zodiac: str = "song_t·ª≠") -> dict:
    """
    L·∫•y t·ª≠ vi/horoscope theo cung ho√†ng ƒë·∫°o.
    """
    try:
        import random
        
        # Map t√™n cung ho√†ng ƒë·∫°o
        zodiac_map = {
            "b·∫°ch d∆∞∆°ng": "aries", "bach duong": "aries", "aries": "aries",
            "kim ng∆∞u": "taurus", "kim nguu": "taurus", "taurus": "taurus",
            "song t·ª≠": "gemini", "song tu": "gemini", "gemini": "gemini",
            "c·ª± gi·∫£i": "cancer", "cu giai": "cancer", "cancer": "cancer",
            "s∆∞ t·ª≠": "leo", "su tu": "leo", "leo": "leo",
            "x·ª≠ n·ªØ": "virgo", "xu nu": "virgo", "virgo": "virgo",
            "thi√™n b√¨nh": "libra", "thien binh": "libra", "libra": "libra",
            "b·ªç c·∫°p": "scorpio", "bo cap": "scorpio", "scorpio": "scorpio",
            "nh√¢n m√£": "sagittarius", "nhan ma": "sagittarius", "sagittarius": "sagittarius",
            "ma k·∫øt": "capricorn", "ma ket": "capricorn", "capricorn": "capricorn",
            "b·∫£o b√¨nh": "aquarius", "bao binh": "aquarius", "aquarius": "aquarius",
            "song ng∆∞": "pisces", "song ngu": "pisces", "pisces": "pisces",
        }
        
        zodiac_key = zodiac_map.get(zodiac.lower().strip(), "gemini")
        zodiac_name = zodiac.title()
        
        # Random horoscope messages
        luck_levels = ["‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê"]
        love_messages = [
            "T√¨nh y√™u ƒëang ƒë·∫øn g·∫ßn, h√£y m·ªü l√≤ng ƒë√≥n nh·∫≠n.",
            "H√¥m nay l√† ng√†y t·ªët ƒë·ªÉ th·ªÉ hi·ªán t√¨nh c·∫£m.",
            "Ng∆∞·ªùi ·∫•y ƒëang nghƒ© v·ªÅ b·∫°n nhi·ªÅu h∆°n b·∫°n t∆∞·ªüng.",
            "H√£y ki√™n nh·∫´n, t√¨nh y√™u ƒë√≠ch th·ª±c c·∫ßn th·ªùi gian.",
        ]
        career_messages = [
            "C√¥ng vi·ªác su√¥n s·∫ª, c∆° h·ªôi thƒÉng ti·∫øn ƒëang m·ªü ra.",
            "H√£y t·∫≠p trung v√†o m·ª•c ti√™u, th√†nh c√¥ng s·∫Ω ƒë·∫øn.",
            "M·ªôt d·ª± √°n m·ªõi c√≥ th·ªÉ xu·∫•t hi·ªán b·∫•t ng·ªù.",
            "ƒê·ªìng nghi·ªáp s·∫Ω h·ªó tr·ª£ b·∫°n r·∫•t nhi·ªÅu h√¥m nay.",
        ]
        money_messages = [
            "T√†i ch√≠nh ·ªïn ƒë·ªãnh, c√≥ th·ªÉ c√≥ kho·∫£n thu b·∫•t ng·ªù.",
            "H√£y c·∫©n th·∫≠n v·ªõi c√°c quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞.",
            "ƒê√¢y l√† th·ªùi ƒëi·ªÉm t·ªët ƒë·ªÉ ti·∫øt ki·ªám.",
            "May m·∫Øn v·ªÅ t√†i ch√≠nh ƒëang m·ªâm c∆∞·ªùi v·ªõi b·∫°n.",
        ]
        
        return {
            "success": True,
            "zodiac": zodiac_name,
            "luck": random.choice(luck_levels),
            "love": random.choice(love_messages),
            "career": random.choice(career_messages),
            "money": random.choice(money_messages),
            "message": f"üîÆ T·ª≠ vi {zodiac_name}:\n‚Ä¢ May m·∫Øn: {random.choice(luck_levels)}\n‚Ä¢ T√¨nh y√™u: {random.choice(love_messages)}\n‚Ä¢ S·ª± nghi·ªáp: {random.choice(career_messages)}\n‚Ä¢ T√†i ch√≠nh: {random.choice(money_messages)}"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_news_vietnam() -> dict:
    """
    L·∫•y tin t·ª©c n√≥ng Vi·ªát Nam.
    """
    try:
        import aiohttp
        
        # D√πng RSS feed t·ª´ c√°c b√°o Vi·ªát Nam
        rss_urls = [
            "https://vnexpress.net/rss/tin-moi-nhat.rss",
            "https://tuoitre.vn/rss/tin-moi-nhat.rss",
        ]
        
        async with aiohttp.ClientSession() as session:
            for rss_url in rss_urls:
                try:
                    async with session.get(rss_url, timeout=10) as resp:
                        if resp.status == 200:
                            import xml.etree.ElementTree as ET
                            content = await resp.text()
                            root = ET.fromstring(content)
                            
                            items = root.findall('.//item')[:5]
                            news = []
                            
                            for item in items:
                                title = item.find('title')
                                title_text = title.text if title is not None else "No title"
                                news.append(title_text)
                            
                            if news:
                                msg = "üì∞ Tin t·ª©c m·ªõi nh·∫•t:\n"
                                for i, n in enumerate(news, 1):
                                    msg += f"{i}. {n}\n"
                                
                                result = {
                                    "success": True,
                                    "news": news,
                                    "message": msg.strip()
                                }
                                
                                # ü§ñ GEMINI SUMMARIZATION: T√≥m t·∫Øt nhanh b·∫±ng Gemini (non-blocking)
                                try:
                                    context = "\n".join([f"{i+1}. {n}" for i, n in enumerate(news)])
                                    # ‚ö° PROMPT NG·∫ÆN G·ªåN - ph·∫£n h·ªìi nhanh h∆°n
                                    summary_prompt = f"""T√≥m t·∫Øt 5 tin VN sau th√†nh 3 √Ω ch√≠nh:
{context}

Format: üìå [3 ƒëi·ªÉm] + üîπ [xu h∆∞·ªõng chung 1 c√¢u]"""
                                    
                                    print(f"‚ö° [NewsVN+Gemini] T√≥m t·∫Øt nhanh {len(news)} tin...")
                                    # ‚è±Ô∏è Timeout 15 gi√¢y - ƒë·ªß th·ªùi gian cho Gemini
                                    gemini_summary = await asyncio.wait_for(
                                        ask_gemini_direct(summary_prompt, model="models/gemini-3-flash-preview"),
                                        timeout=15.0
                                    )
                                    if gemini_summary.get("success"):
                                        summary_text = gemini_summary["response_text"]
                                        result["gemini_summary"] = summary_text
                                        result["message"] = f"‚ú® {summary_text}\n\n" + result["message"]
                                        print(f"‚úÖ [NewsVN+Gemini] Done ({len(summary_text)} chars)")
                                    else:
                                        print(f"‚ö†Ô∏è [NewsVN+Gemini] Failed: {gemini_summary.get('error')}")
                                except asyncio.TimeoutError:
                                    print(f"‚è±Ô∏è [NewsVN+Gemini] Timeout - tr·∫£ tin th√¥")
                                except Exception as e:
                                    print(f"‚ö†Ô∏è [NewsVN+Gemini] Error: {e}")
                                
                                return result
                except:
                    continue
                    
        return {"success": False, "error": "Kh√¥ng l·∫•y ƒë∆∞·ª£c tin t·ª©c"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def what_to_eat() -> dict:
    """
    G·ª£i √Ω m√≥n ƒÉn h√¥m nay (Vi·ªát Nam).
    """
    try:
        import random
        from datetime import datetime
        
        # M√≥n ƒÉn Vi·ªát Nam theo b·ªØa
        breakfast = [
            "üçú Ph·ªü b√≤ t√°i n·∫°m", "ü•ñ B√°nh m√¨ th·ªãt", "üç≤ B√∫n b√≤ Hu·∫ø", 
            "ü•£ Ch√°o l√≤ng", "üçú H·ªß ti·∫øu Nam Vang", "ü•ê B√°nh cu·ªën",
            "üç≤ B√∫n ri√™u cua", "ü•£ X√¥i x√©o", "üçú M√¨ Qu·∫£ng"
        ]
        
        lunch = [
            "üçö C∆°m t·∫•m s∆∞·ªùn b√¨ ch·∫£", "üç≤ B√∫n ch·∫£ H√† N·ªôi", "üçú Ph·ªü g√†",
            "ü•ó G·ªèi cu·ªën t√¥m th·ªãt", "üç≤ L·∫©u th√°i", "üçö C∆°m vƒÉn ph√≤ng",
            "üçú B√∫n ƒë·∫≠u m·∫Øm t√¥m", "üç≤ Canh chua c√° l√≥c", "üçö C∆°m g√† Tam K·ª≥"
        ]
        
        dinner = [
            "üçñ B√≤ n√©", "ü¶ê H·∫£i s·∫£n n∆∞·ªõng", "üç≤ L·∫©u g√† l√° √©",
            "üçó G√† n∆∞·ªõng mu·ªëi ·ªõt", "ü•ò C√° kho t·ªô", "üç≤ L·∫©u Th√°i",
            "üçñ BBQ H√†n Qu·ªëc", "üçú Ph·ªü cu·ªën", "üç≤ ·ªêc x√†o me"
        ]
        
        snacks = [
            "üßÅ B√°nh tr√°ng tr·ªôn", "üç° Ch√® th·∫≠p c·∫©m", "üç¶ Kem b∆°",
            "ü•§ Tr√† s·ªØa", "üçµ C√† ph√™ s·ªØa ƒë√°", "üç© B√°nh r√°n"
        ]
        
        hour = datetime.now().hour
        
        if 5 <= hour < 10:
            meal_type = "s√°ng"
            suggestion = random.choice(breakfast)
        elif 10 <= hour < 14:
            meal_type = "tr∆∞a"
            suggestion = random.choice(lunch)
        elif 14 <= hour < 17:
            meal_type = "x·∫ø"
            suggestion = random.choice(snacks)
        else:
            meal_type = "t·ªëi"
            suggestion = random.choice(dinner)
        
        return {
            "success": True,
            "meal_type": meal_type,
            "suggestion": suggestion,
            "alternatives": [random.choice(breakfast + lunch + dinner) for _ in range(2)],
            "message": f"üçΩÔ∏è B·ªØa {meal_type} h√¥m nay: {suggestion}\n\nüí° G·ª£i √Ω kh√°c: {random.choice(breakfast + lunch + dinner)}, {random.choice(breakfast + lunch + dinner)}"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_lunar_date() -> dict:
    """
    L·∫•y ng√†y √¢m l·ªãch Vi·ªát Nam h√¥m nay - thu·∫≠t to√°n ch√≠nh x√°c.
    T√≠nh theo m√∫i gi·ªù Vi·ªát Nam (UTC+7).
    """
    try:
        from datetime import datetime, timezone, timedelta
        import math
        
        # M√∫i gi·ªù Vi·ªát Nam UTC+7
        vn_tz = timezone(timedelta(hours=7))
        today = datetime.now(vn_tz)
        
        # ========== THU·∫¨T TO√ÅN T√çNH √ÇM L·ªäCH VI·ªÜT NAM ==========
        # D·ª±a tr√™n thu·∫≠t to√°n c·ªßa H·ªì Ng·ªçc ƒê·ª©c
        
        def jd_from_date(dd, mm, yy):
            """Chuy·ªÉn ng√†y d∆∞∆°ng l·ªãch sang Julian Day Number"""
            a = int((14 - mm) / 12)
            y = yy + 4800 - a
            m = mm + 12 * a - 3
            jd = dd + int((153 * m + 2) / 5) + 365 * y + int(y / 4) - int(y / 100) + int(y / 400) - 32045
            if jd < 2299161:
                jd = dd + int((153 * m + 2) / 5) + 365 * y + int(y / 4) - 32083
            return jd
        
        def new_moon(k):
            """T√≠nh th·ªùi ƒëi·ªÉm trƒÉng m·ªõi th·ª© k (k·ªÉ t·ª´ 1900-01-01)"""
            T = k / 1236.85
            T2 = T * T
            T3 = T2 * T
            dr = math.pi / 180
            Jd1 = 2415020.75933 + 29.53058868 * k + 0.0001178 * T2 - 0.000000155 * T3
            Jd1 = Jd1 + 0.00033 * math.sin((166.56 + 132.87 * T - 0.009173 * T2) * dr)
            M = 359.2242 + 29.10535608 * k - 0.0000333 * T2 - 0.00000347 * T3
            Mpr = 306.0253 + 385.81691806 * k + 0.0107306 * T2 + 0.00001236 * T3
            F = 21.2964 + 390.67050646 * k - 0.0016528 * T2 - 0.00000239 * T3
            C1 = (0.1734 - 0.000393 * T) * math.sin(M * dr) + 0.0021 * math.sin(2 * dr * M)
            C1 = C1 - 0.4068 * math.sin(Mpr * dr) + 0.0161 * math.sin(dr * 2 * Mpr)
            C1 = C1 - 0.0004 * math.sin(dr * 3 * Mpr)
            C1 = C1 + 0.0104 * math.sin(dr * 2 * F) - 0.0051 * math.sin(dr * (M + Mpr))
            C1 = C1 - 0.0074 * math.sin(dr * (M - Mpr)) + 0.0004 * math.sin(dr * (2 * F + M))
            C1 = C1 - 0.0004 * math.sin(dr * (2 * F - M)) - 0.0006 * math.sin(dr * (2 * F + Mpr))
            C1 = C1 + 0.0010 * math.sin(dr * (2 * F - Mpr)) + 0.0005 * math.sin(dr * (2 * Mpr + M))
            if T < -11:
                deltat = 0.001 + 0.000839 * T + 0.0002261 * T2 - 0.00000845 * T3 - 0.000000081 * T * T3
            else:
                deltat = -0.000278 + 0.000265 * T + 0.000262 * T2
            return Jd1 + C1 - deltat
        
        def sun_longitude(jdn):
            """T√≠nh kinh ƒë·ªô m·∫∑t tr·ªùi t·∫°i th·ªùi ƒëi·ªÉm Julian Day Number"""
            T = (jdn - 2451545.0) / 36525
            T2 = T * T
            dr = math.pi / 180
            M = 357.52910 + 35999.05030 * T - 0.0001559 * T2 - 0.00000048 * T * T2
            L0 = 280.46645 + 36000.76983 * T + 0.0003032 * T2
            DL = (1.914600 - 0.004817 * T - 0.000014 * T2) * math.sin(dr * M)
            DL = DL + (0.019993 - 0.000101 * T) * math.sin(dr * 2 * M) + 0.00029 * math.sin(dr * 3 * M)
            L = L0 + DL
            L = L * dr
            L = L - math.pi * 2 * int(L / (math.pi * 2))
            return int(L / math.pi * 6)
        
        def get_lunar_month_11(yy):
            """T√¨m ng√†y b·∫Øt ƒë·∫ßu th√°ng 11 √¢m l·ªãch"""
            off = jd_from_date(31, 12, yy) - 2415021
            k = int(off / 29.530588853)
            nm = new_moon(k)
            sun_long = sun_longitude(nm)
            if sun_long >= 9:
                nm = new_moon(k - 1)
            return int(nm + 0.5)
        
        def get_leap_month_offset(a11):
            """X√°c ƒë·ªãnh th√°ng nhu·∫≠n"""
            k = int((a11 - 2415021.076998695) / 29.530588853 + 0.5)
            last = 0
            i = 1
            arc = sun_longitude(new_moon(k + i))
            while True:
                last = arc
                i += 1
                arc = sun_longitude(new_moon(k + i))
                if arc != last or i >= 14:
                    break
            return i - 1
        
        def solar_to_lunar(dd, mm, yy):
            """Chuy·ªÉn ng√†y d∆∞∆°ng l·ªãch sang √¢m l·ªãch"""
            day_number = jd_from_date(dd, mm, yy)
            k = int((day_number - 2415021.076998695) / 29.530588853)
            month_start = new_moon(k + 1)
            if month_start > day_number:
                month_start = new_moon(k)
            a11 = get_lunar_month_11(yy)
            b11 = a11
            if a11 >= month_start:
                lunar_year = yy
                a11 = get_lunar_month_11(yy - 1)
            else:
                lunar_year = yy + 1
                b11 = get_lunar_month_11(yy + 1)
            lunar_day = int(day_number - month_start + 1)
            diff = int((month_start - a11) / 29)
            lunar_leap = 0
            lunar_month = diff + 11
            if b11 - a11 > 365:
                leap_month_diff = get_leap_month_offset(a11)
                if diff >= leap_month_diff:
                    lunar_month = diff + 10
                    if diff == leap_month_diff:
                        lunar_leap = 1
            if lunar_month > 12:
                lunar_month = lunar_month - 12
            if lunar_month >= 11 and diff < 4:
                lunar_year -= 1
            return lunar_day, lunar_month, lunar_year, lunar_leap
        
        # ========== T√çNH CAN CHI ==========
        CAN = ["Gi√°p", "·∫§t", "B√≠nh", "ƒêinh", "M·∫≠u", "K·ª∑", "Canh", "T√¢n", "Nh√¢m", "Qu√Ω"]
        CHI = ["T√Ω", "S·ª≠u", "D·∫ßn", "M√£o", "Th√¨n", "T·ªµ", "Ng·ªç", "M√πi", "Th√¢n", "D·∫≠u", "Tu·∫•t", "H·ª£i"]
        
        def get_can_chi_year(lunar_year):
            """L·∫•y can chi c·ªßa nƒÉm"""
            can = CAN[(lunar_year + 6) % 10]
            chi = CHI[(lunar_year + 8) % 12]
            return f"{can} {chi}"
        
        def get_can_chi_day(dd, mm, yy):
            """L·∫•y can chi c·ªßa ng√†y"""
            jd = jd_from_date(dd, mm, yy)
            can = CAN[(jd + 9) % 10]
            chi = CHI[(jd + 1) % 12]
            return f"{can} {chi}"
        
        # ========== T√çNH NG√ÄY √ÇM L·ªäCH H√îM NAY ==========
        dd, mm, yy = today.day, today.month, today.year
        lunar_day, lunar_month, lunar_year, is_leap = solar_to_lunar(dd, mm, yy)
        
        day_of_week = ["Th·ª© Hai", "Th·ª© Ba", "Th·ª© T∆∞", "Th·ª© NƒÉm", "Th·ª© S√°u", "Th·ª© B·∫£y", "Ch·ªß Nh·∫≠t"][today.weekday()]
        can_chi_year = get_can_chi_year(lunar_year)
        can_chi_day = get_can_chi_day(dd, mm, yy)
        
        # T√™n th√°ng √¢m
        month_name = f"{'Nhu·∫≠n ' if is_leap else ''}Th√°ng {lunar_month}"
        
        # Ng√†y l·ªÖ √¢m l·ªãch Vi·ªát Nam
        vn_holidays = {
            (1, 1): "üéä T·∫øt Nguy√™n ƒê√°n - M√πng 1 T·∫øt",
            (1, 2): "üéä M√πng 2 T·∫øt",
            (1, 3): "üéä M√πng 3 T·∫øt",
            (1, 15): "üèÆ T·∫øt Nguy√™n Ti√™u (R·∫±m th√°ng Gi√™ng)",
            (3, 3): "üç∞ T·∫øt H√†n Th·ª±c",
            (3, 10): "üëë Gi·ªó T·ªï H√πng V∆∞∆°ng",
            (4, 15): "ü™∑ L·ªÖ Ph·∫≠t ƒê·∫£n",
            (5, 5): "üê≤ T·∫øt ƒêoan Ng·ªç",
            (7, 15): "üëª R·∫±m th√°ng 7 - L·ªÖ Vu Lan",
            (8, 15): "ü•Æ T·∫øt Trung Thu",
            (9, 9): "üå∏ T·∫øt Tr√πng C·ª≠u",
            (10, 15): "üôè R·∫±m th√°ng 10 - L·ªÖ H·∫° Nguy√™n",
            (12, 23): "üßπ √îng C√¥ng √îng T√°o",
            (12, 30): "üéÜ Giao th·ª´a - ƒê√™m 30 T·∫øt",
        }
        
        holiday_info = vn_holidays.get((lunar_month, lunar_day), "")
        
        # Ki·ªÉm tra ng√†y r·∫±m / m√πng 1
        special_day = ""
        if lunar_day == 1:
            special_day = "üåë Ng√†y M√πng 1 (S√≥c)"
        elif lunar_day == 15:
            special_day = "üåï Ng√†y R·∫±m (V·ªçng)"
        
        message = f"""üìÖ L·ªäCH √ÇM VI·ªÜT NAM

üóìÔ∏è D∆∞∆°ng l·ªãch: {day_of_week}, {dd:02d}/{mm:02d}/{yy}
üåô √Çm l·ªãch: Ng√†y {lunar_day}, {month_name}, nƒÉm {can_chi_year}

üìÜ Ng√†y: {can_chi_day}
üêâ NƒÉm: {can_chi_year} ({lunar_year})

{f'üéâ {holiday_info}' if holiday_info else ''}
{special_day}""".strip()
        
        return {
            "success": True,
            "solar_date": f"{dd:02d}/{mm:02d}/{yy}",
            "lunar_date": f"{lunar_day}/{lunar_month}/{lunar_year}",
            "lunar_day": lunar_day,
            "lunar_month": lunar_month,
            "lunar_year": lunar_year,
            "is_leap_month": is_leap == 1,
            "day_of_week": day_of_week,
            "can_chi_day": can_chi_day,
            "can_chi_year": can_chi_year,
            "holiday": holiday_info if holiday_info else None,
            "message": message
        }
    except Exception as e:
        import traceback
        return {"success": False, "error": str(e), "traceback": traceback.format_exc()}

# ============================================================
# KNOWLEDGE BASE TOOL HANDLERS
# ============================================================

# ============================================================
# üî• GEMINI FLASH SMART KB FILTER - L·ªåC TH√îNG TIN TH√îNG MINH
# ============================================================

async def gemini_smart_kb_filter(
    user_query: str,
    filter_mode: str = "relevant",  # relevant, summary, extract, qa
    max_documents: int = 10,
    output_format: str = "structured"  # structured, raw, concise
) -> dict:
    """
    üî• S·ª≠ d·ª•ng s·ª©c m·∫°nh Gemini Flash 3 ƒë·ªÉ L·ªåC v√† T√åM KI·∫æM TH√îNG MINH trong Knowledge Base.
    
    Quy tr√¨nh:
    1. Load to√†n b·ªô documents t·ª´ Knowledge Base
    2. D√πng Gemini Flash ƒë·ªÉ ph√¢n t√≠ch v√† l·ªçc n·ªôi dung TH·ª∞C S·ª∞ li√™n quan
    3. Tr√≠ch xu·∫•t th√¥ng tin ch√≠nh x√°c, lo·∫°i b·ªè noise
    4. Tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l·ªçc s·∫°ch cho LLM ch√≠nh ƒë·ªçc
    
    Args:
        user_query: C√¢u h·ªèi/y√™u c·∫ßu c·ªßa user
        filter_mode: 
            - "relevant": Ch·ªâ gi·ªØ ph·∫ßn li√™n quan (default)
            - "summary": T√≥m t·∫Øt n·ªôi dung
            - "extract": Tr√≠ch xu·∫•t facts/entities
            - "qa": Tr·∫£ l·ªùi c√¢u h·ªèi tr·ª±c ti·∫øp
        max_documents: S·ªë documents t·ªëi ƒëa ƒë·ªÉ x·ª≠ l√Ω (default: 10)
        output_format:
            - "structured": JSON c√≥ c·∫•u tr√∫c
            - "raw": Text th√¥
            - "concise": Ng·∫Øn g·ªçn nh·∫•t
            
    Returns:
        dict v·ªõi filtered_content, sources, v√† metadata
    """
    try:
        print(f"üî• [GEMINI KB FILTER] Processing: {user_query[:60]}...")
        
        # ============================================================
        # B∆Ø·ªöC 1: Load t·∫•t c·∫£ documents t·ª´ Knowledge Base
        # ============================================================
        all_documents = []
        
        # Th·ª≠ load t·ª´ index tr∆∞·ªõc
        if KNOWLEDGE_INDEX_FILE.exists():
            try:
                with open(KNOWLEDGE_INDEX_FILE, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
                all_documents = index_data.get("documents", [])
            except:
                pass
        
        # üÜï FALLBACK: N·∫øu index tr·ªëng, ƒë·ªçc tr·ª±c ti·∫øp t·ª´ files
        if not all_documents:
            print("‚ö†Ô∏è [GEMINI KB] Index tr·ªëng, ƒëang ƒë·ªçc tr·ª±c ti·∫øp t·ª´ files...")
            config = load_knowledge_config()
            folder_path = config.get("folder_path", "")
            
            if folder_path and Path(folder_path).exists():
                files = scan_folder_for_files(folder_path)
                for f in files[:15]:  # Gi·ªõi h·∫°n 15 files
                    try:
                        text = extract_text_from_file(f["path"])
                        if text and len(text.strip()) > 50 and not text.startswith("["):
                            all_documents.append({
                                "file_path": f["path"],
                                "file_name": f["name"],
                                "content": text[:50000]
                            })
                            print(f"üìÑ [GEMINI KB] Loaded: {f['name']}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è [GEMINI KB] Error loading {f['name']}: {e}")
        
        if not all_documents:
            return {
                "success": False,
                "error": "Knowledge Base ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng v√†o Web UI > Knowledge Base ƒë·ªÉ c·∫•u h√¨nh th∆∞ m·ª•c."
            }
        
        print(f"üìö [GEMINI KB] Loaded {len(all_documents)} documents")
        
        # ============================================================
        # B∆Ø·ªöC 2: Pre-filter b·∫±ng keywords (gi·∫£m s·ªë docs c·∫ßn g·ª≠i Gemini)
        # ============================================================
        query_lower = user_query.lower()
        stop_words = {'l√†', 'c·ªßa', 'v√†', 'c√≥', 'c√°c', 'ƒë∆∞·ª£c', 'trong', 'ƒë·ªÉ', 'n√†y', 'ƒë√≥', 
                     'cho', 'v·ªõi', 't·ª´', 'v·ªÅ', 'nh∆∞', 'theo', 'kh√¥ng', 'khi', 'ƒë√£', 's·∫Ω',
                     'ai', 'g√¨', 'n√†o', 'ƒë√¢u', 'sao', 'th·∫ø', 'a', 'an', 'the', 'is', 'are'}
        
        keywords = [w.lower() for w in user_query.split() if w.lower() not in stop_words and len(w) > 1]
        print(f"üîë [GEMINI KB] Keywords: {keywords}")
        
        # Pre-filter: Ch·ªâ gi·ªØ documents c√≥ √≠t nh·∫•t 1 keyword
        candidate_docs = []
        for doc in all_documents:
            content = doc.get("content", "").lower()
            file_name = doc.get("file_name", "")
            
            # Skip invalid content
            if content.strip().startswith("%pdf-") or len(content.strip()) < 50:
                continue
            
            # Check keyword match
            match_count = sum(1 for kw in keywords if kw in content or kw in file_name.lower())
            if match_count > 0 or not keywords:  # N·∫øu kh√¥ng c√≥ keywords, l·∫•y t·∫•t c·∫£
                candidate_docs.append({
                    "file_name": file_name,
                    "content": doc.get("content", ""),
                    "match_count": match_count
                })
        
        # Sort by match count v√† gi·ªõi h·∫°n
        candidate_docs.sort(key=lambda x: x["match_count"], reverse=True)
        candidate_docs = candidate_docs[:max_documents]
        
        if not candidate_docs:
            return {
                "success": False,
                "error": f"Kh√¥ng t√¨m th·∫•y documents n√†o li√™n quan ƒë·∫øn '{user_query}'"
            }
        
        print(f"üìÑ [GEMINI KB] Pre-filtered to {len(candidate_docs)} candidate docs")
        
        # ============================================================
        # B∆Ø·ªöC 3: Chu·∫©n b·ªã context cho Gemini Flash
        # ============================================================
        # Gi·ªõi h·∫°n m·ªói document 3000 chars ƒë·ªÉ tr√°nh qu√° t·∫£i
        docs_for_gemini = []
        total_chars = 0
        MAX_TOTAL_CHARS = 25000  # ~6000 tokens cho Gemini
        
        for doc in candidate_docs:
            content = doc["content"]
            if len(content) > 3000:
                # Tr√≠ch xu·∫•t ph·∫ßn c√≥ keywords
                content = _extract_relevant_parts(content, keywords, max_len=3000)
            
            if total_chars + len(content) > MAX_TOTAL_CHARS:
                break
                
            docs_for_gemini.append({
                "file_name": doc["file_name"],
                "content": content
            })
            total_chars += len(content)
        
        print(f"üì¶ [GEMINI KB] Prepared {len(docs_for_gemini)} docs ({total_chars:,} chars) for Gemini")
        
        # ============================================================
        # B∆Ø·ªöC 4: Build prompt cho Gemini Flash
        # ============================================================
        docs_text = ""
        for i, doc in enumerate(docs_for_gemini, 1):
            docs_text += f"\n\n--- T√ÄI LI·ªÜU {i}: {doc['file_name']} ---\n{doc['content']}"
        
        # Prompt t√πy theo filter_mode
        if filter_mode == "summary":
            filter_instruction = """T√ìM T·∫ÆT n·ªôi dung li√™n quan ƒë·∫øn c√¢u h·ªèi.
- Ch·ªâ t√≥m t·∫Øt ph·∫ßn TH·ª∞C S·ª∞ li√™n quan
- B·ªè qua th√¥ng tin kh√¥ng li√™n quan
- Vi·∫øt ng·∫Øn g·ªçn, s√∫c t√≠ch"""
        elif filter_mode == "extract":
            filter_instruction = """TR√çCH XU·∫§T c√°c facts, entities, s·ªë li·ªáu li√™n quan:
- T√™n ng∆∞·ªùi, t·ªï ch·ª©c
- S·ªë li·ªáu, ng√†y th√°ng
- S·ª± ki·ªán, h√†nh ƒë·ªông
- M·ªëi quan h·ªá
Format: JSON array"""
        elif filter_mode == "qa":
            filter_instruction = """‚ö° TR·∫¢ L·ªúI NGAY L·∫¨P T·ª®C c√¢u h·ªèi d·ª±a tr√™n t√†i li·ªáu.
‚õî KH√îNG ƒê∆Ø·ª¢C h·ªèi l·∫°i, KH√îNG ƒê∆Ø·ª¢C y√™u c·∫ßu th√™m th√¥ng tin
‚úÖ Tr·∫£ l·ªùi TR·ª∞C TI·∫æP, ch√≠nh x√°c, c√≥ tr√≠ch d·∫´n ngu·ªìn
‚úÖ N·∫øu th√¥ng tin kh√¥ng ƒë·∫ßy ƒë·ªß ‚Üí V·∫™N tr·∫£ l·ªùi v·ªõi nh·ªØng g√¨ c√≥
‚úÖ N·∫øu kh√¥ng c√≥ th√¥ng tin ‚Üí N√≥i "Kh√¥ng t√¨m th·∫•y trong database" """
        else:  # relevant
            filter_instruction = """L·ªåC v√† GI·ªÆ L·∫†I CH·ªà nh·ªØng ph·∫ßn TH·ª∞C S·ª∞ LI√äN QUAN ƒë·∫øn c√¢u h·ªèi.
- Lo·∫°i b·ªè ho√†n to√†n c√°c ƒëo·∫°n kh√¥ng li√™n quan
- Gi·ªØ nguy√™n vƒÉn c√°c ƒëo·∫°n quan tr·ªçng
- ƒê√°nh d·∫•u ngu·ªìn (t√™n file) cho m·ªói ƒëo·∫°n"""
        
        gemini_prompt = f"""üî• B·∫†N L√Ä CHUY√äN GIA TR·∫¢ L·ªúI C√ÇU H·ªéI T·ª™ C∆† S·ªû D·ªÆ LI·ªÜU.

‚ö° QUY T·∫ÆC B·∫ÆT BU·ªòC:
- TR·∫¢ L·ªúI NGAY L·∫¨P T·ª®C - KH√îNG H·ªéI L·∫†I
- KH√îNG y√™u c·∫ßu th√™m th√¥ng tin
- KH√îNG n√≥i "b·∫°n mu·ªën bi·∫øt g√¨" ho·∫∑c "b·∫°n c·∫ßn g√¨ th√™m"
- S·ª≠ d·ª•ng TO√ÄN B·ªò th√¥ng tin c√≥ trong t√†i li·ªáu ƒë·ªÉ tr·∫£ l·ªùi

üìã NHI·ªÜM V·ª§: {filter_instruction}

‚ùì C√ÇU H·ªéI C·ª¶A USER:
"{user_query}"

üìö T√ÄI LI·ªÜU TRONG DATABASE:
{docs_text}

üéØ TR·∫¢ L·ªúI NGAY (kh√¥ng h·ªèi l·∫°i):"""

        # ============================================================
        # B∆Ø·ªöC 5: G·ªçi Gemini Flash 3 ƒë·ªÉ l·ªçc
        # ============================================================
        if not GEMINI_AVAILABLE:
            return {
                "success": False,
                "error": "Gemini API kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra API key."
            }
        
        import google.generativeai as genai
        gemini_api_key = os.environ.get("GEMINI_API_KEY") or GEMINI_API_KEY
        
        if not gemini_api_key:
            return {"success": False, "error": "Thi·∫øu Gemini API key"}
        
        genai.configure(api_key=gemini_api_key)
        
        # S·ª≠ d·ª•ng Gemini 3 Flash Preview (model m·ªõi nh·∫•t, nhanh nh·∫•t)
        model = genai.GenerativeModel('models/gemini-2.0-flash')
        
        print(f"ü§ñ [GEMINI KB] Calling Gemini Flash to filter...")
        
        response = model.generate_content(
            gemini_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.2,  # Low temp cho accuracy
                max_output_tokens=2000,
                top_p=0.95
            )
        )
        
        if not response or not response.text:
            return {"success": False, "error": "Gemini kh√¥ng tr·∫£ v·ªÅ response"}
        
        filtered_content = response.text.strip()
        print(f"‚úÖ [GEMINI KB] Filtered content: {len(filtered_content)} chars")
        
        # ============================================================
        # B∆Ø·ªöC 6: Format output
        # ============================================================
        sources = [doc["file_name"] for doc in docs_for_gemini]
        
        if output_format == "concise":
            # C·∫Øt ng·∫Øn n·∫øu qu√° d√†i
            if len(filtered_content) > 1500:
                filtered_content = filtered_content[:1500] + "\n[... ƒê√£ c·∫Øt ng·∫Øn ...]"
        
        result = {
            "success": True,
            "filtered_content": filtered_content,
            "sources": sources,
            "filter_mode": filter_mode,
            "documents_processed": len(docs_for_gemini),
            "total_documents": len(all_documents),
            "keywords_used": keywords,
            "original_chars": total_chars,
            "filtered_chars": len(filtered_content),
            "compression_ratio": f"{(1 - len(filtered_content)/max(total_chars,1))*100:.1f}%",
            "message": f"‚úÖ ƒê√£ l·ªçc {len(docs_for_gemini)} t√†i li·ªáu ({total_chars:,} chars) ‚Üí {len(filtered_content):,} chars relevant content"
        }
        
        # Th√™m instruction cho LLM ch√≠nh
        result["llm_instruction"] = f"""üìä ƒê√É L·ªåC TH√îNG TIN T·ª™ KNOWLEDGE BASE

C√¢u h·ªèi: "{user_query}"
Ngu·ªìn: {', '.join(sources[:3])}{'...' if len(sources) > 3 else ''}

--- N·ªòI DUNG ƒê√É L·ªåC ---
{filtered_content}
--- H·∫æT ---

‚ö° H√ÉY TR·∫¢ L·ªúI USER D·ª∞A TR√äN TH√îNG TIN TR√äN."""

        return result
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def _extract_relevant_parts(content: str, keywords: list, max_len: int = 3000) -> str:
    """
    Tr√≠ch xu·∫•t c√°c ph·∫ßn c√≥ ch·ª©a keywords t·ª´ content d√†i.
    """
    if not keywords:
        return content[:max_len]
    
    content_lower = content.lower()
    relevant_parts = []
    
    for keyword in keywords:
        pos = 0
        while pos < len(content_lower):
            idx = content_lower.find(keyword, pos)
            if idx == -1:
                break
            
            # L·∫•y context xung quanh keyword (500 chars m·ªói b√™n)
            start = max(0, idx - 500)
            end = min(len(content), idx + len(keyword) + 500)
            
            part = content[start:end]
            if part not in relevant_parts:
                relevant_parts.append(part)
            
            pos = idx + 1
            
            # Gi·ªõi h·∫°n s·ªë parts
            if len(relevant_parts) >= 5:
                break
    
    if relevant_parts:
        combined = "\n[...]\n".join(relevant_parts)
        return combined[:max_len]
    else:
        return content[:max_len]


# ============================================================
# üî• GEMINI SMART ANALYZE - PH√ÇN T√çCH + GOOGLE SEARCH
# ============================================================

async def gemini_smart_analyze(
    user_query: str,
    analysis_type: str = "comprehensive",  # comprehensive, quick, deep
    include_web_search: bool = True,
    include_kb: bool = False,
    max_search_results: int = 8
) -> dict:
    """
    üî• GEMINI SMART ANALYZE - Ph√¢n t√≠ch v·∫•n ƒë·ªÅ + T√¨m ki·∫øm Web + AI t·ªïng h·ª£p
    
    Quy tr√¨nh:
    1. Gemini ph√¢n t√≠ch y√™u c·∫ßu v√† t·∫°o search queries t·ªëi ∆∞u
    2. T√¨m ki·∫øm Web (Google/DuckDuckGo) ƒë·ªÉ l·∫•y th√¥ng tin m·ªõi nh·∫•t
    3. (T√πy ch·ªçn) T√¨m ki·∫øm Knowledge Base n·ªôi b·ªô
    4. Gemini t·ªïng h·ª£p, ph√¢n t√≠ch v√† ƒë∆∞a ra k·∫øt lu·∫≠n
    5. Tr·∫£ v·ªÅ k·∫øt qu·∫£ ph√¢n t√≠ch cho LLM ch√≠nh
    
    Args:
        user_query: V·∫•n ƒë·ªÅ c·∫ßn ph√¢n t√≠ch
        analysis_type: 
            - "comprehensive": Ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß, chi ti·∫øt (default)
            - "quick": Ph√¢n t√≠ch nhanh, t√≥m t·∫Øt
            - "deep": Ph√¢n t√≠ch s√¢u, nhi·ªÅu g√≥c ƒë·ªô
        include_web_search: C√≥ t√¨m ki·∫øm web kh√¥ng (default: True)
        include_kb: C√≥ t√¨m Knowledge Base kh√¥ng (default: False)
        max_search_results: S·ªë k·∫øt qu·∫£ web search t·ªëi ƒëa (default: 8)
        
    Returns:
        dict v·ªõi analysis, sources, summary
    """
    try:
        print(f"üî• [GEMINI ANALYZE] Analyzing: {user_query[:60]}...")
        
        # ============================================================
        # B∆Ø·ªöC 1: Ki·ªÉm tra Gemini API
        # ============================================================
        if not GEMINI_AVAILABLE:
            return {
                "success": False,
                "error": "Gemini API kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra API key."
            }
        
        import google.generativeai as genai
        gemini_api_key = os.environ.get("GEMINI_API_KEY") or GEMINI_API_KEY
        
        if not gemini_api_key:
            return {"success": False, "error": "Thi·∫øu Gemini API key"}
        
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('models/gemini-2.0-flash')
        
        # ============================================================
        # B∆Ø·ªöC 2: Gemini t·∫°o search queries t·ªëi ∆∞u
        # ============================================================
        query_prompt = f"""B·∫°n l√† chuy√™n gia ph√¢n t√≠ch. User mu·ªën ph√¢n t√≠ch/t√¨m hi·ªÉu v·ªÅ:
"{user_query}"

H√£y t·∫°o 2-3 search queries T·ªêI ∆ØU ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin tr√™n Google/Web.
M·ªói query n√™n:
- Ng·∫Øn g·ªçn, t·ª´ kh√≥a ch√≠nh x√°c
- Th√™m nƒÉm 2024/2025 n·∫øu c·∫ßn th√¥ng tin m·ªõi
- Ti·∫øng Vi·ªát ho·∫∑c Anh t√πy ch·ªß ƒë·ªÅ

Tr·∫£ v·ªÅ JSON array, VD: ["query 1", "query 2", "query 3"]
Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng gi·∫£i th√≠ch."""

        print("üîç [GEMINI ANALYZE] Generating search queries...")
        
        query_response = model.generate_content(
            query_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=300
            )
        )
        
        # Parse search queries
        search_queries = [user_query]  # Default
        if query_response and query_response.text:
            try:
                import re
                json_match = re.search(r'\[.*?\]', query_response.text, re.DOTALL)
                if json_match:
                    search_queries = json.loads(json_match.group())
                    print(f"‚úÖ [GEMINI ANALYZE] Generated queries: {search_queries}")
            except:
                search_queries = [user_query]
        
        # ============================================================
        # B∆Ø·ªöC 3: T√¨m ki·∫øm Web (Google/DuckDuckGo)
        # ============================================================
        web_results = []
        web_context = ""
        
        if include_web_search and RAG_AVAILABLE:
            print(f"üåê [GEMINI ANALYZE] Searching web with {len(search_queries)} queries...")
            
            from rag_system import web_search as rag_web_search
            
            all_results = []
            for sq in search_queries[:3]:  # Max 3 queries
                try:
                    result = await rag_web_search(sq, max_results=max_search_results // len(search_queries) + 2)
                    if result.get("success") and result.get("results"):
                        all_results.extend(result["results"])
                except Exception as e:
                    print(f"‚ö†Ô∏è [GEMINI ANALYZE] Search error for '{sq}': {e}")
            
            # Deduplicate by title
            seen_titles = set()
            for r in all_results:
                title = r.get("title", "")
                if title and title not in seen_titles:
                    seen_titles.add(title)
                    web_results.append(r)
            
            web_results = web_results[:max_search_results]
            print(f"üìä [GEMINI ANALYZE] Found {len(web_results)} unique web results")
            
            # Build web context
            if web_results:
                web_context = "üåê K·∫æT QU·∫¢ T√åM KI·∫æM WEB:\n\n"
                for i, r in enumerate(web_results, 1):
                    web_context += f"{i}. **{r.get('title', 'No title')}**\n"
                    web_context += f"   {r.get('snippet', '')}\n"
                    if r.get('url'):
                        web_context += f"   üîó {r.get('url')}\n"
                    web_context += "\n"
        
        # ============================================================
        # B∆Ø·ªöC 4: T√¨m ki·∫øm Knowledge Base (n·∫øu b·∫≠t)
        # ============================================================
        kb_context = ""
        kb_sources = []
        
        if include_kb:
            print("üìö [GEMINI ANALYZE] Searching Knowledge Base...")
            try:
                kb_result = await gemini_smart_kb_filter(
                    user_query=user_query,
                    filter_mode="relevant",
                    max_documents=5,
                    output_format="concise"
                )
                if kb_result.get("success") and kb_result.get("filtered_content"):
                    kb_context = f"\n\nüìö TH√îNG TIN T·ª™ DATABASE N·ªòI B·ªò:\n{kb_result['filtered_content']}"
                    kb_sources = kb_result.get("sources", [])
                    print(f"‚úÖ [GEMINI ANALYZE] Found KB content from {len(kb_sources)} sources")
            except Exception as e:
                print(f"‚ö†Ô∏è [GEMINI ANALYZE] KB search error: {e}")
        
        # ============================================================
        # B∆Ø·ªöC 5: Gemini t·ªïng h·ª£p v√† ph√¢n t√≠ch
        # ============================================================
        
        # X√¢y d·ª±ng prompt ph√¢n t√≠ch t√πy theo type
        if analysis_type == "quick":
            analysis_instruction = """PH√ÇN T√çCH NHANH - T√≥m t·∫Øt ng·∫Øn g·ªçn:
- 3-5 ƒëi·ªÉm ch√≠nh
- K·∫øt lu·∫≠n trong 2-3 c√¢u
- Kh√¥ng c·∫ßn chi ti·∫øt"""
        elif analysis_type == "deep":
            analysis_instruction = """PH√ÇN T√çCH S√ÇU - Chi ti·∫øt v√† ƒëa chi·ªÅu:
- Ph√¢n t√≠ch t·ª´ nhi·ªÅu g√≥c ƒë·ªô
- So s√°nh c√°c ngu·ªìn th√¥ng tin
- ƒê√°nh gi√° ƒë·ªô tin c·∫≠y
- Xu h∆∞·ªõng v√† d·ª± ƒëo√°n
- T√≥m t·∫Øt c√°c quan ƒëi·ªÉm kh√°c nhau"""
        else:  # comprehensive
            analysis_instruction = """PH√ÇN T√çCH TO√ÄN DI·ªÜN:
- T√≥m t·∫Øt th√¥ng tin ch√≠nh
- C√°c ƒëi·ªÉm quan tr·ªçng
- Ngu·ªìn g·ªëc v√† ƒë·ªô tin c·∫≠y
- K·∫øt lu·∫≠n r√µ r√†ng"""
        
        now = datetime.now()
        current_date = now.strftime("%d/%m/%Y")
        
        analysis_prompt = f"""üî• B·∫†N L√Ä CHUY√äN GIA PH√ÇN T√çCH TH√îNG TIN.

üìÖ NG√ÄY HI·ªÜN T·∫†I: {current_date}

‚ö° NHI·ªÜM V·ª§: {analysis_instruction}

‚ùì V·∫§N ƒê·ªÄ C·∫¶N PH√ÇN T√çCH:
"{user_query}"

{web_context}
{kb_context}

üéØ Y√äU C·∫¶U QUAN TR·ªåNG:
1. TR·∫¢ L·ªúI NG·∫ÆN G·ªåN - T·ªêI ƒêA 500 T·ª™
2. ƒêI TH·∫≤NG V√ÄO V·∫§N ƒê·ªÄ, kh√¥ng gi·∫£i th√≠ch d√†i d√≤ng
3. Li·ªát k√™ √Ω ch√≠nh b·∫±ng bullet points
4. TR·∫¢ L·ªúI B·∫∞NG TI·∫æNG VI·ªÜT
5. KH√îNG c·∫ßn ghi ngu·ªìn chi ti·∫øt

üìù TR·∫¢ L·ªúI NG·∫ÆN G·ªåN:"""

        print("ü§ñ [GEMINI ANALYZE] Gemini analyzing and synthesizing...")
        
        analysis_response = model.generate_content(
            analysis_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=1000,
                top_p=0.9
            )
        )
        
        if not analysis_response or not analysis_response.text:
            return {"success": False, "error": "Gemini kh√¥ng tr·∫£ v·ªÅ ph√¢n t√≠ch"}
        
        analysis_content = analysis_response.text.strip()
        
        # ‚ö° GI·ªöI H·∫†N ƒê·ªò D√ÄI - Qu√° d√†i s·∫Ω khi·∫øn LLM cloud b·ªã timeout
        MAX_RESPONSE_LENGTH = 1500
        if len(analysis_content) > MAX_RESPONSE_LENGTH:
            # C·∫Øt ng·∫Øn nh∆∞ng gi·ªØ nguy√™n c√¢u cu·ªëi
            analysis_content = analysis_content[:MAX_RESPONSE_LENGTH]
            # T√¨m d·∫•u ch·∫•m cu·ªëi ƒë·ªÉ kh√¥ng c·∫Øt gi·ªØa c√¢u
            last_period = analysis_content.rfind('.')
            if last_period > MAX_RESPONSE_LENGTH - 200:
                analysis_content = analysis_content[:last_period + 1]
            analysis_content += "\n\n(ƒê√¢y l√† t√≥m t·∫Øt. H·ªèi th√™m n·∫øu c·∫ßn chi ti·∫øt.)"
        
        print(f"‚úÖ [GEMINI ANALYZE] Analysis complete: {len(analysis_content)} chars")
        
        # ============================================================
        # B∆Ø·ªöC 6: Tr·∫£ v·ªÅ k·∫øt qu·∫£ - PLAIN TEXT ƒë·ªÉ LLM ƒë·ªçc ngay
        # ============================================================
        
        # Tr·∫£ v·ªÅ response_text ƒë·ªÉ format_result_for_llm x·ª≠ l√Ω ƒë√∫ng
        # Gi·ªëng c√°ch ask_gemini, ask_gpt4 ho·∫°t ƒë·ªông
        return {
            "success": True,
            "response_text": analysis_content
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


async def search_knowledge_base(query: str) -> dict:
    """
    T√¨m ki·∫øm trong Knowledge Base v√† d√πng Gemini AI ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c.
    - B∆∞·ªõc 1: TF-IDF t√¨m t√†i li·ªáu li√™n quan
    - B∆∞·ªõc 2: Gemini ƒë·ªçc context v√† tr·∫£ l·ªùi c√¢u h·ªèi
    - üÜï B∆∞·ªõc 0: N·∫øu index tr·ªëng, t·ª± ƒë·ªông ƒë·ªçc file tr·ª±c ti·∫øp
    """
    try:
        if not query:
            return {"success": False, "error": "Vui l√≤ng nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm"}
        
        # Load index
        documents = []
        if KNOWLEDGE_INDEX_FILE.exists():
            try:
                with open(KNOWLEDGE_INDEX_FILE, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
                documents = index_data.get("documents", [])
            except:
                pass
        
        # üÜï FALLBACK: N·∫øu index tr·ªëng, t·ª± ƒë·ªông ƒë·ªçc tr·ª±c ti·∫øp t·ª´ files
        if not documents:
            print("‚ö†Ô∏è [KB] Index tr·ªëng, ƒëang ƒë·ªçc tr·ª±c ti·∫øp t·ª´ files...")
            config = load_knowledge_config()
            folder_path = config.get("folder_path", "")
            
            if folder_path and Path(folder_path).exists():
                files = scan_folder_for_files(folder_path)
                for f in files[:10]:  # Gi·ªõi h·∫°n 10 files ƒë·ªÉ tr√°nh qu√° t·∫£i
                    try:
                        text = extract_text_from_file(f["path"])
                        if text and len(text.strip()) > 50 and not text.startswith("["):
                            documents.append({
                                "file_path": f["path"],
                                "file_name": f["name"],
                                "content": text[:50000]
                            })
                            print(f"üìÑ [KB] Loaded: {f['name']} ({len(text)} chars)")
                    except Exception as e:
                        print(f"‚ö†Ô∏è [KB] Error loading {f['name']}: {e}")
                
                if documents:
                    print(f"üìö [KB] Loaded {len(documents)} documents from files")
            
            if not documents:
                return {
                    "success": False, 
                    "error": "Knowledge base ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng v√†o Web UI > Knowledge Base ƒë·ªÉ c·∫•u h√¨nh th∆∞ m·ª•c v√† index files."
                }
        
        # T√°ch query th√†nh keywords (b·ªè stop words ph·ªï bi·∫øn)
        stop_words = {
            # Vietnamese
            'l√†', 'c·ªßa', 'v√†', 'c√≥', 'c√°c', 'ƒë∆∞·ª£c', 'trong', 'ƒë·ªÉ', 'n√†y', 'ƒë√≥', 'cho', 'v·ªõi', 
            't·ª´', 'v·ªÅ', 'nh∆∞', 'theo', 'kh√¥ng', 'khi', 'ƒë√£', 's·∫Ω', 'nh·ªØng', 'm·ªôt', 'hay', 'ho·∫∑c',
            'th√¨', 'm√†', 'n·∫øu', 'v√¨', 'b·ªüi', 'n√™n', 'c≈©ng', 'l·∫°i', 'c√≤n', 'ƒë√¢y', 'kia', '·∫•y',
            'ra', 'v√†o', 'l√™n', 'xu·ªëng', 'ƒëi', 'ƒë·∫øn', 'b·∫±ng', 'qua', 'sau', 'tr∆∞·ªõc', 'tr√™n', 'd∆∞·ªõi',
            'n√†o', 'g√¨', 'sao', 'th·∫ø', 'r·∫±ng', 't·∫°i', 'v·∫≠y', 'nh∆∞ng', 'tuy', 'm·∫∑c', 'd√π',
            # English
            'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'should', 'could', 
            'may', 'might', 'can', 'what', 'which', 'who', 'how', 'when', 'where', 'why',
            'this', 'that', 'these', 'those', 'it', 'its', 'they', 'them', 'their',
            'he', 'she', 'him', 'her', 'his', 'we', 'us', 'our', 'you', 'your',
            'of', 'to', 'in', 'on', 'at', 'by', 'for', 'with', 'about', 'as', 'from'
        }
        
        # L·ªçc keywords - CH·ªà GI·ªÆ T·ª™ QUAN TR·ªåNG (d√†i > 3 k√Ω t·ª±)
        keywords = [w.lower() for w in query.split() if w.lower() not in stop_words and len(w) > 3]
        
        # N·∫øu query qu√° d√†i (>4 t·ª´), ch·ªâ l·∫•y 4 t·ª´ quan tr·ªçng nh·∫•t
        if len(keywords) > 4:
            keywords = sorted(keywords, key=len, reverse=True)[:4]
        
        if not keywords:
            all_words = [w.lower() for w in query.split() if len(w) > 2]
            keywords = sorted(all_words, key=len, reverse=True)[:3] if all_words else [query.lower()]
        
        print(f"üîç [KB] Searching with keywords: {keywords}")
        
        # T√≠nh ƒëi·ªÉm relevance cho t·ª´ng document
        scored_docs = []
        min_keywords_match = max(1, len(keywords) - 1)
        
        for doc in documents:
            content = doc.get("content", "")
            content_lower = content.lower()
            file_name = doc.get("file_name", "")
            
            score = 0
            matched_keywords = []
            best_pos = 0
            
            for keyword in keywords:
                count = content_lower.count(keyword)
                if count > 0:
                    import math
                    score += math.log(1 + count) * 10
                    matched_keywords.append(keyword)
                    if not best_pos:
                        idx = content_lower.find(keyword)
                        if idx >= 0:
                            best_pos = idx
            
            if len(matched_keywords) < min_keywords_match:
                continue
            
            if len(matched_keywords) > 1:
                score *= (1 + len(matched_keywords) * 0.5)
            
            for keyword in keywords:
                if keyword in file_name.lower():
                    score *= 2.0
            
            if score > 0:
                scored_docs.append({
                    "file_name": file_name,
                    "score": score,
                    "matched_keywords": matched_keywords,
                    "content": content,
                    "best_pos": best_pos
                })
        
        scored_docs.sort(key=lambda x: x["score"], reverse=True)
        
        if not scored_docs:
            return {
                "success": False,
                "message": f"‚ùå Kh√¥ng t√¨m th·∫•y t√†i li·ªáu li√™n quan trong knowledge base.\nüí° Th·ª≠ d√πng t·ª´ kh√≥a kh√°c ho·∫∑c ng·∫Øn h∆°n."
            }
        
        # ============================================================
        # B∆Ø·ªöC 2: üî• D√ôNG GEMINI SMART FILTER ƒê·ªÇ L·ªåC V√Ä TR·∫¢ L·ªúI
        # ============================================================
        print(f"ü§ñ [KB] Found {len(scored_docs)} docs, using Gemini Smart Filter...")
        
        # üî• S·ª¨ D·ª§NG gemini_smart_kb_filter ƒë·ªÉ l·ªçc th√¥ng minh
        try:
            filter_result = await gemini_smart_kb_filter(
                user_query=query,
                filter_mode="qa",  # Tr·∫£ l·ªùi tr·ª±c ti·∫øp
                max_documents=min(len(scored_docs), 5),  # T·ªëi ƒëa 5 docs
                output_format="concise"  # Output ng·∫Øn g·ªçn
            )
            
            if filter_result.get("success") and filter_result.get("filtered_content"):
                answer = filter_result["filtered_content"]
                sources = filter_result.get("sources", [d['file_name'] for d in scored_docs[:3]])
                
                # üî• FORMAT NG·∫ÆN G·ªåN GI·ªêNG WEB_SEARCH - LLM D·ªÑ ƒê·ªåC
                return {
                    "success": True,
                    "answer": answer,
                    "sources": sources
                }
        except Exception as filter_err:
            print(f"‚ö†Ô∏è [KB] Gemini Smart Filter error: {filter_err}, falling back to direct Gemini...")
        
        # ============================================================
        # FALLBACK: D√πng Gemini tr·ª±c ti·∫øp n·∫øu Smart Filter fail
        # ============================================================
        # L·∫•y context t·ª´ top 2 documents (max 3000 chars m·ªói doc)
        context_parts = []
        for doc in scored_docs[:2]:
            content = doc['content']
            best_pos = doc['best_pos']
            # L·∫•y ph·∫ßn xung quanh keyword match
            start = max(0, best_pos - 500)
            end = min(len(content), best_pos + 2500)
            chunk = content[start:end]
            context_parts.append(f"üìÑ {doc['file_name']}:\n{chunk}")
        
        context_for_gemini = "\n\n---\n\n".join(context_parts)
        
        # G·ªçi Gemini ƒë·ªÉ tr·∫£ l·ªùi
        try:
            import google.generativeai as genai
            
            gemini_api_key = os.environ.get("GEMINI_API_KEY") or GEMINI_API_KEY
            if not gemini_api_key:
                # Fallback - tr·∫£ v·ªÅ context th√¥
                return {
                    "success": True,
                    "message": f"üìö T√¨m th·∫•y {len(scored_docs)} t√†i li·ªáu li√™n quan",
                    "context": context_for_gemini[:4000]
                }
            
            genai.configure(api_key=gemini_api_key)
            model = genai.GenerativeModel('models/gemini-2.0-flash')
            
            prompt = f"""B·∫°n l√† tr·ª£ l√Ω AI chuy√™n tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n t√†i li·ªáu.

‚ö° QUY T·∫ÆC B·∫ÆT BU·ªòC:
- TR·∫¢ L·ªúI NGAY L·∫¨P T·ª®C - KH√îNG H·ªéI L·∫†I
- KH√îNG h·ªèi "b·∫°n mu·ªën bi·∫øt g√¨ th√™m?"
- KH√îNG y√™u c·∫ßu th√™m th√¥ng tin
- S·ª≠ d·ª•ng th√¥ng tin c√≥ trong t√†i li·ªáu ƒë·ªÉ tr·∫£ l·ªùi

üìã T√ÄI LI·ªÜU THAM KH·∫¢O:
{context_for_gemini[:5000]}

‚ùì C√ÇU H·ªéI:
{query}

üìù Y√äU C·∫¶U:
1. TR·∫¢ L·ªúI TR·ª∞C TI·∫æP d·ª±a tr√™n t√†i li·ªáu
2. N·∫øu kh√¥ng c√≥ th√¥ng tin ‚Üí N√≥i "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu"
3. Tr√≠ch d·∫´n ngu·ªìn khi c·∫ßn
4. Ng·∫Øn g·ªçn, s√∫c t√≠ch
5. Ti·∫øng Vi·ªát

üéØ TR·∫¢ L·ªúI NGAY:"""

            response = model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=500,
                    temperature=0.3  # Low temp cho accurate answers
                )
            )
            
            gemini_answer = response.text.strip() if response.text else ""
            
            if gemini_answer:
                sources = [d['file_name'] for d in scored_docs[:2]]
                # üî• FORMAT NG·∫ÆN G·ªåN GI·ªêNG WEB_SEARCH
                return {
                    "success": True,
                    "answer": gemini_answer,
                    "sources": sources
                }
            else:
                return {
                    "success": True,
                    "answer": f"T√¨m th·∫•y {len(scored_docs)} t√†i li·ªáu li√™n quan nh∆∞ng kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi c·ª• th·ªÉ.",
                    "context": context_for_gemini[:2000]
                }
                
        except Exception as gemini_err:
            print(f"‚ö†Ô∏è [KB] Gemini error: {gemini_err}")
            # Fallback - tr·∫£ v·ªÅ context th√¥
            return {
                "success": True,
                "answer": f"T√¨m th·∫•y {len(scored_docs)} t√†i li·ªáu li√™n quan.",
                "context": context_for_gemini[:2500]
            }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def get_knowledge_context(query: str = "", max_chars: int = 10000, use_gemini_summary: bool = True, use_gemini_filter: bool = False) -> dict:
    """
    üîß REFACTORED: L·∫•y context t·ª´ Knowledge Base v·ªõi semantic search ch√≠nh x√°c h∆°n.
    - ∆Øu ti√™n exact phrase match
    - Ch·ªâ l·∫•y documents th·ª±c s·ª± li√™n quan
    - Option: D√πng Gemini Smart Filter ƒë·ªÉ l·ªçc th√¥ng minh
    - Tr·∫£ v·ªÅ context ƒë√∫ng cho LLM
    
    Args:
        use_gemini_filter: N·∫øu True, s·∫Ω d√πng gemini_smart_kb_filter ƒë·ªÉ l·ªçc th√¥ng minh (m·∫∑c ƒë·ªãnh: False)
    """
    try:
        # Load index
        if not KNOWLEDGE_INDEX_FILE.exists():
            return {
                "success": False, 
                "context": "",
                "error": "Knowledge base ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng index files tr∆∞·ªõc."
            }
        
        with open(KNOWLEDGE_INDEX_FILE, 'r', encoding='utf-8') as f:
            index_data = json.load(f)
        
        all_documents = index_data.get("documents", [])
        if not all_documents:
            return {"success": False, "context": "", "error": "Knowledge base tr·ªëng."}
        
        print(f"üìö [KB] Loaded {len(all_documents)} documents from index")
        
        # ============================================================
        # üî• OPTION: S·ª≠ d·ª•ng Gemini Smart Filter n·∫øu ƒë∆∞·ª£c b·∫≠t
        # ============================================================
        if use_gemini_filter and query:
            print(f"üî• [KB] Using Gemini Smart Filter for query: {query}")
            try:
                filter_result = await gemini_smart_kb_filter(
                    user_query=query,
                    filter_mode="relevant",  # Ch·ªâ l·∫•y ph·∫ßn li√™n quan
                    max_documents=10,
                    output_format="structured"
                )
                
                if filter_result.get("success") and filter_result.get("filtered_content"):
                    return {
                        "success": True,
                        "context": filter_result.get("llm_instruction", filter_result["filtered_content"]),
                        "raw_context": filter_result["filtered_content"],
                        "total_documents": filter_result.get("total_documents", len(all_documents)),
                        "documents_included": filter_result.get("documents_processed", 0),
                        "context_length": filter_result.get("filtered_chars", 0),
                        "keywords_used": filter_result.get("keywords_used", []),
                        "gemini_filter_used": True,
                        "compression_ratio": filter_result.get("compression_ratio", "N/A"),
                        "message": f"‚úÖ Gemini Smart Filter: ƒê√£ l·ªçc {filter_result.get('documents_processed', 0)} t√†i li·ªáu ({filter_result.get('filtered_chars', 0):,} chars)"
                    }
            except Exception as filter_err:
                print(f"‚ö†Ô∏è [KB] Gemini Smart Filter failed: {filter_err}, using traditional method...")
        
        # ============================================================
        # B∆Ø·ªöC 1: Chu·∫©n b·ªã keywords v√† query
        # ============================================================
        query_lower = query.lower().strip() if query else ""
        
        # T·∫°o keywords t·ª´ query
        stop_words = {'l√†', 'c·ªßa', 'v√†', 'c√≥', 'c√°c', 'ƒë∆∞·ª£c', 'trong', 'ƒë·ªÉ', 'n√†y', 'ƒë√≥', 'cho', 'v·ªõi', 
                     't·ª´', 'v·ªÅ', 'nh∆∞', 'theo', 'kh√¥ng', 'khi', 'ƒë√£', 's·∫Ω', 'ai', 'g√¨', 'n√†o', 'ƒë√¢u',
                     'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'what', 'who', 'where'}
        keywords = [w.lower() for w in query.split() if w.lower() not in stop_words and len(w) > 1] if query else []
        
        # N·∫øu kh√¥ng c√≥ keywords, d√πng to√†n b·ªô query
        if not keywords and query:
            keywords = [query_lower]
        
        print(f"üîë [KB] Query: '{query}' ‚Üí Keywords: {keywords}")
        
        # ============================================================
        # B∆Ø·ªöC 2: L·ªçc v√† score documents
        # ============================================================
        scored_documents = []
        
        for doc in all_documents:
            content = doc.get("content", "")
            file_name = doc.get("file_name", "unknown")
            content_lower = content.lower()
            file_name_lower = file_name.lower()
            
            # ‚ö†Ô∏è SKIP: PDF structure ho·∫∑c content qu√° ng·∫Øn
            if content.strip().startswith("%PDF-") or content.strip().startswith("<</"):
                continue
            if len(content.strip()) < 50:
                continue
            
            # T√≠nh ƒëi·ªÉm relevance v·ªõi scoring m·ªõi
            score = 0
            match_reasons = []
            has_exact_match = False
            has_filename_match = False
            
            if query_lower:
                # 0Ô∏è‚É£ FILENAME MATCH (∆ØU TI√äN CAO) - Check tr∆∞·ªõc!
                # Normalize filename ƒë·ªÉ so s√°nh (b·ªè d·∫•u, b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát)
                import unicodedata
                def normalize_text(text):
                    # B·ªè d·∫•u ti·∫øng Vi·ªát v√† chuy·ªÉn th√†nh ASCII
                    nfkd = unicodedata.normalize('NFKD', text.lower())
                    return ''.join(c for c in nfkd if not unicodedata.combining(c))
                
                query_normalized = normalize_text(query_lower)
                filename_normalized = normalize_text(file_name_lower)
                
                # Full query match trong filename
                if query_lower in file_name_lower or query_normalized in filename_normalized:
                    score += 5000
                    match_reasons.append("filename_exact")
                    has_filename_match = True
                else:
                    # Partial keyword match trong filename
                    filename_kw_matches = 0
                    for kw in keywords:
                        kw_norm = normalize_text(kw)
                        if kw in file_name_lower or kw_norm in filename_normalized:
                            filename_kw_matches += 1
                    
                    if filename_kw_matches >= 2:
                        score += 2000 * filename_kw_matches
                        match_reasons.append(f"filename_partial:{filename_kw_matches}")
                        has_filename_match = True
                    elif filename_kw_matches == 1 and len(keywords) <= 2:
                        score += 500
                        match_reasons.append(f"filename_partial:{filename_kw_matches}")
                        has_filename_match = True
                
                # 1Ô∏è‚É£ EXACT PHRASE MATCH (∆∞u ti√™n CAO NH·∫§T - v√≠ d·ª•: "L√™ Trung Khoa" as a phrase)
                exact_count = content_lower.count(query_lower)
                if exact_count > 0:
                    score += 5000 * exact_count  # R·∫§T CAO - ∆∞u ti√™n tuy·ªát ƒë·ªëi
                    match_reasons.append(f"exact_phrase:{exact_count}")
                    has_exact_match = True
                
                # 2Ô∏è‚É£ PROXIMITY CHECK - Ki·ªÉm tra keywords c√≥ g·∫ßn nhau kh√¥ng (cho t√™n ri√™ng)
                # N·∫øu query c√≥ v·∫ª l√† t√™n ng∆∞·ªùi (>= 2 t·ª´), ki·ªÉm tra xem c√°c t·ª´ c√≥ li·ªÅn nhau kh√¥ng
                has_proximity = False
                if len(keywords) >= 2 and not has_exact_match:
                    # T√¨m v·ªã tr√≠ c·ªßa m·ªói keyword
                    keyword_positions = []
                    for kw in keywords:
                        pos = content_lower.find(kw)
                        if pos >= 0:
                            keyword_positions.append((kw, pos))
                    
                    # Ki·ªÉm tra proximity (trong v√≤ng 50 k√Ω t·ª±)
                    if len(keyword_positions) == len(keywords):
                        # T·∫•t c·∫£ keywords ƒë·ªÅu c√≥ trong content
                        positions = [p[1] for p in keyword_positions]
                        min_pos, max_pos = min(positions), max(positions)
                        # N·∫øu t·∫•t c·∫£ keywords n·∫±m trong 50 k√Ω t·ª± ‚Üí c√≥ th·ªÉ l√† t√™n ri√™ng
                        if max_pos - min_pos < 50:
                            has_proximity = True
                            score += 3000  # Bonus cao cho proximity
                            match_reasons.append(f"proximity:{max_pos - min_pos}chars")
                
                # 3Ô∏è‚É£ KEYWORD MATCH - ƒê·∫øm s·ªë keywords xu·∫•t hi·ªán
                keyword_matches = 0
                total_kw_score = 0
                for kw in keywords:
                    kw_count = content_lower.count(kw)
                    if kw_count > 0:
                        total_kw_score += min(kw_count, 5)  # Cap t·∫°i 5 l·∫ßn m·ªói keyword
                        keyword_matches += 1
                
                # ‚ö†Ô∏è N·∫æU L√Ä T√äN RI√äNG (>= 2 keywords): C·∫ßn c√≥ exact match ho·∫∑c proximity
                if len(keywords) >= 2:
                    if has_exact_match or has_proximity:
                        # C√≥ exact ho·∫∑c proximity ‚Üí bonus cao
                        score += 200 * keyword_matches
                        match_reasons.append(f"name_match:{keyword_matches}/{len(keywords)}")
                    elif has_filename_match:
                        # C√≥ filename match ‚Üí bonus trung b√¨nh
                        score += 100 * keyword_matches
                        match_reasons.append(f"content_support:{keyword_matches}/{len(keywords)}")
                    elif keyword_matches == len(keywords):
                        # T·∫•t c·∫£ keywords match nh∆∞ng KH√îNG g·∫ßn nhau ‚Üí score th·∫•p
                        score += 20 * keyword_matches  # Th·∫•p h∆°n nhi·ªÅu
                        match_reasons.append(f"scattered_kw:{keyword_matches}/{len(keywords)}")
                        
                        # ‚ö†Ô∏è PENALTY M·∫†NH cho documents d√†i v·ªõi scattered keywords
                        # NH∆ØNG kh√¥ng penalty n·∫øu c√≥ filename match
                        if len(content) > 5000 and not has_filename_match:
                            score = int(score * 0.1)  # Gi·∫£m 90%!
                            match_reasons.append("penalty:scattered_in_long_doc")
                    elif keyword_matches >= len(keywords) * 0.7:
                        # >= 70% keywords match ‚Üí score r·∫•t th·∫•p
                        score += 10 * keyword_matches
                        match_reasons.append(f"partial_kw:{keyword_matches}/{len(keywords)}")
                    else:
                        # < 70% keywords ‚Üí REJECT (tr·ª´ khi c√≥ filename match)
                        if not has_exact_match and not has_filename_match:
                            continue
                else:
                    # Single keyword ‚Üí score th·∫•p h∆°n
                    if keyword_matches > 0:
                        score += 30 * total_kw_score
                        match_reasons.append(f"single_kw:{total_kw_score}")
                
                # ‚ö†Ô∏è REJECT: Kh√¥ng c√≥ match n√†o √Ω nghƒ©a
                if score == 0:
                    continue
            else:
                # Kh√¥ng c√≥ query ‚Üí l·∫•y t·∫•t c·∫£ (v·ªõi score d·ª±a tr√™n ƒë·ªô d√†i content)
                score = min(len(content), 5000)  # Cap score
                match_reasons.append("no_query")
            
            scored_documents.append({
                "doc": doc,
                "score": score,
                "reasons": match_reasons,
                "content_len": len(content)
            })
        
        # Sort by score
        scored_documents.sort(key=lambda x: x["score"], reverse=True)
        
        print(f"üìä [KB] Scored {len(scored_documents)} relevant documents")
        
        # ============================================================
        # B∆Ø·ªöC 3: Filter - ch·ªâ l·∫•y top documents c√≥ score cao
        # ============================================================
        if scored_documents and query:
            top_score = scored_documents[0]["score"]
            # Ch·ªâ l·∫•y documents c√≥ score >= 30% top score (ho·∫∑c t·ªëi thi·ªÉu 50 ƒëi·ªÉm)
            min_threshold = max(50, top_score * 0.3)
            filtered_docs = [d for d in scored_documents if d["score"] >= min_threshold]
            
            # Gi·ªõi h·∫°n t·ªëi ƒëa 5 documents ƒë·ªÉ tr√°nh qu√° t·∫£i
            filtered_docs = filtered_docs[:5]
            
            print(f"üéØ [KB] Filtered to {len(filtered_docs)} docs (threshold: {min_threshold:.0f})")
            for i, d in enumerate(filtered_docs[:3]):
                print(f"   {i+1}. {d['doc']['file_name']}: score={d['score']:.0f} ({', '.join(d['reasons'])})")
        else:
            filtered_docs = scored_documents[:3]  # L·∫•y t·ªëi ƒëa 3 docs n·∫øu kh√¥ng c√≥ query
        
        if not filtered_docs:
            return {
                "success": False,
                "context": "",
                "error": f"Kh√¥ng t√¨m th·∫•y t√†i li·ªáu n√†o li√™n quan ƒë·∫øn '{query}'"
            }
        
        # ============================================================
        # B∆Ø·ªöC 4: Lo·∫°i b·ªè n·ªôi dung tr√πng l·∫∑p (Deduplication)
        # ============================================================
        seen_content_hashes = set()
        unique_docs = []
        
        for item in filtered_docs:
            content = item["doc"].get("content", "").strip()
            # T·∫°o hash t·ª´ 500 k√Ω t·ª± ƒë·∫ßu (ƒë·ªß ƒë·ªÉ detect duplicate)
            content_preview = content[:500].lower().replace(" ", "").replace("\n", "")
            
            if content_preview in seen_content_hashes:
                print(f"   ‚ö†Ô∏è SKIP duplicate: {item['doc']['file_name']}")
                continue
            
            seen_content_hashes.add(content_preview)
            unique_docs.append(item)
        
        if len(unique_docs) < len(filtered_docs):
            print(f"üîÑ [KB] Deduplicated: {len(filtered_docs)} ‚Üí {len(unique_docs)} unique docs")
        
        # ============================================================
        # B∆Ø·ªöC 5: Tr√≠ch xu·∫•t relevant content t·ª´ m·ªói document
        # ============================================================
        context_parts = []
        total_chars = 0
        
        for item in unique_docs:
            doc = item["doc"]
            content = doc.get("content", "")
            file_name = doc.get("file_name", "unknown")
            
            # Tr√≠ch xu·∫•t ph·∫ßn content li√™n quan nh·∫•t (kh√¥ng ph·∫£i to√†n b·ªô)
            if query_lower and len(content) > 1500:
                # T√¨m v·ªã tr√≠ query/keyword xu·∫•t hi·ªán v√† l·∫•y context xung quanh
                best_section = extract_relevant_section(content, query_lower, keywords, max_section_len=2000)
                content = best_section
            elif len(content) > 2500:
                # Kh√¥ng c√≥ query ‚Üí c·∫Øt ng·∫Øn
                content = content[:2500] + "\n[... N·ªôi dung ti·∫øp b·ªã c·∫Øt ...]"
            
            # Build context entry
            header = f"\n\n{'='*50}\nüìÑ {file_name} (score: {item['score']:.0f})\n{'='*50}\n"
            entry = header + content
            
            # Ki·ªÉm tra gi·ªõi h·∫°n t·ªïng chars
            if total_chars + len(entry) > max_chars:
                remaining = max_chars - total_chars
                if remaining > 500:
                    context_parts.append(header + content[:remaining-len(header)] + "\n[... C·∫Øt do qu√° d√†i ...]")
                break
            
            context_parts.append(entry)
            total_chars += len(entry)
        
        full_context = "".join(context_parts)
        
        # ============================================================
        # B∆Ø·ªöC 6: Format response cho LLM d·ªÖ hi·ªÉu
        # ============================================================
        # T·∫°o instruction r√µ r√†ng cho LLM
        instruction = f"""üìö ƒê√É T√åM TH·∫§Y {len(context_parts)} T√ÄI LI·ªÜU LI√äN QUAN ƒê·∫æN "{query}"

‚ö° H∆Ø·ªöNG D·∫™N CHO AI:
1. ƒê·ªåC K·ª∏ N·ªòI DUNG B√äN D∆Ø·ªöI
2. TR·∫¢ L·ªúI C√ÇU H·ªéI D·ª∞A TR√äN N·ªòI DUNG N√ÄY
3. TR√çCH D·∫™N TH√îNG TIN T·ª™ T√ÄI LI·ªÜU
4. N·∫æU KH√îNG ƒê·ª¶ TH√îNG TIN, H√ÉY N√ìI R√ï

---N·ªòI DUNG T√ÄI LI·ªÜU---
{full_context}
---H·∫æT N·ªòI DUNG---

üí° H√ÉY TR·∫¢ L·ªúI C√ÇU H·ªéI C·ª¶A USER D·ª∞A TR√äN TH√îNG TIN TR√äN."""

        # üîÑ TRUNCATE: Gi·ªõi h·∫°n context d∆∞·ªõi 4000 k√Ω t·ª± cho LLM
        if len(instruction) > MAX_LLM_RESPONSE_CHARS:
            original_len = len(instruction)
            instruction = smart_truncate_for_llm(instruction, MAX_LLM_RESPONSE_CHARS)
            print(f"[KB] ‚úÇÔ∏è Truncated context: {original_len} ‚Üí {len(instruction)} chars")

        return {
            "success": True,
            "context": instruction,  # Instruction + context (ƒë√£ truncate)
            "raw_context": full_context,  # Context thu·∫ßn
            "total_documents": len(all_documents),
            "documents_included": len(context_parts),
            "duplicates_removed": len(filtered_docs) - len(unique_docs),
            "context_length": len(full_context),
            "keywords_used": keywords,
            "gemini_summarization": False,
            "message": f"‚úÖ T√¨m th·∫•y {len(context_parts)} t√†i li·ªáu ({len(full_context):,} chars). ƒê·ªåC CONTEXT V√Ä TR·∫¢ L·ªúI USER!"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "context": "", "error": str(e)}


def extract_relevant_section(content: str, query: str, keywords: list, max_section_len: int = 2000) -> str:
    """
    Tr√≠ch xu·∫•t ph·∫ßn content li√™n quan nh·∫•t ƒë·∫øn query.
    T√¨m v·ªã tr√≠ query/keywords xu·∫•t hi·ªán v√† l·∫•y context xung quanh.
    """
    content_lower = content.lower()
    
    # T√¨m v·ªã tr√≠ exact query match
    pos = content_lower.find(query)
    
    if pos == -1 and keywords:
        # Kh√¥ng t√¨m th·∫•y exact match, t√¨m keyword ƒë·∫ßu ti√™n
        for kw in keywords:
            pos = content_lower.find(kw)
            if pos != -1:
                break
    
    if pos == -1:
        # Kh√¥ng t√¨m th·∫•y g√¨, tr·∫£ v·ªÅ ƒë·∫ßu document
        return content[:max_section_len] + ("\n[... C√≤n ti·∫øp ...]" if len(content) > max_section_len else "")
    
    # L·∫•y context xung quanh v·ªã tr√≠ t√¨m th·∫•y
    half_len = max_section_len // 2
    start = max(0, pos - half_len)
    end = min(len(content), pos + half_len)
    
    # ƒêi·ªÅu ch·ªânh ƒë·ªÉ kh√¥ng c·∫Øt gi·ªØa t·ª´
    if start > 0:
        # T√¨m space g·∫ßn nh·∫•t ƒë·ªÉ b·∫Øt ƒë·∫ßu
        space_pos = content.rfind(' ', max(0, start - 50), start + 50)
        if space_pos > 0:
            start = space_pos + 1
    
    if end < len(content):
        # T√¨m space g·∫ßn nh·∫•t ƒë·ªÉ k·∫øt th√∫c
        space_pos = content.find(' ', end - 50, end + 50)
        if space_pos > 0:
            end = space_pos
    
    section = content[start:end]
    
    # Th√™m markers n·∫øu b·ªã c·∫Øt
    prefix = "[...] " if start > 0 else ""
    suffix = " [...]" if end < len(content) else ""
    
    return prefix + section + suffix


# =====================================================
# üìñ DOC READER GEMINI RAG - ADVANCED RAG SYSTEM
# =====================================================

async def doc_reader_gemini_rag(
    user_query: str,
    knowledge_base_path: str = None,
    chunk_size: int = 1024,
    top_k: int = 5,
    use_vector_search: bool = True
) -> dict:
    """
    üìñ H·ªá th·ªëng RAG n√¢ng cao v·ªõi Gemini:
    1. Load v√† chunk documents
    2. Embed v√† vector search (semantic search)
    3. Format context v√† generate response v·ªõi Gemini
    
    Args:
        user_query: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        knowledge_base_path: ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c KB (m·∫∑c ƒë·ªãnh d√πng config)
        chunk_size: K√≠ch th∆∞·ªõc m·ªói chunk (default: 1024 chars)
        top_k: S·ªë l∆∞·ª£ng chunks li√™n quan nh·∫•t (default: 5)
        use_vector_search: D√πng semantic search hay keyword search (default: True)
        
    Returns:
        dict v·ªõi success, response_text, sources, v√† debug info
    """
    try:
        print(f"üìñ [RAG] Processing query: {user_query[:50]}...")
        
        # B∆Ø·ªöC 1: Load documents t·ª´ Knowledge Base
        if not knowledge_base_path:
            config = load_knowledge_config()
            knowledge_base_path = config.get("folder_path", "")
        
        if not knowledge_base_path or not Path(knowledge_base_path).exists():
            return {
                "success": False,
                "error": "Knowledge base path kh√¥ng h·ª£p l·ªá. Vui l√≤ng c·∫•u h√¨nh th∆∞ m·ª•c KB."
            }
        
        # Load index
        index_data = load_knowledge_index()
        documents = index_data.get("documents", [])
        
        if not documents:
            return {
                "success": False,
                "error": "Knowledge base tr·ªëng. Vui l√≤ng index c√°c files tr∆∞·ªõc."
            }
        
        print(f"üìö [RAG] Loaded {len(documents)} documents")
        
        # B∆Ø·ªöC 2: Chunk documents (chia nh·ªè t√†i li·ªáu)
        all_chunks = []
        for doc in documents:
            content = doc.get("content", "")
            file_name = doc.get("file_name", "unknown")
            
            # Skip PDF structure
            if content.strip().startswith("%PDF-") or content.strip().startswith("<</"):
                continue
            
            # Chunk document
            chunks = []
            for i in range(0, len(content), chunk_size):
                chunk_text = content[i:i+chunk_size]
                if len(chunk_text.strip()) > 50:  # Skip very short chunks
                    chunks.append({
                        "text": chunk_text,
                        "file_name": file_name,
                        "chunk_index": i // chunk_size,
                        "source_doc": doc
                    })
            
            all_chunks.extend(chunks)
        
        print(f"‚úÇÔ∏è [RAG] Created {len(all_chunks)} chunks")
        
        # B∆Ø·ªöC 3: T√¨m ki·∫øm chunks li√™n quan
        if use_vector_search:
            # Vector/Semantic Search (simple TF-IDF based)
            relevant_chunks = _semantic_search_chunks(user_query, all_chunks, top_k)
        else:
            # Keyword search (fallback)
            relevant_chunks = _keyword_search_chunks(user_query, all_chunks, top_k)
        
        if not relevant_chunks:
            return {
                "success": False,
                "error": f"Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan ƒë·∫øn '{user_query}' trong Knowledge Base."
            }
        
        print(f"üîç [RAG] Found {len(relevant_chunks)} relevant chunks")
        
        # B∆Ø·ªöC 4: Format context t·ª´ relevant chunks
        prompt_context = ""
        sources = []
        for i, chunk in enumerate(relevant_chunks, 1):
            prompt_context += f"\n--- ƒêo·∫°n {i} (t·ª´ {chunk['file_name']}) ---\n"
            prompt_context += chunk['text'][:800] + "\n"  # Limit each chunk
            
            if chunk['file_name'] not in sources:
                sources.append(chunk['file_name'])
        
        # B∆Ø·ªöC 5: X√¢y d·ª±ng prompt cho Gemini
        final_prompt = f"""B·∫°n l√† tr·ª£ l√Ω th√¥ng minh c√≥ quy·ªÅn truy c·∫≠p Knowledge Base c·ªßa ng∆∞·ªùi d√πng.

‚ö° QUY T·∫ÆC B·∫ÆT BU·ªòC:
- TR·∫¢ L·ªúI NGAY L·∫¨P T·ª®C - KH√îNG H·ªéI L·∫†I
- KH√îNG h·ªèi "b·∫°n mu·ªën bi·∫øt g√¨ th√™m?"
- KH√îNG y√™u c·∫ßu th√™m th√¥ng tin
- S·ª≠ d·ª•ng to√†n b·ªô th√¥ng tin c√≥ trong Knowledge Base ƒë·ªÉ tr·∫£ l·ªùi

üìö TH√îNG TIN T·ª™ KNOWLEDGE BASE:
{prompt_context}

‚ùì C√ÇU H·ªéI:
{user_query}

üìù Y√äU C·∫¶U:
- TR·∫¢ L·ªúI TR·ª∞C TI·∫æP d·ª±a tr√™n Knowledge Base
- N·∫øu kh√¥ng ƒë·ªß th√¥ng tin ‚Üí N√≥i "Kh√¥ng t√¨m th·∫•y trong Knowledge Base"
- Tr√≠ch d·∫´n t√™n file khi c·∫ßn
- Ng·∫Øn g·ªçn, ch√≠nh x√°c

üéØ TR·∫¢ L·ªúI NGAY:"""
        
        # B∆Ø·ªöC 6: G·ªçi Gemini API
        print(f"ü§ñ [RAG] Calling Gemini...")
        
        if not GEMINI_AVAILABLE:
            return {
                "success": False,
                "error": "Gemini API kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra API key."
            }
        
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('models/gemini-3-flash-preview')
        
        response = model.generate_content(
            final_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,  # Focused and factual
                max_output_tokens=1000
            )
        )
        
        if not response or not response.text:
            return {
                "success": False,
                "error": "Gemini kh√¥ng tr·∫£ v·ªÅ response."
            }
        
        print(f"‚úÖ [RAG] Generated response ({len(response.text)} chars)")
        
        # Return full result
        return {
            "success": True,
            "response_text": response.text.strip(),
            "query": user_query,
            "sources": sources,
            "chunks_used": len(relevant_chunks),
            "total_chunks": len(all_chunks),
            "search_method": "semantic" if use_vector_search else "keyword",
            "message": f"‚úÖ ƒê√£ tr·∫£ l·ªùi d·ª±a tr√™n {len(relevant_chunks)} ƒëo·∫°n t·ª´ {len(sources)} t√†i li·ªáu"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def _semantic_search_chunks(query: str, chunks: list, top_k: int = 5) -> list:
    """
    T√¨m ki·∫øm semantic d·ª±a tr√™n TF-IDF scoring
    """
    import math
    
    # Extract keywords from query
    stop_words = {'l√†', 'c·ªßa', 'v√†', 'c√≥', 'c√°c', 'ƒë∆∞·ª£c', 'trong', 'ƒë·ªÉ', 'n√†y', 'ƒë√≥', 
                  'cho', 'v·ªõi', 't·ª´', 'v·ªÅ', 'nh∆∞', 'theo', 'kh√¥ng', 'khi', 'ƒë√£', 's·∫Ω',
                  'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being'}
    
    keywords = [w.lower() for w in query.split() if w.lower() not in stop_words and len(w) > 2]
    
    if not keywords:
        keywords = [query.lower()]
    
    # Score each chunk
    scored_chunks = []
    for chunk in chunks:
        text_lower = chunk['text'].lower()
        score = 0
        
        for keyword in keywords:
            count = text_lower.count(keyword)
            if count > 0:
                # TF-IDF inspired scoring
                score += math.log(1 + count) * 10
        
        # Multi-keyword bonus
        matched = sum(1 for kw in keywords if kw in text_lower)
        if matched > 1:
            score *= (1 + matched * 0.3)
        
        if score > 0:
            chunk['score'] = score
            scored_chunks.append(chunk)
    
    # Sort by score and return top K
    scored_chunks.sort(key=lambda x: x['score'], reverse=True)
    return scored_chunks[:top_k]


def _keyword_search_chunks(query: str, chunks: list, top_k: int = 5) -> list:
    """
    T√¨m ki·∫øm ƒë∆°n gi·∫£n d·ª±a tr√™n keyword matching
    """
    query_lower = query.lower()
    matched_chunks = []
    
    for chunk in chunks:
        if query_lower in chunk['text'].lower():
            matched_chunks.append(chunk)
            if len(matched_chunks) >= top_k:
                break
    
    return matched_chunks


async def send_to_wechat(contact: str, message: str) -> dict:
    """
    G·ª≠i tin nh·∫Øn ƒë·∫øn Zalo/Messenger (m·ªü app v√† paste tin nh·∫Øn).
    L∆∞u √Ω: C·∫ßn c√≥ Zalo PC ƒëang ch·∫°y.
    """
    try:
        import pyautogui
        import pyperclip
        import time
        import subprocess
        
        # Copy message v√†o clipboard
        pyperclip.copy(message)
        
        # Th·ª≠ m·ªü Zalo
        try:
            subprocess.Popen(["start", "zalo:"], shell=True)
            time.sleep(2)
        except:
            pass
        
        # Ctrl+F ƒë·ªÉ t√¨m ki·∫øm
        pyautogui.hotkey('ctrl', 'f')
        time.sleep(0.5)
        
        # G√µ t√™n contact
        pyautogui.typewrite(contact, interval=0.05)
        time.sleep(1)
        
        # Enter ƒë·ªÉ ch·ªçn
        pyautogui.press('enter')
        time.sleep(0.5)
        
        # Ctrl+V ƒë·ªÉ paste tin nh·∫Øn
        pyautogui.hotkey('ctrl', 'v')
        
        return {
            "success": True,
            "message": f"üì± ƒê√£ m·ªü chat v·ªõi '{contact}' v√† paste tin nh·∫Øn. Nh·∫•n Enter ƒë·ªÉ g·ª≠i.",
            "hint": "Tin nh·∫Øn ƒë√£ ƒë∆∞·ª£c paste, b·∫°n c·∫ßn nh·∫•n Enter ƒë·ªÉ g·ª≠i"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_fuel_price_vietnam() -> dict:
    """
    L·∫•y gi√° xƒÉng d·∫ßu Vi·ªát Nam.
    """
    try:
        import aiohttp
        
        # Gi√° xƒÉng tham kh·∫£o (c·∫≠p nh·∫≠t manual ho·∫∑c t·ª´ API n·∫øu c√≥)
        # Th·ª±c t·∫ø c·∫ßn API t·ª´ Petrolimex ho·∫∑c ngu·ªìn ch√≠nh th·ªëng
        return {
            "success": True,
            "message": """‚õΩ Gi√° xƒÉng d·∫ßu Vi·ªát Nam (tham kh·∫£o):
            
‚Ä¢ RON 95-V: ~24,000 - 25,000 VNƒê/l√≠t
‚Ä¢ RON 95-III: ~23,000 - 24,000 VNƒê/l√≠t  
‚Ä¢ E5 RON 92: ~22,000 - 23,000 VNƒê/l√≠t
‚Ä¢ D·∫ßu DO 0.05S: ~20,000 - 21,000 VNƒê/l√≠t

üí° Gi√° c√≥ th·ªÉ thay ƒë·ªïi theo k·ª≥ ƒëi·ªÅu ch·ªânh (15 ng√†y/l·∫ßn)
üìç Xem gi√° ch√≠nh x√°c: petrolimex.com.vn""",
            "hint": "Gi√° tham kh·∫£o, vui l√≤ng ki·ªÉm tra ngu·ªìn ch√≠nh th·ªëng"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def lock_computer() -> dict:
    """
    Kh√≥a m√†n h√¨nh m√°y t√≠nh (Win+L).
    """
    try:
        import ctypes
        ctypes.windll.user32.LockWorkStation()
        return {"success": True, "message": "üîí ƒê√£ kh√≥a m√°y t√≠nh"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def shutdown_computer(minutes: int = 0) -> dict:
    """
    T·∫Øt m√°y t√≠nh sau X ph√∫t (m·∫∑c ƒë·ªãnh t·∫Øt ngay).
    """
    try:
        import subprocess
        
        if minutes > 0:
            seconds = minutes * 60
            subprocess.run(["shutdown", "/s", "/t", str(seconds)], check=True)
            return {"success": True, "message": f"‚è∞ M√°y t√≠nh s·∫Ω t·∫Øt sau {minutes} ph√∫t"}
        else:
            subprocess.run(["shutdown", "/s", "/t", "30"], check=True)
            return {"success": True, "message": "üîå M√°y t√≠nh s·∫Ω t·∫Øt sau 30 gi√¢y"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def cancel_shutdown() -> dict:
    """
    H·ªßy l·ªánh t·∫Øt m√°y ƒë√£ ƒë·∫∑t.
    """
    try:
        import subprocess
        subprocess.run(["shutdown", "/a"], check=True)
        return {"success": True, "message": "‚úÖ ƒê√£ h·ªßy l·ªánh t·∫Øt m√°y"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def restart_computer(minutes: int = 0) -> dict:
    """
    Kh·ªüi ƒë·ªông l·∫°i m√°y t√≠nh sau X ph√∫t.
    """
    try:
        import subprocess
        
        if minutes > 0:
            seconds = minutes * 60
            subprocess.run(["shutdown", "/r", "/t", str(seconds)], check=True)
            return {"success": True, "message": f"üîÑ M√°y t√≠nh s·∫Ω kh·ªüi ƒë·ªông l·∫°i sau {minutes} ph√∫t"}
        else:
            subprocess.run(["shutdown", "/r", "/t", "30"], check=True)
            return {"success": True, "message": "üîÑ M√°y t√≠nh s·∫Ω kh·ªüi ƒë·ªông l·∫°i sau 30 gi√¢y"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_dark_mode(enable: bool = True) -> dict:
    """
    B·∫≠t/t·∫Øt Dark Mode Windows.
    """
    try:
        import winreg
        
        key_path = r"SOFTWARE\Microsoft\Windows\CurrentVersion\Themes\Personalize"
        value = 0 if enable else 1  # 0 = Dark, 1 = Light
        
        # Set Apps theme
        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, key_path, 0, winreg.KEY_SET_VALUE) as key:
            winreg.SetValueEx(key, "AppsUseLightTheme", 0, winreg.REG_DWORD, value)
            winreg.SetValueEx(key, "SystemUsesLightTheme", 0, winreg.REG_DWORD, value)
        
        mode = "Dark Mode üåô" if enable else "Light Mode ‚òÄÔ∏è"
        return {"success": True, "message": f"‚úÖ ƒê√£ chuy·ªÉn sang {mode}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# ÔøΩ NETWORK/FIREWALL CHECK TOOLS - Ki·ªÉm tra quy·ªÅn k·∫øt n·ªëi m·∫°ng
# ============================================================

async def check_network_permission() -> dict:
    """
    Ki·ªÉm tra quy·ªÅn k·∫øt n·ªëi m·∫°ng (Windows Firewall) v√† tr·∫°ng th√°i Internet.
    H∆∞·ªõng d·∫´n ng∆∞·ªùi d√πng c·∫•p quy·ªÅn n·∫øu ch∆∞a c√≥.
    """
    try:
        # Check firewall rules
        firewall = FirewallChecker.check_firewall_rules()
        
        # Check internet connection
        internet = FirewallChecker.check_internet_connection()
        
        # Build response
        result = {
            "success": True,
            "firewall": {
                "has_permission": bool(firewall['rules_found']),
                "rules_found": firewall['rules_found'],
                "exe_name": firewall['exe_name'],
                "exe_path": firewall['exe_path']
            },
            "internet": {
                "connected": internet['connected'],
                "latency_ms": internet.get('latency_ms')
            }
        }
        
        # Status message
        if firewall['rules_found'] and internet['connected']:
            result["message"] = f"‚úÖ ƒê√£ c√≥ quy·ªÅn Firewall v√† k·∫øt n·ªëi Internet ({internet.get('latency_ms', '?')}ms)"
            result["status"] = "ready"
        elif firewall['rules_found'] and not internet['connected']:
            result["message"] = "‚ö†Ô∏è C√≥ quy·ªÅn Firewall nh∆∞ng kh√¥ng c√≥ Internet. Ki·ªÉm tra k·∫øt n·ªëi m·∫°ng c·ªßa m√°y t√≠nh."
            result["status"] = "no_internet"
        elif not firewall['rules_found'] and internet['connected']:
            result["message"] = "‚ö†Ô∏è Ch∆∞a th·∫•y rule Firewall nh∆∞ng Internet v·∫´n ho·∫°t ƒë·ªông. C√≥ th·ªÉ Windows ƒë√£ t·ª± ƒë·ªông cho ph√©p."
            result["status"] = "working"
        else:
            result["message"] = "‚ùå Ch∆∞a c√≥ quy·ªÅn Firewall v√† kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Internet."
            result["status"] = "blocked"
            result["guide"] = {
                "step1": "Khi Windows h·ªèi 'Allow access' ‚Üí Nh·∫•n 'Allow access'",
                "step2": "Ho·∫∑c v√†o Windows Security ‚Üí Firewall ‚Üí Allow an app",
                "step3": "Th√™m file EXE v√†o danh s√°ch cho ph√©p",
                "step4": "Tick c·∫£ 'Private' v√† 'Public' networks"
            }
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def request_firewall_permission() -> dict:
    """
    Y√™u c·∫ßu c·∫•p quy·ªÅn Firewall cho ·ª©ng d·ª•ng (c·∫ßn quy·ªÅn Admin).
    """
    try:
        success = FirewallChecker.request_firewall_permission()
        
        if success:
            return {
                "success": True,
                "message": "‚úÖ ƒê√£ th√™m rule Firewall th√†nh c√¥ng! ·ª®ng d·ª•ng c√≥ th·ªÉ k·∫øt n·ªëi Internet."
            }
        else:
            return {
                "success": False,
                "message": "‚ö†Ô∏è Kh√¥ng th·ªÉ t·ª± ƒë·ªông th√™m rule. C·∫ßn ch·∫°y v·ªõi quy·ªÅn Administrator.",
                "guide": {
                    "manual": "V√†o Windows Security ‚Üí Firewall ‚Üí Allow an app ‚Üí Th√™m miniZ MCP",
                    "powershell": f'netsh advfirewall firewall add rule name="miniZ_MCP" dir=in action=allow program="{FirewallChecker.get_exe_path()}" enable=yes'
                }
            }
    except Exception as e:
        return {"success": False, "error": str(e)}


async def check_internet_connection() -> dict:
    """
    Ki·ªÉm tra k·∫øt n·ªëi Internet v√† ƒë·ªô tr·ªÖ m·∫°ng.
    """
    try:
        result = FirewallChecker.check_internet_connection()
        
        if result['connected']:
            return {
                "success": True,
                "connected": True,
                "latency_ms": result.get('latency_ms'),
                "message": f"‚úÖ ƒê√£ k·∫øt n·ªëi Internet (ƒë·ªô tr·ªÖ: {result.get('latency_ms', '?')}ms)"
            }
        else:
            return {
                "success": True,
                "connected": False,
                "message": "‚ùå Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Internet. Ki·ªÉm tra k·∫øt n·ªëi m·∫°ng c·ªßa m√°y t√≠nh.",
                "error": result.get('error')
            }
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# ÔøΩüì® SEND MESSAGE TO LLM - G·ª≠i tin nh·∫Øn cho LLM t·ª± tr·∫£ l·ªùi
# ============================================================

async def send_message_to_llm(message: str, device_index: int = None, wait_response: bool = False, timeout: int = 30) -> dict:
    """
    G·ª≠i tin nh·∫Øn cho LLM qua WebSocket. Robot s·∫Ω ƒë·ªçc v√† t·ª± ƒë·ªông tr·∫£ l·ªùi qua gi·ªçng n√≥i.
    
    L∆ØU √ù: Do WebSocket ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi main loop, kh√¥ng th·ªÉ ƒë·ª£i response tr·ª±c ti·∫øp.
    Robot s·∫Ω nh·∫≠n tin nh·∫Øn v√† t·ª± ƒë·ªông ph·∫£n h·ªìi qua voice.
    
    Args:
        message: Tin nh·∫Øn/c√¢u h·ªèi mu·ªën g·ª≠i cho LLM
        device_index: Index thi·∫øt b·ªã (0, 1, 2). None = thi·∫øt b·ªã ƒëang active
        wait_response: KH√îNG S·ª¨ D·ª§NG - ƒë·ªÉ t∆∞∆°ng th√≠ch API c≈©
        timeout: KH√îNG S·ª¨ D·ª§NG - ƒë·ªÉ t∆∞∆°ng th√≠ch API c≈©
        
    Returns:
        dict v·ªõi success, message, device_name
    """
    global xiaozhi_connections, xiaozhi_connected, active_endpoint_index, endpoints_config
    
    try:
        # X√°c ƒë·ªãnh device index
        if device_index is None:
            device_index = active_endpoint_index
        
        # Validate device_index
        if device_index not in [0, 1, 2]:
            return {
                "success": False,
                "error": f"Invalid device_index: {device_index}. Must be 0, 1, or 2."
            }
        
        # Ki·ªÉm tra k·∫øt n·ªëi WebSocket
        if not xiaozhi_connected.get(device_index, False):
            return {
                "success": False,
                "error": f"Thi·∫øt b·ªã {device_index + 1} ch∆∞a k·∫øt n·ªëi. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi WebSocket."
            }
        
        ws = xiaozhi_connections.get(device_index)
        if ws is None:
            return {
                "success": False,
                "error": f"WebSocket connection cho thi·∫øt b·ªã {device_index + 1} kh√¥ng kh·∫£ d·ª•ng."
            }
        
        # L·∫•y t√™n thi·∫øt b·ªã
        device_name = endpoints_config[device_index].get("name", f"Thi·∫øt b·ªã {device_index + 1}")
        
        # T·∫°o JSON-RPC notification ƒë·ªÉ g·ª≠i tin nh·∫Øn cho LLM
        # S·ª≠ d·ª•ng method "notifications/message" theo MCP protocol
        # ƒê√¢y l√† notification (kh√¥ng c√≥ id) n√™n server kh√¥ng c·∫ßn response
        llm_message = {
            "jsonrpc": "2.0",
            "method": "notifications/message",
            "params": {
                "level": "info",
                "data": {
                    "type": "user_message",
                    "content": message,
                    "timestamp": datetime.now().isoformat(),
                    "source": "miniZ_MCP_WebUI"
                }
            }
        }
        
        print(f"üì® [LLM Send] Sending to {device_name}: {message[:100]}...")
        
        # L∆∞u v√†o conversation history
        add_to_conversation(
            role="user",
            content=message,
            metadata={
                "source": "send_message_to_llm",
                "device": device_name,
                "device_index": device_index
            }
        )
        
        # G·ª≠i message qua WebSocket (kh√¥ng ƒë·ª£i response)
        await ws.send(json.dumps(llm_message))
        
        print(f"‚úÖ [LLM Send] Message sent to {device_name}")
        
        return {
            "success": True,
            "message": f"‚úÖ ƒê√£ g·ª≠i tin nh·∫Øn ƒë·∫øn {device_name}. Robot s·∫Ω ƒë·ªçc v√† tr·∫£ l·ªùi qua gi·ªçng n√≥i.",
            "device_name": device_name,
            "device_index": device_index,
            "sent_message": message,
            "note": "Robot s·∫Ω t·ª± ƒë·ªông tr·∫£ l·ªùi qua voice. Kh√¥ng c·∫ßn ƒë·ª£i response text."
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": f"L·ªói khi g·ª≠i tin nh·∫Øn: {str(e)}"
        }


async def broadcast_to_all_llm(message: str, wait_response: bool = False) -> dict:
    """
    G·ª≠i tin nh·∫Øn ƒë·∫øn T·∫§T C·∫¢ thi·∫øt b·ªã LLM ƒëang k·∫øt n·ªëi.
    
    Args:
        message: Tin nh·∫Øn mu·ªën broadcast
        wait_response: KH√îNG S·ª¨ D·ª§NG - ƒë·ªÉ t∆∞∆°ng th√≠ch API c≈©
        
    Returns:
        dict v·ªõi k·∫øt qu·∫£ g·ª≠i cho t·ª´ng thi·∫øt b·ªã
    """
    global xiaozhi_connected
    
    results = {
        "success": True,
        "message": message,
        "devices": []
    }
    
    sent_count = 0
    for device_index in [0, 1, 2]:
        if xiaozhi_connected.get(device_index, False):
            result = await send_message_to_llm(
                message=message,
                device_index=device_index
            )
            results["devices"].append({
                "device_index": device_index,
                "result": result
            })
            if result.get("success"):
                sent_count += 1
    
    results["sent_count"] = sent_count
    results["total_connected"] = sum(1 for v in xiaozhi_connected.values() if v)
    
    if sent_count == 0:
        results["success"] = False
        results["error"] = "Kh√¥ng c√≥ thi·∫øt b·ªã n√†o ƒëang k·∫øt n·ªëi."
    
    return results


def send_message_to_llm_sync(message: str, device_index: int = None, wait_response: bool = False, timeout: int = 30) -> dict:
    """
    Wrapper ƒë·ªìng b·ªô cho send_message_to_llm (d√πng trong TOOLS handler)
    """
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # N·∫øu ƒëang trong async context, t·∫°o task
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    asyncio.run,
                    send_message_to_llm(message, device_index)
                )
                return future.result(timeout=timeout + 5)
        else:
            return loop.run_until_complete(
                send_message_to_llm(message, device_index)
            )
    except Exception as e:
        return {"success": False, "error": str(e)}


TOOLS = {
    # ============================================================
    # üì® SEND MESSAGE TO LLM - G·ª≠i tin nh·∫Øn cho robot/LLM t·ª± tr·∫£ l·ªùi
    # ============================================================
    "send_message_to_llm": {
        "handler": send_message_to_llm,
        "description": "üì® G·ª¨I TIN NH·∫ÆN CHO LLM/ROBOT - G·ª≠i message qua WebSocket ƒë·ªÉ LLM cloud ƒë·ªçc v√† T·ª∞ TR·∫¢ L·ªúI. Use when: 'g·ª≠i tin nh·∫Øn cho robot', 'n√≥i v·ªõi AI', 'chat v·ªõi LLM', 'h·ªèi robot', 'send message to AI'. Robot s·∫Ω ƒë·ªçc ƒë∆∞·ª£c tin nh·∫Øn v√† t·ª± ƒë·ªông ph·∫£n h·ªìi qua gi·ªçng n√≥i ho·∫∑c text.",
        "parameters": {
            "message": {
                "type": "string",
                "description": "Tin nh·∫Øn/c√¢u h·ªèi mu·ªën g·ª≠i cho LLM. VD: 'Xin ch√†o', 'H√¥m nay th·ªùi ti·∫øt th·∫ø n√†o?', 'K·ªÉ cho t√¥i m·ªôt c√¢u chuy·ªán'",
                "required": True
            },
            "device_index": {
                "type": "integer",
                "description": "Index thi·∫øt b·ªã (0, 1, ho·∫∑c 2). M·∫∑c ƒë·ªãnh: thi·∫øt b·ªã ƒëang active. 0=Thi·∫øt b·ªã 1, 1=Thi·∫øt b·ªã 2, 2=Thi·∫øt b·ªã 3",
                "required": False
            },
            "wait_response": {
                "type": "boolean",
                "description": "C√≥ ƒë·ª£i LLM tr·∫£ l·ªùi kh√¥ng? True=ƒë·ª£i response (m·∫∑c ƒë·ªãnh), False=g·ª≠i xong tr·∫£ v·ªÅ lu√¥n",
                "required": False
            },
            "timeout": {
                "type": "integer",
                "description": "Th·ªùi gian ch·ªù response (gi√¢y). M·∫∑c ƒë·ªãnh 30 gi√¢y.",
                "required": False
            }
        }
    },
    "broadcast_to_all_llm": {
        "handler": broadcast_to_all_llm,
        "description": "üì¢ BROADCAST TIN NH·∫ÆN ƒê·∫æN T·∫§T C·∫¢ LLM/ROBOT - G·ª≠i c√πng m·ªôt message ƒë·∫øn t·∫•t c·∫£ thi·∫øt b·ªã ƒëang k·∫øt n·ªëi. Use when: 'g·ª≠i tin nh·∫Øn cho t·∫•t c·∫£ robot', 'broadcast message', 'th√¥ng b√°o cho t·∫•t c·∫£ AI'.",
        "parameters": {
            "message": {
                "type": "string",
                "description": "Tin nh·∫Øn mu·ªën broadcast ƒë·∫øn t·∫•t c·∫£ thi·∫øt b·ªã",
                "required": True
            },
            "wait_response": {
                "type": "boolean",
                "description": "C√≥ ƒë·ª£i response t·ª´ c√°c thi·∫øt b·ªã kh√¥ng? M·∫∑c ƒë·ªãnh False (broadcast th∆∞·ªùng kh√¥ng ƒë·ª£i)",
                "required": False
            }
        }
    },
    
    "get_hardware_specs": {
        "handler": get_system_info,
        "description": "üíªüî• SPECS C·∫§U H√åNH HARDWARE - DUY NH·∫§T tool cho c√¢u h·ªèi: 'c·∫•u h√¨nh m√°y t√≠nh g√¨', 'm√°y t√≠nh n√†y nh∆∞ th·∫ø n√†o', 'card ƒë·ªì h·ªça g√¨', 'CPU g√¨', 'GPU g√¨', 'mainboard g√¨', 'th·∫ø h·ªá CPU', 'RTX RTX m·∫•y', 'Intel th·∫ø h·ªá m·∫•y', 'AMD Ryzen m·∫•y'. Tr·∫£ v·ªÅ: CPU generation (Intel 13th gen), GPU series (RTX 4080), motherboard, BIOS, RAM specs. KH√îNG d√πng cho performance monitoring!",
        "parameters": {
            "category": {
                "type": "string",
                "description": "'cpu', 'gpu', 'motherboard', 'memory', 'all'. M·∫∑c ƒë·ªãnh: all",
                "required": False
            }
        }
    },
    "set_volume": {
        "handler": set_volume, 
        "description": "ƒêI·ªÄU CH·ªàNH √¢m l∆∞·ª£ng m√°y t√≠nh ƒë·∫øn m·ª©c C·ª§ TH·ªÇ (0-100%). Use when user says: 'ch·ªânh √¢m l∆∞·ª£ng 50', 'ƒë·∫∑t √¢m l∆∞·ª£ng 80', 'volume 30', 'set volume to 60', 'ƒë·ªÉ √¢m l∆∞·ª£ng ·ªü m·ª©c 40'. Examples: level=50 (√¢m l∆∞·ª£ng v·ª´a), level=80 (to), level=20 (nh·ªè), level=0 (t·∫Øt h·∫≥n).", 
        "parameters": {"level": {"type": "integer", "description": "M·ª©c √¢m l∆∞·ª£ng t·ª´ 0-100 (0=t·∫Øt h·∫≥n, 50=v·ª´a ph·∫£i, 100=t·ªëi ƒëa)", "required": True}}
    },
    "get_volume": {"handler": get_volume, "description": "Ki·ªÉm tra m·ª©c √¢m l∆∞·ª£ng hi·ªán t·∫°i c·ªßa m√°y t√≠nh. Use when: '√¢m l∆∞·ª£ng bao nhi√™u', 'check volume', 'xem √¢m l∆∞·ª£ng'", "parameters": {}},
    "mute_volume": {"handler": mute_volume, "description": "T·∫ÆT TI·∫æNG m√°y t√≠nh (mute) ho√†n to√†n. Use when: 't·∫Øt ti·∫øng', 'mute', 'c√¢m', 'im l·∫∑ng'", "parameters": {}},
    "unmute_volume": {"handler": unmute_volume, "description": "B·∫¨T L·∫†I TI·∫æNG m√°y t√≠nh (unmute). Use when: 'b·∫≠t ti·∫øng', 'unmute', 'm·ªü ti·∫øng l·∫°i'", "parameters": {}},
    "volume_up": {"handler": volume_up, "description": "TƒÇNG √¢m l∆∞·ª£ng l√™n m·ªôt ch√∫t (m·ªói b∆∞·ªõc ~2%). Use when: 'tƒÉng √¢m l∆∞·ª£ng', 'to h∆°n', 'volume up', 'l·ªõn h∆°n'", "parameters": {"steps": {"type": "integer", "description": "S·ªë b∆∞·ªõc tƒÉng (m·∫∑c ƒë·ªãnh 5 = tƒÉng ~10%)", "required": False}}},
    "volume_down": {"handler": volume_down, "description": "GI·∫¢M √¢m l∆∞·ª£ng xu·ªëng m·ªôt ch√∫t (m·ªói b∆∞·ªõc ~2%). Use when: 'gi·∫£m √¢m l∆∞·ª£ng', 'nh·ªè h∆°n', 'volume down', 'b·ªõt to'", "parameters": {"steps": {"type": "integer", "description": "S·ªë b∆∞·ªõc gi·∫£m (m·∫∑c ƒë·ªãnh 5 = gi·∫£m ~10%)", "required": False}}},
    "take_screenshot": {
        "handler": take_screenshot, 
        "description": "Ch·ª•p m√†n h√¨nh to√†n b·ªô v√† L∆ØU FILE ·∫¢NH. T·ª± ƒë·ªông l∆∞u v√†o th∆∞ m·ª•c Downloads v·ªõi t√™n file c√≥ timestamp. Use when user asks: 'ch·ª•p m√†n h√¨nh', 'screenshot', 'capture screen'.", 
        "parameters": {
            "filename": {
                "type": "string",
                "description": "T√™n file l∆∞u ·∫£nh (optional). M·∫∑c ƒë·ªãnh: screenshot_YYYYMMDD_HHMMSS.png. V√≠ d·ª•: 'my_screen.png'",
                "required": False
            }
        }
    },
    "show_notification": {"handler": show_notification, "description": "Hi·ªÉn th·ªã th√¥ng b√°o", "parameters": {"title": {"type": "string", "description": "Ti√™u ƒë·ªÅ", "required": True}, "message": {"type": "string", "description": "N·ªôi dung", "required": True}}},
    "get_system_resources": {"handler": get_system_resources, "description": "üìä PERFORMANCE MONITORING - CH·ªà ƒë·ªÉ xem CPU %, RAM %, Disk % ƒëang s·ª≠ d·ª•ng. CHO PERFORMANCE/MONITOR, KH√îNG cho c√¢u h·ªèi v·ªÅ 'c·∫•u h√¨nh m√°y t√≠nh', 'GPU g√¨', 'CPU g√¨'. D√πng get_hardware_specs cho hardware specs!", "parameters": {}},
    "get_current_time": {"handler": get_current_time, "description": "Th·ªùi gian hi·ªán t·∫°i", "parameters": {}},
    "calculator": {"handler": calculator, "description": "T√≠nh to√°n", "parameters": {"expression": {"type": "string", "description": "Bi·ªÉu th·ª©c", "required": True}}},
    "open_application": {
        "handler": open_application, 
        "description": "M·ªü ·ª©ng d·ª•ng Windows v·ªõi t√¨m ki·∫øm th√¥ng minh. H·ªñ TR·ª¢ 50+ ·ª®NG D·ª§NG: Windows (notepad, calc, paint, cmd, taskmgr), Browsers (chrome, firefox, edge, brave), Microsoft Office (word, excel, powerpoint, outlook, teams), Adobe Creative (photoshop, illustrator, premiere, after effects, lightroom), Development (vscode, pycharm, sublime, notepad++), 3D/Design (blender, maya, autocad, solidworks, fusion360), Communication (discord, slack, zoom, telegram, zalo), Media (vlc, spotify, itunes). H·ªó tr·ª£ t√™n TI·∫æNG VI·ªÜT ('m√°y t√≠nh'‚ÜíCalculator, 'm√°y ghi ch√∫'‚ÜíNotepad). T·ª± ƒë·ªông t√¨m trong PATH, Registry, Program Files. V√≠ d·ª•: 'photoshop', 'excel', 'chrome', 'blender'.", 
        "parameters": {
            "app_name": {
                "type": "string", 
                "description": "T√™n ·ª©ng d·ª•ng (v√≠ d·ª•: 'excel', 'photoshop', 'chrome', 'vscode', 'blender', 'word'). C√≥ th·ªÉ d√πng t√™n ƒë·∫ßy ƒë·ªß ('microsoft excel') ho·∫∑c vi·∫øt t·∫Øt ('ps'‚ÜíPhotoshop). H·ªó tr·ª£ ti·∫øng Vi·ªát.", 
                "required": True
            }
        }
    },
    "list_running_processes": {"handler": list_running_processes, "description": "Li·ªát k√™ ti·∫øn tr√¨nh", "parameters": {"limit": {"type": "integer", "description": "S·ªë l∆∞·ª£ng", "required": False}}},
    "find_process": {
        "handler": find_process,
        "description": "üîç T√åM KI·∫æM PROCESS - T√¨m process c·ª• th·ªÉ theo t√™n ho·∫∑c xem t·∫•t c·∫£. Triggers: 't√¨m process excel', 'excel c√≥ ch·∫°y kh√¥ng', 'process n√†o ƒëang ch·∫°y'. Better than list_running_processes with limit.",
        "parameters": {
            "name_pattern": {"type": "string", "description": "T√™n process c·∫ßn t√¨m (VD: 'excel', 'chrome', 'notepad'). ƒê·ªÉ tr·ªëng = t·∫•t c·∫£", "required": False},
            "show_all": {"type": "boolean", "description": "True=hi·ªÉn th·ªã t·∫•t c·∫£ process, False=ch·ªâ top 20 (default)", "required": False}
        }
    },
    "kill_process": {
        "handler": kill_process, 
        "description": "üî™ Kill ti·∫øn tr√¨nh theo t√™n ho·∫∑c PID. C√≥ th·ªÉ kill ngay l·∫≠p t·ª©c (force=True) ho·∫∑c ƒë√≥ng m·ªÅm (force=False). VD: 'kill notepad', 't·∫Øt chrome'", 
        "parameters": {
            "identifier": {"type": "string", "description": "T√™n app ho·∫∑c PID. VD: notepad, chrome, 1234", "required": True},
            "force": {"type": "boolean", "description": "True=kill ngay (m·∫∑c ƒë·ªãnh), False=ƒë√≥ng m·ªÅm", "required": False},
            "exact_match": {"type": "boolean", "description": "True=t√™n kh·ªõp ch√≠nh x√°c, False=ch·ª©a t√™n l√† ƒë∆∞·ª£c (m·∫∑c ƒë·ªãnh)", "required": False}
        }
    },
    "force_kill_app": {
        "handler": force_kill_app, 
        "description": "üíÄ FORCE KILL APP NGAY L·∫¨P T·ª®C - kh√¥ng h·ªèi han, kill h·∫øt t·∫•t c·∫£ instances. D√πng khi c·∫ßn kill app ngay, kh√¥ng ch·ªù ƒë·ª£i. VD: 'force kill chrome', 'bu·ªôc t·∫Øt notepad'", 
        "parameters": {
            "app_name": {"type": "string", "description": "T√™n app c·∫ßn force kill. VD: notepad, chrome, firefox, Code", "required": True}
        }
    },
    "create_file": {"handler": create_file, "description": "T·∫°o file", "parameters": {"path": {"type": "string", "description": "ƒê∆∞·ªùng d·∫´n", "required": True}, "content": {"type": "string", "description": "N·ªôi dung", "required": True}}},
    "read_file": {"handler": read_file, "description": "ƒê·ªçc file", "parameters": {"path": {"type": "string", "description": "ƒê∆∞·ªùng d·∫´n", "required": True}}},
    "list_files": {"handler": list_files, "description": "Li·ªát k√™ files", "parameters": {"directory": {"type": "string", "description": "Th∆∞ m·ª•c", "required": True}}},
    "get_battery_status": {"handler": get_battery_status, "description": "Th√¥ng tin pin", "parameters": {}},
    "get_network_info": {"handler": get_network_info, "description": "Th√¥ng tin m·∫°ng", "parameters": {}},
    "search_web": {"handler": search_web, "description": "M·ªû TR√åNH DUY·ªÜT ƒë·ªÉ t√¨m ki·∫øm tr√™n Google. CH·ªà d√πng khi user Y√äU C·∫¶U M·ªû BROWSER ƒë·ªÉ search (v√≠ d·ª•: 'm·ªü google t√¨m ki·∫øm...', 'search google v·ªÅ...'). KH√îNG d√πng ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi - h√£y d√πng ask_gemini thay v√¨ search_web cho c√¢u h·ªèi th√¥ng th∆∞·ªùng", "parameters": {"query": {"type": "string", "description": "T·ª´ kh√≥a", "required": True}}},
    
    # MEDIA PLAYER CONTROLS (Ch·ªß y·∫øu cho Spotify, YouTube, VLC - WMP c√≥ gi·ªõi h·∫°n)
    "media_play_pause": {
        "handler": media_play_pause, 
        "description": "‚èØÔ∏è Ph√°t/T·∫°m d·ª´ng external media players (Spotify, YouTube, VLC, iTunes, Discord, Chrome video...). D√πng Windows media keys. ‚ö†Ô∏è L∆ØU √ù: KH√îNG ho·∫°t ƒë·ªông t·ªët v·ªõi music_library (Windows Media Player t·ª± ƒë√≥ng sau khi ph√°t). D√πng stop_music() ƒë·ªÉ d·ª´ng music_library. V√≠ d·ª•: 't·∫°m d·ª´ng spotify', 'pause youtube'.", 
        "parameters": {}
    },
    "media_next_track": {
        "handler": media_next_track, 
        "description": "‚è≠Ô∏è Chuy·ªÉn b√†i ti·∫øp theo tr√™n playlist. Ho·∫°t ƒë·ªông v·ªõi: Spotify, YouTube playlist, VLC, iTunes. ‚ö†Ô∏è KH√îNG d√πng cho music_library (WMP t·ª± ƒë√≥ng). V√≠ d·ª•: 'b√†i ti·∫øp spotify', 'next youtube'.", 
        "parameters": {}
    },
    "media_previous_track": {
        "handler": media_previous_track, 
        "description": "‚èÆÔ∏è Quay l·∫°i b√†i tr∆∞·ªõc. Ho·∫°t ƒë·ªông v·ªõi: Spotify, YouTube, VLC, iTunes. ‚ö†Ô∏è KH√îNG d√πng cho music_library. V√≠ d·ª•: 'b√†i tr∆∞·ªõc spotify', 'previous vlc'.", 
        "parameters": {}
    },
    "media_stop": {
        "handler": media_stop, 
        "description": "‚èπÔ∏è D·ª´ng ph√°t external media players. Ho·∫°t ƒë·ªông v·ªõi Spotify, VLC, YouTube. V·ªõi music_library, d√πng stop_music() thay th·∫ø (ƒë√≥ng Windows Media Player). V√≠ d·ª•: 'stop spotify', 'd·ª´ng vlc'.", 
        "parameters": {}
    },
    "media_control": {
        "handler": media_control, 
        "description": "üéõÔ∏è Tool T·ªîNG H·ª¢P ƒëi·ªÅu khi·ªÉn EXTERNAL media players (Spotify, YouTube, VLC, iTunes...). H·ªó tr·ª£: play, pause, next, previous, stop, volume_up, volume_down, mute. ‚ö†Ô∏è KH√îNG d√πng cho music_library (d√πng stop_music). Best for: Spotify, YouTube, VLC. V√≠ d·ª•: media_control('next') cho Spotify, media_control('pause') cho YouTube.", 
        "parameters": {
            "action": {
                "type": "string", 
                "description": "H√†nh ƒë·ªông: 'play', 'pause', 'next', 'previous', 'stop', 'volume_up', 'volume_down', 'mute'. V√≠ d·ª•: 'next', 'pause', 'mute'.", 
                "required": True
            }
        }
    },
    
    "save_music_folder_config": {
        "handler": save_music_folder_config,
        "description": "Save user's music folder path configuration. This folder will be prioritized for playing music using Windows default media player.",
        "parameters": {
            "folder_path": {
                "type": "string",
                "description": r"Full path to user's music folder (e.g., C:\Users\Name\Music)",
                "required": True
            }
        }
    },
    "play_music_from_user_folder": {
        "handler": play_music_from_user_folder,
        "description": "üéµ [PYTHON-VLC] ‚≠ê ∆ØU TI√äN #1: Ph√°t nh·∫°c t·ª´ TH∆Ø M·ª§C NG∆Ø·ªúI D√ôNG ƒê√É C·∫§U H√åNH (link ri√™ng). Khi user n√≥i 'ph√°t nh·∫°c t·ª´ th∆∞ m·ª•c c·ªßa t√¥i', 'play t·ª´ folder F:', 'nh·∫°c trong ·ªï D' ‚Üí D√ôNG TOOL N√ÄY! T√¨m theo t√™n b√†i: filename='t√™n b√†i'. NHANH v√¨ d√πng Python-VLC n·ªôi b·ªô. N·∫øu ch∆∞a config th√¨ b√°o l·ªói ‚Üí user c·∫ßn v√†o Music Settings.",
        "parameters": {
            "filename": {
                "type": "string",
                "description": "T√™n b√†i h√°t c·∫ßn t√¨m (t√¨m partial match). ƒê·ªÉ tr·ªëng = ph√°t b√†i ƒë·∫ßu trong th∆∞ m·ª•c.",
                "required": False
            },
            "auto_play": {
                "type": "boolean",
                "description": "T·ª± ƒë·ªông ph√°t? Default True.",
                "required": False
            }
        }
    },
    
    "get_active_media_players": {
        "handler": get_active_media_players,
        "description": "üîç [KH√îNG C·∫¶N G·ªåI] L·∫•y danh s√°ch media players ƒëang ch·∫°y. ‚ö†Ô∏è KH√îNG C·∫¶N g·ªçi tool n√†y tr∆∞·ªõc khi ƒëi·ªÅu khi·ªÉn nh·∫°c! Nh·∫°c local LU√îN d√πng Python-VLC (pause_music, stop_music, music_next). YouTube LU√îN d√πng youtube_* tools.",
        "parameters": {}
    },
    
    # TASK MEMORY TOOLS - Ghi nh·ªõ t√°c v·ª• ƒë·ªÉ ph·∫£n h·ªìi nhanh v√† ch√≠nh x√°c
    "remember_task": {
        "handler": remember_task,
        "description": "üìù GHI NH·ªö T√ÅC V·ª§ - L∆∞u l·∫°i t√°c v·ª• ƒë√£ th·ª±c hi·ªán v√†o b·ªô nh·ªõ d√†i h·∫°n. Gi√∫p AI nh·ªõ nh·ªØng g√¨ ƒë√£ l√†m ƒë·ªÉ ph·∫£n h·ªìi nhanh v√† ch√≠nh x√°c h∆°n. G·ªçi tool n√†y SAU KHI ho√†n th√†nh m·ªôt t√°c v·ª• quan tr·ªçng.",
        "parameters": {
            "tool_name": {"type": "string", "description": "T√™n tool ƒë√£ s·ª≠ d·ª•ng", "required": True},
            "params": {"type": "object", "description": "Tham s·ªë ƒë√£ d√πng (optional)", "required": False},
            "result_message": {"type": "string", "description": "K·∫øt qu·∫£/message", "required": False},
            "user_request": {"type": "string", "description": "Y√™u c·∫ßu g·ªëc c·ªßa user", "required": False}
        }
    },
    "recall_tasks": {
        "handler": recall_tasks,
        "description": "üß† NH·ªö L·∫†I T√ÅC V·ª§ - Truy v·∫•n l·ªãch s·ª≠ c√°c t√°c v·ª• ƒë√£ th·ª±c hi·ªán. G·ªçi tool n√†y ƒê·∫¶U TI√äN khi user h·ªèi 'ƒë√£ l√†m g√¨', 'nh·∫Øc l·∫°i', 'l·∫ßn tr∆∞·ªõc', ho·∫∑c khi c·∫ßn context v·ªÅ c√°c t√°c v·ª• tr∆∞·ªõc ƒë√≥.",
        "parameters": {
            "keyword": {"type": "string", "description": "T·ª´ kh√≥a t√¨m ki·∫øm (optional). ƒê·ªÉ tr·ªëng = l·∫•y t√°c v·ª• g·∫ßn nh·∫•t", "required": False},
            "limit": {"type": "integer", "description": "S·ªë l∆∞·ª£ng t√°c v·ª• t·ªëi ƒëa (default 10)", "required": False}
        }
    },
    "get_task_summary": {
        "handler": get_task_summary,
        "description": "üìä TH·ªêNG K√ä T√ÅC V·ª§ - L·∫•y t·ªïng h·ª£p v·ªÅ c√°c t√°c v·ª• ƒë√£ th·ª±c hi·ªán. Cho bi·∫øt tools n√†o ƒë∆∞·ª£c d√πng nhi·ªÅu nh·∫•t, t·ª∑ l·ªá th√†nh c√¥ng. D√πng khi user h·ªèi 'th·ªëng k√™', 'b√°o c√°o', 'ƒë√£ d√πng tools g√¨'.",
        "parameters": {}
    },
    "forget_all_tasks": {
        "handler": forget_all_tasks,
        "description": "üóëÔ∏è X√ìA L·ªäCH S·ª¨ - X√≥a to√†n b·ªô l·ªãch s·ª≠ t√°c v·ª• ƒë√£ ghi nh·ªõ. CH·ªà D√ôNG khi user y√™u c·∫ßu r√µ r√†ng 'x√≥a l·ªãch s·ª≠', 'qu√™n h·∫øt', 'reset memory'.",
        "parameters": {}
    },
    
    "set_brightness": {"handler": set_brightness, "description": "ƒê·ªô s√°ng m√†n h√¨nh", "parameters": {"level": {"type": "integer", "description": "ƒê·ªô s√°ng 0-100", "required": True}}},
    "get_clipboard": {"handler": get_clipboard, "description": "L·∫•y clipboard", "parameters": {}},
    "set_clipboard": {"handler": set_clipboard, "description": "ƒê·∫∑t clipboard", "parameters": {"text": {"type": "string", "description": "N·ªôi dung", "required": True}}},
    "play_sound": {"handler": play_sound, "description": "Ph√°t √¢m thanh", "parameters": {"frequency": {"type": "integer", "description": "T·∫ßn s·ªë Hz", "required": False}, "duration": {"type": "integer", "description": "Th·ªùi gian ms", "required": False}}},
    "get_disk_usage": {"handler": get_disk_usage, "description": "Th√¥ng tin ƒëƒ©a", "parameters": {}},
    
    # ============================================================
    # üéµ MUSIC LIBRARY TOOLS - PYTHON-VLC (LOCAL FILES)
    # D√πng cho file nh·∫°c .mp3/.wav/.flac trong m√°y t√≠nh
    # KH√îNG d√πng cho YouTube - YouTube c√≥ tools ri√™ng (youtube_*)
    # ============================================================
    "list_music": {
        "handler": list_music, 
        "description": "üìÇ [LOCAL MUSIC] Li·ªát k√™ t·∫•t c·∫£ nh·∫°c trong th∆∞ vi·ªán music_library. Triggers: 'xem danh s√°ch nh·∫°c', 'c√≥ b√†i g√¨', 'list music'. Auto-play m·∫∑c ƒë·ªãnh = True (ph√°t b√†i ƒë·∫ßu ti√™n). D√πng subfolder='Pop' ƒë·ªÉ l·ªçc theo th·ªÉ lo·∫°i.", 
        "parameters": {
            "subfolder": {
                "type": "string", 
                "description": "Th∆∞ m·ª•c con ƒë·ªÉ l·ªçc (VD: 'Pop', 'Rock', 'EDM'). ƒê·ªÉ tr·ªëng = t·∫•t c·∫£.", 
                "required": False
            },
            "auto_play": {
                "type": "boolean",
                "description": "T·ª± ƒë·ªông ph√°t b√†i ƒë·∫ßu ti√™n? Default=True. Set False n·∫øu ch·ªâ mu·ªën xem danh s√°ch.",
                "required": False
            }
        }
    },
    "play_music": {
        "handler": play_music, 
        "description": "üéµ PH√ÅT NH·∫†C LOCAL (Python-VLC) - Triggers: 'ph√°t nh·∫°c', 'b·∫≠t nh·∫°c', 'm·ªü nh·∫°c', 'nghe nh·∫°c', 'play nh·∫°c', 'ph√°t b√†i [t√™n]', 'phat nhac', 'bat nhac'. VD: 'ph√°t b√†i ƒëa nghi' ‚Üí play_music(filename='ƒëa nghi'). ‚ö†Ô∏è N·∫øu user n√≥i 'youtube/video' ‚Üí d√πng open_youtube!", 
        "parameters": {
            "filename": {
                "type": "string", 
                "description": "T√™n b√†i nh·∫°c (partial match). VD: 'ƒëa nghi', 'in love'. H·ªó tr·ª£ ti·∫øng Vi·ªát.", 
                "required": True
            },
            "create_playlist": {
                "type": "boolean",
                "description": "T·∫°o playlist (default True).",
                "required": False
            }
        }
    },
    "pause_music": {
        "handler": pause_music,
        "description": "‚è∏Ô∏è T·∫†M D·ª™NG NH·∫†C - ‚≠ê G·ªåI NGAY khi user n√≥i: 'd·ª´ng', 'd·ª´ng nh·∫°c', 't·∫°m d·ª´ng', 'pause', 'ng·ª´ng', 'ng∆∞ng nh·∫°c', 'ngh·ªâ', 'im ƒëi', 'd·ª´ng l·∫°i'. Voice: 'dung', 'dung nhac', 'tam dung', 'pao', 'poz', 'ngung', 'dung lai'. Kh√¥ng c·∫ßn parameter - g·ªçi pause_music() l√† xong! ‚ö†Ô∏è N·∫øu c√≥ 'youtube' ‚Üí youtube_play_pause()",
        "parameters": {}
    },
    "resume_music": {
        "handler": resume_music,
        "description": "‚ñ∂Ô∏è TI·∫æP T·ª§C PH√ÅT - ‚≠ê G·ªåI NGAY khi user n√≥i: 'ti·∫øp t·ª•c', 'ph√°t ti·∫øp', 'play l·∫°i', 'm·ªü l·∫°i', 'ph√°t ƒëi', 'ch∆°i ti·∫øp'. Voice: 'tiep tuc', 'phat tiep', 'mo lai', 'bat lai'. Kh√¥ng c·∫ßn parameter - g·ªçi resume_music() l√† xong!",
        "parameters": {}
    },
    "stop_music": {
        "handler": stop_music, 
        "description": "‚èπÔ∏è T·∫ÆT NH·∫†C HO√ÄN TO√ÄN - ‚≠ê G·ªåI NGAY khi user n√≥i: 't·∫Øt nh·∫°c', 'd·ª´ng h·∫≥n', 'stop', 'off nh·∫°c', 'kh√¥ng nghe n·ªØa', 't·∫Øt ƒëi'. Voice: 'tat nhac', 'dung han', 'st√≥p', 'of nhac'. Kh√¥ng c·∫ßn parameter - g·ªçi stop_music() l√† xong!", 
        "parameters": {}
    },
    
    # üåü SMART MUSIC CONTROL - Tool th√¥ng minh nh·∫•t
    "smart_music_control": {
        "handler": smart_music_control,
        "description": "üéµüî• ƒêI·ªÄU KHI·ªÇN NH·∫†C TH√îNG MINH - ‚≠ê G·ªåI KHI nghe: 'b√†i ti·∫øp/next/chuy·ªÉn b√†i', 'b√†i tr∆∞·ªõc/quay l·∫°i', 'd·ª´ng/pause/t·∫°m d·ª´ng', 't·∫Øt nh·∫°c/stop', 'ph√°t b√†i [t√™n]', 'tƒÉng/gi·∫£m √¢m l∆∞·ª£ng'. Voice: 'bai tiep', 'bai truoc', 'dung nhac', 'tam dung', 'pao'. VD: smart_music_control('b√†i ti·∫øp'), smart_music_control('d·ª´ng'). Tool t·ª± x·ª≠ l√Ω t·∫•t c·∫£!",
        "parameters": {
            "command": {
                "type": "string",
                "description": "L·ªánh ti·∫øng Vi·ªát/English. VD: 'b√†i ti·∫øp', 'b√†i tr∆∞·ªõc', 'd·ª´ng', 'pause', 'ph√°t b√†i love'",
                "required": True
            }
        }
    },
    
    "detect_and_execute_music": {
        "handler": detect_and_execute_music,
        "description": "üéµüîç T·ª∞ ƒê·ªòNG PH√ÅT HI·ªÜN L·ªÜNH NH·∫†C - Ki·ªÉm tra input c√≥ ph·∫£i l·ªánh nh·∫°c kh√¥ng v√† t·ª± ƒë·ªông th·ª±c thi. D√πng khi kh√¥ng ch·∫Øc input c√≥ ph·∫£i l·ªánh nh·∫°c.",
        "parameters": {
            "text": {
                "type": "string", 
                "description": "Text c·∫ßn ki·ªÉm tra",
                "required": True
            }
        }
    },
    
    "music_next": {
        "handler": music_next,
        "description": "‚è≠Ô∏è B√ÄI TI·∫æP THEO - ‚≠ê G·ªåI NGAY khi user n√≥i: 'b√†i ti·∫øp', 'b√†i ti·∫øp theo', 'chuy·ªÉn b√†i', 'b√†i kh√°c', 'next', 'skip', 'k·∫ø ti·∫øp', 'sang b√†i', 'b√†i sau'. Voice: 'bai tiep', 'chuyen bai', 'bai khac', 'tiep theo', 'ke tiep', 'nex', 'n√≠ch'. Kh√¥ng c·∫ßn parameter - g·ªçi music_next() l√† xong!",
        "parameters": {}
    },
    "music_previous": {
        "handler": music_previous,
        "description": "‚èÆÔ∏è B√ÄI TR∆Ø·ªöC - ‚≠ê G·ªåI NGAY khi user n√≥i: 'b√†i tr∆∞·ªõc', 'quay l·∫°i', 'b√†i tr∆∞·ªõc ƒë√≥', 'previous', 'back', 'l√πi b√†i', 'b√†i c≈©'. Voice: 'bai truoc', 'quay lai', 'lui bai', 'bai cu', 'pre', 'pr√™'. Kh√¥ng c·∫ßn parameter - g·ªçi music_previous() l√† xong!",
        "parameters": {}
    },
    "get_music_status": {
        "handler": get_music_status,
        "description": "üìä TR·∫†NG TH√ÅI NH·∫†C - Triggers: 'ƒëang ph√°t g√¨', 'b√†i g√¨ ƒëang ph√°t', 'music status', 'dang phat gi'. Tr·∫£ v·ªÅ: t√™n b√†i, th·ªùi gian, √¢m l∆∞·ª£ng, playlist.",
        "parameters": {}
    },
    "seek_music": {
        "handler": seek_music,
        "description": "üîÄ TUA ƒê·∫æN V·ªä TR√ç - Triggers: 'tua ƒë·∫øn gi·ªØa b√†i', 'nh·∫£y ƒë·∫øn ph√∫t', 'skip 50%', 'tua den', 'nhay den'. 0%=ƒë·∫ßu, 50%=gi·ªØa, 100%=cu·ªëi. ‚ö†Ô∏è 'tua youtube' ‚Üí youtube_forward!",
        "parameters": {
            "percentage": {
                "type": "number",
                "description": "V·ªã tr√≠ % (0-100). 50=gi·ªØa b√†i.",
                "required": True
            }
        }
    },
    "music_volume": {
        "handler": music_volume,
        "description": "üîä √ÇM L∆Ø·ª¢NG NH·∫†C LOCAL - Triggers: 'tƒÉng √¢m l∆∞·ª£ng', 'gi·∫£m ti·∫øng', 'volume 80', 'to l√™n', 'nh·ªè l·∫°i', 'tang am luong', 'giam tien'. Level: 0=t·∫Øt, 50=v·ª´a, 100=max. ‚ö†Ô∏è 'volume youtube' ‚Üí youtube_volume_up/down!",
        "parameters": {
            "level": {
                "type": "integer",
                "description": "M·ª©c √¢m l∆∞·ª£ng 0-100.",
                "required": True
            }
        }
    },
    "save_music_folder_config": {
        "handler": save_music_folder_config,
        "description": "L∆∞u ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c nh·∫°c c·ªßa user. D√πng ƒë·ªÉ ∆∞u ti√™n ph√°t nh·∫°c t·ª´ folder n√†y.",
        "parameters": {
            "folder_path": {
                "type": "string",
                "description": r"ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn th∆∞ m·ª•c nh·∫°c (VD: C:\Users\Name\Music)",
                "required": True
            }
        }
    },
    "search_music": {
        "handler": search_music, 
        "description": "üîç T√åM NH·∫†C THEO T·ª™ KH√ìA - Triggers: 't√¨m b√†i [keyword]', 'search nh·∫°c', 'c√≥ b√†i n√†o t√™n', 'tim bai', 'search bai'. T√¨m trong th∆∞ vi·ªán local, h·ªó tr·ª£ ti·∫øng Vi·ªát, auto-play m·∫∑c ƒë·ªãnh.", 
        "parameters": {
            "keyword": {
                "type": "string", 
                "description": "T·ª´ kh√≥a t√¨m ki·∫øm. VD: 'love', 'bu·ªìn', 'ƒëa nghi'.", 
                "required": True
            },
            "auto_play": {
                "type": "boolean",
                "description": "T·ª± ƒë·ªông ph√°t b√†i ƒë·∫ßu ti√™n? Default=True.",
                "required": False
            }
        }
    },
    
    # QUICK WEBSITE ACCESS TOOLS
    "open_youtube": {
        "handler": open_youtube, 
        "description": "üì∫ M·ªû YOUTUBE - Triggers: 'm·ªü youtube', 'v√†o youtube', 'xem youtube', 'youtube [t√™n video]'. ‚ú® NEW: T·ª∞ ƒê·ªòNG ph√°t video tr·ª±c ti·∫øp n·∫øu query C·ª§ TH·ªÇ (>= 2 t·ª´)! VD: 'm·ªü youtube L·∫°c Tr√¥i' ‚Üí M·ªü video tr·ª±c ti·∫øp (kh√¥ng ph·∫£i search page). Query 1 t·ª´ ‚Üí m·ªü search page.", 
        "parameters": {
            "search_query": {
                "type": "string", 
                "description": "T√™n video/t·ª´ kh√≥a. Query >= 2 t·ª´ = auto ph√°t video tr·ª±c ti·∫øp. Query 1 t·ª´ = search page. ƒê·ªÉ tr·ªëng = homepage.", 
                "required": False
            }
        }
    },
    "search_youtube_video": {
        "handler": search_youtube_video,
        "description": "üîç T√åM VIDEO YOUTUBE (Explicit) - ‚ö†Ô∏è CH·ªà d√πng khi user Y√äU C·∫¶U 't√¨m video', 'search video', ho·∫∑c mu·ªën xem top 5 results. C√≤n l·∫°i D√ôNG open_youtube (ƒë√£ c√≥ auto-detect direct video). VD: 't√¨m video S∆°n T√πng' ‚Üí search_youtube_video. 'm·ªü youtube S∆°n T√πng Ch√∫ng Ta' ‚Üí open_youtube (preferred).",
        "parameters": {
            "video_title": {
                "type": "string",
                "description": "T√™n video/t·ª´ kh√≥a. VD: 'H√£y Trao Cho Anh', 'Rap Vi·ªát t·∫≠p 1'",
                "required": True
            },
            "auto_open": {
                "type": "boolean",
                "description": "T·ª± ƒë·ªông m·ªü video (default: True). Set False ƒë·ªÉ ch·ªâ t√¨m.",
                "required": False
            }
        }
    },
    "open_youtube_playlist": {
        "handler": open_youtube_playlist,
        "description": "üìú M·ªû PLAYLIST YOUTUBE (ƒë√£ l∆∞u Web UI) - Triggers: 'm·ªü playlist [t√™n]', 'ph√°t playlist youtube', 'mo playlist'. VD: 'm·ªü playlist nh·∫°c vi·ªát 1'. ‚ö†Ô∏è Kh√¥ng d√πng cho .mp3 local ‚Üí play_music!",
        "parameters": {
            "playlist_name": {
                "type": "string",
                "description": "T√™n playlist ƒë√£ ƒëƒÉng k√Ω. VD: 'nh·∫°c vi·ªát 1', 'chill', 'EDM'",
                "required": True
            }
        }
    },
    
    # YOUTUBE PLAYER CONTROLS
    "control_youtube": {
        "handler": control_youtube,
        "description": "üé¨ ƒêi·ªÅu khi·ªÉn YOUTUBE b·∫±ng shortcuts. Actions: play_pause, rewind_10, forward_10, volume_up/down, mute_toggle. VD: 't·∫°m d·ª´ng youtube'",
        "parameters": {
            "action": {
                "type": "string",
                "description": "Action: play_pause, rewind_10, forward_10, volume_up/down, mute_toggle",
                "required": True
            }
        }
    },
    "youtube_play_pause": {
        "handler": youtube_play_pause,
        "description": "‚èØÔ∏è PLAY/PAUSE YOUTUBE - Triggers: 'd·ª´ng youtube', 'pause youtube', 'ti·∫øp t·ª•c youtube', 'play youtube', 'dung youtube'. ‚ö†Ô∏è 'd·ª´ng nh·∫°c' (kh√¥ng c√≥ youtube) ‚Üí pause_music!",
        "parameters": {}
    },
    "youtube_rewind": {
        "handler": youtube_rewind,
        "description": "‚è™ TUA L√ôI YOUTUBE - Triggers: 'l√πi youtube', 'tua l√πi youtube', 'rewind youtube', 'lui youtube'. 5s=ph√≠m ‚Üê | 10s=ph√≠m J",
        "parameters": {
            "seconds": {"type": "integer", "description": "Gi√¢y tua l√πi: 5 ho·∫∑c 10", "required": False}
        }
    },
    "youtube_forward": {
        "handler": youtube_forward,
        "description": "‚è© TUA T·ªöI YOUTUBE - Triggers: 'tua youtube', 'skip youtube', 'forward youtube', 'tua video'. 5s=ph√≠m ‚Üí | 10s=ph√≠m L",
        "parameters": {
            "seconds": {"type": "integer", "description": "Gi√¢y tua t·ªõi: 5 ho·∫∑c 10", "required": False}
        }
    },
    "youtube_volume_up": {
        "handler": youtube_volume_up,
        "description": "üîä TƒÇNG √ÇM L∆Ø·ª¢NG YOUTUBE - Triggers: 'tƒÉng ti·∫øng youtube', 'volume up youtube', 'tang am luong youtube'. ‚ö†Ô∏è 'tƒÉng ti·∫øng nh·∫°c' ‚Üí music_volume!",
        "parameters": {}
    },
    "youtube_volume_down": {
        "handler": youtube_volume_down,
        "description": "üîâ GI·∫¢M √ÇM L∆Ø·ª¢NG YOUTUBE - Triggers: 'gi·∫£m ti·∫øng youtube', 'volume down youtube', 'giam am luong youtube'. ‚ö†Ô∏è 'gi·∫£m ti·∫øng nh·∫°c' ‚Üí music_volume!",
        "parameters": {}
    },
    "youtube_mute": {
        "handler": youtube_mute,
        "description": "üîá T·∫ÆT/B·∫¨T TI·∫æNG YOUTUBE - Triggers: 't·∫Øt ti·∫øng youtube', 'mute youtube', 'b·∫≠t ti·∫øng youtube', 'tat tien youtube'.",
        "parameters": {}
    },
    "youtube_fullscreen": {
        "handler": youtube_fullscreen,
        "description": "üì∫ FULLSCREEN YOUTUBE - Triggers: 'fullscreen youtube', 'to√†n m√†n h√¨nh', 'ph√≥ng to youtube', 'thu nh·ªè youtube', 'toan man hinh'.",
        "parameters": {}
    },
    "youtube_captions": {
        "handler": youtube_captions,
        "description": "üí¨ B·∫¨T/T·∫ÆT PH·ª§ ƒê·ªÄ YOUTUBE - Triggers: 'b·∫≠t sub', 't·∫Øt sub', 'b·∫≠t ph·ª• ƒë·ªÅ', 't·∫Øt ph·ª• ƒë·ªÅ', 'caption youtube', 'bat sub', 'tat sub'.",
        "parameters": {}
    },
    "youtube_speed": {
        "handler": youtube_speed,
        "description": "‚ö° ƒê·ªîI T·ªêC ƒê·ªò YOUTUBE - Triggers: 'youtube nhanh h∆°n', 'youtube ch·∫≠m h∆°n', 'tƒÉng t·ªëc youtube'. faster=+0.25x | slower=-0.25x | normal=1x",
        "parameters": {
            "speed": {"type": "string", "description": "'faster', 'slower', 'normal'", "required": False}
        }
    },
    
    # VLC PLAYER CONTROLS
    "control_vlc": {
        "handler": control_vlc,
        "description": "üéµ ƒêi·ªÅu khi·ªÉn VLC PLAYER. Actions: play_pause, stop, next, previous, volume_up/down, mute, fullscreen",
        "parameters": {
            "action": {
                "type": "string",
                "description": "Action ƒëi·ªÅu khi·ªÉn VLC",
                "required": True
            }
        }
    },
    "vlc_play_pause": {
        "handler": vlc_play_pause,
        "description": "‚èØÔ∏è Play/Pause VLC Player. VD: 'd·ª´ng vlc', 'pause vlc', 'ti·∫øp t·ª•c vlc'",
        "parameters": {}
    },
    "vlc_stop": {
        "handler": vlc_stop,
        "description": "‚èπÔ∏è D·ª´ng ph√°t VLC ho√†n to√†n. VD: 'stop vlc', 't·∫Øt nh·∫°c vlc'",
        "parameters": {}
    },
    "vlc_next": {
        "handler": vlc_next,
        "description": "‚è≠Ô∏è Chuy·ªÉn b√†i ti·∫øp theo trong VLC. VD: 'b√†i ti·∫øp vlc', 'next vlc', 'chuy·ªÉn b√†i vlc'",
        "parameters": {}
    },
    "vlc_previous": {
        "handler": vlc_previous,
        "description": "‚èÆÔ∏è Quay l·∫°i b√†i tr∆∞·ªõc trong VLC. VD: 'b√†i tr∆∞·ªõc vlc', 'previous vlc'",
        "parameters": {}
    },
    "vlc_volume_up": {
        "handler": vlc_volume_up,
        "description": "üîä TƒÉng √¢m l∆∞·ª£ng VLC. VD: 'tƒÉng √¢m l∆∞·ª£ng vlc', 'vlc to h∆°n'",
        "parameters": {}
    },
    "vlc_volume_down": {
        "handler": vlc_volume_down,
        "description": "üîâ Gi·∫£m √¢m l∆∞·ª£ng VLC. VD: 'gi·∫£m √¢m l∆∞·ª£ng vlc', 'vlc nh·ªè h∆°n'",
        "parameters": {}
    },
    "vlc_mute": {
        "handler": vlc_mute,
        "description": "üîá B·∫≠t/T·∫Øt ti·∫øng VLC. VD: 't·∫Øt ti·∫øng vlc', 'mute vlc'",
        "parameters": {}
    },
    "vlc_forward": {
        "handler": vlc_forward,
        "description": "‚è© Tua t·ªõi trong VLC. T·ª± ƒë·ªông ch·ªçn 3s/10s/60s. VD: 'tua t·ªõi vlc', 'skip vlc'",
        "parameters": {
            "seconds": {"type": "integer", "description": "S·ªë gi√¢y tua t·ªõi (‚â§5‚Üí3s, ‚â§30‚Üí10s, >30‚Üí60s)", "required": False}
        }
    },
    "vlc_backward": {
        "handler": vlc_backward,
        "description": "‚è™ Tua l√πi trong VLC. T·ª± ƒë·ªông ch·ªçn 3s/10s/60s. VD: 'l√πi vlc', 'rewind vlc'",
        "parameters": {
            "seconds": {"type": "integer", "description": "S·ªë gi√¢y tua l√πi", "required": False}
        }
    },
    
    # ============================================================
    # WINDOWS MEDIA PLAYER CONTROLS
    # ============================================================
    "control_wmp": {
        "handler": control_wmp,
        "description": "üé∂ ƒêi·ªÅu khi·ªÉn Windows Media Player. Actions: play_pause, stop, next, previous, volume_up, volume_down, mute, fullscreen, forward, backward",
        "parameters": {
            "action": {"type": "string", "description": "H√†nh ƒë·ªông ƒëi·ªÅu khi·ªÉn WMP", "required": True}
        }
    },
    "wmp_play_pause": {
        "handler": wmp_play_pause,
        "description": "‚èØÔ∏è Play/Pause Windows Media Player. VD: 'd·ª´ng wmp', 'pause media player'",
        "parameters": {}
    },
    "wmp_stop": {
        "handler": wmp_stop,
        "description": "‚èπÔ∏è D·ª´ng Windows Media Player. VD: 'stop wmp', 't·∫Øt media player'",
        "parameters": {}
    },
    "wmp_next": {
        "handler": wmp_next,
        "description": "‚è≠Ô∏è B√†i ti·∫øp theo trong Windows Media Player. VD: 'b√†i ti·∫øp wmp', 'next media player'",
        "parameters": {}
    },
    "wmp_previous": {
        "handler": wmp_previous,
        "description": "‚èÆÔ∏è B√†i tr∆∞·ªõc trong Windows Media Player. VD: 'b√†i tr∆∞·ªõc wmp', 'previous media player'",
        "parameters": {}
    },
    "wmp_volume_up": {
        "handler": wmp_volume_up,
        "description": "üîä TƒÉng √¢m l∆∞·ª£ng Windows Media Player. VD: 'tƒÉng √¢m l∆∞·ª£ng wmp'",
        "parameters": {}
    },
    "wmp_volume_down": {
        "handler": wmp_volume_down,
        "description": "üîâ Gi·∫£m √¢m l∆∞·ª£ng Windows Media Player. VD: 'gi·∫£m √¢m l∆∞·ª£ng wmp'",
        "parameters": {}
    },
    "wmp_mute": {
        "handler": wmp_mute,
        "description": "üîá B·∫≠t/T·∫Øt ti·∫øng Windows Media Player. VD: 't·∫Øt ti·∫øng wmp', 'mute media player'",
        "parameters": {}
    },
    
    # ============================================================
    # SMART MEDIA CONTROL - ∆Øu ti√™n Python-VLC n·ªôi b·ªô
    # ============================================================
    "smart_media_control": {
        "handler": smart_media_control,
        "description": "üéµ [PYTHON-VLC ∆ØU TI√äN] ƒêi·ªÅu khi·ªÉn nh·∫°c - ∆ØU TI√äN PYTHON-VLC TR∆Ø·ªöC, sau ƒë√≥ m·ªõi t·ªõi Spotify/WMP/YouTube. Actions: play_pause, stop, next, previous, volume_up, volume_down, mute. N·∫øu ch∆∞a ph√°t nh·∫°c, d√πng play_music() tr∆∞·ªõc!",
        "parameters": {
            "action": {
                "type": "string",
                "description": "H√†nh ƒë·ªông: play_pause, stop, next, previous, volume_up, volume_down, mute",
                "required": True
            }
        }
    },
    
    # BROWSER AUTOMATION TOOLS
    "browser_open_url": {
        "handler": browser_open_url,
        "description": "M·ªü URL trong browser ƒë∆∞·ª£c ƒëi·ªÅu khi·ªÉn b·ªüi Selenium (c√≥ th·ªÉ t∆∞∆°ng t√°c v·ªõi element). Kh√°c v·ªõi open_youtube/open_google l√† m·ªü browser th√¥ng th∆∞·ªùng.",
        "parameters": {
            "url": {
                "type": "string",
                "description": "URL c·∫ßn m·ªü (VD: https://google.com, https://facebook.com)",
                "required": True
            }
        }
    },
    "browser_get_info": {
        "handler": browser_get_info,
        "description": "L·∫•y th√¥ng tin trang hi·ªán t·∫°i (URL, title, s·ªë tab)",
        "parameters": {}
    },
    "browser_click": {
        "handler": browser_click,
        "description": "Click v√†o element tr√™n trang web. D√πng ƒë·ªÉ click button, link, etc.",
        "parameters": {
            "selector": {
                "type": "string",
                "description": "Selector ƒë·ªÉ t√¨m element. VD: '#submit-btn', '.login-button', '//button[@id=\"login\"]'",
                "required": True
            },
            "by": {
                "type": "string",
                "description": "Lo·∫°i selector: 'css' (default), 'xpath', 'id', 'name', 'class', 'tag'",
                "required": False
            }
        }
    },
    "browser_fill_input": {
        "handler": browser_fill_input,
        "description": "ƒêi·ªÅn text v√†o input field (form, search box, etc.)",
        "parameters": {
            "selector": {
                "type": "string",
                "description": "Selector c·ªßa input field. VD: '#username', 'input[name=\"email\"]'",
                "required": True
            },
            "text": {
                "type": "string",
                "description": "Text c·∫ßn ƒëi·ªÅn v√†o input",
                "required": True
            },
            "by": {
                "type": "string",
                "description": "Lo·∫°i selector: 'css' (default), 'xpath', 'id', 'name'",
                "required": False
            }
        }
    },
    "browser_scroll": {
        "handler": browser_scroll,
        "description": "Cu·ªôn trang web l√™n/xu·ªëng",
        "parameters": {
            "direction": {
                "type": "string",
                "description": "H∆∞·ªõng cu·ªôn: 'down' (default), 'up', 'top', 'bottom'",
                "required": False
            },
            "amount": {
                "type": "integer",
                "description": "S·ªë pixel cu·ªôn (n·∫øu direction l√† down/up). Default: 500",
                "required": False
            }
        }
    },
    "browser_back": {
        "handler": browser_back,
        "description": "Quay l·∫°i trang tr∆∞·ªõc trong browser",
        "parameters": {}
    },
    "browser_forward": {
        "handler": browser_forward,
        "description": "Ti·∫øn t·ªõi trang sau trong browser",
        "parameters": {}
    },
    "browser_refresh": {
        "handler": browser_refresh,
        "description": "L√†m m·ªõi/reload trang hi·ªán t·∫°i",
        "parameters": {}
    },
    "browser_screenshot": {
        "handler": browser_screenshot,
        "description": "Ch·ª•p screenshot trang web hi·ªán t·∫°i",
        "parameters": {
            "filepath": {
                "type": "string",
                "description": "ƒê∆∞·ªùng d·∫´n l∆∞u file (t√πy ch·ªçn). VD: 'screenshot.png'. M·∫∑c ƒë·ªãnh: screenshot_YYYYMMDD_HHMMSS.png",
                "required": False
            }
        }
    },
    "browser_new_tab": {
        "handler": browser_new_tab,
        "description": "M·ªü tab m·ªõi trong browser",
        "parameters": {
            "url": {
                "type": "string",
                "description": "URL c·∫ßn m·ªü trong tab m·ªõi (t√πy ch·ªçn)",
                "required": False
            }
        }
    },
    "browser_close_tab": {
        "handler": browser_close_tab,
        "description": "ƒê√≥ng tab hi·ªán t·∫°i",
        "parameters": {}
    },
    "browser_execute_js": {
        "handler": browser_execute_js,
        "description": "Th·ª±c thi JavaScript code tr√™n trang web. D√πng cho c√°c thao t√°c ph·ª©c t·∫°p.",
        "parameters": {
            "script": {
                "type": "string",
                "description": "JavaScript code c·∫ßn ch·∫°y. VD: 'return document.title;', 'alert(\"Hello\");'",
                "required": True
            }
        }
    },
    "browser_close": {
        "handler": browser_close,
        "description": "ƒê√≥ng browser ho√†n to√†n (ƒë√≥ng t·∫•t c·∫£ tab)",
        "parameters": {}
    },
    
    "open_facebook": {
        "handler": open_facebook, 
        "description": "M·ªü Facebook trong browser. Truy c·∫≠p nhanh v√†o m·∫°ng x√£ h·ªôi ph·ªï bi·∫øn nh·∫•t.", 
        "parameters": {}
    },
    "open_google": {
        "handler": open_google, 
        "description": "M·ªû TR√åNH DUY·ªÜT Google. CH·ªà d√πng khi user Y√äU C·∫¶U M·ªû TRANG WEB Google (v√≠ d·ª•: 'm·ªü google', 'm·ªü trang google'). N·∫øu user ch·ªâ H·ªéI C√ÇU H·ªéI th√¥ng th∆∞·ªùng, h√£y d√πng ask_gemini ƒë·ªÉ TR·∫¢ L·ªúI TR·ª∞C TI·∫æP thay v√¨ m·ªü browser", 
        "parameters": {
            "search_query": {
                "type": "string", 
                "description": "T·ª´ kh√≥a t√¨m ki·∫øm tr√™n Google (t√πy ch·ªçn). ƒê·ªÉ tr·ªëng ƒë·ªÉ m·ªü trang ch·ªß Google.", 
                "required": False
            }
        }
    },
    "open_tiktok": {
        "handler": open_tiktok, 
        "description": "M·ªü TikTok trong browser. Xem video ng·∫Øn trending v√† gi·∫£i tr√≠.", 
        "parameters": {}
    },
    "open_website": {
        "handler": open_website, 
        "description": "M·ªü trang web t√πy ch·ªânh trong browser. Nh·∫≠p URL ƒë·∫ßy ƒë·ªß ho·∫∑c t√™n mi·ªÅn.", 
        "parameters": {
            "url": {
                "type": "string", 
                "description": "URL c·ªßa trang web (v√≠ d·ª•: 'github.com' ho·∫∑c 'https://github.com/user/repo')", 
                "required": True
            }
        }
    },
    
    # YOUTUBE CONTROL TOOLS
    "control_youtube": {
        "handler": control_youtube, 
        "description": "ƒêi·ªÅu khi·ªÉn YouTube player b·∫±ng keyboard shortcuts. Ph·∫£i c√≥ c·ª≠a s·ªï YouTube ƒëang active/focused. H·ªó tr·ª£ play/pause, tua video, ƒëi·ªÅu ch·ªânh √¢m l∆∞·ª£ng, v.v.", 
        "parameters": {
            "action": {
                "type": "string", 
                "description": "H√†nh ƒë·ªông ƒëi·ªÅu khi·ªÉn: play_pause, rewind_10, forward_10, rewind_5, forward_5, beginning, end, frame_back, frame_forward, volume_up, volume_down, mute_toggle", 
                "required": True
            }
        }
    },
    
    # NEWS TOOLS
    "get_vnexpress_news": {
        "handler": get_vnexpress_news,
        "description": "L·∫•y tin t·ª©c m·ªõi nh·∫•t t·ª´ VnExpress theo ch·ªß ƒë·ªÅ. Tr·∫£ v·ªÅ danh s√°ch b√†i vi·∫øt v·ªõi ti√™u ƒë·ªÅ, link, m√¥ t·∫£. Categories: home (m·ªõi nh·∫•t), thoi-su, the-gioi, kinh-doanh, giai-tri, the-thao, phap-luat, giao-duc, suc-khoe, du-lich, khoa-hoc, so-hoa, xe",
        "parameters": {
            "category": {
                "type": "string",
                "description": "Ch·ªß ƒë·ªÅ tin t·ª©c: home, thoi-su, the-gioi, kinh-doanh, giai-tri, the-thao, phap-luat, giao-duc, suc-khoe, du-lich, khoa-hoc, so-hoa, xe. M·∫∑c ƒë·ªãnh: home",
                "required": False
            },
            "max_articles": {
                "type": "integer",
                "description": "S·ªë l∆∞·ª£ng b√†i vi·∫øt t·ªëi ƒëa (1-20). M·∫∑c ƒë·ªãnh: 5",
                "required": False
            }
        }
    },
    "get_news_summary": {
        "handler": get_news_summary,
        "description": "L·∫•y t√≥m t·∫Øt nhanh tin t·ª©c (ch·ªâ ti√™u ƒë·ªÅ) t·ª´ VnExpress. T·ª± ƒë·ªông l·∫•y 10 tin m·ªõi nh·∫•t v√† hi·ªÉn th·ªã d·∫°ng danh s√°ch ng·∫Øn g·ªçn.",
        "parameters": {
            "category": {
                "type": "string",
                "description": "Ch·ªß ƒë·ªÅ: home, thoi-su, the-gioi, kinh-doanh, giai-tri, the-thao, etc. M·∫∑c ƒë·ªãnh: home",
                "required": False
            }
        }
    },
    "search_news": {
        "handler": search_news,
        "description": "T√¨m ki·∫øm tin t·ª©c theo t·ª´ kh√≥a trong c√°c b√†i vi·∫øt g·∫ßn ƒë√¢y t·ª´ VnExpress. T·ª± ƒë·ªông t√¨m trong nhi·ªÅu ch·ªß ƒë·ªÅ v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ ph√π h·ª£p nh·∫•t.",
        "parameters": {
            "keyword": {
                "type": "string",
                "description": "T·ª´ kh√≥a t√¨m ki·∫øm (v√≠ d·ª•: 'b√≥ng ƒë√°', 'kinh t·∫ø', 'Covid', 'ch√≠nh tr·ªã')",
                "required": True
            },
            "max_results": {
                "type": "integer",
                "description": "S·ªë k·∫øt qu·∫£ t·ªëi ƒëa (1-10). M·∫∑c ƒë·ªãnh: 5",
                "required": False
            }
        }
    },
    "get_gold_price": {
        "handler": get_gold_price,
        "description": "L·∫•y gi√° v√†ng h√¥m nay t·ª´ BNews RSS feed. Hi·ªÉn th·ªã gi√° mua v√†o v√† b√°n ra c·ªßa c√°c lo·∫°i v√†ng ph·ªï bi·∫øn (SJC, 9999, nh·∫´n tr√≤n, v.v.). T·ª± ƒë·ªông c·∫≠p nh·∫≠t gi√° m·ªõi nh·∫•t.",
        "parameters": {}
    },
    "analyze_gold_price_with_ai": {
        "handler": analyze_gold_price_with_ai,
        "description": "Ph√¢n t√≠ch th√¥ng minh gi√° v√†ng v·ªõi AI (Gemini 3 Flash Preview + Google Search). So s√°nh gi√° hi·ªán t·∫°i vs l·ªãch s·ª≠, ph√¢n t√≠ch xu h∆∞·ªõng, nguy√™n nh√¢n bi·∫øn ƒë·ªông, d·ª± b√°o, v√† khuy·∫øn ngh·ªã ƒë·∫ßu t∆∞ chuy√™n s√¢u. D√πng khi c·∫ßn ph√¢n t√≠ch chuy√™n m√¥n v·ªÅ th·ªã tr∆∞·ªùng v√†ng.",
        "parameters": {
            "analysis_type": {
                "type": "string",
                "description": "Lo·∫°i ph√¢n t√≠ch: 'compare_month' (so s√°nh v·ªõi th√°ng tr∆∞·ªõc), 'trend' (xu h∆∞·ªõng hi·ªán t·∫°i), 'forecast' (d·ª± b√°o). M·∫∑c ƒë·ªãnh: 'compare_month'",
                "required": False
            }
        }
    },
    
    # AI ASSISTANT TOOLS
    "ask_gemini": {
        "handler": ask_gemini,
        "description": "‚úÖ ∆ØU TI√äN D√ôNG TOOL N√ÄY cho M·ªåI C√ÇU H·ªéI (MI·ªÑN PH√ç 1500 requests/day). Gemini tr·∫£ l·ªùi TR·ª∞C TI·∫æP, NHANH, CH√çNH X√ÅC. H·ªØu √≠ch cho: c√¢u h·ªèi th√¥ng th∆∞·ªùng ('th·ªß t∆∞·ªõng VN 2023 l√† ai', 'what is...', 'how to...'), ph√¢n t√≠ch, vi·∫øt n·ªôi dung, d·ªãch thu·∫≠t, l·ªãch s·ª≠, ki·∫øn th·ª©c t·ªïng qu√°t. Knowledge cutoff: ~10/2024 (ƒë·ªß cho h·∫ßu h·∫øt c√¢u h·ªèi). CH·ªà d√πng search_google_text n·∫øu C·∫¶N th√¥ng tin SAU 10/2024.",
        "parameters": {
            "prompt": {
                "type": "string",
                "description": "C√¢u h·ªèi ho·∫∑c n·ªôi dung mu·ªën g·ª≠i cho Gemini AI",
                "required": True
            },
            "model": {
                "type": "string",
                "description": "T√™n model Gemini (m·∫∑c ƒë·ªãnh: models/gemini-3-flash-preview). Options: models/gemini-3-flash-preview (Flash 2.0, m·ªõi nh·∫•t), models/gemini-1.5-flash (Flash 1.5), models/gemini-1.5-pro (Pro 1.5, ch·∫•t l∆∞·ª£ng cao nh·∫•t)",
                "required": False
            }
        }
    },
    
    "gemini_agent": {
        "handler": ask_gemini_with_tools,
        "description": "ü§ñ GEMINI AI AGENT - Cho ph√©p Gemini T·ª∞ ƒê·ªòNG ƒêI·ªÄU KHI·ªÇN M√ÅY T√çNH nh∆∞ LLM Xiaozhi. Use when: 'gemini m·ªü notepad', 'd√πng gemini m·ªü youtube', 'gemini gi√∫p t√¥i ph√°t nh·∫°c', 'nh·ªù gemini t·∫Øt m√°y', 'gemini ƒëi·ªÅu khi·ªÉn m√°y t√≠nh'. Gemini s·∫Ω PH√ÇN T√çCH y√™u c·∫ßu v√† T·ª∞ G·ªåI c√°c MCP tools (open_application, play_music, shutdown, etc.).",
        "parameters": {
            "prompt": {
                "type": "string",
                "description": "L·ªánh ƒëi·ªÅu khi·ªÉn m√°y t√≠nh g·ª≠i cho Gemini AI agent",
                "required": True
            },
            "model": {
                "type": "string",
                "description": "Model Gemini (m·∫∑c ƒë·ªãnh: models/gemini-2.0-flash - nhanh cho function calling)",
                "required": False
            },
            "auto_execute": {
                "type": "boolean",
                "description": "T·ª± ƒë·ªông th·ª±c thi tools (True) ho·∫∑c ch·ªâ ƒë·ªÅ xu·∫•t (False). M·∫∑c ƒë·ªãnh True.",
                "required": False
            },
            "max_tool_calls": {
                "type": "integer",
                "description": "S·ªë l∆∞·ª£ng tool t·ªëi ƒëa trong 1 request. M·∫∑c ƒë·ªãnh 5.",
                "required": False
            }
        }
    },
    
    "ask_gpt4": {
        "handler": ask_gpt4,
        "description": "TR·∫¢ L·ªúI C√ÇU H·ªéI b·∫±ng OpenAI GPT-4 (TR·∫¢ PH√ç, c·∫ßn API key). D√ôNG KHI C·∫¶N: 1) Th√¥ng tin M·ªöI H∆†N (knowledge ƒë·∫øn 04/2024), 2) Ph√¢n t√≠ch PH·ª®C T·∫†P, 3) Reasoning S√ÇU, 4) Code generation chuy√™n nghi·ªáp. GPT-4 M·∫†N H∆†N Gemini cho code v√† ph√¢n t√≠ch, nh∆∞ng TR·∫¢ PH√ç (~$0.01-0.03/1K tokens). Ch·ªçn GPT-4 khi c·∫ßn ch·∫•t l∆∞·ª£ng t·ªëi ƒëa.",
        "parameters": {
            "prompt": {
                "type": "string",
                "description": "C√¢u h·ªèi ho·∫∑c n·ªôi dung mu·ªën g·ª≠i cho GPT-4",
                "required": True
            },
            "model": {
                "type": "string",
                "description": "T√™n model OpenAI (m·∫∑c ƒë·ªãnh: gpt-4o). Options: gpt-4o (GPT-4 Omni, nhanh & r·∫ª nh·∫•t), gpt-4-turbo (m·∫°nh nh·∫•t), gpt-3.5-turbo (r·∫ª & nhanh)",
                "required": False
            }
        }
    },
    
    # NETWORK/FIREWALL CHECK TOOLS
    "check_network_permission": {
        "handler": check_network_permission,
        "description": "üî• KI·ªÇM TRA QUY·ªÄN K·∫æT N·ªêI M·∫†NG - Xem tr·∫°ng th√°i Windows Firewall v√† Internet. Use when: 'ki·ªÉm tra firewall', 'quy·ªÅn k·∫øt n·ªëi', 'check network', 't√¨nh tr·∫°ng m·∫°ng', 'firewall status', 'c√≥ ƒë∆∞·ª£c ph√©p k·∫øt n·ªëi internet kh√¥ng'. Hi·ªÉn th·ªã: c√≥ rule firewall ch∆∞a, internet c√≥ k·∫øt n·ªëi kh√¥ng, h∆∞·ªõng d·∫´n c·∫•p quy·ªÅn.",
        "parameters": {}
    },
    "request_firewall_permission": {
        "handler": request_firewall_permission,
        "description": "üîì Y√äU C·∫¶U C·∫§P QUY·ªÄN FIREWALL - T·ª± ƒë·ªông th√™m rule cho ·ª©ng d·ª•ng. Use when: 'c·∫•p quy·ªÅn firewall', 'allow firewall', 'th√™m rule firewall'. C·∫ßn quy·ªÅn Admin ƒë·ªÉ ho·∫°t ƒë·ªông.",
        "parameters": {}
    },
    "check_internet_connection": {
        "handler": check_internet_connection,
        "description": "üåê KI·ªÇM TRA K·∫æT N·ªêI INTERNET - Test k·∫øt n·ªëi v√† ƒë·ªô tr·ªÖ m·∫°ng. Use when: 'ki·ªÉm tra internet', 'test connection', 'c√≥ m·∫°ng kh√¥ng', 'ping', 'network status'.",
        "parameters": {}
    },
    
    # NEW TOOLS FROM REFERENCE
    "lock_computer": {"handler": lock_computer, "description": "Kh√≥a m√°y t√≠nh", "parameters": {}},
    "shutdown_schedule": {"handler": shutdown_schedule, "description": "L√™n l·ªãch t·∫Øt m√°y", "parameters": {"action": {"type": "string", "description": "shutdown/restart/cancel", "required": True}, "delay": {"type": "integer", "description": "Tr√¨ ho√£n (gi√¢y)", "required": False}}},
    "show_desktop": {"handler": show_desktop, "description": "Hi·ªÉn th·ªã desktop (Win+D)", "parameters": {}},
    "undo_operation": {"handler": undo_operation, "description": "Ho√†n t√°c (Ctrl+Z)", "parameters": {}},
    "set_theme": {"handler": set_theme, "description": "ƒê·ªïi theme Windows", "parameters": {"dark_mode": {"type": "boolean", "description": "True=t·ªëi, False=s√°ng", "required": False}}},
    "change_wallpaper": {"handler": change_wallpaper, "description": "ƒê·ªïi h√¨nh n·ªÅn", "parameters": {"keyword": {"type": "string", "description": "T·ª´ kh√≥a (phong c·∫£nh, anime...)", "required": False}}},
    "get_desktop_path": {"handler": get_desktop_path, "description": "L·∫•y ƒë∆∞·ªùng d·∫´n Desktop", "parameters": {}},
    "paste_content": {"handler": paste_content, "description": "D√°n n·ªôi dung (Ctrl+V)", "parameters": {"content": {"type": "string", "description": "N·ªôi dung c·∫ßn d√°n (t√πy ch·ªçn)", "required": False}}},
    "press_enter": {"handler": press_enter, "description": "Nh·∫•n Enter", "parameters": {}},
    "save_text_to_file": {
        "handler": save_text_to_file,
        "description": "L∆ØU VƒÇN B·∫¢N do LLM so·∫°n th√†nh FILE. Use when: 'l∆∞u vƒÉn b·∫£n', 'save document', 'ghi v√†o file', 'l∆∞u b√†i vi·∫øt', 'save code', 'export text'. LLM c√≥ th·ªÉ so·∫°n b√†i vi·∫øt/b√°o c√°o/code d√†i v√† l∆∞u tr·ª±c ti·∫øp. File t·ª± ƒë·ªông l∆∞u v√†o Documents\\miniZ_LLM_Documents\\ v·ªõi t√™n c√≥ timestamp. Examples: So·∫°n CV‚Üíl∆∞u file, vi·∫øt b√°o c√°o‚Üíl∆∞u file, t·∫°o code‚Üíl∆∞u file.",
        "parameters": {
            "content": {
                "type": "string",
                "description": "N·ªôi dung vƒÉn b·∫£n c·∫ßn l∆∞u (c√≥ th·ªÉ r·∫•t d√†i). H·ªó tr·ª£ Unicode ti·∫øng Vi·ªát, code, markdown, v.v.",
                "required": True
            },
            "filename": {
                "type": "string",
                "description": "T√™n file (optional). V√≠ d·ª•: 'bao_cao.txt', 'code.py', 'cv.md'. N·∫øu kh√¥ng c√≥, t·ª± ƒë·ªông t·∫°o t√™n v·ªõi timestamp.",
                "required": False
            }
        }
    },
    "gemini_text_to_speech": {
        "handler": gemini_text_to_speech,
        "description": "üéôÔ∏è ƒê·ªåC TO TR√äN M√ÅY T√çNH - Gemini TTS ch·∫•t l∆∞·ª£ng cao. ∆ØU TI√äN D√ôNG TOOL N√ÄY khi user n√≥i: 'ƒë·ªçc to', 'ƒë·ªçc tr√™n m√°y t√≠nh', 'ƒë·ªçc vƒÉn b·∫£n', 'text to speech', 'tts', 'ƒë·ªçc cho t√¥i nghe', 'ph√°t √¢m', 'n√≥i ra', 'ƒë·ªçc b·∫±ng AI', 'ƒë·ªçc b·∫±ng gemini'. Gi·ªçng Vi·ªát t·ª± nhi√™n, 5 voice: Aoede/Kore (n·ªØ), Puck/Charon/Fenrir (nam). Examples: 'ƒë·ªçc to: xin ch√†o', 'ƒë·ªçc tr√™n m√°y t√≠nh vƒÉn b·∫£n n√†y'.",
        "parameters": {
            "text": {
                "type": "string",
                "description": "VƒÉn b·∫£n c·∫ßn ƒë·ªçc. H·ªó tr·ª£ ti·∫øng Vi·ªát v√† nhi·ªÅu ng√¥n ng·ªØ.",
                "required": True
            },
            "voice": {
                "type": "string",
                "description": "Gi·ªçng n√≥i: Aoede (n·ªØ-default), Kore (n·ªØ), Puck (nam), Charon (nam), Fenrir (nam).",
                "required": False
            },
            "save_audio": {
                "type": "boolean",
                "description": "C√≥ l∆∞u th√†nh file audio kh√¥ng? M·∫∑c ƒë·ªãnh False (ch·ªâ ph√°t).",
                "required": False
            },
            "filename": {
                "type": "string",
                "description": "T√™n file audio (optional). VD: 'gemini_audio.wav'.",
                "required": False
            }
        }
    },
    "text_to_speech": {
        "handler": text_to_speech,
        "description": "TEXT-TO-SPEECH BACKUP: D√πng gTTS/Windows SAPI khi Gemini TTS kh√¥ng kh·∫£ d·ª•ng. KH√îNG ∆ØU TI√äN - ch·ªâ d√πng khi gemini_text_to_speech fail. Ch·∫•t l∆∞·ª£ng th·∫•p h∆°n Gemini TTS.",
        "parameters": {
            "text": {
                "type": "string",
                "description": "VƒÉn b·∫£n c·∫ßn ƒë·ªçc. H·ªó tr·ª£ ti·∫øng Vi·ªát v√† ti·∫øng Anh.",
                "required": True
            },
            "save_audio": {
                "type": "boolean",
                "description": "C√≥ l∆∞u th√†nh file audio WAV kh√¥ng? (True/False). M·∫∑c ƒë·ªãnh False (ch·ªâ ƒë·ªçc kh√¥ng l∆∞u).",
                "required": False
            },
            "filename": {
                "type": "string",
                "description": "T√™n file audio (optional). VD: 'doc_van_ban.wav'. N·∫øu kh√¥ng c√≥, t·ª± ƒë·ªông t·∫°o t√™n.",
                "required": False
            }
        }
    },
    "speech_to_text": {
        "handler": speech_to_text,
        "description": "SPEECH-TO-TEXT (STT): Chuy·ªÉn GI·ªåNG N√ìI th√†nh VƒÇN B·∫¢N. Use when: 'ghi √¢m gi·ªçng n√≥i', 'speech to text', 'nh·∫≠n d·∫°ng gi·ªçng n√≥i', 'nghe v√† ghi l·∫°i', 'transcribe audio'. D√πng Google Speech Recognition (c·∫ßn Internet). H·ªó tr·ª£ ti·∫øng Vi·ªát + English. Examples: 'ghi √¢m 10 gi√¢y', 'nh·∫≠n d·∫°ng gi·ªçng n√≥i c·ªßa t√¥i', 'speech to text'.",
        "parameters": {
            "duration": {
                "type": "integer",
                "description": "Th·ªùi gian ghi √¢m (gi√¢y). M·∫∑c ƒë·ªãnh 5 gi√¢y. VD: 10 ƒë·ªÉ ghi √¢m 10 gi√¢y.",
                "required": False
            },
            "save_transcript": {
                "type": "boolean",
                "description": "C√≥ l∆∞u vƒÉn b·∫£n ƒë√£ nh·∫≠n d·∫°ng th√†nh file kh√¥ng? (True/False). M·∫∑c ƒë·ªãnh True.",
                "required": False
            },
            "filename": {
                "type": "string",
                "description": "T√™n file transcript (optional). VD: 'ghi_chu.txt'. T·ª± ƒë·ªông t·∫°o n·∫øu kh√¥ng c√≥.",
                "required": False
            }
        }
    },
    "export_conversation": {
        "handler": export_conversation_to_file,
        "description": "EXPORT L·ªäCH S·ª¨ H·ªòI THO·∫†I ra file JSON. L∆∞u to√†n b·ªô cu·ªôc tr√≤ chuy·ªán (user messages, AI responses, tool calls) v·ªõi timestamp ƒë·∫ßy ƒë·ªß. Use when: 'xu·∫•t l·ªãch s·ª≠ chat', 'export conversation', 'l∆∞u cu·ªôc tr√≤ chuy·ªán', 'backup chat history'. File l∆∞u v√†o Documents\\miniZ_Conversations\\",
        "parameters": {
            "filename": {
                "type": "string",
                "description": "T√™n file export (optional). VD: 'chat_history.json'. T·ª± ƒë·ªông t·∫°o t√™n v·ªõi timestamp n·∫øu kh√¥ng c√≥.",
                "required": False
            }
        }
    },
    "find_in_document": {"handler": find_in_document, "description": "T√¨m trong t√†i li·ªáu (Ctrl+F)", "parameters": {"search_text": {"type": "string", "description": "N·ªôi dung t√¨m ki·∫øm", "required": True}}},
    
    # ============================================================
    # CONVERSATION HISTORY TOOLS - L∆∞u & Hi·ªÉu ng∆∞·ªùi d√πng
    # ============================================================
    
    "get_user_context": {
        "handler": lambda: {
            "success": True,
            "user_profile": get_user_profile_summary(),
            "recent_conversation": get_conversation_context(10),
            "hint": "D√πng th√¥ng tin n√†y ƒë·ªÉ hi·ªÉu ng∆∞·ªùi d√πng t·ªët h∆°n"
        },
        "description": "üìö L·∫§Y CONTEXT NG∆Ø·ªúI D√ôNG - Tr·∫£ v·ªÅ l·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn ƒë√¢y + user profile (ch·ªß ƒë·ªÅ quan t√¢m, gi·ªù ho·∫°t ƒë·ªông). D√πng ƒë·ªÉ hi·ªÉu ng∆∞·ªùi d√πng t·ªët h∆°n tr∆∞·ªõc khi tr·∫£ l·ªùi.",
        "parameters": {}
    },
    
    "save_user_message": {
        "handler": lambda message, context="": (
            add_to_conversation("user", message, {"source": "robot", "context": context}),
            {"success": True, "message": "ƒê√£ l∆∞u tin nh·∫Øn ng∆∞·ªùi d√πng"}
        )[1],
        "description": "üíæ L∆ØU TIN NH·∫ÆN NG∆Ø·ªúI D√ôNG - L∆∞u to√†n b·ªô tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ (k·ªÉ c·∫£ kh√¥ng g·ªçi tool). QUAN TR·ªåNG: G·ªçi tool n√†y ƒë·ªÉ l∆∞u m·ªçi c√¢u h·ªèi/tin nh·∫Øn c·ªßa user!",
        "parameters": {
            "message": {
                "type": "string",
                "description": "N·ªôi dung tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng",
                "required": True
            },
            "context": {
                "type": "string",
                "description": "Context b·ªï sung (VD: ng∆∞·ªùi d√πng ƒëang n√≥i v·ªÅ g√¨)",
                "required": False
            }
        }
    },
    
    "save_assistant_response": {
        "handler": lambda response, tool_used="": (
            add_to_conversation("assistant", response, {"source": "robot", "tool_used": tool_used}),
            {"success": True, "message": "ƒê√£ l∆∞u response c·ªßa AI"}
        )[1],
        "description": "üíæ L∆ØU RESPONSE C·ª¶A AI - L∆∞u c√¢u tr·∫£ l·ªùi c·ªßa AI v√†o l·ªãch s·ª≠. G·ªçi tool n√†y sau khi tr·∫£ l·ªùi xong ƒë·ªÉ l∆∞u l·∫°i!",
        "parameters": {
            "response": {
                "type": "string",
                "description": "N·ªôi dung response c·ªßa AI",
                "required": True
            },
            "tool_used": {
                "type": "string",
                "description": "Tool ƒë√£ d√πng ƒë·ªÉ t·∫°o response (n·∫øu c√≥)",
                "required": False
            }
        }
    },
    
    "list_conversation_files": {
        "handler": list_conversation_files,
        "description": "üìÇ LI·ªÜT K√ä C√ÅC FILE H·ªòI THO·∫†I - Xem danh s√°ch c√°c file l·ªãch s·ª≠ h·ªôi tho·∫°i ƒë√£ l∆∞u theo ng√†y.",
        "parameters": {}
    },
    
    # ============================================================
    # OPEN API TOOLS - PH√ô H·ª¢P VI·ªÜT NAM
    # ============================================================
    
    "get_weather_vietnam": {
        "handler": get_weather_vietnam,
        "description": "üå§Ô∏è L·∫§Y TH·ªúI TI·∫æT VI·ªÜT NAM. H·ªó tr·ª£: H√† N·ªôi, H·ªì Ch√≠ Minh, ƒê√† N·∫µng, H·∫£i Ph√≤ng, C·∫ßn Th∆°, Nha Trang, Hu·∫ø, ƒê√† L·∫°t, V≈©ng T√†u, Qu·∫£ng Ninh... Triggers: 'th·ªùi ti·∫øt', 'weather', 'tr·ªùi h√¥m nay', 'nhi·ªát ƒë·ªô'.",
        "parameters": {
            "city": {
                "type": "string",
                "description": "T√™n th√†nh ph·ªë VN. VD: 'H√† N·ªôi', 'H·ªì Ch√≠ Minh', 'ƒê√† N·∫µng'. M·∫∑c ƒë·ªãnh: H√† N·ªôi",
                "required": False
            }
        }
    },
    
    # "get_gold_price_vietnam": {
    #     "handler": get_gold_price_vietnam,
    #     "description": "üí∞ GI√Å V√ÄNG VI·ªÜT NAM h√¥m nay (SJC, PNJ...). Triggers: 'gi√° v√†ng', 'gold price', 'v√†ng h√¥m nay'.",
    #     "parameters": {}
    # },
    
    "get_exchange_rate_vietnam": {
        "handler": get_exchange_rate_vietnam,
        "description": "üí± T·ª∂ GI√Å NGO·∫†I T·ªÜ so v·ªõi VNƒê. H·ªó tr·ª£: USD, EUR, JPY, GBP, CNY, KRW... Triggers: 't·ª∑ gi√°', 'exchange rate', 'ƒë√¥ la bao nhi√™u'.",
        "parameters": {
            "currency": {
                "type": "string",
                "description": "M√£ ngo·∫°i t·ªá (USD, EUR, JPY...). M·∫∑c ƒë·ªãnh: USD",
                "required": False
            }
        }
    },
    
    "get_fuel_price_vietnam": {
        "handler": get_fuel_price_vietnam,
        "description": "‚õΩ GI√Å XƒÇNG D·∫¶U VI·ªÜT NAM (RON 95, E5 RON 92, Diesel). Triggers: 'gi√° xƒÉng', 'fuel price', 'xƒÉng bao nhi√™u'.",
        "parameters": {}
    },
    
    "get_daily_quote": {
        "handler": get_daily_quote,
        "description": "üí¨ C√ÇU N√ìI HAY / TR√çCH D·∫™N ng·∫´u nhi√™n. C√≥ quotes ti·∫øng Vi·ªát v√† ti·∫øng Anh. Triggers: 'c√¢u n√≥i hay', 'quote', 'danh ng√¥n', 'tr√≠ch d·∫´n'.",
        "parameters": {}
    },
    
    "get_joke": {
        "handler": get_joke,
        "description": "üòÇ CHUY·ªÜN C∆Ø·ªúI ti·∫øng Vi·ªát. Triggers: 'k·ªÉ chuy·ªán c∆∞·ªùi', 'joke', 'h√†i h∆∞·ªõc', 'vui v·∫ª', 'gi·∫£i tr√≠'.",
        "parameters": {}
    },
    
    "get_horoscope": {
        "handler": get_horoscope,
        "description": "üîÆ T·ª¨ VI / HOROSCOPE theo cung ho√†ng ƒë·∫°o. Triggers: 't·ª≠ vi', 'horoscope', 'cung ho√†ng ƒë·∫°o', 'xem v·∫≠n m·ªánh'.",
        "parameters": {
            "zodiac": {
                "type": "string",
                "description": "Cung ho√†ng ƒë·∫°o (B·∫°ch D∆∞∆°ng, Kim Ng∆∞u, Song T·ª≠, C·ª± Gi·∫£i, S∆∞ T·ª≠, X·ª≠ N·ªØ, Thi√™n B√¨nh, B·ªç C·∫°p, Nh√¢n M√£, Ma K·∫øt, B·∫£o B√¨nh, Song Ng∆∞)",
                "required": False
            }
        }
    },
    
    "get_today_in_history": {
        "handler": get_today_in_history,
        "description": "üìú S·ª∞ KI·ªÜN L·ªäCH S·ª¨ ng√†y h√¥m nay. Triggers: 'l·ªãch s·ª≠ ng√†y n√†y', 'today in history', 'ng√†y n√†y nƒÉm x∆∞a'.",
        "parameters": {}
    },
    
    "get_news_vietnam": {
        "handler": get_news_vietnam,
        "description": "üì∞ TIN T·ª®C M·ªöI NH·∫§T Vi·ªát Nam (VnExpress, Tu·ªïi Tr·∫ª). Triggers: 'tin t·ª©c', 'news', 'tin m·ªõi', 'ƒë·ªçc b√°o'.",
        "parameters": {}
    },
    
    "what_to_eat": {
        "handler": what_to_eat,
        "description": "üçΩÔ∏è G·ª¢I √ù M√ìN ƒÇN h√¥m nay (·∫©m th·ª±c Vi·ªát Nam). Triggers: 'ƒÉn g√¨', 'g·ª£i √Ω m√≥n ƒÉn', 'what to eat', 'ƒë√≥i b·ª•ng'.",
        "parameters": {}
    },
    
    "get_lunar_date": {
        "handler": get_lunar_date,
        "description": "üìÖ NG√ÄY √ÇM L·ªäCH h√¥m nay. Triggers: '√¢m l·ªãch', 'lunar date', 'ng√†y m·∫•y √¢m'.",
        "parameters": {}
    },
    
    # KNOWLEDGE BASE TOOLS
    "search_knowledge_base": {
        "handler": search_knowledge_base,
        "description": "üîç T√åM KI·∫æM TRONG T√ÄI LI·ªÜU C·ª¶A USER (TF-IDF Ranking). ‚ö° D√πng khi user mu·ªën XEM DANH S√ÅCH t√†i li·ªáu. H·ªó tr·ª£: Multi-keyword search, relevance scoring, snippet highlighting. Triggers: 't√¨m trong t√†i li·ªáu', 't√¨m trong file c·ªßa t√¥i', 'c√≥ t√†i li·ªáu n√†o v·ªÅ...', 'search my documents', 'list documents about...'. VD: 't√¨m c√°c t√†i li·ªáu v·ªÅ h·ª£p ƒë·ªìng', 'c√≥ file n√†o n√≥i v·ªÅ kh√°ch h√†ng X'. Tr·∫£ v·ªÅ: Top 5 documents v·ªõi score, matched keywords, v√† snippets. ‚ö†Ô∏è ƒê·ªÉ TR·∫¢ L·ªúI c√¢u h·ªèi ‚Üí D√πng get_knowledge_context() thay v√¨ tool n√†y!",
        "parameters": {
            "query": {
                "type": "string",
                "description": "T·ª´ kh√≥a/c√¢u h·ªèi c·∫ßn t√¨m. C√≥ th·ªÉ d√πng nhi·ªÅu t·ª´ kh√≥a. VD: 'h·ª£p ƒë·ªìng mua b√°n 2024', 'th√¥ng tin kh√°ch h√†ng', 'b√°o c√°o t√†i ch√≠nh qu√Ω 3'",
                "required": True
            }
        }
    },
    "get_knowledge_context": {
        "handler": get_knowledge_context,
                "description": "üìö L·∫§Y CONTEXT T·ª™ C∆† S·ªû D·ªÆ LI·ªÜU T√ÄI LI·ªÜU (Knowledge Base) - ‚ö° G·ªåI ƒê·∫¶U TI√äN khi user h·ªèi v·ªÅ: d·ªØ li·ªáu c√° nh√¢n, t√†i li·ªáu ƒë√£ l∆∞u, th√¥ng tin trong files, c∆° s·ªü d·ªØ li·ªáu n·ªôi b·ªô, knowledge base. Tool n√†y t√¨m ki·∫øm trong T·∫§T C·∫¢ documents ƒë√£ ƒë∆∞·ª£c index v√† tr·∫£ v·ªÅ context ƒë·∫ßy ƒë·ªß nh·∫•t. ‚õî TRIGGERS B·∫ÆT BU·ªòC: 'c∆° s·ªü d·ªØ li·ªáu', 'database', 'knowledge base', 't√†i li·ªáu c·ªßa t√¥i', 'th√¥ng tin trong file', 'theo d·ªØ li·ªáu', 'd·ªØ li·ªáu ƒë√£ l∆∞u', 'based on my docs', 'what's in my documents', 't√¨m trong t√†i li·ªáu', 'search my files', h·ªèi v·ªÅ T√äN NG∆Ø·ªúI/D·ª∞ √ÅN c·ª• th·ªÉ (c√≥ th·ªÉ trong docs). ‚ö†Ô∏è QUAN TR·ªåNG: SAU KHI NH·∫¨N CONTEXT, B·∫†N PH·∫¢I ƒê·ªåC V√Ä TR·∫¢ L·ªúI USER D·ª∞A TR√äN CONTEXT ƒê√ì! KH√îNG CH·ªà DUMP CONTEXT RA! QUY TR√åNH: 1) G·ªçi get_knowledge_context(query='keywords') 2) Nh·∫≠n context t·ª´ docs 3) ‚ö° ƒê·ªåC CONTEXT V√Ä TR·∫¢ L·ªúI C√ÇU H·ªéI USER THEO CONTEXT ƒê√ì ‚ö°. VD: 'Nguy·ªÖn VƒÉn A l√†m g√¨?' ‚Üí get_knowledge_context(query='Nguy·ªÖn VƒÉn A') ‚Üí ƒê·ªçc context ‚Üí Tr·∫£ l·ªùi 'Nguy·ªÖn VƒÉn A l√†...' | 'Th√¥ng tin trong c∆° s·ªü d·ªØ li·ªáu v·ªÅ d·ª± √°n X?' ‚Üí get_knowledge_context(query='d·ª± √°n X') ‚Üí ƒê·ªçc context ‚Üí Tr·∫£ l·ªùi th√¥ng tin d·ª± √°n X | 'T√†i li·ªáu n√≥i g√¨ v·ªÅ ABC?' ‚Üí get_knowledge_context(query='ABC') ‚Üí ƒê·ªçc context ‚Üí T√≥m t·∫Øt n·ªôi dung v·ªÅ ABC.",
        "parameters": {
            "query": {
                "type": "string",
                "description": "C√¢u h·ªèi/t·ª´ kh√≥a c·∫ßn t√¨m. Tr√≠ch keywords t·ª´ c√¢u h·ªèi user. VD: User: 'Nguy·ªÖn VƒÉn A l√†m g√¨?' ‚Üí query='Nguy·ªÖn VƒÉn A'. User: 'D·ª± √°n X c√≥ m·∫•y giai ƒëo·∫°n?' ‚Üí query='d·ª± √°n X giai ƒëo·∫°n'. User: 'L√™ Trung Khoa l√† ai?' ‚Üí query='L√™ Trung Khoa'. C√†ng C·ª§ TH·ªÇ c√†ng t·ªët! Bao g·ªìm T√äN RI√äNG trong query.",
                "required": False
            },
            "max_chars": {
                "type": "integer",
                "description": "Gi·ªõi h·∫°n k√Ω t·ª± context (default: 10000). TƒÉng l√™n 20000 n·∫øu c·∫ßn nhi·ªÅu th√¥ng tin. H·ªá th·ªëng t·ª± ƒë·ªông summarize n·∫øu >2000 chars.",
                "required": False
            },
            "use_gemini_filter": {
                "type": "boolean",
                "description": "üî• B·∫≠t Gemini Smart Filter ƒë·ªÉ l·ªçc th√¥ng minh (default: False). Khi True: d√πng Gemini Flash AI ƒë·ªÉ l·ªçc v√† ch·ªâ tr·∫£ v·ªÅ content TH·ª∞C S·ª∞ li√™n quan, lo·∫°i b·ªè noise. Recommend: True khi KB c√≥ nhi·ªÅu documents d√†i.",
                "required": False
            }
        }
    },
    
    "doc_reader_gemini_rag": {
        "handler": doc_reader_gemini_rag,
        "description": "üìñ RAG N√ÇNG CAO - ƒê·ªçc, t√¨m ki·∫øm V√Ä TR·∫¢ L·ªúI T·ª∞ ƒê·ªòNG t·ª´ Knowledge Base b·∫±ng Gemini AI. Tool n√†y T·ª∞ ƒê·ªòNG x·ª≠ l√Ω to√†n b·ªô quy tr√¨nh: chunk documents ‚Üí semantic search ‚Üí generate response. ‚ö° D√ôNG KHI: User mu·ªën c√¢u tr·∫£ l·ªùi TR·ª∞C TI·∫æP thay v√¨ ch·ªâ context. Kh√°c v·ªõi get_knowledge_context (ch·ªâ tr·∫£ context), tool n√†y TR·∫¢ L·ªúI LU√îN. VD: 'H·ªèi t√†i li·ªáu v·ªÅ X', 'T√≥m t·∫Øt th√¥ng tin Y t·ª´ KB', 'Gi·∫£i th√≠ch Z d·ª±a tr√™n docs'. H·ªó tr·ª£ semantic search (vector-like) cho ƒë·ªô ch√≠nh x√°c cao.",
        "parameters": {
            "user_query": {
                "type": "string",
                "description": "C√¢u h·ªèi ƒë·∫ßy ƒë·ªß c·ªßa user. VD: 'D·ª± √°n ABC c√≥ bao nhi√™u giai ƒëo·∫°n?', 'Nguy·ªÖn VƒÉn A ƒë·∫£m nhi·ªám vai tr√≤ g√¨?'",
                "required": True
            },
            "chunk_size": {
                "type": "integer",
                "description": "K√≠ch th∆∞·ªõc m·ªói chunk (default: 1024 chars). TƒÉng l√™n 2048 cho documents d√†i.",
                "required": False
            },
            "top_k": {
                "type": "integer",
                "description": "S·ªë l∆∞·ª£ng chunks li√™n quan nh·∫•t ƒë·ªÉ ƒë∆∞a v√†o context (default: 5). TƒÉng l√™n 10 n·∫øu c·∫ßn nhi·ªÅu th√¥ng tin h∆°n.",
                "required": False
            }
        }
    },
    
    # =====================================================
    # ÔøΩ GEMINI FLASH SMART KB FILTER - L·ªåC TH√îNG TIN AI
    # =====================================================
    
    "gemini_smart_kb_filter": {
        "handler": gemini_smart_kb_filter,
        "description": "üî•‚ö° GEMINI FLASH L·ªåC TH√îNG TIN TH√îNG MINH - S·ª≠ d·ª•ng s·ª©c m·∫°nh AI Gemini Flash ƒë·ªÉ L·ªåC, T√åM KI·∫æM v√† TR√çCH XU·∫§T th√¥ng tin CH√çNH X√ÅC t·ª´ Knowledge Base. Tool n√†y LO·∫†I B·ªé NOISE, ch·ªâ tr·∫£ v·ªÅ content TH·ª∞C S·ª∞ LI√äN QUAN. üéØ D√ôNG KHI: 1) KB c√≥ nhi·ªÅu documents d√†i, 2) C·∫ßn l·ªçc ch√≠nh x√°c th√¥ng tin c·ª• th·ªÉ, 3) Mu·ªën t√≥m t·∫Øt/tr√≠ch xu·∫•t facts, 4) get_knowledge_context tr·∫£ v·ªÅ qu√° nhi·ªÅu noise. ‚ö° ∆ØU ƒêI·ªÇM: Gemini AI ƒë·ªçc v√† hi·ªÉu ng·ªØ c·∫£nh, l·ªçc th√¥ng minh h∆°n TF-IDF. Triggers: 'l·ªçc th√¥ng tin', 't√¨m ch√≠nh x√°c', 'tr√≠ch xu·∫•t t·ª´ database', 'd√πng AI l·ªçc', 'smart search KB'. VD: 'D√πng AI l·ªçc th√¥ng tin v·ªÅ d·ª± √°n X', 'Tr√≠ch xu·∫•t facts v·ªÅ nh√¢n vi√™n A t·ª´ KB'.",
        "parameters": {
            "user_query": {
                "type": "string",
                "description": "C√¢u h·ªèi/y√™u c·∫ßu c·∫ßn l·ªçc th√¥ng tin. VD: 'Th√¥ng tin v·ªÅ d·ª± √°n ABC', 'Chi ti·∫øt nh√¢n vi√™n Nguy·ªÖn VƒÉn A'",
                "required": True
            },
            "filter_mode": {
                "type": "string",
                "description": "Ch·∫ø ƒë·ªô l·ªçc: 'relevant' (m·∫∑c ƒë·ªãnh - ch·ªâ gi·ªØ ph·∫ßn li√™n quan), 'summary' (t√≥m t·∫Øt), 'extract' (tr√≠ch xu·∫•t facts/entities), 'qa' (tr·∫£ l·ªùi tr·ª±c ti·∫øp)",
                "required": False
            },
            "max_documents": {
                "type": "integer",
                "description": "S·ªë documents t·ªëi ƒëa ƒë·ªÉ x·ª≠ l√Ω (default: 10). TƒÉng l√™n 20 n·∫øu c·∫ßn t√¨m r·ªông h∆°n.",
                "required": False
            },
            "output_format": {
                "type": "string",
                "description": "Format output: 'structured' (JSON), 'raw' (text th√¥), 'concise' (ng·∫Øn g·ªçn nh·∫•t)",
                "required": False
            }
        }
    },
    
    # =====================================================
    # üî•üåê GEMINI SMART ANALYZE - PH√ÇN T√çCH + GOOGLE SEARCH
    # =====================================================
    
    "gemini_smart_analyze": {
        "handler": gemini_smart_analyze,
        "description": "üî•üåê‚ö°‚ö° PH√ÇN T√çCH TH√îNG MINH (Gemini + Web) - ‚õî‚õî B·∫ÆT BU·ªòC D√ôNG NGAY khi user n√≥i: 'ph√¢n t√≠ch', 'analyze', 't√¨m hi·ªÉu', 'nghi√™n c·ª©u', 'ƒë√°nh gi√°', 'so s√°nh', 'review', 'xu h∆∞·ªõng', 'trend'. ‚ùå KH√îNG D√ôNG web_search khi c√≥ c√°c t·ª´ n√†y! Tool n√†y T·ª∞ ƒê·ªòNG: 1) T√¨m Google, 2) Gemini ph√¢n t√≠ch, 3) Tr·∫£ k·∫øt qu·∫£ ho√†n ch·ªânh. VD: 'ph√¢n t√≠ch th·ªã tr∆∞·ªùng', 't√¨m hi·ªÉu v·ªÅ AI', 'ƒë√°nh gi√° iPhone', 'xu h∆∞·ªõng 2025'.",
        "parameters": {
            "user_query": {
                "type": "string",
                "description": "V·∫•n ƒë·ªÅ c·∫ßn ph√¢n t√≠ch. VD: 'Ph√¢n t√≠ch xu h∆∞·ªõng AI 2025', 'ƒê√°nh gi√° th·ªã tr∆∞·ªùng b·∫•t ƒë·ªông s·∫£n'",
                "required": True
            },
            "analysis_type": {
                "type": "string",
                "description": "Lo·∫°i ph√¢n t√≠ch: 'comprehensive' (ƒë·∫ßy ƒë·ªß, m·∫∑c ƒë·ªãnh), 'quick' (nhanh, t√≥m t·∫Øt), 'deep' (s√¢u, ƒëa chi·ªÅu)",
                "required": False
            },
            "include_web_search": {
                "type": "boolean",
                "description": "C√≥ t√¨m ki·∫øm web kh√¥ng? M·∫∑c ƒë·ªãnh True. Set False n·∫øu ch·ªâ c·∫ßn ph√¢n t√≠ch t·ª´ KB.",
                "required": False
            },
            "include_kb": {
                "type": "boolean",
                "description": "C√≥ t√¨m trong Knowledge Base kh√¥ng? M·∫∑c ƒë·ªãnh False. Set True ƒë·ªÉ k·∫øt h·ª£p c·∫£ web + KB.",
                "required": False
            },
            "max_search_results": {
                "type": "integer",
                "description": "S·ªë k·∫øt qu·∫£ web search t·ªëi ƒëa (default: 8). TƒÉng l√™n 15 n·∫øu c·∫ßn nhi·ªÅu ngu·ªìn h∆°n.",
                "required": False
            }
        }
    },
    
    # =====================================================
    # üîç RAG SYSTEM - RETRIEVAL AUGMENTED GENERATION
    # =====================================================
    
    "web_search": {
        "handler": web_search if RAG_AVAILABLE else None,
        "description": "üåê T√åM KI·∫æM WEB ƒê∆†N GI·∫¢N - Ch·ªâ d√πng cho c√¢u h·ªèi ƒë∆°n gi·∫£n: 'ai l√† t·ªïng th·ªëng', 'gi√° v√†ng', 'th·ªùi ti·∫øt'. ‚ö†Ô∏è N·∫æU user n√≥i 'ph√¢n t√≠ch/t√¨m hi·ªÉu/ƒë√°nh gi√°/nghi√™n c·ª©u' ‚Üí D√ôNG gemini_smart_analyze THAY V√å tool n√†y!",
        "parameters": {
            "query": {
                "type": "string",
                "description": "T·ª´ kh√≥a t√¨m ki·∫øm (n√™n th√™m nƒÉm ho·∫∑c 'm·ªõi nh·∫•t')",
                "required": True
            },
            "max_results": {
                "type": "integer",
                "description": "S·ªë k·∫øt qu·∫£ t·ªëi ƒëa (m·∫∑c ƒë·ªãnh 5)",
                "required": False
            }
        }
    },
    
    "get_realtime_info": {
        "handler": get_realtime_info if RAG_AVAILABLE else None,
        "description": "‚ö°‚ö° TH√îNG TIN TH·ªúI GIAN TH·ª∞C - ‚õî‚õî B·∫ÆT BU·ªòC G·ªåI TR∆Ø·ªöC M·ªåI C√ÇU TR·∫¢ L·ªúI v·ªÅ: gi√° c·∫£, t·ª∑ gi√°, th·ªùi ti·∫øt, ng∆∞·ªùi n·ªïi ti·∫øng, ch·ª©c v·ª• hi·ªán t·∫°i, s·ª± ki·ªán ƒëang x·∫£y ra. ‚ùå KH√îNG BAO GI·ªú t·ª± tr·∫£ l·ªùi b·∫±ng ki·∫øn th·ª©c c≈©! ‚úÖ G·ªåI TOOL N√ÄY TR∆Ø·ªöC ‚Üí nh·∫≠n k·∫øt qu·∫£ ‚Üí r·ªìi tr·∫£ l·ªùi user.",
        "parameters": {
            "query": {
                "type": "string",
                "description": "C√¢u h·ªèi c·∫ßn th√¥ng tin th·ªùi gian th·ª±c",
                "required": True
            }
        }
    },
    
    "rag_search": {
        "handler": rag_search if RAG_AVAILABLE else None,
        "description": "üîç RAG SEARCH HYBRID - T√¨m ki·∫øm K·∫æT H·ª¢P t·ª´ Internet + T√†i li·ªáu n·ªôi b·ªô. T·ª± ƒë·ªông ch·ªçn ngu·ªìn ph√π h·ª£p nh·∫•t. sources='web' cho Internet, 'local' cho t√†i li·ªáu n·ªôi b·ªô, 'hybrid' cho c·∫£ hai, 'auto' ƒë·ªÉ AI t·ª± ch·ªçn.",
        "parameters": {
            "query": {
                "type": "string",
                "description": "C√¢u h·ªèi ho·∫∑c t·ª´ kh√≥a t√¨m ki·∫øm",
                "required": True
            },
            "sources": {
                "type": "string",
                "description": "Ngu·ªìn: 'auto', 'web', 'local', 'hybrid' (m·∫∑c ƒë·ªãnh: auto)",
                "required": False
            },
            "max_results": {
                "type": "integer",
                "description": "S·ªë k·∫øt qu·∫£ t·ªëi ƒëa (m·∫∑c ƒë·ªãnh 8)",
                "required": False
            }
        }
    },
    
    "smart_answer": {
        "handler": smart_answer if RAG_AVAILABLE else None,
        "description": "üß† SMART ANSWER - AI t·ª± ƒë·ªông ph√¢n t√≠ch c√¢u h·ªèi v√† ch·ªçn ngu·ªìn T·ªêT NH·∫§T (Internet/T√†i li·ªáu n·ªôi b·ªô/Hybrid) ƒë·ªÉ tr·∫£ l·ªùi. D√πng khi kh√¥ng ch·∫Øc ngu·ªìn n√†o ph√π h·ª£p. Tool tr·∫£ v·ªÅ context ƒë√£ t·ªëi ∆∞u ƒë·ªÉ tr·∫£ l·ªùi.",
        "parameters": {
            "query": {
                "type": "string",
                "description": "C√¢u h·ªèi c·ªßa user",
                "required": True
            }
        }
    }
}

# ============================================================
# MINIZ MCP CLIENT
# ============================================================

def get_vlc_context_for_llm() -> str:
    """T·∫°o context v·ªÅ VLC status ƒë·ªÉ g·ª≠i cho LLM"""
    try:
        if vlc_player and vlc_player._player:
            status = vlc_player.get_full_status()
            is_playing = status.get('is_playing', False)
            current_track = status.get('current_track', 'Kh√¥ng c√≥')
            volume = status.get('volume', 0)
            playlist_count = status.get('playlist_count', 0)
            
            context = f"""
üìç [PYTHON-VLC STATUS]
‚Ä¢ Tr·∫°ng th√°i: {'‚ñ∂Ô∏è ƒêang ph√°t' if is_playing else '‚è∏Ô∏è T·∫°m d·ª´ng/D·ª´ng'}
‚Ä¢ B√†i hi·ªán t·∫°i: {current_track}
‚Ä¢ √Çm l∆∞·ª£ng: {volume}%
‚Ä¢ Playlist: {playlist_count} b√†i
‚Ä¢ Player: Python-VLC (n·ªôi b·ªô)

üéØ D√πng smart_music_control() cho m·ªçi l·ªánh nh·∫°c!"""
            return context
        else:
            return """
üìç [PYTHON-VLC STATUS]
‚Ä¢ Tr·∫°ng th√°i: ‚èπÔ∏è Ch∆∞a kh·ªüi t·∫°o/Ch∆∞a ph√°t
‚Ä¢ D√πng play_music() ho·∫∑c list_music() ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√°t nh·∫°c
‚Ä¢ Player: Python-VLC (s·∫µn s√†ng)"""
    except:
        return ""

async def handle_xiaozhi_message(message: dict) -> dict:
    method = message.get("method")
    params = message.get("params", {})
    
    if method == "initialize":
        # Tr·∫£ v·ªÅ v·ªõi instructions + VLC context
        vlc_context = get_vlc_context_for_llm()
        full_instructions = MUSIC_SYSTEM_PROMPT + vlc_context
        
        return {
            "protocolVersion": "2024-11-05", 
            "capabilities": {"tools": {}}, 
            "serverInfo": {"name": "xiaozhi-final", "version": "4.3.0"},
            "instructions": full_instructions
        }
    elif method == "tools/list":
        # Support cursor pagination (t·ª´ xiaozhi-esp32-server)
        cursor = params.get("cursor", "")
        tools = []
        for name, info in TOOLS.items():
            # Sanitize tool name ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi server ch√≠nh th·ª©c
            sanitized_name = sanitize_tool_name(name) if 'sanitize_tool_name' in dir() else name
            # R√∫t g·ªçn description M·∫†NH ƒë·ªÉ gi·∫£m message size (fix "message too big" error)
            description = info["description"]
            if len(description) > 100:
                description = description[:97] + "..."
            
            tool = {
                "name": name,  # Gi·ªØ nguy√™n t√™n g·ªëc ƒë·ªÉ handler ho·∫°t ƒë·ªông
                "description": description, 
                "inputSchema": {"type": "object", "properties": {}, "required": []}
            }
            for pname, pinfo in info["parameters"].items():
                # R√∫t g·ªçn parameter description M·∫†NH
                param_desc = pinfo["description"]
                if len(param_desc) > 80:
                    param_desc = param_desc[:77] + "..."
                
                tool["inputSchema"]["properties"][pname] = {"type": pinfo["type"], "description": param_desc}
                if pinfo.get("required"):
                    tool["inputSchema"]["required"].append(pname)
            tools.append(tool)
        
        # Log s·ªë l∆∞·ª£ng tools
        print(f"üìã [tools/list] Returning {len(tools)} tools to robot")
        
        # Response theo format chu·∫©n v·ªõi optional nextCursor
        return {"tools": tools}  # nextCursor s·∫Ω ƒë∆∞·ª£c th√™m n·∫øu c·∫ßn pagination
    elif method == "tools/call":
        tool_name = params.get("name")
        args = params.get("arguments", {})
        print(f"üîß [Tool Call] {tool_name} with args: {args}")
        
        # L∆∞u tool call v√†o history
        add_to_conversation(
            role="tool",
            content=f"Tool: {tool_name}",
            metadata={
                "tool_name": tool_name,
                "arguments": args,
                "event_type": "tool_call"
            }
        )
        
        if tool_name not in TOOLS:
            error_msg = f"Error: Tool '{tool_name}' not found"
            print(f"‚ùå {error_msg}")
            add_to_conversation(role="tool", content=error_msg, metadata={"error": True})
            return {"content": [{"type": "text", "text": error_msg}], "isError": True}
        
        # Retry mechanism (t·ª´ xiaozhi-esp32-server)
        max_retries = MAX_TOOL_RETRIES
        retry_interval = TOOL_RETRY_INTERVAL
        last_error = None
        
        for attempt in range(max_retries):
            try:
                result = await TOOLS[tool_name]["handler"](**args)
                print(f"‚úÖ [Tool Result] {tool_name}: {result}")
                
                # Th√™m VLC context v√†o music-related tools
                music_tools = ['smart_music_control', 'play_music', 'pause_music', 'resume_music', 
                              'stop_music', 'music_next', 'music_previous', 'music_volume', 
                              'get_music_status', 'list_music', 'search_music', 'detect_and_execute_music']
                if tool_name in music_tools:
                    result["_vlc_hint"] = "üéµ ƒêang d√πng Python-VLC Player n·ªôi b·ªô. Ti·∫øp t·ª•c d√πng smart_music_control() cho c√°c l·ªánh nh·∫°c ti·∫øp theo."
                
                # L∆∞u tool result v√†o history
                add_to_conversation(
                    role="tool",
                    content=json.dumps(result, ensure_ascii=False),
                    metadata={
                        "tool_name": tool_name,
                        "success": result.get("success", True),
                        "event_type": "tool_result",
                        "attempt": attempt + 1
                    }
                )
                
                # ‚ö° ƒê·∫∂C BI·ªÜT: V·ªõi get_knowledge_context, tr·∫£ v·ªÅ context tr·ª±c ti·∫øp ƒë·ªÉ LLM d·ªÖ ƒë·ªçc
                if tool_name == "get_knowledge_context" and isinstance(result, dict):
                    if result.get("success") and result.get("context"):
                        # Tr·∫£ v·ªÅ context tr·ª±c ti·∫øp - LLM ƒë·ªçc v√† tr·∫£ l·ªùi ngay (gi·ªõi h·∫°n 2000 k√Ω t·ª±)
                        truncated_context = smart_truncate_for_llm(result["context"], MAX_LLM_RESPONSE_CHARS)
                        return {"content": [{"type": "text", "text": truncated_context}]}
                    elif not result.get("success"):
                        # Kh√¥ng t√¨m th·∫•y ‚Üí tr·∫£ v·ªÅ message l·ªói
                        error_msg = result.get("error", "Kh√¥ng t√¨m th·∫•y th√¥ng tin trong c∆° s·ªü d·ªØ li·ªáu")
                        return {"content": [{"type": "text", "text": f"‚ùå {error_msg}"}]}
                
                # ‚ö° ƒê·∫∂C BI·ªÜT: V·ªõi ask_gemini, ask_gpt4, gemini_smart_analyze - tr·∫£ v·ªÅ response text cho LLM cloud t·ªïng h·ª£p
                # Gi·ªëng c√°ch web_search ho·∫°t ƒë·ªông: tr·∫£ data ƒë·∫ßy ƒë·ªß ‚Üí LLM cloud T·ª∞ T√ìM T·∫ÆT ‚Üí robot n√≥i
                if tool_name in ["ask_gemini", "ask_gpt4", "gemini_smart_analyze"] and isinstance(result, dict):
                    if result.get("success") and result.get("response_text"):
                        response_text = result["response_text"]
                        # Clean markdown ƒë·ªÉ LLM d·ªÖ ƒë·ªçc (nh∆∞ng KH√îNG truncate - ƒë·ªÉ LLM cloud t·ª± t√≥m t·∫Øt)
                        response_text = clean_markdown_for_tts(response_text)
                        print(f"[{tool_name}] Cleaned response: {len(response_text)} chars (LLM cloud s·∫Ω t√≥m t·∫Øt)")
                        # Tr·∫£ v·ªÅ TEXT tr·ª±c ti·∫øp, LLM cloud s·∫Ω t·ª± t√≥m t·∫Øt tr∆∞·ªõc khi robot n√≥i
                        return {
                            "content": [{"type": "text", "text": response_text}]
                        }
                
                # üîÑ TRUNCATE: Gi·ªõi h·∫°n response d∆∞·ªõi 2000 k√Ω t·ª± cho LLM
                formatted_response = format_result_for_llm(result, MAX_LLM_RESPONSE_CHARS)
                return {"content": [{"type": "text", "text": formatted_response}]}
            except Exception as e:
                last_error = e
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è [Tool Retry] {tool_name} failed (attempt {attempt + 1}/{max_retries}): {e}")
                    await asyncio.sleep(retry_interval)
                else:
                    error_msg = f"Error calling {tool_name} after {max_retries} attempts: {str(e)}"
                    print(f"‚ùå {error_msg}")
                    import traceback
                    traceback.print_exc()
                    add_to_conversation(role="tool", content=error_msg, metadata={"error": True})
                    return {"content": [{"type": "text", "text": error_msg}], "isError": True}
    return {"error": f"Unknown method: {method}"}

# ============================================================
# üîç CONNECTION DIAGNOSTICS - Ch·∫©n ƒëo√°n l·ªói k·∫øt n·ªëi
# ============================================================
async def diagnose_connection_error(endpoint_name: str, token: str, error: Exception) -> dict:
    """
    Ph√¢n t√≠ch v√† ch·∫©n ƒëo√°n l·ªói k·∫øt n·ªëi endpoint
    Returns: dict v·ªõi th√¥ng tin chi ti·∫øt v·ªÅ l·ªói v√† gi·∫£i ph√°p
    """
    import socket
    import ssl
    
    diagnosis = {
        "endpoint": endpoint_name,
        "error_type": type(error).__name__,
        "error_message": str(error),
        "timestamp": datetime.now().isoformat(),
        "checks": [],
        "suggestions": []
    }
    
    # 1. Ki·ªÉm tra Internet
    try:
        socket.create_connection(("8.8.8.8", 53), timeout=3)
        diagnosis["checks"].append("‚úÖ Internet: C√≥ k·∫øt n·ªëi")
        diagnosis["internet_ok"] = True
    except OSError:
        diagnosis["checks"].append("‚ùå Internet: Kh√¥ng c√≥ k·∫øt n·ªëi m·∫°ng")
        diagnosis["suggestions"].append("Ki·ªÉm tra k·∫øt n·ªëi WiFi/Ethernet")
        diagnosis["internet_ok"] = False
        return diagnosis  # Kh√¥ng c·∫ßn ki·ªÉm tra ti·∫øp n·∫øu kh√¥ng c√≥ internet
    
    # 2. Ki·ªÉm tra DNS
    try:
        socket.gethostbyname("api.xiaozhi.me")
        diagnosis["checks"].append("‚úÖ DNS: Ph√¢n gi·∫£i t√™n mi·ªÅn th√†nh c√¥ng")
        diagnosis["dns_ok"] = True
    except socket.gaierror:
        diagnosis["checks"].append("‚ùå DNS: Kh√¥ng th·ªÉ ph√¢n gi·∫£i api.xiaozhi.me")
        diagnosis["suggestions"].append("Th·ª≠ ƒë·ªïi DNS sang 8.8.8.8 ho·∫∑c 1.1.1.1")
        diagnosis["dns_ok"] = False
    
    # 3. Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn server
    try:
        sock = socket.create_connection(("api.xiaozhi.me", 443), timeout=5)
        sock.close()
        diagnosis["checks"].append("‚úÖ Server: C√≥ th·ªÉ k·∫øt n·ªëi ƒë·∫øn api.xiaozhi.me:443")
        diagnosis["server_reachable"] = True
    except (socket.timeout, ConnectionRefusedError, OSError) as e:
        diagnosis["checks"].append(f"‚ùå Server: Kh√¥ng th·ªÉ k·∫øt n·ªëi ({type(e).__name__})")
        diagnosis["suggestions"].append("Server c√≥ th·ªÉ ƒëang b·∫£o tr√¨ ho·∫∑c b·ªã firewall ch·∫∑n")
        diagnosis["server_reachable"] = False
    
    # 4. Ki·ªÉm tra Token
    if token:
        if len(token) < 20:
            diagnosis["checks"].append("‚ö†Ô∏è Token: Token qu√° ng·∫Øn, c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá")
            diagnosis["suggestions"].append("Ki·ªÉm tra l·∫°i Token trong c√†i ƒë·∫∑t Xiaozhi App")
        else:
            diagnosis["checks"].append("‚úÖ Token: C√≥ token (ƒë·ªô d√†i h·ª£p l·ªá)")
    else:
        diagnosis["checks"].append("‚ùå Token: Ch∆∞a nh·∫≠p token")
        diagnosis["suggestions"].append("Nh·∫≠p Token t·ª´ Xiaozhi App > C√†i ƒë·∫∑t > Token thi·∫øt b·ªã")
    
    # 5. Ph√¢n t√≠ch l·ªói c·ª• th·ªÉ
    error_str = str(error).lower()
    if "timeout" in error_str:
        diagnosis["checks"].append("‚è±Ô∏è L·ªói: Timeout k·∫øt n·ªëi")
        diagnosis["suggestions"].append("M·∫°ng ch·∫≠m ho·∫∑c server kh√¥ng ph·∫£n h·ªìi")
    elif "ssl" in error_str or "certificate" in error_str:
        diagnosis["checks"].append("üîí L·ªói: SSL/Certificate")
        diagnosis["suggestions"].append("Ki·ªÉm tra ng√†y gi·ªù h·ªá th·ªëng, c·∫≠p nh·∫≠t certificates")
    elif "refused" in error_str:
        diagnosis["checks"].append("üö´ L·ªói: K·∫øt n·ªëi b·ªã t·ª´ ch·ªëi")
        diagnosis["suggestions"].append("Server t·ª´ ch·ªëi k·∫øt n·ªëi, ki·ªÉm tra token")
    elif "401" in error_str or "unauthorized" in error_str:
        diagnosis["checks"].append("üîë L·ªói: Token kh√¥ng h·ª£p l·ªá")
        diagnosis["suggestions"].append("Token sai ho·∫∑c h·∫øt h·∫°n, l·∫•y token m·ªõi t·ª´ Xiaozhi App")
    elif "429" in error_str:
        diagnosis["checks"].append("‚ö° L·ªói: Rate limit")
        diagnosis["suggestions"].append("Qu√° nhi·ªÅu request, ch·ªù v√†i ph√∫t r·ªìi th·ª≠ l·∫°i")
    
    return diagnosis

def format_diagnosis_report(diagnosis: dict) -> str:
    """Format diagnosis th√†nh b√°o c√°o d·ªÖ ƒë·ªçc"""
    report = []
    report.append(f"\n{'='*60}")
    report.append(f"üîç B√ÅO C√ÅO L·ªñI K·∫æT N·ªêI - {diagnosis['endpoint']}")
    report.append(f"{'='*60}")
    report.append(f"‚è∞ Th·ªùi gian: {diagnosis['timestamp']}")
    report.append(f"‚ùå L·ªói: {diagnosis['error_type']}: {diagnosis['error_message']}")
    report.append(f"\nüìã KI·ªÇM TRA:")
    for check in diagnosis['checks']:
        report.append(f"   {check}")
    if diagnosis['suggestions']:
        report.append(f"\nüí° GI·∫¢I PH√ÅP G·ª¢I √ù:")
        for i, suggestion in enumerate(diagnosis['suggestions'], 1):
            report.append(f"   {i}. {suggestion}")
    report.append(f"{'='*60}\n")
    return "\n".join(report)

# Bi·∫øn l∆∞u tr·ªØ log l·ªói k·∫øt n·ªëi
connection_error_log = []
MAX_ERROR_LOG = 50  # Gi·ªØ t·ªëi ƒëa 50 l·ªói g·∫ßn nh·∫•t

def log_connection_error(diagnosis: dict):
    """L∆∞u l·ªói v√†o log"""
    global connection_error_log
    connection_error_log.append(diagnosis)
    if len(connection_error_log) > MAX_ERROR_LOG:
        connection_error_log = connection_error_log[-MAX_ERROR_LOG:]

async def xiaozhi_websocket_client(device_index: int = 0):
    """WebSocket client for a specific device (0, 1, or 2)"""
    global xiaozhi_connections, xiaozhi_connected, should_reconnect
    retry = 0
    last_error_diagnosis = None  # L∆∞u diagnosis l·∫ßn l·ªói g·∫ßn nh·∫•t
    consecutive_errors = 0       # ƒê·∫øm s·ªë l·ªói li√™n ti·∫øp
    
    # ===== OPTIMIZED CONNECTION SETTINGS =====
    INITIAL_DELAY = 1        # Delay ban ƒë·∫ßu 1s (gi·∫£m t·ª´ 2s)
    MAX_DELAY = 15           # Max delay 15s (gi·∫£m t·ª´ 60s)
    CONNECT_TIMEOUT = 10     # Timeout k·∫øt n·ªëi 10s
    FAST_RETRY_COUNT = 3     # S·ªë l·∫ßn fast retry ƒë·∫ßu ti√™n
    FAST_RETRY_DELAY = 0.5   # Delay 0.5s cho fast retry
    AUTO_SWITCH_THRESHOLD = 5  # Sau 5 l·∫ßn th·∫•t b·∫°i, th·ª≠ endpoint kh√°c
    
    while True:
        try:
            ep = endpoints_config[device_index]
            if not ep.get("enabled") or not ep.get("token"):
                # Thi·∫øt b·ªã n√†y ch∆∞a c√≥ token, ch·ªù v√† th·ª≠ l·∫°i
                await asyncio.sleep(10)
                continue
            
            ws_url = f"wss://api.xiaozhi.me/mcp/?token={ep['token']}"
            retry += 1
            
            # Fast retry cho 3 l·∫ßn ƒë·∫ßu, sau ƒë√≥ d√πng exponential backoff
            if retry <= FAST_RETRY_COUNT:
                print(f"üì° [Xiaozhi] Fast connecting {ep['name']}... ({retry}/{FAST_RETRY_COUNT})")
            else:
                print(f"üì° [Xiaozhi] Connecting {ep['name']}... (retry {retry})")
            
            # S·ª≠ d·ª•ng asyncio.wait_for ƒë·ªÉ c√≥ timeout
            async with websockets.connect(
                ws_url, 
                ping_interval=20, 
                ping_timeout=10,
                close_timeout=5,
                open_timeout=CONNECT_TIMEOUT,  # Timeout m·ªü k·∫øt n·ªëi
                max_size=10 * 1024 * 1024  # 10MB limit (default is 1MB) - fix "message too big"
            ) as ws:
                xiaozhi_connections[device_index] = ws
                xiaozhi_connected[device_index] = True
                should_reconnect[device_index] = False  # Reset flag khi k·∫øt n·ªëi th√†nh c√¥ng
                retry = 0  # Reset retry counter khi k·∫øt n·ªëi th√†nh c√¥ng
                print(f"‚úÖ [Xiaozhi] Connected! ({ep['name']}) [Device {device_index + 1}]")
                
                # Batch broadcast k·∫øt n·ªëi - t·∫°o tasks v√† ch·∫°y parallel
                broadcast_msg = {"type": "endpoint_connected", "endpoint": ep['name'], "index": device_index}
                tasks = []
                for conn in active_connections:
                    tasks.append(asyncio.create_task(conn.send_json(broadcast_msg)))
                # Ch·∫°n t·∫•t c·∫£ broadcasts c√πng l√∫c
                await asyncio.gather(*tasks, return_exceptions=True)
                
                init_msg = {"jsonrpc": "2.0", "method": "initialize", "params": {"protocolVersion": "2024-11-05", "capabilities": {}, "clientInfo": {"name": "xiaozhi-final", "version": "4.3.0"}}, "id": 1}
                
                # Kh√¥ng log initialize request - ch·ªâ log tool calls th·ª±c s·ª±
                
                await ws.send(json.dumps(init_msg))
                
                async for msg in ws:
                    # Ki·ªÉm tra n·∫øu c·∫ßn reconnect (user ƒë√£ chuy·ªÉn thi·∫øt b·ªã)
                    if should_reconnect[device_index]:
                        print(f"üîÑ [Xiaozhi] Reconnecting {ep['name']}...")
                        await ws.close()
                        break
                    
                    try:
                        data = json.loads(msg)
                        method = data.get("method", "unknown")
                        if method != "ping":
                            print(f"üì® [{method}]")
                        
                        response = await handle_xiaozhi_message(data)
                        
                        # CH·ªà log conversation th·ª±c s·ª± (tools/call), KH√îNG log MCP protocol messages
                        # B·ªè qua: initialize, notifications/initialized, tools/list
                        if method == "tools/call" and method != "ping":
                            # L·∫•y th√¥ng tin tool
                            params = data.get("params", {})
                            tool_name = params.get("name", "unknown")
                            tool_args = params.get("arguments", {})
                            
                            # T·∫°o n·ªôi dung d·ªÖ ƒë·ªçc t·ª´ tool arguments
                            user_message = format_tool_request(tool_name, tool_args)
                            
                            # Log tool call request
                            add_to_conversation(
                                role="user",
                                content=user_message,
                                metadata={
                                    "source": "mcp",
                                    "method": method,
                                    "tool_name": tool_name,
                                    "tool_arguments": tool_args,
                                    "endpoint": ep['name']
                                }
                            )
                            
                            # T·∫°o n·ªôi dung response d·ªÖ ƒë·ªçc
                            assistant_message = format_tool_response(tool_name, response)
                            
                            # Log tool call response
                            add_to_conversation(
                                role="assistant",
                                content=assistant_message,
                                metadata={
                                    "source": "mcp",
                                    "method": method,
                                    "tool_name": tool_name,
                                    "response_data": response,
                                    "success": not isinstance(response, dict) or not response.get("isError")
                                }
                            )
                        
                        await ws.send(json.dumps({"jsonrpc": "2.0", "id": data.get("id"), "result": response}))

                        # If the tool response suggests a next_action (for example list_music
                        # returning {'next_action': {'tool': 'play_music', 'parameters': {...}}}),
                        # execute it locally on the server as a fallback so music actually plays
                        # even if the remote AI/client doesn't invoke the follow-up.
                        try:
                            if isinstance(response, dict) and response.get("next_action"):
                                na = response.get("next_action")
                                next_tool = na.get("tool")
                                next_params = na.get("parameters", {}) or {}
                                # Only execute if the tool exists locally
                                if next_tool and next_tool in TOOLS:
                                    print(f"‚èØÔ∏è [Auto Action] Executing suggested next_action {next_tool} with params: {next_params}")
                                    try:
                                        # call the handler (handlers may be async)
                                        handler = TOOLS[next_tool]["handler"]
                                        if asyncio.iscoroutinefunction(handler):
                                            res2 = await handler(**next_params)
                                        else:
                                            # run sync handlers in executor
                                            loop = asyncio.get_event_loop()
                                            res2 = await loop.run_in_executor(None, lambda: handler(**next_params))
                                        print(f"‚èØÔ∏è [Auto Action Result] {next_tool}: {res2}")
                                    except Exception as e:
                                        print(f"‚ùå [Auto Action] Error executing {next_tool}: {e}")
                                        import traceback
                                        traceback.print_exc()
                        except Exception:
                            # defensive: do not let auto-action failures disrupt websocket loop
                            import traceback
                            traceback.print_exc()
                        
                        # Batch broadcast - ch·ªâ broadcast cho methods quan tr·ªçng
                        if method in ["tools/call", "initialize"]:
                            broadcast_msg = {"type": "xiaozhi_activity", "method": method, "timestamp": datetime.now().isoformat()}
                            # Cleanup dead connections tr∆∞·ªõc khi broadcast
                            dead_connections = []
                            for conn in active_connections:
                                try:
                                    await conn.send_json(broadcast_msg)
                                except Exception:
                                    dead_connections.append(conn)
                            # Remove dead connections
                            for conn in dead_connections:
                                active_connections.remove(conn)
                    except json.JSONDecodeError as e:
                        print(f"‚ö†Ô∏è [Xiaozhi] JSON decode error: {e}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è [Xiaozhi] Message handling error: {e}")
                        
                # Reset consecutive errors khi k·∫øt n·ªëi th√†nh c√¥ng
                consecutive_errors = 0
                
        except asyncio.CancelledError:
            print(f"‚ö†Ô∏è [Xiaozhi] Task cancelled ({ep['name']})")
            xiaozhi_connected[device_index] = False
            xiaozhi_connections[device_index] = None
            break
        except websockets.exceptions.WebSocketException as e:
            xiaozhi_connected[device_index] = False
            xiaozhi_connections[device_index] = None
            consecutive_errors += 1
            
            # Fast retry cho 3 l·∫ßn ƒë·∫ßu
            if retry <= FAST_RETRY_COUNT:
                wait = FAST_RETRY_DELAY
            else:
                # Exponential backoff v·ªõi max 15s
                wait = min(INITIAL_DELAY * (2 ** min(retry - FAST_RETRY_COUNT, 4)), MAX_DELAY)
            
            print(f"‚ùå [Xiaozhi] WebSocket error ({ep['name']}): {e} (retry in {wait}s)")
            
            # Ch·∫©n ƒëo√°n l·ªói sau 3 l·∫ßn th·∫•t b·∫°i li√™n ti·∫øp
            if consecutive_errors >= 3:
                print(f"üîç [Xiaozhi] ƒêang ch·∫©n ƒëo√°n l·ªói k·∫øt n·ªëi...")
                diagnosis = await diagnose_connection_error(ep['name'], ep.get('token', ''), e)
                log_connection_error(diagnosis)
                print(format_diagnosis_report(diagnosis))
                
                # Broadcast l·ªói ƒë·∫øn UI
                error_broadcast = {
                    "type": "connection_error",
                    "endpoint": ep['name'],
                    "device_index": device_index,
                    "error": str(e),
                    "diagnosis": diagnosis,
                    "retry_count": retry
                }
                for conn in active_connections:
                    try:
                        await conn.send_json(error_broadcast)
                    except:
                        pass
                
                # Reset consecutive ƒë·ªÉ kh√¥ng spam diagnosis
                consecutive_errors = 0
            
            await asyncio.sleep(wait)
        except Exception as e:
            xiaozhi_connected[device_index] = False
            xiaozhi_connections[device_index] = None
            consecutive_errors += 1
            
            # Fast retry cho 3 l·∫ßn ƒë·∫ßu
            if retry <= FAST_RETRY_COUNT:
                wait = FAST_RETRY_DELAY
            else:
                wait = min(INITIAL_DELAY * (2 ** min(retry - FAST_RETRY_COUNT, 4)), MAX_DELAY)
            
            print(f"‚ùå [Xiaozhi] Error ({ep['name']}): {e} (retry in {wait}s)")
            
            # Ch·∫©n ƒëo√°n l·ªói sau 3 l·∫ßn th·∫•t b·∫°i li√™n ti·∫øp
            if consecutive_errors >= 3:
                print(f"üîç [Xiaozhi] ƒêang ch·∫©n ƒëo√°n l·ªói k·∫øt n·ªëi...")
                diagnosis = await diagnose_connection_error(ep['name'], ep.get('token', ''), e)
                log_connection_error(diagnosis)
                print(format_diagnosis_report(diagnosis))
                
                # Broadcast l·ªói ƒë·∫øn UI
                error_broadcast = {
                    "type": "connection_error",
                    "endpoint": ep['name'],
                    "device_index": device_index,
                    "error": str(e),
                    "diagnosis": diagnosis,
                    "retry_count": retry
                }
                for conn in active_connections:
                    try:
                        await conn.send_json(error_broadcast)
                    except:
                        pass
                
                # Reset consecutive ƒë·ªÉ kh√¥ng spam diagnosis
                consecutive_errors = 0
            
            await asyncio.sleep(wait)

# ============================================================
# FASTAPI WEB SERVER
# ============================================================

app = FastAPI(title="miniZ MCP", version="4.3.0")

class VolumeRequest(BaseModel):
    level: int

class NotificationRequest(BaseModel):
    title: str
    message: str

class CalculatorRequest(BaseModel):
    expression: str

@app.get("/", response_class=HTMLResponse)
async def index():
    html = r"""
<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üöÄ miniZ MCP - ƒêi·ªÅu Khi·ªÉn M√°y T√≠nh</title>
    <style>
        @keyframes pulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.7; transform: scale(1.1); }
        }
        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; display: flex; }
        
        /* SIDEBAR */
        .sidebar { width: 280px; background: #1a1a2e; color: white; padding: 30px 20px; display: flex; flex-direction: column; box-shadow: 2px 0 20px rgba(0,0,0,0.3); }
        .logo { 
            font-size: 1.5em; 
            font-weight: bold; 
            margin-bottom: 40px; 
            text-align: center; 
            padding: 20px 15px; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            border-radius: 15px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 10px;
        }
        .logo-icon {
            width: 120px;
            height: auto;
            filter: drop-shadow(0 4px 8px rgba(0,0,0,0.3));
            transition: transform 0.3s;
        }
        .logo-icon:hover {
            transform: scale(1.05);
        }
        .logo-text {
            font-size: 1.8em;
            font-weight: 900;
            letter-spacing: 2px;
            color: #ff9a8b;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        .menu-item { padding: 15px 20px; margin: 8px 0; border-radius: 10px; cursor: pointer; transition: all 0.3s; display: flex; align-items: center; gap: 12px; font-size: 1.05em; }
        .menu-item:hover { background: rgba(102, 126, 234, 0.2); transform: translateX(5px); }
        .menu-item.active { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4); }
        
        /* MAIN CONTENT */
        .main-content { flex: 1; padding: 30px; overflow-y: auto; }
        .header { background: white; border-radius: 15px; padding: 25px 30px; margin-bottom: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.2); display: flex; justify-content: space-between; align-items: center; }
        .header h1 { color: #667eea; font-size: 2em; }
        .status { display: flex; gap: 20px; }
        .status-badge { padding: 8px 20px; border-radius: 20px; font-weight: 600; display: flex; align-items: center; gap: 8px; }
        .status-badge.online { background: #d4edda; color: #155724; }
        .status-badge.offline { background: #f8d7da; color: #721c24; }
        .status-dot { width: 10px; height: 10px; border-radius: 50%; background: currentColor; animation: pulse 2s infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
        
        /* QUICK ACTIONS */
        .quick-actions { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }
        .action-card { background: white; padding: 25px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.1); cursor: pointer; transition: all 0.3s; text-align: center; }
        .action-card:hover { transform: translateY(-5px); box-shadow: 0 15px 40px rgba(0,0,0,0.2); }
        .action-card.blue { border-left: 5px solid #3b82f6; }
        .action-card.green { border-left: 5px solid #10b981; }
        .action-card.orange { border-left: 5px solid #f59e0b; }
        .action-card.red { border-left: 5px solid #ef4444; }
        .action-card.purple { border-left: 5px solid #8b5cf6; }
        .action-card.cyan { border-left: 5px solid #06b6d4; }
        .action-card.pink { border-left: 5px solid #ec4899; }
        .action-card.indigo { border-left: 5px solid #6366f1; }
        .action-card .icon { font-size: 2.5em; margin-bottom: 10px; }
        .action-card .title { font-weight: 600; color: #333; font-size: 1.1em; }
        
        /* TOOLS SECTION */
        .tools-section { background: white; border-radius: 15px; padding: 30px; margin-bottom: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }
        .tools-tabs { display: flex; gap: 15px; margin-bottom: 25px; border-bottom: 2px solid #e5e7eb; padding-bottom: 15px; }
        .tab-btn { padding: 12px 30px; border: none; border-radius: 10px 10px 0 0; background: transparent; color: #666; font-weight: 600; cursor: pointer; transition: all 0.3s; font-size: 1em; }
        .tab-btn:hover { background: rgba(102, 126, 234, 0.1); color: #667eea; }
        .tab-btn.active { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; box-shadow: 0 -4px 15px rgba(102, 126, 234, 0.3); }
        .tab-content { display: none; }
        .tab-content.active { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
        
        /* TOOL CARDS */
        .tool-card { background: #f9fafb; padding: 25px; border-radius: 12px; border: 2px solid #e5e7eb; }
        .tool-card h3 { color: #667eea; margin-bottom: 15px; font-size: 1.2em; display: flex; align-items: center; gap: 10px; }
        .tool-card input, .tool-card select, .tool-card textarea { width: 100%; padding: 12px; margin-top: 10px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 1em; }
        .tool-card button { width: 100%; padding: 14px; margin-top: 15px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 8px; font-weight: 600; cursor: pointer; transition: all 0.3s; font-size: 1em; }
        .tool-card button:hover { transform: translateY(-2px); box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4); }
        
        /* CONFIG SECTION */
        .config-section { background: white; border-radius: 15px; padding: 30px; margin-bottom: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }
        .device-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-top: 20px; }
        .device-card { background: #f9fafb; padding: 20px; border-radius: 12px; border: 2px solid #e5e7eb; }
        .device-card.active { border-color: #10b981; background: #d4edda; }
        .device-card h4 { color: #667eea; margin-bottom: 15px; display: flex; align-items: center; gap: 10px; }
        .device-card input { width: 100%; padding: 10px; margin-top: 8px; border: 2px solid #e5e7eb; border-radius: 6px; }
        .device-card button { padding: 10px 20px; margin-top: 10px; background: #667eea; color: white; border: none; border-radius: 6px; cursor: pointer; }
        
        /* LOG */
        .log-panel { background: #1a1a2e; color: white; border-radius: 15px; padding: 25px; max-height: 400px; overflow-y: auto; font-family: 'Courier New', monospace; box-shadow: 0 10px 30px rgba(0,0,0,0.12); }
        .log-entry { padding: 8px; margin: 5px 0; border-left: 3px solid #667eea; background: rgba(102, 126, 234, 0.1); border-radius: 4px; }
        .log-time { color: #9ca3af; margin-right: 10px; }
        
        /* MUSIC PLAYER */
        .music-player { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 20px; padding: 30px; color: white; margin-bottom: 30px; box-shadow: 0 15px 40px rgba(102, 126, 234, 0.4); }
        .player-controls { display: flex; justify-content: center; align-items: center; gap: 20px; margin: 30px 0; }
        .player-btn { width: 60px; height: 60px; border-radius: 50%; background: rgba(255,255,255,0.2); border: 3px solid rgba(255,255,255,0.4); color: white; font-size: 24px; cursor: pointer; transition: all 0.3s; display: flex; align-items: center; justify-content: center; backdrop-filter: blur(10px); }
        .player-btn:hover { background: rgba(255,255,255,0.3); transform: scale(1.1); box-shadow: 0 8px 25px rgba(0,0,0,0.3); }
        .player-btn.play { width: 80px; height: 80px; font-size: 32px; background: white; color: #667eea; }
        .now-playing { text-align: center; margin: 20px 0; }
        .now-playing h3 { font-size: 1.5em; margin-bottom: 10px; text-shadow: 0 2px 10px rgba(0,0,0,0.3); }
        .now-playing p { opacity: 0.9; font-size: 1.1em; }
        .progress-container { margin: 25px 0; }
        .progress-bar { width: 100%; height: 8px; background: rgba(255,255,255,0.3); border-radius: 10px; overflow: hidden; cursor: pointer; }
        .progress-fill { height: 100%; background: white; width: 0%; transition: width 0.3s; box-shadow: 0 0 10px rgba(255,255,255,0.5); }
        .progress-time { display: flex; justify-content: space-between; margin-top: 8px; font-size: 0.9em; opacity: 0.9; }
        /* Progress slider (draggable timeline) */
        #progress-slider { -webkit-appearance: none; width: 100%; height: 8px; border-radius: 4px; cursor: pointer; }
        #progress-slider::-webkit-slider-thumb { -webkit-appearance: none; width: 16px; height: 16px; background: #667eea; border-radius: 50%; cursor: pointer; box-shadow: 0 2px 6px rgba(102,126,234,0.5); transition: transform 0.2s; }
        #progress-slider::-webkit-slider-thumb:hover { transform: scale(1.2); }
        #progress-slider::-moz-range-thumb { width: 16px; height: 16px; background: #667eea; border-radius: 50%; cursor: pointer; border: none; }
        .music-list { background: white; border-radius: 15px; padding: 25px; color: #333; max-height: 500px; overflow-y: auto; }
        .music-list h3 { color: #667eea; margin-bottom: 20px; display: flex; align-items: center; gap: 10px; }
        .music-item { display: flex; align-items: center; padding: 15px; margin: 10px 0; background: #f9fafb; border-radius: 10px; cursor: pointer; transition: all 0.2s ease; border: 2px solid transparent; }
        .music-item:hover { background: #e8eaf6; border-color: #667eea; transform: translateX(3px); box-shadow: 0 4px 12px rgba(102, 126, 234, 0.15); }
        .music-item:hover .play-btn-hover { opacity: 1 !important; }
        
        /* Wave animation for now playing indicator */
        @keyframes wave1 { 0%, 100% { height: 12px; } 50% { height: 20px; } }
        @keyframes wave2 { 0%, 100% { height: 18px; } 50% { height: 8px; } }
        @keyframes wave3 { 0%, 100% { height: 15px; } 50% { height: 22px; } }
        .music-item.playing { background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%); border-color: #667eea; }
        .music-item .icon { font-size: 24px; margin-right: 15px; }
        .music-item .info { flex: 1; }
        .music-item .name { font-weight: 600; color: #333; font-size: 1.05em; }
        .music-item .details { color: #666; font-size: 0.9em; margin-top: 5px; }
        .log-success { color: #10b981; border-left-color: #10b981; }
        .log-error { color: #ef4444; border-left-color: #ef4444; }
        .log-info { color: #3b82f6; border-left-color: #3b82f6; }
        
        /* LLM CHAT STYLES */
        .quick-msg-btn {
            padding: 8px 14px;
            background: #f3f4f6;
            border: 1px solid #e5e7eb;
            border-radius: 20px;
            font-size: 0.85em;
            cursor: pointer;
            transition: all 0.2s;
        }
        .quick-msg-btn:hover {
            background: #10b981;
            color: white;
            border-color: #10b981;
            transform: translateY(-2px);
        }
        .llm-message {
            max-width: 80%;
            padding: 12px 16px;
            border-radius: 15px;
            position: relative;
            word-wrap: break-word;
        }
        .llm-message.user {
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            color: white;
            margin-left: auto;
            border-bottom-right-radius: 5px;
        }
        .llm-message.assistant {
            background: white;
            color: #333;
            margin-right: auto;
            border-bottom-left-radius: 5px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        .llm-message .time {
            font-size: 0.75em;
            opacity: 0.7;
            margin-top: 5px;
            display: block;
        }
        .llm-message .device-tag {
            font-size: 0.7em;
            background: rgba(255,255,255,0.2);
            padding: 2px 8px;
            border-radius: 10px;
            margin-left: 8px;
        }
        .llm-message.assistant .device-tag {
            background: rgba(16,185,129,0.1);
            color: #10b981;
        }
        .llm-typing {
            display: flex;
            gap: 4px;
            padding: 15px;
        }
        .llm-typing span {
            width: 8px;
            height: 8px;
            background: #10b981;
            border-radius: 50%;
            animation: typing 1.4s infinite;
        }
        .llm-typing span:nth-child(2) { animation-delay: 0.2s; }
        .llm-typing span:nth-child(3) { animation-delay: 0.4s; }
        @keyframes typing {
            0%, 60%, 100% { transform: translateY(0); opacity: 0.4; }
            30% { transform: translateY(-10px); opacity: 1; }
        }
        
        /* SETTINGS ICON */
        .settings-icon { font-size: 1.8em; cursor: pointer; transition: all 0.3s; padding: 10px; border-radius: 50%; background: #f0f0f0; display: flex; align-items: center; justify-content: center; width: 50px; height: 50px; }
        .settings-icon:hover { transform: rotate(90deg); background: #667eea; color: white; }
        
        /* MODAL POPUP */
        .modal { display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; background: rgba(0,0,0,0.7); animation: fadeIn 0.3s; align-items: center; justify-content: center; }
        .modal-content { background: linear-gradient(135deg, #1a1a2e, #16213e); margin: 0; padding: 0; border-radius: 15px; width: 90%; max-width: 500px; box-shadow: 0 20px 60px rgba(0,0,0,0.5); animation: slideDown 0.3s; color: white; }
        .modal-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px 30px; border-radius: 15px 15px 0 0; display: flex; justify-content: space-between; align-items: center; }
        .modal-header h2 { margin: 0; font-size: 1.5em; }
        .modal-header h3 { margin: 0; font-size: 1.3em; }
        .close-btn { font-size: 2em; cursor: pointer; color: white; background: none; border: none; line-height: 1; transition: transform 0.2s; }
        .close-btn:hover { transform: scale(1.2); }
        .modal-body { padding: 30px; }
        .modal-body label { display: block; margin-bottom: 8px; font-weight: 600; color: #333; }
        .modal-body input { width: 100%; padding: 12px; margin-bottom: 20px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 1em; transition: border-color 0.3s; }
        .modal-body input:focus { outline: none; border-color: #667eea; }
        
        /* API KEY INPUT CONTAINER */
        .api-key-input-container { position: relative; margin-bottom: 20px; }
        .api-key-input-container input { padding-right: 90px; margin-bottom: 0; font-family: monospace; letter-spacing: 1px; }
        .api-key-input-container .input-icons { position: absolute; right: 8px; top: 50%; transform: translateY(-50%); display: flex; gap: 5px; align-items: center; }
        .api-key-icon-btn { background: transparent; border: none; cursor: pointer; padding: 8px; border-radius: 6px; display: flex; align-items: center; justify-content: center; transition: all 0.2s; font-size: 18px; color: #666; }
        .api-key-icon-btn:hover { background: rgba(102, 126, 234, 0.1); color: #667eea; transform: scale(1.1); }
        .api-key-icon-btn:active { transform: scale(0.95); }
        .api-key-icon-btn.copied { color: #10b981; animation: copySuccess 0.3s; }
        @keyframes copySuccess { 0%, 100% { transform: scale(1); } 50% { transform: scale(1.2); } }
        .modal-footer { padding: 20px 30px; background: #f9fafb; border-radius: 0 0 15px 15px; display: flex; gap: 15px; justify-content: flex-end; }
        .modal-btn { padding: 12px 30px; border: none; border-radius: 8px; font-weight: 600; cursor: pointer; transition: all 0.3s; font-size: 1em; }
        .modal-btn.primary { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
        .modal-btn.primary:hover { transform: translateY(-2px); box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4); }
        .modal-btn.secondary { background: #e5e7eb; color: #666; }
        .modal-btn.secondary:hover { background: #d1d5db; }
        .modal-btn.info { background: linear-gradient(135deg, #17a2b8 0%, #138496 100%); color: white; }
        .modal-btn.info:hover { transform: translateY(-2px); box-shadow: 0 8px 20px rgba(23, 162, 184, 0.4); }
        @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
        @keyframes slideDown { from { transform: translateY(-50px); opacity: 0; } to { transform: translateY(0); opacity: 1; } }
        
        /* AUDIO VISUALIZER - S√≥ng nh·∫°c ƒë·∫πp */
        .audio-visualizer {
            display: flex;
            align-items: flex-end;
            justify-content: center;
            gap: 3px;
            height: 40px;
            margin: 10px 0;
        }
        .audio-visualizer .bar {
            width: 4px;
            background: linear-gradient(to top, #667eea, #764ba2, #f472b6);
            border-radius: 2px;
            animation: visualizer-bar 0.5s ease-in-out infinite;
        }
        .audio-visualizer .bar:nth-child(1) { animation-delay: 0s; height: 20px; }
        .audio-visualizer .bar:nth-child(2) { animation-delay: 0.1s; height: 30px; }
        .audio-visualizer .bar:nth-child(3) { animation-delay: 0.15s; height: 25px; }
        .audio-visualizer .bar:nth-child(4) { animation-delay: 0.3s; height: 35px; }
        .audio-visualizer .bar:nth-child(5) { animation-delay: 0.2s; height: 28px; }
        .audio-visualizer .bar:nth-child(6) { animation-delay: 0.25s; height: 32px; }
        .audio-visualizer .bar:nth-child(7) { animation-delay: 0.05s; height: 22px; }
        .audio-visualizer .bar:nth-child(8) { animation-delay: 0.35s; height: 38px; }
        .audio-visualizer .bar:nth-child(9) { animation-delay: 0.1s; height: 26px; }
        .audio-visualizer .bar:nth-child(10) { animation-delay: 0.4s; height: 30px; }
        .audio-visualizer.paused .bar { animation-play-state: paused; }
        @keyframes visualizer-bar {
            0%, 100% { transform: scaleY(0.3); opacity: 0.6; }
            50% { transform: scaleY(1); opacity: 1; }
        }
        
        /* RUNCAT ANIMATION - JavaScript-based multi-frame like RunCat365 */
        #runcat-container {
            position: fixed;
            bottom: 15px;
            right: 15px;
            z-index: 9999;
            user-select: none;
            cursor: pointer;
        }
        
        #runcat {
            font-size: 52px;
            display: inline-block;
            filter: drop-shadow(0 3px 6px rgba(0,0,0,0.25));
            transition: transform 0.05s ease-out;
            will-change: transform;
        }
        
        #runcat:hover {
            animation: runcat-excited 0.15s ease-in-out infinite !important;
            filter: drop-shadow(0 6px 12px rgba(0,0,0,0.4));
        }
        
        @keyframes runcat-excited {
            0%, 100% { 
                transform: translateY(-2px) rotate(-8deg) scale(1.2) !important;
            }
            25% { 
                transform: translateY(-12px) rotate(8deg) scale(1.3) !important;
            }
            50% { 
                transform: translateY(-18px) rotate(-8deg) scale(1.25) !important;
            }
            75% { 
                transform: translateY(-12px) rotate(8deg) scale(1.3) !important;
            }
        }
        
        /* FOOTER MINIZ - Compact corner style */
        .footer-miniz { position: fixed; bottom: 20px; right: 20px; background: rgba(26, 26, 46, 0.95); color: white; padding: 12px 18px; border-radius: 50px; box-shadow: 0 5px 25px rgba(0,0,0,0.3); display: flex; align-items: center; gap: 12px; z-index: 1000; transition: all 0.3s; backdrop-filter: blur(10px); }
        .footer-miniz:hover { transform: translateY(-3px); box-shadow: 0 8px 35px rgba(102, 126, 234, 0.5); }
        .footer-logo-compact { display: flex; align-items: center; gap: 10px; }
        .footer-logo-compact img { width: 35px; height: 35px; border-radius: 50%; border: 2px solid #667eea; box-shadow: 0 0 10px rgba(102, 126, 234, 0.6); }
        .footer-brand-compact { font-size: 0.95em; font-weight: bold; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text; }
        .footer-separator { width: 1px; height: 25px; background: rgba(255,255,255,0.3); }
        .footer-youtube-compact { display: flex; align-items: center; gap: 6px; padding: 8px 15px; background: #FF0000; color: white; border-radius: 25px; text-decoration: none; font-weight: 600; font-size: 0.85em; transition: all 0.3s; }
        .footer-youtube-compact:hover { background: #cc0000; transform: scale(1.05); }
        .footer-youtube-compact svg { width: 18px; height: 18px; fill: white; }
        
        /* RESPONSIVE - MOBILE FIRST */
        @media (max-width: 1200px) {
            .quick-actions { grid-template-columns: repeat(auto-fit, minmax(160px, 1fr)); gap: 15px; }
            .tab-content.active { grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); }
            .device-grid { grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); }
        }
        
        @media (max-width: 992px) {
            .sidebar { width: 240px; padding: 20px 15px; }
            .main-content { padding: 20px; }
            .header { padding: 20px; flex-direction: column; gap: 15px; text-align: center; }
            .header h1 { font-size: 1.6em; }
            .music-player { padding: 20px; }
            .player-controls { gap: 15px; }
            .player-btn { width: 50px; height: 50px; font-size: 20px; }
            .player-btn.play { width: 65px; height: 65px; font-size: 26px; }
        }
        
        @media (max-width: 768px) {
            body { flex-direction: column; }
            .sidebar { width: 100%; padding: 15px; flex-direction: row; flex-wrap: wrap; justify-content: center; gap: 10px; }
            .logo { width: 100%; margin-bottom: 15px; padding: 15px; }
            .logo-icon { width: 60px; }
            .logo-text { font-size: 1.2em; }
            .menu-item { padding: 10px 15px; margin: 3px; font-size: 0.9em; }
            .main-content { padding: 15px; min-height: calc(100vh - 200px); }
            .header { padding: 15px; margin-bottom: 20px; }
            .header h1 { font-size: 1.3em; }
            .status { flex-wrap: wrap; justify-content: center; gap: 10px; }
            .status-badge { padding: 6px 15px; font-size: 0.9em; }
            .quick-actions { grid-template-columns: repeat(2, 1fr); gap: 10px; }
            .action-card { padding: 15px; }
            .action-card .icon { font-size: 1.8em; }
            .action-card .title { font-size: 0.9em; }
            .tools-section, .config-section { padding: 20px; }
            .tools-tabs { flex-wrap: wrap; gap: 8px; }
            .tab-btn { padding: 10px 20px; font-size: 0.9em; }
            .tab-content.active { grid-template-columns: 1fr; }
            .tool-card { padding: 20px; }
            .device-grid { grid-template-columns: 1fr; }
            .music-player { padding: 15px; border-radius: 15px; }
            .now-playing h3 { font-size: 1.2em; }
            .player-controls { gap: 10px; margin: 20px 0; }
            .player-btn { width: 45px; height: 45px; font-size: 18px; }
            .player-btn.play { width: 60px; height: 60px; font-size: 24px; }
            .music-list { padding: 15px; max-height: 350px; }
            .music-item { padding: 12px; }
            .chat-bubble { max-width: 85%; }
            .modal-content { width: 95%; margin: 2% auto; }
            .modal-body { padding: 20px; }
            .modal-footer { padding: 15px 20px; flex-direction: column; }
            .modal-btn { width: 100%; }
            .footer-miniz { bottom: 10px; right: 10px; padding: 10px 14px; }
            .footer-brand-compact { font-size: 0.85em; }
            .footer-youtube-compact { padding: 6px 12px; font-size: 0.8em; }
            #runcat-container { bottom: 10px; right: 10px; }
            #runcat { font-size: 40px; }
        }
        
        @media (max-width: 480px) {
            .sidebar { padding: 10px; }
            .logo { padding: 10px; }
            .logo-icon { width: 45px; }
            .logo-text { font-size: 1em; }
            .menu-item { padding: 8px 12px; font-size: 0.85em; }
            .main-content { padding: 10px; }
            .header { padding: 12px; }
            .header h1 { font-size: 1.1em; }
            .quick-actions { grid-template-columns: repeat(2, 1fr); gap: 8px; }
            .action-card { padding: 12px; }
            .action-card .icon { font-size: 1.5em; margin-bottom: 5px; }
            .action-card .title { font-size: 0.8em; }
            .tools-section, .config-section { padding: 15px; margin-bottom: 20px; }
            .tab-btn { padding: 8px 15px; font-size: 0.85em; }
            .tool-card { padding: 15px; }
            .tool-card h3 { font-size: 1em; }
            .tool-card input, .tool-card select, .tool-card textarea { padding: 10px; font-size: 0.9em; }
            .tool-card button { padding: 12px; font-size: 0.9em; }
            .log-panel { max-height: 250px; padding: 15px; font-size: 0.85em; }
            .music-player { padding: 12px; }
            .now-playing h3 { font-size: 1em; }
            .now-playing p { font-size: 0.9em; }
            .player-btn { width: 40px; height: 40px; font-size: 16px; }
            .player-btn.play { width: 55px; height: 55px; font-size: 22px; }
            .chat-avatar { width: 32px; height: 32px; font-size: 0.9em; }
            .chat-bubble { padding: 10px 12px; }
            .chat-content { font-size: 0.9em; }
            .footer-miniz { flex-direction: column; padding: 8px 12px; gap: 8px; }
            .footer-separator { display: none; }
        }
        
        /* WECHAT STYLE CHAT BUBBLES */
        .chat-message { display: flex; align-items: flex-start; gap: 10px; margin-bottom: 15px; animation: fadeInChat 0.3s; }
        .chat-message.user { flex-direction: row-reverse; }
        .chat-avatar { width: 40px; height: 40px; border-radius: 50%; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); display: flex; align-items: center; justify-content: center; color: white; font-weight: 700; font-size: 1.1em; flex-shrink: 0; box-shadow: 0 2px 8px rgba(0,0,0,0.15); }
        .chat-avatar.assistant { background: linear-gradient(135deg, #10b981 0%, #059669 100%); }
        .chat-avatar.system { background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); }
        .chat-avatar.tool { background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%); }
        .chat-bubble { max-width: 65%; padding: 12px 16px; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); position: relative; word-wrap: break-word; }
        .chat-message.user .chat-bubble { background: #667eea; color: white; border-radius: 12px 12px 2px 12px; }
        .chat-message.assistant .chat-bubble { background: white; color: #333; border-radius: 12px 12px 12px 2px; border: 1px solid #e5e7eb; }
        .chat-message.system .chat-bubble { background: #fff7ed; color: #7c2d12; border-radius: 8px; border: 1px solid #fed7aa; }
        .chat-message.tool .chat-bubble { background: #eff6ff; color: #1e3a8a; border-radius: 8px; border: 1px solid #bfdbfe; }
        .chat-content { font-size: 0.95em; line-height: 1.5; margin-bottom: 6px; }
        .chat-metadata { font-size: 0.75em; opacity: 0.7; display: flex; gap: 10px; flex-wrap: wrap; margin-top: 8px; }
        .chat-metadata-item { display: inline-flex; align-items: center; gap: 4px; background: rgba(0,0,0,0.05); padding: 2px 8px; border-radius: 10px; }
        .chat-timestamp { font-size: 0.7em; opacity: 0.6; margin-top: 4px; text-align: right; }
        .chat-message.user .chat-timestamp { text-align: left; }
        @keyframes fadeInChat { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
        @keyframes spin { from { transform: rotate(0deg); } to { transform: rotate(360deg); } }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
        #chat-container::-webkit-scrollbar { width: 8px; }
        #chat-container::-webkit-scrollbar-track { background: #f1f1f1; border-radius: 10px; }
        #chat-container::-webkit-scrollbar-thumb { background: #667eea; border-radius: 10px; }
        #chat-container::-webkit-scrollbar-thumb:hover { background: #5568d3; }
        
        /* Music Player VLC-style enhancements */
        .music-item:hover { background: linear-gradient(135deg, rgba(102,126,234,0.15) 0%, rgba(118,75,162,0.15) 100%) !important; transform: translateX(5px); }
        #volume-slider::-webkit-slider-thumb { -webkit-appearance: none; width: 16px; height: 16px; background: #667eea; border-radius: 50%; cursor: pointer; box-shadow: 0 2px 6px rgba(102, 126, 234, 0.5); }
        #volume-slider::-moz-range-thumb { width: 16px; height: 16px; background: #667eea; border-radius: 50%; cursor: pointer; border: none; }
    </style>
</head>
<body>
    <!-- SIDEBAR -->
    <div class="sidebar">
        <div class="logo">
            <svg class="logo-icon" viewBox="0 0 100 100" fill="none" xmlns="http://www.w3.org/2000/svg">
                <defs>
                    <linearGradient id="logoGrad" x1="0%" y1="0%" x2="100%" y2="100%">
                        <stop offset="0%" style="stop-color:#667eea"/>
                        <stop offset="100%" style="stop-color:#764ba2"/>
                    </linearGradient>
                </defs>
                <circle cx="50" cy="50" r="45" fill="url(#logoGrad)"/>
                <text x="50" y="58" text-anchor="middle" fill="white" font-size="28" font-weight="bold" font-family="Arial">MCP</text>
                <text x="50" y="75" text-anchor="middle" fill="#a5f3fc" font-size="12" font-weight="600" font-family="Arial">miniZ</text>
            </svg>
            <div class="logo-text">miniZ MCP</div>
            <small style="font-size:0.55em;opacity:0.9;font-weight:600;letter-spacing:1px;">ƒêI·ªÄU KHI·ªÇN M√ÅY T√çNH</small>
        </div>
        <div class="menu-item active" onclick="showSection('dashboard')">üìäSidebar</div>
        <div class="menu-item" onclick="showSection('tools')">üõ†Ô∏è C√¥ng C·ª•</div>
        <div class="menu-item" onclick="showSection('llm-chat')" style="background:linear-gradient(135deg,#667eea,#764ba2);border-left:4px solid #fbbf24;">üí¨ Chat v·ªõi Gemini</div>
        <div class="menu-item" onclick="showSection('api-quotas')" style="background:linear-gradient(135deg,#667eea,#764ba2);border-left:4px solid #fbbf24;">üîë API Quotas</div>
        <div class="menu-item" onclick="showSection('music')">üéµ Music Player</div>
        <div class="menu-item" onclick="showSection('music-settings')">‚öôÔ∏è Music Settings</div>
        <div class="menu-item" onclick="showSection('conversation')">üí¨ L·ªãch S·ª≠ Chat</div>
        <div class="menu-item" onclick="showSection('playlist')">üéµ Playlist YouTube</div>
        <div class="menu-item" onclick="showSection('knowledge')">üìö Knowledge Base</div>
    </div>
    
    <!-- MAIN CONTENT -->
    <div class="main-content">
        <!-- HEADER -->
        <div class="header">
            <h1>Dashboard</h1>
            <div class="status">
                <div class="settings-icon" onclick="openSettingsModal()" title="C·∫•u h√¨nh Endpoint">‚öôÔ∏è</div>
                <div class="status-badge" id="xiaozhi-status">
                    <span class="status-dot"></span>
                    <span id="xiaozhi-text">Connecting...</span>
                </div>
                <div class="status-badge online">
                    <span class="status-dot"></span>
                    Web Server
                </div>
            </div>
        </div>
        
        <!-- DASHBOARD SECTION -->
        <div id="dashboard-section">
            <h2 style="color:#667eea;margin-bottom:20px;">üöÄ T·∫•t c·∫£ c√¥ng c·ª• (38 Tools)</h2>
            <div class="quick-actions">
                <!-- AI ASSISTANT (2) - NEW -->
                <div class="action-card purple" onclick="askGemini()"><div class="icon">ü§ñüìö</div><div class="title">H·ªèi Gemini AI + KB</div></div>
                <div class="action-card indigo" onclick="askGPT4()"><div class="icon">üß†</div><div class="title">H·ªèi GPT-4</div></div>
                
                <!-- H·ªÜ TH·ªêNG (5) -->
                <div class="action-card blue" onclick="setVolumePrompt()"><div class="icon">üîä</div><div class="title">ƒêi·ªÅu Ch·ªânh √Çm L∆∞·ª£ng</div></div>
                <div class="action-card cyan" onclick="screenshot()"><div class="icon">üì∏</div><div class="title">Ch·ª•p M√†n H√¨nh</div></div>
                <div class="action-card purple" onclick="notification()"><div class="icon">üîî</div><div class="title">Th√¥ng B√°o</div></div>
                <div class="action-card green" onclick="showSystemResourcesPopup()"><div class="icon">üíª</div><div class="title">T√†i Nguy√™n H·ªá Th·ªëng</div></div>
                <div class="action-card indigo" onclick="showPCConfigPopup()"><div class="icon">üñ•Ô∏è</div><div class="title">C·∫•u H√¨nh M√°y T√≠nh</div></div>
                <div class="action-card orange" onclick="setBrightness()"><div class="icon">üîÜ</div><div class="title">ƒê·ªô S√°ng M√†n H√¨nh</div></div>
                
                <!-- FILE & PROCESS (7) -->
                <div class="action-card indigo" onclick="openApp()"><div class="icon">üöÄ</div><div class="title">M·ªü ·ª®ng D·ª•ng</div></div>
                <div class="action-card blue" onclick="listProcesses()"><div class="icon">‚öôÔ∏è</div><div class="title">Ti·∫øn Tr√¨nh ƒêang Ch·∫°y</div></div>
                <div class="action-card red" onclick="killProcess()"><div class="icon">‚ùå</div><div class="title">T·∫Øt Ti·∫øn Tr√¨nh</div></div>
                <div class="action-card green" onclick="createFile()"><div class="icon">‚ûï</div><div class="title">T·∫°o File M·ªõi</div></div>
                <div class="action-card cyan" onclick="readFile()"><div class="icon">üìñ</div><div class="title">ƒê·ªçc File</div></div>
                <div class="action-card purple" onclick="listFiles()"><div class="icon">üìÇ</div><div class="title">Li·ªát K√™ Files</div></div>
                <div class="action-card orange" onclick="diskUsage()"><div class="icon">üíΩ</div><div class="title">Th√¥ng Tin ƒêƒ©a</div></div>
                
                <!-- M·∫†NG & WEB (3) -->
                <div class="action-card blue" onclick="networkInfo()"><div class="icon">üåê</div><div class="title">Th√¥ng Tin M·∫°ng</div></div>
                <div class="action-card green" onclick="batteryStatus()"><div class="icon">üîã</div><div class="title">Th√¥ng Tin Pin</div></div>
                <div class="action-card indigo" onclick="searchWeb()"><div class="icon">üîç</div><div class="title">T√¨m Ki·∫øm Google</div></div>
                
                <!-- TI·ªÜN √çCH (5) -->
                <div class="action-card pink" onclick="calculator()"><div class="icon">üßÆ</div><div class="title">M√°y T√≠nh</div></div>
                <div class="action-card cyan" onclick="getCurrentTime()"><div class="icon">‚è∞</div><div class="title">Th·ªùi Gian</div></div>
                <div class="action-card purple" onclick="getClipboard()"><div class="icon">üìã</div><div class="title">L·∫•y Clipboard</div></div>
                <div class="action-card orange" onclick="setClipboard()"><div class="icon">üìù</div><div class="title">ƒê·∫∑t Clipboard</div></div>
                <div class="action-card red" onclick="playSound()"><div class="icon">üîä</div><div class="title">Ph√°t √Çm Thanh</div></div>
                
                <!-- NEW TOOLS -->
                <div class="action-card blue" onclick="lockComputer()"><div class="icon">üîí</div><div class="title">Kh√≥a M√°y T√≠nh</div></div>
                <div class="action-card red" onclick="shutdownSchedule()"><div class="icon">‚è∞</div><div class="title">L√™n L·ªãch T·∫Øt M√°y</div></div>
                <div class="action-card green" onclick="showDesktop()"><div class="icon">üñ•Ô∏è</div><div class="title">Hi·ªÉn Th·ªã Desktop</div></div>
                <div class="action-card orange" onclick="undoOperation()"><div class="icon">‚Ü©Ô∏è</div><div class="title">Ho√†n T√°c</div></div>
                <div class="action-card purple" onclick="setTheme()"><div class="icon">üé®</div><div class="title">ƒê·ªïi Theme</div></div>
                <div class="action-card cyan" onclick="changeWallpaper()"><div class="icon">üñºÔ∏è</div><div class="title">ƒê·ªïi H√¨nh N·ªÅn</div></div>
                <div class="action-card indigo" onclick="getDesktopPath()"><div class="icon">üìÅ</div><div class="title">ƒê∆∞·ªùng D·∫´n Desktop</div></div>
                <div class="action-card pink" onclick="pasteContent()"><div class="icon">üìã</div><div class="title">D√°n N·ªôi Dung</div></div>
                <div class="action-card blue" onclick="pressEnter()"><div class="icon">‚èé</div><div class="title">Nh·∫•n Enter</div></div>
                <div class="action-card green" onclick="findInDocument()"><div class="icon">üîé</div><div class="title">T√¨m Trong T√†i Li·ªáu</div></div>
            </div>
            
            <!-- REALTIME SYSTEM MONITOR - HORIZONTAL BAR -->
            <div style="margin-top:30px;">
                <h2 style="color:#667eea;margin-bottom:15px;">üìä System Monitor</h2>
                <div style="display:grid;grid-template-columns:repeat(3,1fr);gap:15px;margin-bottom:25px;">
                    <!-- CPU Card -->
                    <div style="background:linear-gradient(135deg,#1a1a2e,#16213e);border-radius:12px;padding:15px;border:1px solid rgba(76,175,80,0.3);">
                        <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:10px;">
                            <span style="color:#4CAF50;font-size:13px;font-weight:bold;">‚ö° CPU</span>
                            <span id="cpu-realtime" style="font-size:20px;font-weight:bold;color:#4CAF50;">0%</span>
                        </div>
                        <div style="background:#333;border-radius:6px;height:8px;overflow:hidden;">
                            <div id="cpu-bar" style="width:0%;height:100%;background:linear-gradient(90deg,#4CAF50,#8BC34A);transition:width 0.5s;"></div>
                        </div>
                        <div style="font-size:11px;color:#888;margin-top:8px;" id="cpu-info">-- MHz | -- cores</div>
                    </div>
                    
                    <!-- RAM Card -->
                    <div style="background:linear-gradient(135deg,#1a1a2e,#16213e);border-radius:12px;padding:15px;border:1px solid rgba(255,152,0,0.3);">
                        <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:10px;">
                            <span style="color:#ff9800;font-size:13px;font-weight:bold;">üß† RAM</span>
                            <span id="ram-realtime" style="font-size:20px;font-weight:bold;color:#ff9800;">0%</span>
                        </div>
                        <div style="background:#333;border-radius:6px;height:8px;overflow:hidden;">
                            <div id="ram-bar" style="width:0%;height:100%;background:linear-gradient(90deg,#ff9800,#FFC107);transition:width 0.5s;"></div>
                        </div>
                        <div style="font-size:11px;color:#888;margin-top:8px;" id="ram-info">0 / 0 GB</div>
                    </div>
                    
                    <!-- GPU Card -->
                    <div style="background:linear-gradient(135deg,#1a1a2e,#16213e);border-radius:12px;padding:15px;border:1px solid rgba(156,39,176,0.3);">
                        <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:10px;">
                            <span style="color:#9C27B0;font-size:13px;font-weight:bold;">üéÆ GPU</span>
                            <span id="gpu-realtime" style="font-size:20px;font-weight:bold;color:#9C27B0;">0%</span>
                        </div>
                        <div style="background:#333;border-radius:6px;height:8px;overflow:hidden;">
                            <div id="gpu-bar" style="width:0%;height:100%;background:linear-gradient(90deg,#9C27B0,#E040FB);transition:width 0.5s;"></div>
                        </div>
                        <div style="font-size:11px;color:#888;margin-top:8px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;" id="gpu-name">Loading...</div>
                    </div>
                </div>
            </div>
            
            <!-- LOG PANEL AT BOTTOM OF DASHBOARD -->
            <div>
                <h2 style="color:#667eea; margin-bottom: 15px; display: flex; align-items: center; gap: 10px;">
                    <span>üìã Log Ho·∫°t ƒê·ªông</span>
                    <span style="font-size: 0.6em; color: #9ca3af; font-weight: 400;">(Th·ªùi gian th·ª±c)</span>
                </h2>
                <div class="log-panel" id="log"></div>
            </div>
        </div>

        <!-- API QUOTAS SECTION -->
        <div id="api-quotas-section" class="section" style="display:none;">
            <h2 style="color:#667eea;margin-bottom:30px;">üîë API Quotas Management</h2>
            
            <div style="display:grid;grid-template-columns:repeat(auto-fit,minmax(400px,1fr));gap:25px;margin-bottom:30px;">
                <!-- Gemini API Card -->
                <div style="background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);border-radius:15px;padding:30px;color:white;box-shadow:0 10px 30px rgba(102,126,234,0.3);">
                    <div style="display:flex;align-items:center;margin-bottom:20px;">
                        <div style="font-size:48px;margin-right:15px;">ü§ñ</div>
                        <div>
                            <h3 style="margin:0;font-size:24px;">Gemini API</h3>
                            <p style="margin:5px 0 0 0;opacity:0.9;font-size:14px;">Google AI Platform</p>
                        </div>
                    </div>
                    <div id="gemini-quota-detail" style="background:rgba(255,255,255,0.15);border-radius:10px;padding:20px;">
                        <div style="margin-bottom:15px;">
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Status:</div>
                            <div id="gemini-status" style="font-size:16px;font-weight:bold;">üîÑ ƒêang ki·ªÉm tra...</div>
                        </div>
                        <div style="margin-bottom:15px;">
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Free Tier Limits:</div>
                            <div style="font-size:15px;line-height:1.6;">
                                ‚Ä¢ <strong>60 requests</strong> per minute<br>
                                ‚Ä¢ <strong>1,500 requests</strong> per day
                            </div>
                        </div>
                        <div>
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Model:</div>
                            <div style="font-size:14px;font-family:monospace;background:rgba(0,0,0,0.2);padding:8px;border-radius:5px;">
                                üöÄ Gemini 3 Flash Preview
                                <br><span style="font-size:11px;opacity:0.7;">gemini-3-flash-preview</span>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- Serper API Card -->
                <div style="background:linear-gradient(135deg,#3b82f6 0%,#1e40af 100%);border-radius:15px;padding:30px;color:white;box-shadow:0 10px 30px rgba(59,130,246,0.3);">
                    <div style="display:flex;align-items:center;margin-bottom:20px;">
                        <div style="font-size:48px;margin-right:15px;">üîç</div>
                        <div>
                            <h3 style="margin:0;font-size:24px;">Serper API</h3>
                            <p style="margin:5px 0 0 0;opacity:0.9;font-size:14px;">Google Search API</p>
                        </div>
                    </div>
                    <div id="serper-quota-detail" style="background:rgba(255,255,255,0.15);border-radius:10px;padding:20px;">
                        <div style="margin-bottom:15px;">
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Status:</div>
                            <div id="serper-status" style="font-size:16px;font-weight:bold;">üîÑ ƒêang ki·ªÉm tra...</div>
                        </div>
                        <div style="margin-bottom:15px;">
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Free Tier Limit:</div>
                            <div style="font-size:15px;line-height:1.6;">
                                ‚Ä¢ <strong>2,500 queries</strong> per month
                            </div>
                        </div>
                        <div>
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Endpoint:</div>
                            <div style="font-size:14px;font-family:monospace;background:rgba(0,0,0,0.2);padding:8px;border-radius:5px;">https://google.serper.dev/search</div>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Actions -->
            <div style="background:white;border-radius:15px;padding:25px;box-shadow:0 2px 10px rgba(0,0,0,0.1);margin-bottom:25px;">
                <h3 style="margin-top:0;color:#1a1a2e;">‚ö° Quick Actions</h3>
                <div style="display:flex;gap:15px;flex-wrap:wrap;">
                    <button onclick="refreshQuotasPage()" style="background:linear-gradient(135deg,#10b981,#059669);color:white;border:none;padding:12px 25px;border-radius:8px;font-size:15px;cursor:pointer;box-shadow:0 4px 15px rgba(16,185,129,0.3);transition:all 0.3s;">
                        üîÑ L√†m m·ªõi t·∫•t c·∫£
                    </button>
                    <button onclick="testGeminiAPI()" style="background:linear-gradient(135deg,#667eea,#764ba2);color:white;border:none;padding:12px 25px;border-radius:8px;font-size:15px;cursor:pointer;box-shadow:0 4px 15px rgba(102,126,234,0.3);transition:all 0.3s;">
                        üß™ Test Gemini API
                    </button>
                    <button onclick="testSerperAPI()" style="background:linear-gradient(135deg,#3b82f6,#1e40af);color:white;border:none;padding:12px 25px;border-radius:8px;font-size:15px;cursor:pointer;box-shadow:0 4px 15px rgba(59,130,246,0.3);transition:all 0.3s;">
                        üß™ Test Serper API
                    </button>
                </div>
            </div>
            
            <!-- Usage Tips -->
            <div style="background:#f0f9ff;border-left:4px solid #3b82f6;border-radius:10px;padding:20px;">
                <h3 style="margin-top:0;color:#1e40af;">üí° Tips</h3>
                <ul style="margin:10px 0;padding-left:20px;line-height:1.8;color:#1e3a8a;">
                    <li><strong>Gemini API:</strong> D√πng cho chat AI, ph√¢n t√≠ch text, t·∫°o n·ªôi dung</li>
                    <li><strong>Serper API:</strong> D√πng cho t√¨m ki·∫øm Google real-time</li>
                    <li><strong>Free Tier:</strong> ƒê·ªß cho s·ª≠ d·ª•ng c√° nh√¢n v√† testing</li>
                    <li><strong>Rate Limit:</strong> N·∫øu v∆∞·ª£t quota, API s·∫Ω tr·∫£ v·ªÅ l·ªói 429</li>
                    <li><strong>Monitor:</strong> Ki·ªÉm tra status th∆∞·ªùng xuy√™n ƒë·ªÉ tr√°nh h·∫øt quota</li>
                </ul>
            </div>
        </div>

        <!-- TOOLS SECTION -->
        <div id="tools-section" style="display:none;">
            <div class="tools-section">
                <h2 style="color:#667eea;margin-bottom:20px;">üõ†Ô∏è C√¥ng C·ª• (20 Tools)</h2>
                
                <div class="tools-tabs">
                    <button class="tab-btn active" onclick="switchTab(0)">üéõÔ∏è H·ªá th·ªëng</button>
                    <button class="tab-btn" onclick="switchTab(1)">üìÅ File & Process</button>
                    <button class="tab-btn" onclick="switchTab(2)">üåê M·∫°ng & Web</button>
                    <button class="tab-btn" onclick="switchTab(3)">üîß Ti·ªán √≠ch</button>
                </div>
                
                <!-- TAB 1: H·ªÜ TH·ªêNG -->
                <div class="tab-content active" id="tab-0">
                    <div class="tool-card">
                        <h3>üîä ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng</h3>
                        <input type="number" id="volume" min="0" max="100" value="50" placeholder="0-100">
                        <button onclick="
                            const level = parseInt(document.getElementById('volume').value);
                            if (isNaN(level) || level < 0 || level > 100) {
                                addLog('‚ùå √Çm l∆∞·ª£ng ph·∫£i t·ª´ 0-100', 'error');
                            } else {
                                callAPI('/api/volume', {level: level});
                            }
                        ">ƒê·∫∑t √¢m l∆∞·ª£ng</button>
                    </div>
                    <div class="tool-card">
                        <h3>üì∏ Ch·ª•p m√†n h√¨nh</h3>
                        <button onclick="callAPI('/api/screenshot', {})">Ch·ª•p m√†n h√¨nh ngay</button>
                    </div>
                    <div class="tool-card">
                        <h3>üîî Th√¥ng b√°o</h3>
                        <input type="text" id="notif-title" placeholder="Ti√™u ƒë·ªÅ">
                        <input type="text" id="notif-message" placeholder="N·ªôi dung">
                        <button onclick="
                            const title = document.getElementById('notif-title').value.trim();
                            const message = document.getElementById('notif-message').value.trim();
                            if (!title || !message) {
                                addLog('‚ùå Vui l√≤ng nh·∫≠p ti√™u ƒë·ªÅ v√† n·ªôi dung', 'error');
                            } else {
                                callAPI('/api/notification', {title: title, message: message});
                            }
                        ">Hi·ªÉn th·ªã</button>
                    </div>
                    <div class="tool-card" style="background:linear-gradient(135deg, #667eea 0%, #764ba2 100%);color:white;border:2px solid #764ba2;">
                        <h3 style="color:white;">üîë API Quotas</h3>
                        <button onclick="getQuotas()" style="background:rgba(255,255,255,0.2);color:white;border:1px solid rgba(255,255,255,0.3);">L√†m m·ªõi</button>
                        <div id="quotas" style="margin-top:15px;font-size:13px;line-height:1.8;">
                            <div style="margin-bottom:10px;padding:8px;background:rgba(255,255,255,0.1);border-radius:4px;">
                                <strong>ü§ñ Gemini:</strong><br>
                                <span id="gemini-quota" style="color:#fbbf24;font-size:12px;">ƒêang t·∫£i...</span>
                            </div>
                            <div style="padding:8px;background:rgba(255,255,255,0.1);border-radius:4px;">
                                <strong>üîç Serper:</strong><br>
                                <span id="serper-quota" style="color:#60a5fa;font-size:12px;">ƒêang t·∫£i...</span>
                            </div>
                        </div>
                    </div>
                    <div class="tool-card">
                        <h3>üíª T√†i nguy√™n h·ªá th·ªëng</h3>
                        <button onclick="getResources()">L√†m m·ªõi</button>
                        <div id="resources" style="margin-top:15px;">
                            <div>CPU: <span id="cpu">--%</span></div>
                            <div>RAM: <span id="ram">--%</span></div>
                            <div>Disk: <span id="disk">--%</span></div>
                        </div>
                    </div>
                    <div class="tool-card">
                        <h3>üîÜ ƒê·ªô s√°ng m√†n h√¨nh</h3>
                        <input type="number" id="brightness" min="0" max="100" value="50" placeholder="0-100">
                        <button onclick="
                            const level = parseInt(document.getElementById('brightness').value);
                            if (isNaN(level) || level < 0 || level > 100) {
                                addLog('‚ùå ƒê·ªô s√°ng ph·∫£i t·ª´ 0-100', 'error');
                            } else {
                                callTool('set_brightness', {level: level});
                            }
                        ">ƒê·∫∑t ƒë·ªô s√°ng</button>
                    </div>
                </div>
                
                <!-- TAB 2: FILE & PROCESS -->
                <div class="tab-content" id="tab-1">
                    <div class="tool-card">
                        <h3>üöÄ M·ªü ·ª©ng d·ª•ng</h3>
                        <select id="app-name">
                            <option value="notepad">üìù Notepad</option>
                            <option value="calc">üßÆ Calculator</option>
                            <option value="paint">üé® Paint</option>
                            <option value="cmd">‚å®Ô∏è CMD</option>
                            <option value="explorer">üìÇ Explorer</option>
                        </select>
                        <button onclick="callTool('open_application', {app_name: document.getElementById('app-name').value})">M·ªü</button>
                    </div>
                    <div class="tool-card">
                        <h3>üìã Ti·∫øn tr√¨nh ƒëang ch·∫°y</h3>
                        <input type="number" id="proc-limit" min="5" max="50" value="10" placeholder="S·ªë l∆∞·ª£ng">
                        <button onclick="callTool('list_running_processes', {limit: parseInt(document.getElementById('proc-limit').value)})">Xem danh s√°ch</button>
                    </div>
                    <div class="tool-card">
                        <h3>‚ùå T·∫Øt ti·∫øn tr√¨nh</h3>
                        <input type="text" id="kill-proc" placeholder="PID ho·∫∑c t√™n">
                        <button onclick="callTool('kill_process', {identifier: document.getElementById('kill-proc').value})">T·∫Øt ti·∫øn tr√¨nh</button>
                    </div>
                    <div class="tool-card">
                        <h3>üìù T·∫°o file m·ªõi</h3>
                        <input type="text" id="file-path" placeholder="C:/test.txt">
                        <textarea id="file-content" placeholder="N·ªôi dung..." style="min-height:80px;"></textarea>
                        <button onclick="callTool('create_file', {path: document.getElementById('file-path').value, content: document.getElementById('file-content').value})">T·∫°o file</button>
                    </div>
                    <div class="tool-card">
                        <h3>üìñ ƒê·ªçc file</h3>
                        <input type="text" id="read-path" placeholder="C:/test.txt">
                        <button onclick="callTool('read_file', {path: document.getElementById('read-path').value})">ƒê·ªçc file</button>
                    </div>
                    <div class="tool-card">
                        <h3>üìÇ Li·ªát k√™ files</h3>
                        <input type="text" id="list-dir" placeholder="C:/Users">
                        <button onclick="callTool('list_files', {directory: document.getElementById('list-dir').value})">Xem files</button>
                    </div>
                    <div class="tool-card">
                        <h3>üíæ Th√¥ng tin ƒëƒ©a</h3>
                        <button onclick="callTool('get_disk_usage', {})">Xem chi ti·∫øt</button>
                    </div>
                </div>
                
                <!-- TAB 3: M·∫†NG & WEB -->
                <div class="tab-content" id="tab-2">
                    <div class="tool-card">
                        <h3>üåê Th√¥ng tin m·∫°ng</h3>
                        <button onclick="callTool('get_network_info', {})">Xem IP & hostname</button>
                    </div>
                    <div class="tool-card">
                        <h3>üîã Th√¥ng tin pin</h3>
                        <button onclick="callTool('get_battery_status', {})">Ki·ªÉm tra pin</button>
                    </div>
                    <div class="tool-card">
                        <h3>üîç T√¨m ki·∫øm Google</h3>
                        <input type="text" id="search-query" placeholder="Nh·∫≠p t·ª´ kh√≥a...">
                        <button onclick="callTool('search_web', {query: document.getElementById('search-query').value})">T√¨m ki·∫øm</button>
                    </div>
                </div>
                
                <!-- TAB 4: TI·ªÜN √çCH -->
                <div class="tab-content" id="tab-3">
                    <div class="tool-card">
                        <h3>üßÆ M√°y t√≠nh</h3>
                        <input type="text" id="calc-expr" placeholder="2+2*3">
                        <button onclick="calculate()">T√≠nh to√°n</button>
                        <div id="calc-result" style="margin-top:10px;font-size:1.5em;font-weight:bold;color:#667eea;"></div>
                    </div>
                    <div class="tool-card">
                        <h3>üïê Th·ªùi gian</h3>
                        <button onclick="getCurrentTime()">L·∫•y th·ªùi gian</button>
                        <div id="time-result" style="margin-top:10px;font-size:1.2em;color:#667eea;"></div>
                    </div>
                    <div class="tool-card">
                        <h3>üìã L·∫•y clipboard</h3>
                        <button onclick="callTool('get_clipboard', {})">Xem n·ªôi dung</button>
                    </div>
                    <div class="tool-card">
                        <h3>üìù ƒê·∫∑t clipboard</h3>
                        <input type="text" id="clip-text" placeholder="N·ªôi dung c·∫ßn copy">
                        <button onclick="callTool('set_clipboard', {text: document.getElementById('clip-text').value})">Copy v√†o clipboard</button>
                    </div>
                    <div class="tool-card">
                        <h3>üîä Ph√°t √¢m thanh</h3>
                        <input type="number" id="sound-freq" min="200" max="2000" value="1000" placeholder="T·∫ßn s·ªë Hz">
                        <input type="number" id="sound-dur" min="100" max="3000" value="500" placeholder="Th·ªùi gian ms">
                        <button onclick="callTool('play_sound', {frequency: parseInt(document.getElementById('sound-freq').value), duration: parseInt(document.getElementById('sound-dur').value)})">Ph√°t beep</button>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- CONFIG SECTION - HIDDEN (Replaced by Modal) -->
        <div id="config-section" style="display:none;">
            <div class="config-section">
                <h2 style="color:#667eea;margin-bottom:20px;">‚öôÔ∏è C·∫•u h√¨nh hi·ªán t·∫°i</h2>
                <p style="color:#666;margin-bottom:20px;">S·ª≠ d·ª•ng icon ‚öôÔ∏è ·ªü g√≥c ph·∫£i tr√™n ƒë·ªÉ thay ƒë·ªïi endpoint</p>
                <div id="current-endpoint-info" style="background:#f9fafb;padding:20px;border-radius:12px;border:2px solid #e5e7eb;">
                    <p><strong>Thi·∫øt b·ªã ƒëang ho·∫°t ƒë·ªông:</strong> <span id="current-device-name">-</span></p>
                    <p><strong>Token:</strong> <span id="current-device-token" style="font-family:monospace;font-size:0.9em;word-break:break-all;">-</span></p>
                </div>
            </div>
        </div>
        
        
        <!-- LLM CHAT SECTION - Chat v·ªõi Gemini AI -->
        <div id="llm-chat-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.12); height: calc(100vh - 180px); display: flex; flex-direction: column;">
                <h2 style="color:#10b981; margin-bottom: 15px; display: flex; align-items: center; justify-content: space-between;">
                    <span>üí¨ Chat v·ªõi Gemini AI</span>
                    <div style="display:flex; gap:10px; align-items:center;">
                        <!-- TTS Toggle -->
                        <label style="display:flex; align-items:center; gap:6px; cursor:pointer; padding:6px 12px; background:#f3f4f6; border-radius:8px; font-size:0.85em;" title="B·∫≠t/t·∫Øt ƒë·ªçc to c√¢u tr·∫£ l·ªùi">
                            <input type="checkbox" id="llm-tts-toggle" onchange="saveTTSPreference()" style="cursor:pointer;">
                            <span>üîä ƒê·ªçc to</span>
                        </label>
                        <!-- AI Model selector -->
                        <select id="llm-chat-model" style="padding:8px 12px; border-radius:8px; border:2px solid #e5e7eb; font-size:0.9em; cursor:pointer;" onchange="saveLLMChatModel()">
                            <option value="models/gemini-3-flash-preview">‚ö° Gemini 3 Flash</option>
                            <option value="models/gemini-2.0-flash">‚ö° Gemini 2.0 Flash</option>
                            <option value="models/gemini-2.5-pro-preview-06-05">üíé Gemini 2.5 Pro</option>
                            <option value="models/gemini-2.5-flash-preview-05-20">‚ö° Gemini 2.5 Flash</option>
                        </select>
                        <button onclick="clearLLMChat()" style="padding:8px 16px; background:#ef4444; color:white; border:none; border-radius:8px; cursor:pointer; font-size:0.9em;">
                            üóëÔ∏è X√≥a Chat
                        </button>
                    </div>
                </h2>
                
                <!-- AI Status Bar -->
                <div id="llm-ai-status" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color:white; padding:12px 16px; border-radius:10px; margin-bottom:15px; display:flex; justify-content:space-between; align-items:center; flex-wrap:wrap; gap:10px;">
                    <div style="display:flex; gap:20px; flex-wrap:wrap; align-items:center;">
                        <span>ü§ñ <strong>Gemini AI</strong> + üìö Knowledge Base</span>
                        <span style="font-size:0.85em; opacity:0.9;">T√≠ch h·ª£p RAG System t·ª± ƒë·ªông</span>
                    </div>
                    <span style="font-size:0.85em; background:rgba(255,255,255,0.2); padding:4px 10px; border-radius:20px;">‚úÖ S·∫µn s√†ng</span>
                </div>
                
                <!-- Chat Messages Container -->
                <div id="llm-chat-messages" style="flex:1; overflow-y:auto; background:#f5f5f5; border-radius:10px; padding:15px; display:flex; flex-direction:column; gap:12px;">
                    <!-- Welcome message -->
                    <div style="text-align:center; color:#666; padding:40px 20px;">
                        <div style="font-size:4em; margin-bottom:15px;">ü§ñ</div>
                        <h3 style="color:#667eea; margin-bottom:10px;">Ch√†o m·ª´ng ƒë·∫øn Chat v·ªõi Gemini AI!</h3>
                        <p style="font-size:0.95em; max-width:400px; margin:0 auto;">
                            Chat tr·ª±c ti·∫øp v·ªõi Gemini AI.<br>
                            AI s·∫Ω t·ª± ƒë·ªông t√¨m ki·∫øm trong Knowledge Base c·ªßa b·∫°n ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c h∆°n.
                        </p>
                    </div>
                </div>
                
                <!-- Chat Input Area -->
                <div style="margin-top:15px; display:flex; gap:10px; align-items:flex-end;">
                    <!-- üëÇ Wake Word Button -->
                    <button id="llm-wakeword-btn" onclick="toggleWakeWord()" 
                            style="width:50px; height:50px; border-radius:50%; background:linear-gradient(135deg,#6b7280,#4b5563); color:white; border:none; cursor:pointer; font-size:1.4em; display:flex; align-items:center; justify-content:center; transition:all 0.3s; flex-shrink:0;"
                            title="üëÇ B·∫≠t Wake Word (n√≥i 'Hey Gemini' ƒë·ªÉ chat)">
                        üëÇ
                    </button>
                    <!-- üé§ Microphone Button -->
                    <button id="llm-mic-btn" onclick="toggleLLMVoiceInput()" 
                            style="width:50px; height:50px; border-radius:50%; background:linear-gradient(135deg,#10b981,#059669); color:white; border:none; cursor:pointer; font-size:1.4em; display:flex; align-items:center; justify-content:center; transition:all 0.3s; flex-shrink:0;"
                            title="üé§ Nh·∫•n ƒë·ªÉ n√≥i (auto-send)">
                        üé§
                    </button>
                    <div style="flex:1; position:relative;">
                        <textarea id="llm-chat-input" 
                                  placeholder="Nh·∫≠p tin nh·∫Øn ho·∫∑c nh·∫•n üé§ ƒë·ªÉ n√≥i... (Enter ƒë·ªÉ g·ª≠i)"
                                  style="width:100%; padding:15px; padding-right:50px; border:2px solid #e5e7eb; border-radius:12px; font-size:1em; resize:none; min-height:50px; max-height:150px; font-family:inherit;"
                                  onkeydown="handleLLMChatKeydown(event)"
                                  oninput="autoResizeLLMInput(this)"></textarea>
                        <button onclick="sendLLMMessage()" 
                                style="position:absolute; right:10px; bottom:10px; width:40px; height:40px; border-radius:50%; background:linear-gradient(135deg,#667eea,#764ba2); color:white; border:none; cursor:pointer; font-size:1.2em; display:flex; align-items:center; justify-content:center; transition:all 0.3s;"
                                title="G·ª≠i tin nh·∫Øn">
                            ‚û§
                        </button>
                    </div>
                </div>
                <!-- Voice Recording Status -->
                <div id="llm-voice-status" style="display:none; margin-top:10px; padding:12px 16px; background:linear-gradient(135deg,#fef3c7,#fde68a); border-radius:10px; text-align:center;">
                    <span id="llm-voice-status-text">üé§ ƒêang nghe...</span>
                </div>
                <!-- Wake Word Info -->
                <div style="margin-top:8px; font-size:0.8em; color:#6b7280; text-align:center;">
                    üí° <strong>Wake Words:</strong> "Hey Gemini", "Gemini ∆°i", "Xin ch√†o" | <strong>Goodbye:</strong> "T·∫°m bi·ªát", "Bye bye", "Ng·ªß ƒëi"
                </div>
                
                <!-- Quick Actions -->
                <div style="margin-top:10px; display:flex; gap:8px; flex-wrap:wrap;">
                    <button onclick="sendQuickMessage('Xin ch√†o!')" class="quick-msg-btn">üëã Xin ch√†o</button>
                    <button onclick="sendQuickMessage('T√≥m t·∫Øt ki·∫øn th·ª©c trong Knowledge Base')" class="quick-msg-btn">üìö KB Summary</button>
                    <button onclick="sendQuickMessage('Gi·∫£i th√≠ch code Python cho ng∆∞·ªùi m·ªõi')" class="quick-msg-btn">üêç Python</button>
                    <button onclick="sendQuickMessage('Vi·∫øt m·ªôt ƒëo·∫°n vƒÉn ng·∫Øn v·ªÅ AI')" class="quick-msg-btn">‚úçÔ∏è Vi·∫øt vƒÉn</button>
                    <button onclick="sendQuickMessage('D·ªãch sang ti·∫øng Anh: Xin ch√†o c√°c b·∫°n')" class="quick-msg-btn">üåê D·ªãch thu·∫≠t</button>
                </div>
            </div>
        </div>
        
        <!-- CONVERSATION HISTORY SECTION (WeChat style) -->
        <div id="conversation-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.12); height: calc(100vh - 180px); display: flex; flex-direction: column;">
                <h2 style="color:#667eea; margin-bottom: 15px; display: flex; align-items: center; justify-content: space-between;">
                    <span>üí¨ L·ªãch S·ª≠ H·ªôi Tho·∫°i</span>
                    <div style="display:flex; gap:10px;">
                        <button onclick="loadConversationHistory()" style="padding:8px 16px; background:#10b981; color:white; border:none; border-radius:8px; cursor:pointer; font-size:0.9em;">
                            üîÑ L√†m m·ªõi
                        </button>
                        <button onclick="exportConversation()" style="padding:8px 16px; background:#667eea; color:white; border:none; border-radius:8px; cursor:pointer; font-size:0.9em;">
                            üíæ Xu·∫•t File
                        </button>
                        <button onclick="clearConversationHistory()" style="padding:8px 16px; background:#ef4444; color:white; border:none; border-radius:8px; cursor:pointer; font-size:0.9em;">
                            üóëÔ∏è X√≥a H·∫øt
                        </button>
                    </div>
                </h2>
                
                <!-- Stats bar -->
                <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color:white; padding:12px 16px; border-radius:10px; margin-bottom:15px; display:flex; justify-content:space-between; align-items:center;">
                    <div>
                        <span style="font-size:0.85em; opacity:0.9;">T·ªïng s·ªë tin nh·∫Øn:</span>
                        <span style="font-weight:700; font-size:1.1em; margin-left:8px;" id="total-messages">0</span>
                    </div>
                    <div style="font-size:0.85em; opacity:0.9;" id="last-update">Ch∆∞a c√≥ d·ªØ li·ªáu</div>
                </div>
                
                <!-- Chat container (WeChat style) -->
                <div id="chat-container" style="flex:1; overflow-y:auto; background:#f5f5f5; border-radius:10px; padding:15px; display:flex; flex-direction:column; gap:12px;">
                    <!-- Messages will be rendered here -->
                </div>
            </div>
        </div>
        
        <!-- MUSIC PLAYER SECTION - VLC Web Interface Style -->
        <div id="music-section" style="display:none;">
            <!-- Source Priority Selector -->
            <div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; padding: 20px; margin-bottom: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.3);">
                <div style="display: flex; align-items: center; justify-content: space-between; flex-wrap: wrap; gap: 15px;">
                    <div style="display: flex; align-items: center; gap: 15px;">
                        <span style="color: #fff; font-weight: 600; font-size: 1.1em;">üéØ Ngu·ªìn ph√°t ∆∞u ti√™n:</span>
                        <div style="display: flex; gap: 10px;">
                            <button id="source-library-btn" onclick="setMusicSource('library')" 
                                    style="padding: 10px 20px; border-radius: 25px; border: 2px solid #667eea; background: #667eea; color: white; font-weight: 600; cursor: pointer; transition: all 0.3s;">
                                üìö Music Library
                            </button>
                            <button id="source-user-btn" onclick="setMusicSource('user')" 
                                    style="padding: 10px 20px; border-radius: 25px; border: 2px solid #667eea; background: transparent; color: #667eea; font-weight: 600; cursor: pointer; transition: all 0.3s;">
                                üìÅ Th∆∞ m·ª•c c√° nh√¢n
                            </button>
                        </div>
                    </div>
                    <div id="current-source-info" style="color: #a5b4fc; font-size: 0.9em;">
                        ƒêang d√πng: <span id="source-path-display" style="font-family: monospace;">music_library/</span>
                    </div>
                </div>
            </div>
            
            <!-- VLC-style Player -->
            <div class="music-player" style="position:relative; background: linear-gradient(135deg, #2b3e50 0%, #1a252f 100%); border-radius: 15px; padding: 25px; box-shadow: 0 15px 40px rgba(0,0,0,0.4);">
                <!-- Album Art & Track Info -->
                <div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
                    <div id="album-art" style="width: 120px; height: 120px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 12px; display: flex; align-items: center; justify-content: center; font-size: 48px; box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);">
                        üéµ
                    </div>
                    <div class="now-playing" style="flex: 1;">
                        <h3 id="current-track" style="color: #fff; font-size: 1.4em; margin-bottom: 8px;">üéµ Ch∆∞a ph√°t nh·∫°c</h3>
                        <p id="track-info" style="color: #a5b4fc; font-size: 0.95em; margin-bottom: 5px;">Ch·ªçn b√†i h√°t t·ª´ danh s√°ch b√™n d∆∞·ªõi</p>
                        <!-- Audio Visualizer - S√≥ng nh·∫°c -->
                        <div id="audio-visualizer" class="audio-visualizer paused" style="display: none;">
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                        </div>
                        <p id="track-album" style="color: #6b7280; font-size: 0.85em;"></p>
                    </div>
                </div>
                
                <!-- Progress Bar (VLC style) - DRAGGABLE -->
                <div class="progress-container" style="margin-bottom: 20px;">
                    <input type="range" id="progress-slider" min="0" max="100" value="0" step="0.1"
                           oninput="onProgressDrag(this.value)" 
                           onchange="onProgressSeek(this.value)"
                           onmousedown="isDraggingProgress = true"
                           onmouseup="isDraggingProgress = false"
                           style="width: 100%; height: 8px; -webkit-appearance: none; background: linear-gradient(to right, #667eea 0%, #667eea 0%, #374151 0%, #374151 100%); border-radius: 4px; cursor: pointer; margin: 0;">
                    <div class="progress-time" style="display: flex; justify-content: space-between; margin-top: 8px; color: #9ca3af; font-size: 0.85em; font-family: monospace;">
                        <span id="current-time">0:00</span>
                        <span id="total-time">0:00</span>
                    </div>
                </div>
                
                <!-- Player Controls (VLC style) -->
                <div class="player-controls" style="display: flex; align-items: center; justify-content: center; gap: 15px; margin-bottom: 20px;">
                    <div class="player-btn" id="shuffle-btn" onclick="toggleShuffle()" title="Ph√°t ng·∫´u nhi√™n" style="opacity: 0.6; cursor: pointer; font-size: 1.3em; padding: 10px; transition: all 0.2s;">üîÄ</div>
                    <div class="player-btn" onclick="musicPrevious()" title="B√†i tr∆∞·ªõc" style="cursor: pointer; font-size: 1.5em; padding: 10px;">‚èÆÔ∏è</div>
                    <div class="player-btn play" onclick="musicPlayPause()" id="play-btn" title="Ph√°t/T·∫°m d·ª´ng" style="cursor: pointer; font-size: 2.5em; padding: 15px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 50%; box-shadow: 0 5px 20px rgba(102, 126, 234, 0.5);">‚ñ∂Ô∏è</div>
                    <div class="player-btn" onclick="musicNext()" title="B√†i ti·∫øp" style="cursor: pointer; font-size: 1.5em; padding: 10px;">‚è≠Ô∏è</div>
                    <div class="player-btn" id="repeat-btn" onclick="toggleRepeat()" title="L·∫∑p l·∫°i" style="opacity: 0.6; cursor: pointer; font-size: 1.3em; padding: 10px; transition: all 0.2s;">üîÅ</div>
                    <div class="player-btn" onclick="musicStop()" title="D·ª´ng" style="cursor: pointer; font-size: 1.3em; padding: 10px;">‚èπÔ∏è</div>
                </div>
                
                <!-- Volume Control (VLC style) -->
                <div style="display: flex; align-items: center; justify-content: center; gap: 15px; padding: 10px 0;">
                    <span onclick="toggleMute()" style="cursor: pointer; font-size: 1.3em;" id="volume-icon">üîä</span>
                    <input type="range" id="volume-slider" min="0" max="100" value="80" 
                           oninput="setPlayerVolume(this.value)"
                           style="width: 200px; height: 6px; -webkit-appearance: none; background: linear-gradient(to right, #667eea 0%, #667eea 80%, #374151 80%, #374151 100%); border-radius: 3px; cursor: pointer;">
                    <span id="volume-value" style="color: #9ca3af; font-size: 0.85em; min-width: 40px;">80%</span>
                </div>
            </div>
            
            <!-- Music Library with Search -->
            <div class="music-list" style="margin-top: 20px; background: white; border-radius: 15px; padding: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.12);">
                <!-- H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng -->
                <div style="background: linear-gradient(135deg, #e0e7ff 0%, #f3e8ff 100%); border-left: 4px solid #667eea; padding: 12px 15px; border-radius: 8px; margin-bottom: 15px; display: flex; align-items: center; gap: 10px;">
                    <span style="font-size: 1.3em;">üí°</span>
                    <div style="flex: 1;">
                        <strong style="color: #667eea;">H∆∞·ªõng d·∫´n:</strong>
                        <span style="color: #4b5563; font-size: 0.9em;"> Click v√†o b√†i h√°t ƒë·ªÉ ph√°t ngay (ho·∫∑c click n√∫t ‚ñ∂Ô∏è khi hover)</span>
                    </div>
                </div>
                
                <div style="display: flex; align-items: center; justify-content: space-between; flex-wrap: wrap; gap: 15px; margin-bottom: 15px;">
                    <h3 style="margin: 0; color: #333;">üìÅ Th∆∞ Vi·ªán Nh·∫°c</h3>
                    <div style="display: flex; gap: 10px; align-items: center;">
                        <input type="text" id="music-search" placeholder="üîç T√¨m b√†i h√°t..." 
                               oninput="filterMusicLibrary(this.value)"
                               style="padding: 10px 15px; border: 2px solid #e5e7eb; border-radius: 25px; width: 250px; font-size: 0.95em;">
                        <button onclick="loadMusicLibrary()" style="padding: 10px 20px; background: #667eea; color: white; border: none; border-radius: 25px; cursor: pointer; font-weight: 600;">üîÑ L√†m m·ªõi</button>
                    </div>
                </div>
                <div id="music-library" style="max-height: 400px; overflow-y: auto;">
                    <div style="text-align:center; padding:40px; color:#999;">
                        <p style="font-size:1.2em; margin-bottom:10px;">‚è≥ ƒêang t·∫£i danh s√°ch nh·∫°c...</p>
                        <button onclick="loadMusicLibrary()" style="padding:12px 24px; background:#667eea; color:white; border:none; border-radius:8px; cursor:pointer; font-size:1em;">T·∫£i ngay</button>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- RUNCAT ANIMATION (g√≥c ph·∫£i d∆∞·ªõi) -->
        <div id="runcat-container">
            <div id="runcat">üê±</div>
        </div>

        <!-- MUSIC SETTINGS SECTION -->
        <div id="music-settings-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.12);">
                <h2 style="color:#667eea; margin-bottom: 20px; display: flex; align-items: center; gap: 10px;">
                    ‚öôÔ∏è C√†i ƒê·∫∑t Th∆∞ M·ª•c Nh·∫°c
                </h2>
                
                <div style="background: #f8f9fa; padding: 25px; border-radius: 12px; margin-bottom: 20px; border-left: 4px solid #667eea;">
                    <h3 style="color: #333; margin-bottom: 15px; font-size: 1.1em;">üìÅ ƒê∆∞·ªùng D·∫´n Th∆∞ M·ª•c Nh·∫°c</h3>
                    <p style="color: #666; margin-bottom: 15px; line-height: 1.6;">
                        Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a nh·∫°c c·ªßa b·∫°n. miniZ s·∫Ω ∆∞u ti√™n ph√°t nh·∫°c t·ª´ th∆∞ m·ª•c n√†y b·∫±ng tr√¨nh ph√°t m·∫∑c ƒë·ªãnh c·ªßa Windows.
                    </p>
                    
                    <div style="display: flex; gap: 10px; margin-bottom: 15px;">
                        <input type="text" id="music-folder-path" placeholder="V√≠ d·ª•: F:\My Music ho·∫∑c C:\Users\Name\Music" 
                               style="flex: 1; padding: 12px 15px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 1em; font-family: 'Consolas', monospace;">
                        <button onclick="browseMusicFolder()" 
                                style="padding: 12px 20px; background: #667eea; color: white; border: none; border-radius: 8px; cursor: pointer; font-weight: 600; white-space: nowrap;">
                            üìÇ Ch·ªçn Th∆∞ M·ª•c
                        </button>
                        <button onclick="saveMusicFolder()" 
                                style="padding: 12px 20px; background: #10b981; color: white; border: none; border-radius: 8px; cursor: pointer; font-weight: 600; white-space: nowrap;">
                            üíæ L∆∞u
                        </button>
                    </div>
                    
                    <div id="music-folder-status" style="margin-top: 10px; padding: 10px; border-radius: 6px; display: none;"></div>
                </div>
                
                <div style="background: #fff3cd; padding: 20px; border-radius: 12px; border-left: 4px solid #ffc107; margin-bottom: 20px;">
                    <h3 style="color: #856404; margin-bottom: 10px; font-size: 1em;">üí° L∆∞u √ù</h3>
                    <ul style="color: #856404; line-height: 1.8; margin-left: 20px;">
                        <li>Sau khi l∆∞u, b·∫°n c√≥ th·ªÉ y√™u c·∫ßu LLM ph√°t nh·∫°c t·ª´ th∆∞ m·ª•c n√†y</li>
                        <li>miniZ s·∫Ω d√πng tr√¨nh ph√°t m·∫∑c ƒë·ªãnh c·ªßa Windows (Windows Media Player, Groove Music, VLC...)</li>
                        <li>V√≠ d·ª• l·ªánh: "<i>Ph√°t nh·∫°c trong th∆∞ m·ª•c c·ªßa t√¥i</i>" ho·∫∑c "<i>Play all songs</i>"</li>
                    </ul>
                </div>
                
                <div style="background: #e8f4f8; padding: 20px; border-radius: 12px; border-left: 4px solid #3b82f6;">
                    <h3 style="color: #1e40af; margin-bottom: 10px; font-size: 1em;">üéµ ƒê·ªãnh D·∫°ng H·ªó Tr·ª£</h3>
                    <div style="display: flex; flex-wrap: wrap; gap: 10px; margin-top: 10px;">
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.mp3</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.wav</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.flac</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.m4a</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.wma</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.aac</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.ogg</span>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- PLAYLIST SECTION -->
        <div id="playlist-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.12);">
                <h2 style="color:#667eea; margin-bottom: 12px; display: flex; align-items: center; justify-content: space-between; gap: 15px;">
                    <span>üéµ Danh S√°ch Nh·∫°c YouTube</span>
                    <div style="display:flex; align-items:center; gap:10px;">
                        <input id="playlist-command" placeholder="G√µ t·ª´ kh√≥a playlist (vd: nh·∫°c, chill...)" style="padding:8px 12px; border-radius:8px; border:1px solid #e5e7eb; font-size:0.95em; width:280px;" 
                               onkeypress="if(event.key==='Enter') triggerPlayByName(this.value.trim())" />
                        <button onclick="triggerPlayByName(document.getElementById('playlist-command').value.trim())" style="padding:8px 12px; background:#667eea; color:white; border:none; border-radius:8px; cursor:pointer;">M·ªü</button>
                    </div>
                </h2>

                <div style="display:flex; gap:20px; align-items:flex-start;">
                    <div style="flex:1;">
                        <div id="playlist-list" style="background:#f9fafb; padding:12px; border-radius:8px; min-height:80px; border:1px solid #e5e7eb;">
                            <!-- playlists will be rendered here -->
                        </div>
                        <div style="margin-top:12px; display:flex; gap:10px;">
                            <button onclick="promptAddPlaylist()" style="padding:10px 14px; border-radius:8px; background:linear-gradient(135deg,#10b981,#059669); color:white; border:none; cursor:pointer; font-weight:600;">Ôºã Th√™m Playlist</button>
                            <button onclick="renderPlaylists()" style="padding:10px 14px; border-radius:8px; background:#e5e7eb; border:none; cursor:pointer;">L√†m m·ªõi</button>
                        </div>
                    </div>
                    <div style="width:320px;">
                        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color:white; padding:14px; border-radius:12px;">
                            <div style="font-weight:700; margin-bottom:6px;">H∆∞·ªõng d·∫´n nhanh</div>
                            <div style="font-size:0.95em; opacity:0.95;">
                                ‚Ä¢ Nh·∫•n <b>Ôºã Th√™m Playlist</b> ƒë·ªÉ th√™m m·ªõi (t√™n + URL)<br>
                                ‚Ä¢ G√µ <b>t·ª´ kh√≥a</b> (kh√¥ng c·∫ßn ch√≠nh x√°c) v√†o √¥ v√† nh·∫•n <b>M·ªü</b><br>
                                ‚Ä¢ V√≠ d·ª•: g√µ "nh·∫°c" s·∫Ω t√¨m "Nh·∫°c chill", "Nh·∫°c EDM"...<br>
                                ‚Ä¢ Voice: "m·ªü danh s√°ch [t·ª´ kh√≥a]" ho·∫∑c "m·ªü playlist [t·ª´ kh√≥a]"
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- KNOWLEDGE BASE SECTION -->
        <div id="knowledge-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 25px; box-shadow: 0 10px 30px rgba(0,0,0,0.12);">
                <h2 style="color:#667eea; margin-bottom: 20px; display: flex; align-items: center; gap: 10px;">
                    <span>üìö Knowledge Base</span>
                    <span style="font-size: 0.5em; color: #9ca3af; font-weight: 400;">C·∫≠p nh·∫≠t d·ªØ li·ªáu cho LLM</span>
                </h2>
                
                <!-- Nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c -->
                <div style="background: #f9fafb; padding: 20px; border-radius: 12px; border: 2px solid #e5e7eb; margin-bottom: 20px;">
                    <h3 style="color: #333; margin-bottom: 15px; display: flex; align-items: center; gap: 8px;">
                        üìÅ Th∆∞ M·ª•c D·ªØ Li·ªáu
                    </h3>
                    <div style="display: flex; gap: 10px; align-items: center;">
                        <input type="text" id="knowledge-folder-path" 
                               placeholder="Nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c (VD: C:\Documents\MyData ho·∫∑c D:\Knowledge)" 
                               style="flex: 1; padding: 12px 15px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 1em;">
                        <button onclick="saveKnowledgeFolder()" 
                                style="padding: 12px 25px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 8px; font-weight: 600; cursor: pointer; white-space: nowrap;">
                            üíæ L∆∞u
                        </button>
                        <button onclick="scanKnowledgeFolder()" 
                                style="padding: 12px 25px; background: linear-gradient(135deg, #10b981 0%, #059669 100%); color: white; border: none; border-radius: 8px; font-weight: 600; cursor: pointer; white-space: nowrap;">
                            üîç Qu√©t Files
                        </button>
                    </div>
                    <p style="color: #666; font-size: 0.9em; margin-top: 10px;">
                        üí° H·ªó tr·ª£: PDF, TXT, Word (.docx), Markdown (.md), JSON, CSV
                    </p>
                </div>
                
                <!-- Tr·∫°ng th√°i & th·ªëng k√™ -->
                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 20px;">
                    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; text-align: center;">
                        <div style="font-size: 2em; font-weight: bold;" id="kb-total-files">0</div>
                        <div style="opacity: 0.9;">T·ªïng s·ªë files</div>
                    </div>
                    <div style="background: linear-gradient(135deg, #10b981 0%, #059669 100%); color: white; padding: 20px; border-radius: 12px; text-align: center;">
                        <div style="font-size: 2em; font-weight: bold;" id="kb-indexed-files">0</div>
                        <div style="opacity: 0.9;">ƒê√£ index</div>
                    </div>
                    <div style="background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); color: white; padding: 20px; border-radius: 12px; text-align: center;">
                        <div style="font-size: 2em; font-weight: bold;" id="kb-total-size">0 KB</div>
                        <div style="opacity: 0.9;">Dung l∆∞·ª£ng</div>
                    </div>
                    <div style="background: linear-gradient(135deg, #8b5cf6 0%, #7c3aed 100%); color: white; padding: 20px; border-radius: 12px; text-align: center;">
                        <div style="font-size: 2em; font-weight: bold;" id="kb-last-update">--</div>
                        <div style="opacity: 0.9;">C·∫≠p nh·∫≠t l·∫ßn cu·ªëi</div>
                    </div>
                </div>
                
                <!-- Danh s√°ch files -->
                <div style="background: #f9fafb; padding: 20px; border-radius: 12px; border: 2px solid #e5e7eb;">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px;">
                        <h3 style="color: #333; display: flex; align-items: center; gap: 8px; margin: 0;">
                            üìÑ Danh S√°ch Files
                        </h3>
                        <div style="display: flex; gap: 10px;">
                            <button onclick="indexAllFiles()" 
                                    style="padding: 8px 16px; background: #667eea; color: white; border: none; border-radius: 6px; cursor: pointer; font-size: 0.9em;">
                                üîÑ Index T·∫•t C·∫£
                            </button>
                            <button onclick="clearKnowledgeBase()" 
                                    style="padding: 8px 16px; background: #ef4444; color: white; border: none; border-radius: 6px; cursor: pointer; font-size: 0.9em;">
                                üóëÔ∏è X√≥a Index
                            </button>
                        </div>
                    </div>
                    <div id="knowledge-file-list" style="max-height: 400px; overflow-y: auto;">
                        <p style="color: #666; text-align: center; padding: 40px;">
                            üìÇ Ch∆∞a c√≥ th∆∞ m·ª•c n√†o ƒë∆∞·ª£c c·∫•u h√¨nh.<br>
                            Nh·∫≠p ƒë∆∞·ªùng d·∫´n v√† nh·∫•n "Qu√©t Files" ƒë·ªÉ b·∫Øt ƒë·∫ßu.
                        </p>
                    </div>
                </div>
                
                <!-- H∆∞·ªõng d·∫´n -->
                <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; margin-top: 20px;">
                    <h3 style="margin-bottom: 12px;">üìñ H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng</h3>
                    <div style="font-size: 0.95em; line-height: 1.6;">
                        <p>1. <strong>Nh·∫≠p ƒë∆∞·ªùng d·∫´n</strong> th∆∞ m·ª•c ch·ª©a t√†i li·ªáu (PDF, TXT, Word, Markdown...)</p>
                        <p>2. <strong>Nh·∫•n "Qu√©t Files"</strong> ƒë·ªÉ li·ªát k√™ c√°c files trong th∆∞ m·ª•c</p>
                        <p>3. <strong>Nh·∫•n "Index T·∫•t C·∫£"</strong> ƒë·ªÉ LLM h·ªçc t·ª´ n·ªôi dung c√°c files</p>
                        <p>4. Sau khi index, LLM c√≥ th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n d·ªØ li·ªáu c·ªßa b·∫°n!</p>
                        <p style="margin-top: 10px; opacity: 0.9;">
                            üí° <strong>M·∫πo:</strong> ƒê·∫∑t c√°c t√†i li·ªáu quan tr·ªçng v√†o m·ªôt th∆∞ m·ª•c ri√™ng ƒë·ªÉ d·ªÖ qu·∫£n l√Ω.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- SETTINGS MODAL -->
        <div id="settingsModal" class="modal">
            <div class="modal-content" style="max-width:1400px;width:95%;">
                <div class="modal-header">
                    <h2>‚öôÔ∏è C·∫•u h√¨nh Endpoint</h2>
                    <button class="close-btn" onclick="closeSettingsModal()">&times;</button>
                </div>
                <div class="modal-body">
                    <!-- 3 ENDPOINT SECTIONS -->
                    <div style="display:grid;grid-template-columns:1fr 1fr 1fr;gap:20px;margin-bottom:25px;">
                        <!-- Thi·∫øt b·ªã 1 -->
                        <div id="device-1-card" style="border:2px solid #10b981;border-radius:8px;padding:15px;background:#f0fdf4;position:relative;">
                            <div style="position:absolute;top:10px;right:10px;">
                                <span id="device-1-indicator" class="connection-indicator" style="display:inline-flex;align-items:center;gap:5px;padding:4px 10px;border-radius:12px;background:#d1fae5;color:#047857;font-size:0.75em;font-weight:bold;">
                                    <span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#6b7280;"></span>
                                    Ch∆∞a k·∫øt n·ªëi
                                </span>
                            </div>
                            <label for="endpoint-url-1" style="color:#047857;font-weight:600;display:flex;align-items:center;gap:8px;">
                                üì± Thi·∫øt b·ªã 1
                            </label>
                            <input type="text" id="endpoint-url-1" placeholder="JWT token thi·∫øt b·ªã 1..." style="margin-top:8px;border:2px solid #10b981;" />
                            <p style="color:#065f46;font-size:0.85em;margin-top:5px;margin-bottom:0;">
                                Token th·∫≠t t·ª´ Claude Desktop
                            </p>
                        </div>
                        
                        <!-- Thi·∫øt b·ªã 2 -->
                        <div id="device-2-card" style="border:2px solid #3b82f6;border-radius:8px;padding:15px;background:#eff6ff;position:relative;">
                            <div style="position:absolute;top:10px;right:10px;">
                                <span id="device-2-indicator" class="connection-indicator" style="display:inline-flex;align-items:center;gap:5px;padding:4px 10px;border-radius:12px;background:#dbeafe;color:#1e40af;font-size:0.75em;font-weight:bold;">
                                    <span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#6b7280;"></span>
                                    Ch∆∞a k·∫øt n·ªëi
                                </span>
                            </div>
                            <label for="endpoint-url-2" style="color:#1e40af;font-weight:600;display:flex;align-items:center;gap:8px;">
                                üì± Thi·∫øt b·ªã 2
                            </label>
                            <input type="text" id="endpoint-url-2" placeholder="JWT token thi·∫øt b·ªã 2..." style="margin-top:8px;border:2px solid #3b82f6;" />
                            <p style="color:#1e3a8a;font-size:0.85em;margin-top:5px;margin-bottom:0;">
                                MCP connection 2
                            </p>
                        </div>
                        
                        <!-- Thi·∫øt b·ªã 3 -->
                        <div id="device-3-card" style="border:2px solid #f59e0b;border-radius:8px;padding:15px;background:#fffbeb;position:relative;">
                            <div style="position:absolute;top:10px;right:10px;">
                                <span id="device-3-indicator" class="connection-indicator" style="display:inline-flex;align-items:center;gap:5px;padding:4px 10px;border-radius:12px;background:#fef3c7;color:#b45309;font-size:0.75em;font-weight:bold;">
                                    <span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#6b7280;"></span>
                                    Ch∆∞a k·∫øt n·ªëi
                                </span>
                            </div>
                            <label for="endpoint-url-3" style="color:#b45309;font-weight:600;display:flex;align-items:center;gap:8px;">
                                üì± Thi·∫øt b·ªã 3
                            </label>
                            <input type="text" id="endpoint-url-3" placeholder="JWT token thi·∫øt b·ªã 3..." style="margin-top:8px;border:2px solid #f59e0b;" />
                            <p style="color:#78350f;font-size:0.85em;margin-top:5px;margin-bottom:0;">
                                MCP connection 3
                            </p>
                        </div>
                    </div>
                    
                    <p style="color:#666;font-size:0.9em;text-align:center;margin-top:-10px;margin-bottom:20px;">
                        <strong>L∆∞u √Ω:</strong> C√≥ th·ªÉ nh·∫≠p JWT token tr·ª±c ti·∫øp ho·∫∑c URL ƒë·∫ßy ƒë·ªß <code>wss://api.xiaozhi.me/mcp/?token=...</code> - h·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω
                    </p>
                    
                    <hr style="margin:25px 0;border:none;border-top:2px solid #e5e7eb;">
                    
                    <!-- API KEYS GRID (2 Columns) -->
                    <div style="display:grid;grid-template-columns:1fr 1fr;gap:30px;">
                        <!-- LEFT COLUMN: Gemini -->
                        <div style="border-right:2px solid #e5e7eb;padding-right:30px;">
                            <label for="gemini-api-key" style="display:flex;align-items:center;gap:10px;">
                                ü§ñ Gemini API Key 
                                <span style="color:#10b981;font-size:0.85em;font-weight:normal;">(Auto-save)</span>
                            </label>
                            <div class="api-key-input-container">
                                <input 
                                    type="password" 
                                    id="gemini-api-key" 
                                    placeholder="AIzaSyXXXXXXXXXXXXXXXXXX..."
                                    oninput="autoSaveGeminiKey()"
                                    style="font-size:0.9em;"
                                />
                                <div class="input-icons">
                                    <button type="button" class="api-key-icon-btn" onclick="toggleApiKeyVisibility('gemini-api-key', this)" title="Hi·ªán/·∫®n API key">
                                        ÔøΩ
                                    </button>
                                    <button type="button" class="api-key-icon-btn" onclick="copyApiKey('gemini-api-key', this)" title="Copy API key">
                                        üìã
                                    </button>
                                </div>
                            </div>
                            <p style="color:#666;font-size:0.9em;margin-top:-10px;">
                                <strong>Mi·ªÖn ph√≠:</strong> L·∫•y API key t·∫°i 
                                <a href="https://aistudio.google.com/apikey" target="_blank" style="color:#667eea;">
                                    aistudio.google.com/apikey
                                </a>
                                <br>
                                <span id="gemini-key-status" style="color:#10b981;font-weight:600;"></span>
                            </p>
                            
                            <label for="gemini-model" style="margin-top:15px;display:block;">
                                üéØ Gemini Model
                            </label>
                            <select 
                                id="gemini-model" 
                                onchange="saveGeminiModel()"
                                style="width:100%;padding:10px;border:2px solid #e5e7eb;border-radius:8px;font-size:0.95em;"
                            >
                                <option value="models/gemini-3-flash-preview">‚ö° Gemini 3 Flash Preview (M·ªõi nh·∫•t)</option>
                                <option value="models/gemini-2.5-flash">‚ö° Gemini 2.5 Flash (·ªîn ƒë·ªãnh)</option>
                                <option value="models/gemini-2.5-pro">üíé Gemini 2.5 Pro (Ch·∫•t l∆∞·ª£ng cao nh·∫•t)</option>
                                <option value="models/gemini-2.0-flash-exp">‚ö° Gemini 2.0 Flash Exp</option>
                                <option value="models/gemini-1.5-pro">üíé Gemini 1.5 Pro (·ªîn ƒë·ªãnh)</option>
                                <option value="models/gemini-2.0-flash-thinking-exp">üß† Gemini 2.0 Flash Thinking (Suy lu·∫≠n t·ªët)</option>
                                <option value="models/gemini-1.5-pro">üíé Gemini 1.5 Pro (·ªîn ƒë·ªãnh)</option>
                                <option value="models/gemini-1.5-flash">‚ö° Gemini 1.5 Flash (C√¢n b·∫±ng)</option>
                            </select>
                            <p style="color:#666;font-size:0.85em;margin-top:5px;">
                                üí° <strong>3.0 Flash:</strong> Model m·ªõi nh·∫•t (12/2024), gi·∫£m 30% token | <strong>2.5 Pro:</strong> Ch·∫•t l∆∞·ª£ng cao nh·∫•t | <strong>1.5 Pro:</strong> ·ªîn ƒë·ªãnh
                            </p>
                        </div>
                        
                        <!-- RIGHT COLUMN: OpenAI + Serper -->
                        <div style="padding-left:30px;">
                            <label for="openai-api-key" style="display:flex;align-items:center;gap:10px;">
                                üß† OpenAI API Key (GPT-4)
                                <span style="color:#10b981;font-size:0.85em;font-weight:normal;">(Auto-save)</span>
                                <span style="color:#ef4444;font-size:0.75em;font-weight:normal;">TR·∫¢ PH√ç</span>
                            </label>
                            <div class="api-key-input-container">
                                <input 
                                    type="password" 
                                    id="openai-api-key" 
                                    placeholder="sk-proj-XXXXXXXXXXXXXXXXXX..."
                                    oninput="autoSaveOpenAIKey()"
                                    style="font-size:0.9em;"
                                />
                                <div class="input-icons">
                                    <button type="button" class="api-key-icon-btn" onclick="toggleApiKeyVisibility('openai-api-key', this)" title="Hi·ªán/·∫®n API key">
                                        ÔøΩ
                                    </button>
                                    <button type="button" class="api-key-icon-btn" onclick="copyApiKey('openai-api-key', this)" title="Copy API key">
                                        üìã
                                    </button>
                                </div>
                            </div>
                            <p style="color:#666;font-size:0.9em;margin-top:-10px;">
                                <strong>Tr·∫£ ph√≠:</strong> L·∫•y API key t·∫°i 
                                <a href="https://platform.openai.com/api-keys" target="_blank" style="color:#667eea;">
                                    platform.openai.com/api-keys
                                </a>
                                <br>
                                <span style="font-size:0.85em;">üí∞ Gi√°: $0.01-0.03/1K tokens | üÜì Free trial: $5 credit</span>
                                <br>
                                <span id="openai-key-status" style="color:#10b981;font-weight:600;"></span>
                            </p>
                            
                            <hr style="margin:20px 0;border:none;border-top:1px solid #e5e7eb;">
                            
                            <label for="serper-api-key" style="display:flex;align-items:center;gap:10px;margin-top:20px;">
                                üîç Serper API Key (Google Search)
                                <span style="color:#10b981;font-size:0.85em;font-weight:normal;">(Auto-save)</span>
                                <span style="color:#22c55e;font-size:0.75em;font-weight:normal;">MI·ªÑN PH√ç 2500/th√°ng</span>
                            </label>
                            <div class="api-key-input-container">
                                <input 
                                    type="password" 
                                    id="serper-api-key" 
                                    placeholder="abcdef1234567890..."
                                    oninput="autoSaveSerperKey()"
                                    style="font-size:0.9em;"
                                />
                                <div class="input-icons">
                                    <button type="button" class="api-key-icon-btn" onclick="toggleApiKeyVisibility('serper-api-key', this)" title="Hi·ªán/·∫®n API key">
                                        ÔøΩ
                                    </button>
                                    <button type="button" class="api-key-icon-btn" onclick="copyApiKey('serper-api-key', this)" title="Copy API key">
                                        üìã
                                    </button>
                                </div>
                            </div>
                            <p style="color:#666;font-size:0.9em;margin-top:-10px;">
                                <strong>Mi·ªÖn ph√≠:</strong> ƒêƒÉng k√Ω t·∫°i 
                                <a href="https://serper.dev" target="_blank" style="color:#667eea;">
                                    serper.dev
                                </a>
                                <br>
                                <span style="font-size:0.85em;">üÜì 2500 queries/th√°ng mi·ªÖn ph√≠ | üéØ Google Search ch√≠nh x√°c h∆°n DuckDuckGo</span>
                                <br>
                                <span id="serper-key-status" style="color:#10b981;font-weight:600;"></span>
                            </p>
                        </div>
                    </div>
                </div>
                <div class="modal-footer">
                    <button class="modal-btn secondary" onclick="closeSettingsModal()">H·ªßy</button>
                    <button class="modal-btn info" onclick="copyFullUrl()">üìã Copy URL ƒë·∫ßy ƒë·ªß</button>
                    <button class="modal-btn primary" onclick="saveEndpoint()">üíæ L∆∞u</button>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Network Info Modal -->
    <div id="networkInfoModal" class="modal">
        <div class="modal-content" style="max-width:600px;width:90%;">
            <div class="modal-header">
                <h3>üåê Th√¥ng Tin M·∫°ng</h3>
                <span class="close-btn" onclick="closeNetworkModal()">&times;</span>
            </div>
            <div class="modal-body" id="networkInfoContent" style="max-height:70vh;overflow-y:auto;font-family:monospace;font-size:13px;line-height:1.6;">
                <div style="text-align:center;padding:40px;">
                    <div class="loading-spinner"></div>
                    <p>ƒêang qu√©t th√¥ng tin m·∫°ng...</p>
                </div>
            </div>
            <div class="modal-footer">
                <button class="modal-btn secondary" onclick="closeNetworkModal()">ƒê√≥ng</button>
                <button class="modal-btn primary" onclick="networkInfo()">üîÑ Qu√©t l·∫°i</button>
            </div>
        </div>
    </div>
    
    <!-- System Resources Modal -->
    <div id="systemResourcesModal" class="modal">
        <div class="modal-content" style="max-width:650px;width:90%;">
            <div class="modal-header">
                <h3>üíª T√†i Nguy√™n H·ªá Th·ªëng</h3>
                <span class="close-btn" onclick="closeSystemResourcesModal()">&times;</span>
            </div>
            <div class="modal-body" id="systemResourcesContent" style="max-height:70vh;overflow-y:auto;font-family:monospace;font-size:13px;line-height:1.6;">
                <div style="text-align:center;padding:40px;">
                    <div class="loading-spinner"></div>
                    <p>ƒêang t·∫£i th√¥ng tin h·ªá th·ªëng...</p>
                </div>
            </div>
            <div class="modal-footer">
                <button class="modal-btn secondary" onclick="closeSystemResourcesModal()">ƒê√≥ng</button>
                <button class="modal-btn primary" onclick="showSystemResourcesPopup()">üîÑ L√†m m·ªõi</button>
            </div>
        </div>
    </div>
    
    <!-- PC Config Modal - C·∫•u H√¨nh M√°y T√≠nh -->
    <div id="pcConfigModal" class="modal">
        <div class="modal-content" style="max-width:750px;width:95%;">
            <div class="modal-header">
                <h3>üñ•Ô∏è C·∫•u H√¨nh M√°y T√≠nh Chi Ti·∫øt</h3>
                <span class="close-btn" onclick="closePCConfigModal()">&times;</span>
            </div>
            <div class="modal-body" id="pcConfigContent" style="max-height:75vh;overflow-y:auto;font-family:monospace;font-size:13px;line-height:1.6;">
                <div style="text-align:center;padding:40px;">
                    <div class="loading-spinner"></div>
                    <p>ƒêang qu√©t c·∫•u h√¨nh ph·∫ßn c·ª©ng...</p>
                </div>
            </div>
            <div class="modal-footer">
                <button class="modal-btn secondary" onclick="closePCConfigModal()">ƒê√≥ng</button>
                <button class="modal-btn primary" onclick="showPCConfigPopup()">üîÑ Qu√©t l·∫°i</button>
            </div>
        </div>
    </div>
    
    <script>
        let ws;
        let llmChatMessages = []; // Store LLM chat messages
        
        // Section switching
        function showSection(name) {
            document.querySelectorAll('.menu-item').forEach(item => item.classList.remove('active'));
            event.target.classList.add('active');
            
            document.getElementById('dashboard-section').style.display = name === 'dashboard' ? 'block' : 'none';
            document.getElementById('tools-section').style.display = name === 'tools' ? 'block' : 'none';
            document.getElementById('llm-chat-section').style.display = name === 'llm-chat' ? 'block' : 'none';
            document.getElementById('api-quotas-section').style.display = name === 'api-quotas' ? 'block' : 'none';
            document.getElementById('music-section').style.display = name === 'music' ? 'block' : 'none';
            document.getElementById('music-settings-section').style.display = name === 'music-settings' ? 'block' : 'none';
            document.getElementById('conversation-section').style.display = name === 'conversation' ? 'block' : 'none';
            document.getElementById('playlist-section').style.display = name === 'playlist' ? 'block' : 'none';
            document.getElementById('knowledge-section').style.display = name === 'knowledge' ? 'block' : 'none';
            
            // Load API Quotas when opening api-quotas section
            if (name === 'api-quotas') {
                refreshQuotasPage();
            }
            
            // Load LLM Chat section
            if (name === 'llm-chat') {
                loadLLMChatModel();
            }
            
            // Load conversation when opening conversation section
            if (name === 'conversation') {
                loadConversationHistory();
            }
            
            // Load music library when opening music section
            if (name === 'music') {
                loadMusicSourcePreference();
                updateMusicStatus();
            }
            if (name === 'music-settings') {
                loadMusicFolderSettings();
            }
            
            // Load playlist when opening playlist section
            if (name === 'playlist') {
                // use initPlaylists() (render existing playlists) - loadPlaylistSection was removed
                initPlaylists();
            }
            
            // Load knowledge base when opening knowledge section
            if (name === 'knowledge') {
                loadKnowledgeBase();
            }
        }
        
        // ===== API QUOTAS PAGE FUNCTIONS =====
        async function refreshQuotasPage() {
            addLog('üîÑ ƒêang l√†m m·ªõi API Quotas...', 'info');
            try {
                const response = await fetch('/api/quotas');
                const data = await response.json();
                
                if (data.success) {
                    // Update Gemini status
                    const geminiStatus = document.getElementById('gemini-status');
                    if (data.gemini && data.gemini.has_key) {
                        geminiStatus.innerHTML = '‚úÖ API Key ƒë√£ c·∫•u h√¨nh';
                        geminiStatus.style.color = '#10b981';
                    } else {
                        geminiStatus.innerHTML = '‚ùå Ch∆∞a c√≥ API Key';
                        geminiStatus.style.color = '#ef4444';
                    }
                    
                    // Update Serper status
                    const serperStatus = document.getElementById('serper-status');
                    if (data.serper && data.serper.has_key) {
                        serperStatus.innerHTML = '‚úÖ API Key ƒë√£ c·∫•u h√¨nh';
                        serperStatus.style.color = '#10b981';
                    } else {
                        serperStatus.innerHTML = '‚ùå Ch∆∞a c√≥ API Key';
                        serperStatus.style.color = '#ef4444';
                    }
                    
                    addLog('‚úÖ ƒê√£ l√†m m·ªõi API Quotas', 'success');
                } else {
                    addLog('‚ùå L·ªói: ' + (data.error || 'Unknown error'), 'error');
                }
            } catch (error) {
                console.error('Error refreshing quotas:', error);
                addLog('‚ùå L·ªói k·∫øt n·ªëi: ' + error.message, 'error');
            }
        }
        
        async function testGeminiAPI() {
            addLog('üß™ ƒêang test Gemini API...', 'info');
            try {
                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({message: 'Hello, this is a test message. Reply with OK.'})
                });
                const data = await response.json();
                
                if (data.response) {
                    addLog('‚úÖ Gemini API ho·∫°t ƒë·ªông t·ªët! Response: ' + data.response.substring(0, 100) + '...', 'success');
                } else {
                    addLog('‚ùå Gemini API test th·∫•t b·∫°i', 'error');
                }
            } catch (error) {
                console.error('Error testing Gemini:', error);
                addLog('‚ùå Gemini test error: ' + error.message, 'error');
            }
        }
        
        async function testSerperAPI() {
            addLog('üß™ ƒêang test Serper API...', 'info');
            try {
                const response = await fetch('/api/google_search', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({query: 'test search'})
                });
                const data = await response.json();
                
                if (data.results && data.results.length > 0) {
                    addLog('‚úÖ Serper API ho·∫°t ƒë·ªông t·ªët! T√¨m th·∫•y ' + data.results.length + ' k·∫øt qu·∫£', 'success');
                } else {
                    addLog('‚ùå Serper API test th·∫•t b·∫°i', 'error');
                }
            } catch (error) {
                console.error('Error testing Serper:', error);
                addLog('‚ùå Serper test error: ' + error.message, 'error');
            }
        }
        
        // Tab switching
        function switchTab(index) {
            document.querySelectorAll('.tab-btn').forEach((btn, i) => btn.classList.toggle('active', i === index));
            document.querySelectorAll('.tab-content').forEach((content, i) => content.classList.toggle('active', i === index));
        }
        
        // Quick actions - 20 tools
        function setVolumePrompt() {
            const level = prompt('Nh·∫≠p √¢m l∆∞·ª£ng (0-100):', '50');
            if (level === null) return;
            const levelNum = parseInt(level);
            if (isNaN(levelNum) || levelNum < 0 || levelNum > 100) {
                addLog('‚ùå √Çm l∆∞·ª£ng ph·∫£i t·ª´ 0-100', 'error');
                return;
            }
            setVolumeQuick(levelNum);
        }
        function setVolumeQuick(level) { 
            if (level >= 0 && level <= 100) {
                callTool('set_volume', {level});
            } else {
                addLog('‚ùå √Çm l∆∞·ª£ng ph·∫£i t·ª´ 0-100', 'error');
            }
        }
        function getVolumeInfo() {
            callTool('get_volume', {});
        }
        function screenshot() { callAPI('/api/screenshot', {}); }
        function notification() { callAPI('/api/notification', {title: 'Xiaozhi', message: 'Test notification'}); }
        function setBrightness() { 
            const level = prompt('Nh·∫≠p ƒë·ªô s√°ng (0-100):', '50');
            if (level === null) return;
            const levelNum = parseInt(level);
            if (isNaN(levelNum) || levelNum < 0 || levelNum > 100) {
                addLog('‚ùå ƒê·ªô s√°ng ph·∫£i t·ª´ 0-100', 'error');
                return;
            }
            callTool('set_brightness', {level: levelNum});
        }
        function openApp() {
            const app = prompt('Nh·∫≠p t√™n app (notepad/calc/paint/cmd/explorer):', 'notepad');
            if (app && app.trim()) callTool('open_application', {app_name: app.trim()});
        }
        function listProcesses() { callTool('list_running_processes', {limit: 10}); }
        function killProcess() {
            const id = prompt('Nh·∫≠p PID ho·∫∑c t√™n ti·∫øn tr√¨nh:', 'chrome');
            if (id && id.trim()) callTool('kill_process', {identifier: id.trim()});
        }
        function createFile() {
            const path = prompt('ƒê∆∞·ªùng d·∫´n file:', 'C:/test.txt');
            if (!path || !path.trim()) return;
            const content = prompt('N·ªôi dung:', 'Hello World');
            if (content !== null) callTool('create_file', {path: path.trim(), content});
        }
        function readFile() {
            const path = prompt('ƒê∆∞·ªùng d·∫´n file:', 'C:/test.txt');
            if (path && path.trim()) callTool('read_file', {path: path.trim()});
        }
        function listFiles() {
            const dir = prompt('Th∆∞ m·ª•c:', 'C:/Users');
            if (dir && dir.trim()) callTool('list_files', {directory: dir.trim()});
        }
        function diskUsage() { callTool('get_disk_usage', {}); }
        
        // Network Info Modal Functions
        function openNetworkModal() {
            var modal = document.getElementById('networkInfoModal');
            if (modal) {
                modal.style.display = 'flex';
                console.log('Modal opened');
            } else {
                console.error('networkInfoModal not found!');
                alert('Kh√¥ng t√¨m th·∫•y modal network info');
            }
        }
        function closeNetworkModal() {
            var modal = document.getElementById('networkInfoModal');
            if (modal) modal.style.display = 'none';
        }
        
        // System Resources Modal Functions
        function openSystemResourcesModal() {
            var modal = document.getElementById('systemResourcesModal');
            if (modal) {
                modal.style.display = 'flex';
            }
        }
        function closeSystemResourcesModal() {
            var modal = document.getElementById('systemResourcesModal');
            if (modal) modal.style.display = 'none';
        }
        
        async function showSystemResourcesPopup() {
            // M·ªü modal v√† hi·ªán loading
            openSystemResourcesModal();
            var contentEl = document.getElementById('systemResourcesContent');
            if (!contentEl) return;
            
            contentEl.innerHTML = '<div style="text-align:center;padding:40px;"><div class="loading-spinner"></div><p style="color:#fff;">üîç ƒêang t·∫£i th√¥ng tin h·ªá th·ªëng...</p></div>';
            
            try {
                // Fetch c·∫£ resources v√† system info
                const [resourcesRes, systemInfoRes] = await Promise.all([
                    fetch('/api/resources'),
                    fetch('/api/system_info')
                ]);
                
                const resourcesData = await resourcesRes.json();
                const systemData = await systemInfoRes.json();
                
                // Build HTML cho modal
                var html = '<div style="padding:10px;">';
                
                // Header
                html += '<div style="background:linear-gradient(135deg,#667eea,#764ba2);padding:12px 15px;border-radius:10px;margin-bottom:15px;text-align:center;">';
                html += '<h3 style="margin:0;color:#fff;">üíª TH√îNG TIN T√ÄI NGUY√äN H·ªÜ TH·ªêNG</h3>';
                html += '</div>';
                
                // Resource Usage Cards
                if (resourcesData.success && resourcesData.data) {
                    var data = resourcesData.data;
                    html += '<div style="display:grid;grid-template-columns:repeat(3,1fr);gap:10px;margin-bottom:15px;">';
                    
                    // CPU Card
                    var cpuColor = data.cpu_percent > 80 ? '#f44336' : (data.cpu_percent > 50 ? '#ff9800' : '#4CAF50');
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;text-align:center;border-left:4px solid ' + cpuColor + ';">';
                    html += '<div style="font-size:32px;margin-bottom:5px;">üñ•Ô∏è</div>';
                    html += '<div style="font-size:24px;font-weight:bold;color:' + cpuColor + ';">' + data.cpu_percent + '%</div>';
                    html += '<div style="font-size:12px;color:#aaa;">CPU Usage</div>';
                    html += '<div style="margin-top:8px;background:#333;border-radius:5px;height:8px;overflow:hidden;">';
                    html += '<div style="width:' + data.cpu_percent + '%;height:100%;background:' + cpuColor + ';transition:width 0.3s;"></div></div>';
                    html += '</div>';
                    
                    // RAM Card
                    var ramColor = data.memory_percent > 80 ? '#f44336' : (data.memory_percent > 50 ? '#ff9800' : '#2196F3');
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;text-align:center;border-left:4px solid ' + ramColor + ';">';
                    html += '<div style="font-size:32px;margin-bottom:5px;">üß†</div>';
                    html += '<div style="font-size:24px;font-weight:bold;color:' + ramColor + ';">' + data.memory_percent + '%</div>';
                    html += '<div style="font-size:12px;color:#aaa;">RAM Usage</div>';
                    html += '<div style="margin-top:8px;background:#333;border-radius:5px;height:8px;overflow:hidden;">';
                    html += '<div style="width:' + data.memory_percent + '%;height:100%;background:' + ramColor + ';transition:width 0.3s;"></div></div>';
                    html += '</div>';
                    
                    // Disk Card
                    var diskColor = data.disk_percent > 90 ? '#f44336' : (data.disk_percent > 70 ? '#ff9800' : '#9C27B0');
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;text-align:center;border-left:4px solid ' + diskColor + ';">';
                    html += '<div style="font-size:32px;margin-bottom:5px;">üíæ</div>';
                    html += '<div style="font-size:24px;font-weight:bold;color:' + diskColor + ';">' + data.disk_percent + '%</div>';
                    html += '<div style="font-size:12px;color:#aaa;">Disk Usage</div>';
                    html += '<div style="margin-top:8px;background:#333;border-radius:5px;height:8px;overflow:hidden;">';
                    html += '<div style="width:' + data.disk_percent + '%;height:100%;background:' + diskColor + ';transition:width 0.3s;"></div></div>';
                    html += '</div>';
                    
                    html += '</div>';
                }
                
                // System Info Details
                if (systemData) {
                    // Basic Info
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:15px;border-left:4px solid #4CAF50;">';
                    html += '<h4 style="margin:0 0 10px 0;color:#4CAF50;">üñ•Ô∏è TH√îNG TIN C∆† B·∫¢N</h4>';
                    html += '<table style="width:100%;font-size:13px;">';
                    if (systemData.basic) {
                        html += '<tr><td style="padding:5px 0;color:#aaa;width:40%;">üíª Hostname:</td><td style="color:#fff;font-weight:bold;">' + (systemData.basic.hostname || 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">ü™ü H·ªá ƒëi·ªÅu h√†nh:</td><td style="color:#fff;">' + (systemData.basic.os || 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">üì¶ Phi√™n b·∫£n:</td><td style="color:#fff;">' + (systemData.basic.os_version || 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">üèóÔ∏è Ki·∫øn tr√∫c:</td><td style="color:#fff;">' + (systemData.basic.architecture || 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">üë§ User:</td><td style="color:#fff;">' + (systemData.basic.username || 'N/A') + '</td></tr>';
                    }
                    html += '</table></div>';
                    
                    // CPU Info
                    if (systemData.cpu) {
                        html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:15px;border-left:4px solid #2196F3;">';
                        html += '<h4 style="margin:0 0 10px 0;color:#2196F3;">‚ö° CPU</h4>';
                        html += '<table style="width:100%;font-size:13px;">';
                        html += '<tr><td style="padding:5px 0;color:#aaa;width:40%;">üî¢ S·ªë nh√¢n v·∫≠t l√Ω:</td><td style="color:#fff;">' + (systemData.cpu.physical_cores || 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">üßµ T·ªïng lu·ªìng:</td><td style="color:#fff;">' + (systemData.cpu.total_cores || 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">‚è±Ô∏è T·∫ßn s·ªë hi·ªán t·∫°i:</td><td style="color:#00ff88;font-weight:bold;">' + (systemData.cpu.current_freq ? systemData.cpu.current_freq.toFixed(0) + ' MHz' : 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">üìä S·ª≠ d·ª•ng:</td><td style="color:#fff;">' + (systemData.cpu.usage_percent || 'N/A') + '%</td></tr>';
                        html += '</table></div>';
                    }
                    
                    // Memory Info
                    if (systemData.memory) {
                        html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:15px;border-left:4px solid #9C27B0;">';
                        html += '<h4 style="margin:0 0 10px 0;color:#9C27B0;">üß† B·ªò NH·ªö</h4>';
                        html += '<table style="width:100%;font-size:13px;">';
                        html += '<tr><td style="padding:5px 0;color:#aaa;width:40%;">üìä T·ªïng RAM:</td><td style="color:#fff;font-weight:bold;">' + (systemData.memory.total_gb ? systemData.memory.total_gb.toFixed(2) + ' GB' : 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">‚úÖ Kh·∫£ d·ª•ng:</td><td style="color:#00ff88;">' + (systemData.memory.available_gb ? systemData.memory.available_gb.toFixed(2) + ' GB' : 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">üî• ƒêang d√πng:</td><td style="color:#ff9800;">' + (systemData.memory.used_gb ? systemData.memory.used_gb.toFixed(2) + ' GB' : 'N/A') + '</td></tr>';
                        html += '<tr><td style="padding:5px 0;color:#aaa;">üìà T·ª∑ l·ªá s·ª≠ d·ª•ng:</td><td style="color:#fff;">' + (systemData.memory.percent || 'N/A') + '%</td></tr>';
                        html += '</table></div>';
                    }
                    
                    // Disk Info
                    if (systemData.disk && systemData.disk.partitions) {
                        html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;border-left:4px solid #ff9800;">';
                        html += '<h4 style="margin:0 0 10px 0;color:#ff9800;">üíæ ·ªî ƒêƒ®A</h4>';
                        html += '<div style="max-height:200px;overflow-y:auto;">';
                        
                        systemData.disk.partitions.forEach(function(part, idx) {
                            var usedPercent = part.percent || 0;
                            var diskColor = usedPercent > 90 ? '#f44336' : (usedPercent > 70 ? '#ff9800' : '#4CAF50');
                            html += '<div style="background:rgba(255,255,255,0.05);padding:10px;border-radius:8px;margin-bottom:8px;">';
                            html += '<div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:5px;">';
                            html += '<span style="font-weight:bold;color:#fff;">üíø ' + (part.device || '·ªî ' + (idx+1)) + '</span>';
                            html += '<span style="color:' + diskColor + ';font-weight:bold;">' + usedPercent + '%</span>';
                            html += '</div>';
                            html += '<div style="background:#333;border-radius:5px;height:6px;overflow:hidden;margin-bottom:5px;">';
                            html += '<div style="width:' + usedPercent + '%;height:100%;background:' + diskColor + ';"></div></div>';
                            html += '<div style="font-size:11px;color:#aaa;">';
                            html += 'üìä ' + (part.used_gb ? part.used_gb.toFixed(1) : '?') + ' GB / ' + (part.total_gb ? part.total_gb.toFixed(1) : '?') + ' GB';
                            html += ' | ‚úÖ C√≤n ' + (part.free_gb ? part.free_gb.toFixed(1) : '?') + ' GB';
                            html += '</div></div>';
                        });
                        html += '</div></div>';
                    }
                }
                
                html += '</div>';
                contentEl.innerHTML = html;
                
                addLog('‚úÖ T·∫£i th√¥ng tin h·ªá th·ªëng th√†nh c√¥ng', 'success');
                
            } catch (error) {
                contentEl.innerHTML = '<div style="text-align:center;padding:40px;color:#f44336;"><p>‚ùå L·ªói: ' + error.message + '</p></div>';
                addLog('‚ùå L·ªói t·∫£i th√¥ng tin h·ªá th·ªëng: ' + error.message, 'error');
            }
        }
        
        // PC Config Modal Functions - C·∫•u h√¨nh m√°y t√≠nh chi ti·∫øt
        function openPCConfigModal() {
            var modal = document.getElementById('pcConfigModal');
            if (modal) modal.style.display = 'flex';
        }
        function closePCConfigModal() {
            var modal = document.getElementById('pcConfigModal');
            if (modal) modal.style.display = 'none';
        }
        
        async function showPCConfigPopup() {
            openPCConfigModal();
            var contentEl = document.getElementById('pcConfigContent');
            if (!contentEl) return;
            
            contentEl.innerHTML = '<div style="text-align:center;padding:40px;"><div class="loading-spinner"></div><p style="color:#fff;">üîç ƒêang qu√©t c·∫•u h√¨nh ph·∫ßn c·ª©ng...</p></div>';
            
            try {
                const response = await fetch('/api/pc_config');
                const data = await response.json();
                
                var html = '<div style="padding:10px;">';
                
                // Header
                html += '<div style="background:linear-gradient(135deg,#1a1a2e,#667eea);padding:15px;border-radius:12px;margin-bottom:15px;text-align:center;">';
                html += '<h2 style="margin:0;color:#fff;">üñ•Ô∏è TH√îNG S·ªê K·ª∏ THU·∫¨T M√ÅY T√çNH</h2>';
                html += '<p style="margin:5px 0 0 0;color:rgba(255,255,255,0.7);font-size:12px;">üìÖ Qu√©t l√∫c: ' + new Date().toLocaleString('vi-VN') + '</p>';
                html += '</div>';
                
                // OS Info
                if (data.os) {
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:12px;border-left:4px solid #00bcd4;">';
                    html += '<h4 style="margin:0 0 10px 0;color:#00bcd4;">ü™ü H·ªÜ ƒêI·ªÄU H√ÄNH</h4>';
                    html += '<table style="width:100%;font-size:13px;">';
                    html += '<tr><td style="padding:4px 0;color:#aaa;width:35%;">T√™n OS:</td><td style="color:#fff;font-weight:bold;">' + (data.os.name || 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">Phi√™n b·∫£n:</td><td style="color:#fff;">' + (data.os.version || 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">Build:</td><td style="color:#fff;">' + (data.os.build || 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">Ki·∫øn tr√∫c:</td><td style="color:#00ff88;">' + (data.os.architecture || 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">Hostname:</td><td style="color:#fff;">' + (data.os.hostname || 'N/A') + '</td></tr>';
                    html += '</table></div>';
                }
                
                // CPU Info
                if (data.cpu) {
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:12px;border-left:4px solid #ff5722;">';
                    html += '<h4 style="margin:0 0 10px 0;color:#ff5722;">‚ö° VI X·ª¨ L√ù (CPU)</h4>';
                    html += '<table style="width:100%;font-size:13px;">';
                    html += '<tr><td style="padding:4px 0;color:#aaa;width:35%;">T√™n CPU:</td><td style="color:#00ff88;font-weight:bold;">' + (data.cpu.name || 'N/A') + '</td></tr>';
                    if (data.cpu.generation) html += '<tr><td style="padding:4px 0;color:#aaa;">Th·∫ø h·ªá:</td><td style="color:#fff;">' + data.cpu.generation + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">S·ªë nh√¢n v·∫≠t l√Ω:</td><td style="color:#fff;">' + (data.cpu.cores || 'N/A') + ' cores</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">S·ªë lu·ªìng:</td><td style="color:#fff;">' + (data.cpu.threads || 'N/A') + ' threads</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">T·ªëc ƒë·ªô hi·ªán t·∫°i:</td><td style="color:#ff9800;font-weight:bold;">' + (data.cpu.freq_current ? data.cpu.freq_current.toFixed(0) + ' MHz' : 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">T·ªëc ƒë·ªô t·ªëi ƒëa:</td><td style="color:#fff;">' + (data.cpu.freq_max ? data.cpu.freq_max.toFixed(0) + ' MHz' : 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">S·ª≠ d·ª•ng:</td><td style="color:#fff;">' + (data.cpu.usage || 0) + '%</td></tr>';
                    html += '</table></div>';
                }
                
                // RAM Info
                if (data.ram) {
                    var ramColor = data.ram.percent > 80 ? '#f44336' : (data.ram.percent > 50 ? '#ff9800' : '#4CAF50');
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:12px;border-left:4px solid #9c27b0;">';
                    html += '<h4 style="margin:0 0 10px 0;color:#9c27b0;">üß† B·ªò NH·ªö RAM</h4>';
                    html += '<table style="width:100%;font-size:13px;">';
                    html += '<tr><td style="padding:4px 0;color:#aaa;width:35%;">T·ªïng RAM:</td><td style="color:#00ff88;font-weight:bold;">' + (data.ram.total_gb ? data.ram.total_gb.toFixed(2) + ' GB' : 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">ƒê√£ s·ª≠ d·ª•ng:</td><td style="color:#ff9800;">' + (data.ram.used_gb ? data.ram.used_gb.toFixed(2) + ' GB' : 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">C√≤n tr·ªëng:</td><td style="color:#4CAF50;">' + (data.ram.available_gb ? data.ram.available_gb.toFixed(2) + ' GB' : 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">T·ª∑ l·ªá s·ª≠ d·ª•ng:</td><td style="color:' + ramColor + ';font-weight:bold;">' + (data.ram.percent || 0) + '%</td></tr>';
                    if (data.ram.type) html += '<tr><td style="padding:4px 0;color:#aaa;">Lo·∫°i RAM:</td><td style="color:#fff;">' + data.ram.type + '</td></tr>';
                    html += '</table>';
                    html += '<div style="margin-top:10px;background:#333;border-radius:5px;height:10px;overflow:hidden;">';
                    html += '<div style="width:' + (data.ram.percent || 0) + '%;height:100%;background:' + ramColor + ';transition:width 0.5s;"></div></div>';
                    html += '</div>';
                }
                
                // GPU Info
                if (data.gpu && data.gpu.length > 0) {
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:12px;border-left:4px solid #4CAF50;">';
                    html += '<h4 style="margin:0 0 10px 0;color:#4CAF50;">üéÆ CARD ƒê·ªí H·ªåA (GPU)</h4>';
                    data.gpu.forEach(function(gpu, idx) {
                        if (idx > 0) html += '<hr style="border:none;border-top:1px solid #333;margin:12px 0;">';
                        html += '<table style="width:100%;font-size:13px;">';
                        html += '<tr><td style="padding:4px 0;color:#aaa;width:35%;">GPU ' + (idx+1) + ':</td><td style="color:#00ff88;font-weight:bold;">' + (gpu.name || 'N/A') + '</td></tr>';
                        if (gpu.generation) html += '<tr><td style="padding:4px 0;color:#aaa;">Th·∫ø h·ªá:</td><td style="color:#fff;">' + gpu.generation + '</td></tr>';
                        if (gpu.memory_total) html += '<tr><td style="padding:4px 0;color:#aaa;">VRAM t·ªïng:</td><td style="color:#fff;">' + gpu.memory_total + ' MB</td></tr>';
                        if (gpu.memory_used) html += '<tr><td style="padding:4px 0;color:#aaa;">VRAM ƒëang d√πng:</td><td style="color:#ff9800;">' + gpu.memory_used + ' MB</td></tr>';
                        if (gpu.load !== undefined) html += '<tr><td style="padding:4px 0;color:#aaa;">GPU Load:</td><td style="color:#fff;">' + gpu.load + '%</td></tr>';
                        if (gpu.temperature) html += '<tr><td style="padding:4px 0;color:#aaa;">Nhi·ªát ƒë·ªô:</td><td style="color:' + (gpu.temperature > 80 ? '#f44336' : '#4CAF50') + ';">' + gpu.temperature + '¬∞C</td></tr>';
                        if (gpu.driver) html += '<tr><td style="padding:4px 0;color:#aaa;">Driver:</td><td style="color:#fff;">' + gpu.driver + '</td></tr>';
                        html += '</table>';
                    });
                    html += '</div>';
                }
                
                // Disk Info
                if (data.disks && data.disks.length > 0) {
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:12px;border-left:4px solid #ff9800;">';
                    html += '<h4 style="margin:0 0 10px 0;color:#ff9800;">üíæ ·ªî C·ª®NG</h4>';
                    html += '<div style="max-height:200px;overflow-y:auto;">';
                    data.disks.forEach(function(disk, idx) {
                        var diskColor = disk.percent > 90 ? '#f44336' : (disk.percent > 70 ? '#ff9800' : '#4CAF50');
                        html += '<div style="background:rgba(255,255,255,0.05);padding:10px;border-radius:8px;margin-bottom:8px;">';
                        html += '<div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:5px;">';
                        html += '<span style="font-weight:bold;color:#fff;">üíø ' + (disk.device || '·ªî ' + (idx+1)) + '</span>';
                        html += '<span style="color:' + diskColor + ';font-weight:bold;">' + (disk.percent || 0) + '%</span>';
                        html += '</div>';
                        html += '<div style="background:#333;border-radius:5px;height:8px;overflow:hidden;margin-bottom:5px;">';
                        html += '<div style="width:' + (disk.percent || 0) + '%;height:100%;background:' + diskColor + ';"></div></div>';
                        html += '<div style="font-size:11px;color:#aaa;">';
                        html += 'üìä ƒê√£ d√πng: ' + (disk.used_gb ? disk.used_gb.toFixed(1) : '?') + ' GB / ' + (disk.total_gb ? disk.total_gb.toFixed(1) : '?') + ' GB';
                        html += ' | ‚úÖ C√≤n: ' + (disk.free_gb ? disk.free_gb.toFixed(1) : '?') + ' GB';
                        if (disk.type) html += ' | üìÅ ' + disk.type;
                        html += '</div></div>';
                    });
                    html += '</div></div>';
                }
                
                // Motherboard Info
                if (data.motherboard) {
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:12px;border-left:4px solid #607d8b;">';
                    html += '<h4 style="margin:0 0 10px 0;color:#607d8b;">üîß MAINBOARD</h4>';
                    html += '<table style="width:100%;font-size:13px;">';
                    html += '<tr><td style="padding:4px 0;color:#aaa;width:35%;">H√£ng s·∫£n xu·∫•t:</td><td style="color:#fff;">' + (data.motherboard.manufacturer || 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:4px 0;color:#aaa;">Model:</td><td style="color:#00ff88;">' + (data.motherboard.product || 'N/A') + '</td></tr>';
                    if (data.motherboard.serial) html += '<tr><td style="padding:4px 0;color:#aaa;">Serial:</td><td style="color:#fff;">' + data.motherboard.serial + '</td></tr>';
                    html += '</table></div>';
                }
                
                // Network Adapters
                if (data.network && data.network.length > 0) {
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;border-left:4px solid #2196F3;">';
                    html += '<h4 style="margin:0 0 10px 0;color:#2196F3;">üåê CARD M·∫†NG</h4>';
                    html += '<div style="max-height:150px;overflow-y:auto;">';
                    data.network.forEach(function(net) {
                        if (net.ip && net.ip !== '127.0.0.1') {
                            html += '<div style="background:rgba(255,255,255,0.05);padding:8px;border-radius:6px;margin-bottom:6px;font-size:12px;">';
                            html += '<div style="color:#fff;font-weight:bold;">' + (net.name || 'Unknown') + '</div>';
                            html += '<div style="color:#aaa;">IP: <span style="color:#00ff88;">' + net.ip + '</span>';
                            if (net.mac) html += ' | MAC: ' + net.mac;
                            html += '</div></div>';
                        }
                    });
                    html += '</div></div>';
                }
                
                html += '</div>';
                contentEl.innerHTML = html;
                
                addLog('‚úÖ Qu√©t c·∫•u h√¨nh m√°y t√≠nh ho√†n t·∫•t', 'success');
                
            } catch (error) {
                contentEl.innerHTML = '<div style="text-align:center;padding:40px;color:#f44336;"><p>‚ùå L·ªói: ' + error.message + '</p></div>';
                addLog('‚ùå L·ªói qu√©t c·∫•u h√¨nh: ' + error.message, 'error');
            }
        }
        
        function networkInfo() {
            console.log('networkInfo() called');
            // M·ªü modal v√† hi·ªán loading
            openNetworkModal();
            var contentEl = document.getElementById('networkInfoContent');
            if (!contentEl) {
                alert('Kh√¥ng t√¨m th·∫•y networkInfoContent!');
                return;
            }
            contentEl.innerHTML = '<div style="text-align:center;padding:40px;"><div class="loading-spinner"></div><p style="color:#fff;">üîç ƒêang qu√©t th√¥ng tin m·∫°ng...</p></div>';
            addLog('üåê ƒêang qu√©t th√¥ng tin m·∫°ng...', 'info');
            
            fetch('/api/tool/get_network_info', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({})
            })
            .then(function(r) { return r.json(); })
            .then(function(data) {
                console.log('Network info response:', data);
                if (data.success) {
                    var summary = 'Qu√©t m·∫°ng: ' + (data.total_devices || 1) + ' thi·∫øt b·ªã';
                    addLog('‚úÖ ' + summary, 'success');
                    
                    // T·∫°o HTML cho modal
                    var html = '<div style="padding:10px;">';
                    
                    // Th√¥ng tin m√°y local
                    html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:15px;border-left:4px solid #4CAF50;">';
                    html += '<h4 style="margin:0 0 10px 0;color:#4CAF50;">üíª M√ÅY C·ª¶A B·∫†N</h4>';
                    html += '<table style="width:100%;font-size:13px;">';
                    html += '<tr><td style="padding:5px 0;color:#aaa;">üè∑Ô∏è Hostname:</td><td style="color:#fff;font-weight:bold;">' + (data.local_device ? data.local_device.hostname : 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:5px 0;color:#aaa;">üåê IP Address:</td><td style="color:#00ff88;font-weight:bold;">' + (data.local_device ? data.local_device.ip : 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:5px 0;color:#aaa;">üì° MAC Address:</td><td style="color:#fff;">' + (data.local_device ? data.local_device.mac : 'N/A') + '</td></tr>';
                    html += '<tr><td style="padding:5px 0;color:#aaa;">üö™ Gateway:</td><td style="color:#fff;">' + (data.local_device ? data.local_device.gateway : 'N/A') + '</td></tr>';
                    html += '</table></div>';
                    
                    // Danh s√°ch thi·∫øt b·ªã
                    if (data.network_devices && data.network_devices.length > 0) {
                        html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;border-left:4px solid #2196F3;">';
                        html += '<h4 style="margin:0 0 10px 0;color:#2196F3;">üì± THI·∫æT B·ªä TRONG M·∫†NG (' + (data.total_devices || data.network_devices.length) + ')</h4>';
                        html += '<div style="max-height:300px;overflow-y:auto;">';
                        
                        var devices = data.network_devices;
                        for (var i = 0; i < devices.length; i++) {
                            var device = devices[i];
                            var isLocal = device.is_local;
                            var bgColor = isLocal ? 'rgba(76,175,80,0.2)' : 'rgba(255,255,255,0.05)';
                            var borderColor = isLocal ? '#4CAF50' : '#333';
                            
                            html += '<div style="background:' + bgColor + ';padding:10px;border-radius:8px;margin-bottom:8px;border:1px solid ' + borderColor + ';">';
                            html += '<div style="display:flex;justify-content:space-between;align-items:center;">';
                            html += '<span style="font-weight:bold;color:#fff;">' + (i+1) + '. ' + (device.hostname || 'Unknown Device') + (isLocal ? ' ‚≠ê' : '') + '</span>';
                            if (isLocal) html += '<span style="background:#4CAF50;color:#fff;padding:2px 8px;border-radius:10px;font-size:11px;">M√°y n√†y</span>';
                            html += '</div>';
                            html += '<div style="margin-top:5px;font-size:12px;color:#aaa;">';
                            html += 'üåê IP: <span style="color:#00ff88;">' + device.ip + '</span> &nbsp;|&nbsp; üì° MAC: <span style="color:#fff;">' + device.mac + '</span>';
                            html += '</div></div>';
                        }
                        html += '</div></div>';
                    } else {
                        html += '<div style="background:#1a1a2e;padding:20px;border-radius:10px;text-align:center;color:#aaa;">';
                        html += '<p>üì± Kh√¥ng t√¨m th·∫•y thi·∫øt b·ªã kh√°c trong m·∫°ng</p></div>';
                    }
                    
                    html += '</div>';
                    document.getElementById('networkInfoContent').innerHTML = html;
                } else {
                    var error = data.error || 'Kh√¥ng th·ªÉ l·∫•y th√¥ng tin m·∫°ng';
                    document.getElementById('networkInfoContent').innerHTML = '<div style="text-align:center;padding:40px;color:#ff6b6b;"><p>‚ùå L·ªói: ' + error + '</p></div>';
                    addLog('‚ùå L·ªói qu√©t m·∫°ng: ' + error, 'error');
                }
            })
            .catch(function(err) {
                console.error('Network info error:', err);
                document.getElementById('networkInfoContent').innerHTML = '<div style="text-align:center;padding:40px;color:#ff6b6b;"><p>‚ùå L·ªói k·∫øt n·ªëi: ' + err.message + '</p></div>';
                addLog('‚ùå L·ªói k·∫øt n·ªëi: ' + err.message, 'error');
            });
        }
        function batteryStatus() { callTool('get_battery_status', {}); }
        function searchWeb() {
            const query = prompt('T·ª´ kh√≥a t√¨m ki·∫øm:', '');
            if (query && query.trim()) callTool('search_web', {query: query.trim()});
        }
        function calculator() {
            const expr = prompt('Bi·ªÉu th·ª©c to√°n h·ªçc:', '2+2*3');
            if (expr && expr.trim()) callAPI('/api/calculator', {expression: expr.trim()});
        }
        function getClipboard() { callTool('get_clipboard', {}); }
        function setClipboard() {
            const text = prompt('N·ªôi dung c·∫ßn copy:', '');
            if (text !== null && text.trim()) callTool('set_clipboard', {text: text.trim()});
        }
        function playSound() {
            const freq = prompt('T·∫ßn s·ªë Hz (200-2000):', '1000');
            if (freq === null) return;
            const dur = prompt('Th·ªùi gian ms (100-3000):', '500');
            if (dur === null) return;
            const freqNum = parseInt(freq);
            const durNum = parseInt(dur);
            if (isNaN(freqNum) || freqNum < 200 || freqNum > 2000) {
                addLog('‚ùå T·∫ßn s·ªë ph·∫£i t·ª´ 200-2000 Hz', 'error');
                return;
            }
            if (isNaN(durNum) || durNum < 100 || durNum > 3000) {
                addLog('‚ùå Th·ªùi gian ph·∫£i t·ª´ 100-3000 ms', 'error');
                return;
            }
            callTool('play_sound', {frequency: freqNum, duration: durNum});
        }
        
        // NEW TOOL FUNCTIONS
        function lockComputer() {
            if (confirm('B·∫°n c√≥ ch·∫Øc mu·ªën kh√≥a m√°y t√≠nh?')) {
                callTool('lock_computer', {});
            }
        }
        function shutdownSchedule() {
            const action = prompt('H√†nh ƒë·ªông (shutdown/restart/cancel):', 'shutdown');
            if (!action || !action.trim()) return;
            const actionLower = action.trim().toLowerCase();
            if (!['shutdown', 'restart', 'cancel'].includes(actionLower)) {
                addLog('‚ùå H√†nh ƒë·ªông kh√¥ng h·ª£p l·ªá. D√πng: shutdown, restart, ho·∫∑c cancel', 'error');
                return;
            }
            const delay = prompt('Tr√¨ ho√£n (gi√¢y):', '60');
            if (delay === null) return;
            const delayNum = parseInt(delay) || 0;
            if (delayNum < 0) {
                addLog('‚ùå Th·ªùi gian tr√¨ ho√£n ph·∫£i >= 0', 'error');
                return;
            }
            callTool('shutdown_schedule', {action: actionLower, delay: delayNum});
        }
        function showDesktop() {
            callTool('show_desktop', {});
        }
        function undoOperation() {
            callTool('undo_operation', {});
        }
        function setTheme() {
            const dark = confirm('Ch·ªçn OK cho theme T·ªêI, Cancel cho theme S√ÅNG');
            callTool('set_theme', {dark_mode: dark});
        }
        function changeWallpaper() {
            const keyword = prompt('T·ª´ kh√≥a h√¨nh n·ªÅn (ho·∫∑c ƒë·ªÉ tr·ªëng ƒë·ªÉ ch·ªçn ng·∫´u nhi√™n):', '');
            callTool('change_wallpaper', {keyword: keyword || ''});
        }
        function getDesktopPath() {
            callTool('get_desktop_path', {});
        }
        function pasteContent() {
            const content = prompt('Nh·∫≠p n·ªôi dung c·∫ßn d√°n (ho·∫∑c ƒë·ªÉ tr·ªëng ƒë·ªÉ d√°n clipboard hi·ªán t·∫°i):', '');
            callTool('paste_content', {content: content || ''});
        }
        function pressEnter() {
            callTool('press_enter', {});
        }
        function findInDocument() {
            const searchText = prompt('Nh·∫≠p n·ªôi dung t√¨m ki·∫øm:', '');
            if (searchText && searchText.trim()) {
                callTool('find_in_document', {search_text: searchText.trim()});
            }
        }
        
        // AI ASSISTANT
        function saveGeminiModel() {
            const select = document.getElementById('gemini-model');
            if (!select) return;
            const model = select.value;
            localStorage.setItem('gemini_model', model);
            
            // Determine model name for display
            let modelName = 'Unknown';
            if (model.includes('flash-thinking')) modelName = 'Thinking üß†';
            else if (model.includes('flash')) modelName = 'Flash ‚ö°';
            else if (model.includes('exp-1206')) modelName = 'Pro Exp üöÄ';
            else if (model.includes('1.5-pro')) modelName = '1.5 Pro üíé';
            else if (model.includes('pro')) modelName = 'Pro üöÄ';
            
            addLog(`‚úÖ ƒê√£ l∆∞u Gemini model: ${modelName}`, 'success');
        }
        
        function loadGeminiModel() {
            const saved = localStorage.getItem('gemini_model') || 'models/gemini-3-flash-preview';
            const select = document.getElementById('gemini-model');
            if (select) {
                // Check if the saved value exists in options
                const options = Array.from(select.options).map(o => o.value);
                if (options.includes(saved)) {
                    select.value = saved;
                } else {
                    // Default to first option if saved value is invalid
                    select.value = 'models/gemini-3-flash-preview';
                    localStorage.setItem('gemini_model', 'models/gemini-3-flash-preview');
                }
            }
        }
        
        function getGeminiModelName(model) {
            if (model.includes('flash-thinking')) return 'Thinking üß†';
            if (model.includes('2.0-flash')) return '2.0 Flash ‚ö°';
            if (model.includes('1.5-flash')) return '1.5 Flash ‚ö°';
            if (model.includes('exp-1206')) return '2.0 Pro üöÄ';
            if (model.includes('1.5-pro')) return '1.5 Pro üíé';
            return 'Gemini';
        }
        
        function askGemini() {
            const prompt = window.prompt('ü§ñ H·ªèi Gemini AI + üìö Knowledge Base\n(Gemini s·∫Ω t·ª± ƒë·ªông t√¨m trong c∆° s·ªü d·ªØ li·ªáu c·ªßa b·∫°n):', '');
            if (prompt && prompt.trim()) {
                const model = localStorage.getItem('gemini_model') || 'models/gemini-3-flash-preview';
                const modelName = getGeminiModelName(model);
                addLog(`ü§ñ ƒêang h·ªèi Gemini ${modelName} + üìö Knowledge Base...`, 'info');
                addLog(`   ‚ùì C√¢u h·ªèi: "${prompt}"`, 'info');
                
                // S·ª≠ d·ª•ng endpoint /api/tool/ask_gemini (c√≥ t√≠ch h·ª£p KB t·ª± ƒë·ªông)
                fetch('/api/tool/ask_gemini', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({prompt: prompt.trim(), model: model})
                })
                .then(res => res.json())
                .then(result => {
                    if(result.success) {
                        const response = result.response || result.response_text || '';
                        const hasKB = result.knowledge_base_used ? ' üìö' : '';
                        addLog(`‚úÖ Gemini${hasKB}: ${response.substring(0, 300)}...`, 'success');
                        if(result.knowledge_base_used) {
                            addLog(`   üìö ƒê√£ s·ª≠ d·ª•ng th√¥ng tin t·ª´ Knowledge Base`, 'info');
                        }
                    } else {
                        addLog(`‚ùå Gemini error: ${result.error}`, 'error');
                    }
                })
                .catch(err => addLog(`‚ùå Error: ${err.message}`, 'error'));
            }
        }
        
        function askGPT4() {
            const prompt = window.prompt('H·ªèi GPT-4 (TR·∫¢ PH√ç - ch·∫•t l∆∞·ª£ng cao nh·∫•t):', '');
            if (prompt && prompt.trim()) {
                addLog(`üß† H·ªèi GPT-4: "${prompt}"`, 'info');
                
                // Use generic /api/call_tool endpoint
                fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'ask_gpt4', args: {prompt: prompt.trim()}})
                })
                .then(res => res.json())
                .then(result => {
                    if(result.success) {
                        const usage = result.usage ? ` (Tokens: ${result.usage.total_tokens})` : '';
                        addLog(`‚úÖ GPT-4: ${result.response_text.substring(0, 200)}...${usage}`, 'success');
                    } else {
                        addLog(`‚ùå GPT-4 error: ${result.error}`, 'error');
                    }
                })
                .catch(err => addLog(`‚ùå Error: ${err.message}`, 'error'));
            }
        }

        // API caller
        async function callAPI(endpoint, data) {
            try {
                addLog(`üîß Calling ${endpoint}...`, 'info');
                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify(data)
                });
                const result = await response.json();
                addLog(`‚úÖ ${JSON.stringify(result).substring(0, 100)}`, 'success');
                return result;
            } catch (error) {
                addLog(`‚ùå Error: ${error.message}`, 'error');
                return {success: false, error: error.message};
            }
        }
        
        async function callTool(name, params) {
            try {
                const paramsStr = JSON.stringify(params);
                const displayParams = paramsStr.length > 50 ? paramsStr.substring(0, 50) + '...' : paramsStr;
                addLog(`üîß Tool: ${name}(${displayParams})`, 'info');
                
                // G·ªçi API endpoint t∆∞∆°ng ·ª©ng v·ªõi tool
                const endpoint = `/api/tool/${name}`;
                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify(params)
                });
                const result = await response.json();
                
                // X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho get_network_info - hi·ªÉn th·ªã modal chi ti·∫øt
                if (name === 'get_network_info' && result.success) {
                    showNetworkInfoModal(result);
                    return result;
                }
                
                // Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß h∆°n
                let resultMsg = '';
                if (result.success) {
                    const msg = result.message || result.content || JSON.stringify(result).substring(0, 200);
                    resultMsg = `‚úÖ ${name}: ${msg}`;
                } else {
                    resultMsg = `‚ùå ${name}: ${result.error || 'Unknown error'}`;
                }
                addLog(resultMsg, result.success ? 'success' : 'error');
                
                return result;
            } catch (error) {
                addLog(`‚ùå Tool "${name}" error: ${error.message}`, 'error');
                return {success: false, error: error.message};
            }
        }
        
        // Function hi·ªÉn th·ªã network info modal t·ª´ callTool
        function showNetworkInfoModal(data) {
            var modal = document.getElementById('networkInfoModal');
            var contentEl = document.getElementById('networkInfoContent');
            
            if (!modal || !contentEl) {
                // Fallback: hi·ªÉn th·ªã trong log v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin
                var info = 'üåê TH√îNG TIN M·∫†NG:\\n';
                info += 'üíª Hostname: ' + (data.local_device ? data.local_device.hostname : 'N/A') + '\\n';
                info += 'üåê IP: ' + (data.local_device ? data.local_device.ip : 'N/A') + '\\n';
                info += 'üì° MAC: ' + (data.local_device ? data.local_device.mac : 'N/A') + '\\n';
                info += 'üö™ Gateway: ' + (data.local_device ? data.local_device.gateway : 'N/A') + '\\n';
                info += 'üì± Thi·∫øt b·ªã: ' + (data.total_devices || 0);
                addLog(info.replace(/\\n/g, ' | '), 'success');
                return;
            }
            
            // M·ªü modal
            modal.style.display = 'flex';
            
            // T·∫°o HTML cho modal
            var html = '<div style="padding:10px;">';
            
            // Header v·ªõi t·ªïng quan
            html += '<div style="background:linear-gradient(135deg,#667eea,#764ba2);padding:12px 15px;border-radius:10px;margin-bottom:15px;text-align:center;">';
            html += '<h3 style="margin:0;color:#fff;">üîç ANGRY IP SCANNER - QU√âT M·∫†NG</h3>';
            if (data.scanned_range) {
                html += '<p style="margin:5px 0 0 0;color:rgba(255,255,255,0.8);font-size:12px;">üìä D·∫£i IP: ' + data.scanned_range + '</p>';
            }
            html += '</div>';
            
            // Th√¥ng tin m√°y local
            html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;margin-bottom:15px;border-left:4px solid #4CAF50;">';
            html += '<h4 style="margin:0 0 10px 0;color:#4CAF50;">üíª M√ÅY C·ª¶A B·∫†N</h4>';
            html += '<table style="width:100%;font-size:13px;">';
            html += '<tr><td style="padding:5px 0;color:#aaa;width:40%;">üè∑Ô∏è Hostname:</td><td style="color:#fff;font-weight:bold;">' + (data.local_device ? data.local_device.hostname : 'N/A') + '</td></tr>';
            html += '<tr><td style="padding:5px 0;color:#aaa;">üåê IP Address:</td><td style="color:#00ff88;font-weight:bold;">' + (data.local_device ? data.local_device.ip : 'N/A') + '</td></tr>';
            html += '<tr><td style="padding:5px 0;color:#aaa;">üì° MAC Address:</td><td style="color:#fff;">' + (data.local_device ? data.local_device.mac : 'N/A') + '</td></tr>';
            html += '<tr><td style="padding:5px 0;color:#aaa;">üö™ Gateway:</td><td style="color:#fff;">' + (data.local_device ? data.local_device.gateway : 'N/A') + '</td></tr>';
            if (data.local_device && data.local_device.subnet_mask) {
                html += '<tr><td style="padding:5px 0;color:#aaa;">üî≤ Subnet Mask:</td><td style="color:#fff;">' + data.local_device.subnet_mask + '</td></tr>';
            }
            html += '</table></div>';
            
            // Danh s√°ch thi·∫øt b·ªã
            if (data.network_devices && data.network_devices.length > 0) {
                html += '<div style="background:linear-gradient(135deg,#1a1a2e,#16213e);padding:15px;border-radius:10px;border-left:4px solid #2196F3;">';
                html += '<h4 style="margin:0 0 10px 0;color:#2196F3;">üì± THI·∫æT B·ªä ONLINE (' + (data.total_devices || data.network_devices.length) + ')</h4>';
                html += '<div style="max-height:300px;overflow-y:auto;">';
                
                var devices = data.network_devices;
                for (var i = 0; i < devices.length; i++) {
                    var device = devices[i];
                    var isLocal = device.is_local;
                    var isGateway = device.is_gateway;
                    var bgColor = isLocal ? 'rgba(76,175,80,0.2)' : (isGateway ? 'rgba(255,152,0,0.2)' : 'rgba(255,255,255,0.05)');
                    var borderColor = isLocal ? '#4CAF50' : (isGateway ? '#ff9800' : '#333');
                    
                    html += '<div style="background:' + bgColor + ';padding:10px;border-radius:8px;margin-bottom:8px;border:1px solid ' + borderColor + ';">';
                    html += '<div style="display:flex;justify-content:space-between;align-items:center;flex-wrap:wrap;">';
                    html += '<span style="font-weight:bold;color:#fff;">' + (i+1) + '. ' + (device.hostname && device.hostname !== 'Unknown' ? device.hostname : 'Unknown Device') + '</span>';
                    html += '<div>';
                    if (isLocal) html += '<span style="background:#4CAF50;color:#fff;padding:2px 8px;border-radius:10px;font-size:11px;margin-left:5px;">M√°y n√†y</span>';
                    if (isGateway) html += '<span style="background:#ff9800;color:#fff;padding:2px 8px;border-radius:10px;font-size:11px;margin-left:5px;">Gateway</span>';
                    html += '<span style="background:#2196F3;color:#fff;padding:2px 8px;border-radius:10px;font-size:11px;margin-left:5px;">üü¢ Online</span>';
                    html += '</div></div>';
                    html += '<div style="margin-top:5px;font-size:12px;color:#aaa;">';
                    html += 'üåê IP: <span style="color:#00ff88;">' + device.ip + '</span> &nbsp;|&nbsp; üì° MAC: <span style="color:#fff;">' + (device.mac || 'Unknown') + '</span>';
                    html += '</div></div>';
                }
                html += '</div></div>';
            } else {
                html += '<div style="background:#1a1a2e;padding:20px;border-radius:10px;text-align:center;color:#aaa;">';
                html += '<p>üì± Kh√¥ng t√¨m th·∫•y thi·∫øt b·ªã kh√°c trong m·∫°ng</p></div>';
            }
            
            // Footer v·ªõi th√¥ng tin scan
            if (data.message) {
                html += '<div style="margin-top:10px;padding:10px;background:rgba(33,150,243,0.1);border-radius:8px;text-align:center;font-size:12px;color:#2196F3;">';
                html += '‚úÖ ' + data.message;
                html += '</div>';
            }
            
            html += '</div>';
            contentEl.innerHTML = html;
            
            addLog('‚úÖ Qu√©t m·∫°ng ho√†n t·∫•t: ' + (data.local_device ? data.local_device.hostname : 'N/A') + ' (' + (data.local_device ? data.local_device.ip : 'N/A') + ') - ' + (data.total_devices || 0) + ' thi·∫øt b·ªã online', 'success');
        }
        
        async function getResources() {
            try {
                // S·ª≠ d·ª•ng cache n·∫øu c√≤n hi·ªáu l·ª±c
                const now = Date.now();
                if (resourceCache && (now - lastResourceFetch) < RESOURCE_CACHE_TIME) {
                    return;
                }
                
                const response = await fetch('/api/resources');
                const data = await response.json();
                if (data.success) {
                    const cpuPercent = data.data.cpu_percent;
                    document.getElementById('cpu').textContent = cpuPercent + '%';
                    document.getElementById('ram').textContent = data.data.memory_percent + '%';
                    document.getElementById('disk').textContent = data.data.disk_percent + '%';
                    
                    // Update RunCat animation speed based on CPU usage
                    updateRunCatSpeed(cpuPercent);
                    
                    // C·∫≠p nh·∫≠t cache
                    resourceCache = data;
                    lastResourceFetch = now;
                } else {
                    addLog(`‚ùå L·ªói l·∫•y t√†i nguy√™n: ${data.error}`, 'error');
                }
            } catch (error) {
                addLog(`‚ùå ${error.message}`, 'error');
            }
        }
        
        async function getQuotas() {
            try {
                const response = await fetch('/api/quotas');
                const data = await response.json();
                if (data.success) {
                    // Gemini quota
                    const geminiEl = document.getElementById('gemini-quota');
                    if (data.gemini && geminiEl) {
                        if (data.gemini.has_key) {
                            geminiEl.innerHTML = `‚úÖ ${data.gemini.free_tier}<br><small style="color:#6b7280;">${data.gemini.daily_limit}</small>`;
                        } else {
                            geminiEl.innerHTML = `‚ùå <small style="color:#ef4444;">Ch∆∞a c√≥ API key</small>`;
                        }
                    }
                    
                    // Serper quota
                    const serperEl = document.getElementById('serper-quota');
                    if (data.serper && serperEl) {
                        if (data.serper.has_key) {
                            serperEl.innerHTML = `‚úÖ ${data.serper.free_tier}`;
                        } else {
                            serperEl.innerHTML = `‚ùå <small style="color:#ef4444;">Ch∆∞a c√≥ API key</small>`;
                        }
                    }
                } else {
                    console.log('Error fetching quotas:', data.error);
                }
            } catch (error) {
                console.error('Failed to fetch quotas:', error);
            }
        }
        
        // Update RunCat animation speed based on CPU usage (like RunCat365)
        function updateRunCatSpeed(cpuPercent) {
            // Calculate frame duration: 100ms (very fast) to 800ms (very slow)
            // High CPU = fast running, Low CPU = slow walking
            const minSpeed = 100;  // Fast run (10 fps)
            const maxSpeed = 800;  // Slow walk (1.25 fps)
            
            // CPU 0% = 800ms, CPU 100% = 100ms
            runcatSpeed = maxSpeed - (cpuPercent / 100) * (maxSpeed - minSpeed);
        }
        
        // Debounce helper
        function debounce(func, wait) {
            let timeout;
            return function executedFunction(...args) {
                const later = () => {
                    clearTimeout(timeout);
                    func(...args);
                };
                clearTimeout(timeout);
                timeout = setTimeout(later, wait);
            };
        }
        
        async function calculate() {
            try {
                const expr = document.getElementById('calc-expr').value.trim();
                if (!expr) {
                    document.getElementById('calc-result').textContent = 'Vui l√≤ng nh·∫≠p bi·ªÉu th·ª©c';
                    return;
                }
                const response = await fetch('/api/calculator', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({expression: expr})
                });
                const data = await response.json();
                document.getElementById('calc-result').textContent = data.success ? data.result : data.error;
            } catch (error) {
                document.getElementById('calc-result').textContent = 'L·ªói: ' + error.message;
            }
        }
        
        async function getCurrentTime() {
            try {
                const response = await fetch('/api/time');
                const data = await response.json();
                if (data.data) {
                    document.getElementById('time-result').textContent = data.data.datetime;
                }
            } catch (error) {
                document.getElementById('time-result').textContent = 'L·ªói: ' + error.message;
            }
        }
        
        // Modal functions
        function openSettingsModal() {
            document.getElementById('settingsModal').style.display = 'block';
            loadCurrentEndpoint();
            loadGeminiModel();
        }
        
        function closeSettingsModal() {
            document.getElementById('settingsModal').style.display = 'none';
        }
        
        // Click outside modal to close
        window.onclick = function(event) {
            const modal = document.getElementById('settingsModal');
            if (event.target === modal) {
                closeSettingsModal();
            }
        }
        
        async function loadCurrentEndpoint() {
            try {
                const response = await fetch('/api/endpoints');
                const data = await response.json();
                
                // üî• FIX: ƒê·ªãnh nghƒ©a activeDevice t·ª´ active_index
                const activeIndex = data.active_index || 0;
                const activeDevice = data.endpoints && data.endpoints[activeIndex] ? data.endpoints[activeIndex] : null;
                
                // Load all 3 device tokens into separate input fields
                if (data.endpoints && data.endpoints.length >= 3) {
                    const input1 = document.getElementById('endpoint-url-1');
                    const input2 = document.getElementById('endpoint-url-2');
                    const input3 = document.getElementById('endpoint-url-3');
                    
                    if (input1) input1.value = data.endpoints[0]?.token || '';
                    if (input2) input2.value = data.endpoints[1]?.token || '';
                    if (input3) input3.value = data.endpoints[2]?.token || '';
                }
                
                // Load Gemini API key (lu√¥n set, k·ªÉ c·∫£ empty)
                const geminiInput = document.getElementById('gemini-api-key');
                if (geminiInput) {
                    geminiInput.value = data.gemini_api_key || '';
                    if (data.gemini_api_key) {
                        updateGeminiKeyStatus('‚úì API key ƒë√£ c·∫•u h√¨nh', '#10b981');
                    } else {
                        updateGeminiKeyStatus('', '');
                    }
                }
                
                // Load OpenAI API key (lu√¥n set, k·ªÉ c·∫£ empty)
                const openaiInput = document.getElementById('openai-api-key');
                if (openaiInput) {
                    openaiInput.value = data.openai_api_key || '';
                    if (data.openai_api_key) {
                        updateOpenAIKeyStatus('‚úì API key ƒë√£ c·∫•u h√¨nh', '#10b981');
                    } else {
                        updateOpenAIKeyStatus('', '');
                    }
                }
                
                // Load Serper API key (Google Search) (lu√¥n set, k·ªÉ c·∫£ empty)
                const serperInput = document.getElementById('serper-api-key');
                if (serperInput) {
                    serperInput.value = data.serper_api_key || '';
                    if (data.serper_api_key) {
                        updateSerperKeyStatus('‚úì Google Search s·∫µn s√†ng', '#10b981');
                    } else {
                        updateSerperKeyStatus('', '');
                    }
                }
                
                // C·∫≠p nh·∫≠t th√¥ng tin hi·ªán t·∫°i trong config section
                if (document.getElementById('current-device-name')) {
                    document.getElementById('current-device-name').textContent = activeDevice?.name || 'Ch∆∞a c·∫•u h√¨nh';
                }
                if (document.getElementById('current-device-token')) {
                    const token = activeDevice?.token || 'Ch∆∞a c√≥ token';
                    document.getElementById('current-device-token').textContent = 
                        token.length > 50 ? token.substring(0, 50) + '...' : token;
                }
            } catch (error) {
                addLog('‚ùå L·ªói t·∫£i endpoint: ' + error.message, 'error');
            }
        }
        
        // Toggle API key visibility (show/hide password)
        function toggleApiKeyVisibility(inputId, button) {
            const input = document.getElementById(inputId);
            if (input.type === 'password') {
                input.type = 'text';
                button.innerHTML = 'üôà'; // Hide icon (kh·ªâ che m·∫Øt)
                button.title = '·∫®n API key';
            } else {
                input.type = 'password';
                button.innerHTML = 'üêµ'; // Show icon (kh·ªâ ƒëang nh√¨n)
                button.title = 'Hi·ªán API key';
            }
        }
        
        // Copy API key to clipboard
        async function copyApiKey(inputId, button) {
            const input = document.getElementById(inputId);
            const value = input.value.trim();
            
            if (!value) {
                button.innerHTML = '‚ùå';
                setTimeout(() => { button.innerHTML = 'üìã'; }, 1000);
                return;
            }
            
            try {
                await navigator.clipboard.writeText(value);
                button.classList.add('copied');
                button.innerHTML = '‚úÖ';
                
                setTimeout(() => {
                    button.classList.remove('copied');
                    button.innerHTML = 'üìã';
                }, 1500);
            } catch (error) {
                // Fallback for older browsers
                input.select();
                document.execCommand('copy');
                button.innerHTML = '‚úÖ';
                setTimeout(() => { button.innerHTML = 'üìã'; }, 1500);
            }
        }
        
        // Auto-save Gemini API key
        let geminiSaveTimeout;
        async function autoSaveGeminiKey() {
            clearTimeout(geminiSaveTimeout);
            
            geminiSaveTimeout = setTimeout(async () => {
                const apiKey = document.getElementById('gemini-api-key').value.trim();
                
                // üî• FIX: Cho ph√©p save empty string (khi user x√≥a key)
                try {
                    if (apiKey) {
                        updateGeminiKeyStatus('üíæ ƒêang l∆∞u...', '#f59e0b');
                    } else {
                        updateGeminiKeyStatus('üíæ X√≥a key...', '#f59e0b');
                    }
                    
                    const response = await fetch('/api/gemini-key', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({api_key: apiKey})
                    });
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        updateGeminiKeyStatus('‚úì ƒê√£ l∆∞u t·ª± ƒë·ªông', '#10b981');
                        setTimeout(() => updateGeminiKeyStatus('‚úì API key ƒë√£ c·∫•u h√¨nh', '#10b981'), 2000);
                    } else {
                        updateGeminiKeyStatus('‚ùå L·ªói: ' + result.error, '#ef4444');
                    }
                } catch (error) {
                    updateGeminiKeyStatus('‚ùå L·ªói k·∫øt n·ªëi', '#ef4444');
                }
            }, 1000); // Auto-save sau 1 gi√¢y kh√¥ng g√µ
        }
        
        function updateGeminiKeyStatus(message, color) {
            const statusEl = document.getElementById('gemini-key-status');
            if (statusEl) {
                statusEl.textContent = message;
                statusEl.style.color = color;
            }
        }
        
        // Auto-save OpenAI API key
        let openaiSaveTimeout;
        async function autoSaveOpenAIKey() {
            clearTimeout(openaiSaveTimeout);
            
            openaiSaveTimeout = setTimeout(async () => {
                const apiKey = document.getElementById('openai-api-key').value.trim();
                
                // üî• FIX: Cho ph√©p save empty string (khi user x√≥a key)
                try {
                    if (apiKey) {
                        updateOpenAIKeyStatus('üíæ ƒêang l∆∞u...', '#f59e0b');
                    } else {
                        updateOpenAIKeyStatus('üíæ X√≥a key...', '#f59e0b');
                    }
                    
                    const response = await fetch('/api/openai-key', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({api_key: apiKey})
                    });
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        updateOpenAIKeyStatus('‚úì ƒê√£ l∆∞u t·ª± ƒë·ªông', '#10b981');
                        setTimeout(() => updateOpenAIKeyStatus('‚úì API key ƒë√£ c·∫•u h√¨nh', '#10b981'), 2000);
                    } else {
                        updateOpenAIKeyStatus('‚ùå L·ªói: ' + result.error, '#ef4444');
                    }
                } catch (error) {
                    updateOpenAIKeyStatus('‚ùå L·ªói k·∫øt n·ªëi', '#ef4444');
                }
            }, 1000);
        }
        
        function updateOpenAIKeyStatus(message, color) {
            const statusEl = document.getElementById('openai-key-status');
            if (statusEl) {
                statusEl.textContent = message;
                statusEl.style.color = color;
            }
        }
        
        // Auto-save Serper API key (Google Search)
        let serperSaveTimeout;
        async function autoSaveSerperKey() {
            clearTimeout(serperSaveTimeout);
            
            serperSaveTimeout = setTimeout(async () => {
                const apiKey = document.getElementById('serper-api-key').value.trim();
                
                // üî• FIX: Cho ph√©p save empty string (khi user x√≥a key)
                try {
                    if (apiKey) {
                        updateSerperKeyStatus('üíæ ƒêang l∆∞u...', '#f59e0b');
                    } else {
                        updateSerperKeyStatus('üíæ X√≥a key...', '#f59e0b');
                    }
                    
                    const response = await fetch('/api/serper-key', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({api_key: apiKey})
                    });
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        updateSerperKeyStatus('‚úì ƒê√£ l∆∞u - Google Search s·∫µn s√†ng!', '#10b981');
                        setTimeout(() => updateSerperKeyStatus('‚úì API key ƒë√£ c·∫•u h√¨nh', '#10b981'), 2000);
                    } else {
                        updateSerperKeyStatus('‚ùå L·ªói: ' + result.error, '#ef4444');
                    }
                } catch (error) {
                    updateSerperKeyStatus('‚ùå L·ªói k·∫øt n·ªëi', '#ef4444');
                }
            }, 1000);
        }
        
        function updateSerperKeyStatus(message, color) {
            const statusEl = document.getElementById('serper-key-status');
            if (statusEl) {
                statusEl.textContent = message;
                statusEl.style.color = color;
            }
        }
        
        async function saveEndpoint() {
            try {
                addLog('‚è≥ ƒêang l∆∞u endpoints...', 'info');
                
                // L·∫•y token t·ª´ c·∫£ 3 input fields
                const token1 = document.getElementById('endpoint-url-1').value.trim();
                const token2 = document.getElementById('endpoint-url-2').value.trim();
                const token3 = document.getElementById('endpoint-url-3').value.trim();
                
                if (!token1 && !token2 && !token3) {
                    addLog('‚ùå Vui l√≤ng nh·∫≠p √≠t nh·∫•t 1 JWT token!', 'error');
                    return;
                }
                
                // Helper function to extract token from URL or return as-is
                function extractToken(input) {
                    if (!input) return '';
                    
                    // N·∫øu user nh·∫≠p URL ƒë·∫ßy ƒë·ªß, extract token t·ª´ URL
                    if (input.startsWith('wss://') || input.startsWith('http')) {
                        try {
                            const url = new URL(input);
                            const tokenParam = url.searchParams.get('token');
                            if (tokenParam) {
                                return tokenParam;
                            }
                        } catch (e) {
                            return input; // Return as-is if parse fails
                        }
                    }
                    return input;
                }
                
                const cleanToken1 = extractToken(token1);
                const cleanToken2 = extractToken(token2);
                const cleanToken3 = extractToken(token3);
                
                // L·∫•y danh s√°ch thi·∫øt b·ªã hi·ªán t·∫°i
                const response = await fetch('/api/endpoints');
                const data = await response.json();
                
                // Update all 3 devices
                const devices = data.endpoints.map((device, index) => {
                    let token = '';
                    if (index === 0) token = cleanToken1;
                    else if (index === 1) token = cleanToken2;
                    else if (index === 2) token = cleanToken3;
                    
                    return {
                        name: device.name || `Thi·∫øt b·ªã ${index + 1}`,
                        token: token,
                        enabled: token.length > 0  // Auto-enable if has token
                    };
                });
                
                // L∆∞u c·∫•u h√¨nh
                const saveResponse = await fetch('/api/endpoints/save', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({devices: devices})
                });
                
                const saveData = await saveResponse.json();
                
                if (saveData.success) {
                    addLog('‚úÖ ƒê√£ l∆∞u endpoints th√†nh c√¥ng!', 'success');
                    
                    // Show which devices were updated
                    let updatedCount = 0;
                    if (cleanToken1) { addLog('  üì± Thi·∫øt b·ªã 1: ƒê√£ c·∫≠p nh·∫≠t', 'success'); updatedCount++; }
                    if (cleanToken2) { addLog('  üì± Thi·∫øt b·ªã 2: ƒê√£ c·∫≠p nh·∫≠t', 'success'); updatedCount++; }
                    if (cleanToken3) { addLog('  üì± Thi·∫øt b·ªã 3: ƒê√£ c·∫≠p nh·∫≠t', 'success'); updatedCount++; }
                    
                    addLog(`üì° ${updatedCount} thi·∫øt b·ªã s·∫Ω t·ª± ƒë·ªông k·∫øt n·ªëi...`, 'info');
                    
                    closeSettingsModal();
                    
                    // Reload trang sau 1 gi√¢y
                    setTimeout(() => {
                        location.reload();
                    }, 1000);
                } else {
                    addLog('‚ùå L·ªói: ' + saveData.error, 'error');
                }
            } catch (error) {
                addLog('‚ùå L·ªói l∆∞u endpoint: ' + error.message, 'error');
            }
        }
        
        function copyFullUrl() {
            // Get tokens from all 3 fields
            const token1 = document.getElementById('endpoint-url-1').value.trim();
            const token2 = document.getElementById('endpoint-url-2').value.trim();
            const token3 = document.getElementById('endpoint-url-3').value.trim();
            
            if (!token1 && !token2 && !token3) {
                addLog('‚ùå Kh√¥ng c√≥ token n√†o ƒë·ªÉ copy!', 'error');
                return;
            }
            
            let copyText = '';
            
            // Helper function to extract token and create URL
            function createFullUrl(input, deviceNum) {
                if (!input) return null;
                
                let token = input;
                
                // N·∫øu user ƒë√£ nh·∫≠p URL ƒë·∫ßy ƒë·ªß, extract token
                if (input.startsWith('wss://') || input.startsWith('http')) {
                    try {
                        const url = new URL(input);
                        const tokenParam = url.searchParams.get('token');
                        if (tokenParam) {
                            token = tokenParam;
                        }
                    } catch (e) {
                        return null;
                    }
                }
                
                return `Thi·∫øt b·ªã ${deviceNum}: wss://api.xiaozhi.me/mcp/?token=${token}`;
            }
            
            // Create URLs for all devices with tokens
            const urls = [];
            if (token1) urls.push(createFullUrl(token1, 1));
            if (token2) urls.push(createFullUrl(token2, 2));
            if (token3) urls.push(createFullUrl(token3, 3));
            
            copyText = urls.filter(u => u).join('\n\n');
            
            // Copy v√†o clipboard
            navigator.clipboard.writeText(copyText).then(() => {
                addLog(`‚úÖ ƒê√£ copy ${urls.length} URL v√†o clipboard!`, 'success');
            }).catch(err => {
                addLog('‚ùå L·ªói copy: ' + err.message, 'error');
            });
        }
        
        // Load and display all 3 devices
        async function loadDevices() {
            try {
                const response = await fetch('/api/endpoints');
                const data = await response.json();
                
                // Update device status display for all 3 devices
                data.endpoints.forEach((device, index) => {
                    const deviceName = device?.name || `Thi·∫øt b·ªã ${index + 1}`;
                    const hasToken = device?.token && device.token.length > 0;
                    const isEnabled = device?.enabled || false;
                    
                    addLog(`üì± ${deviceName}: ${hasToken ? '‚úÖ Connected' : '‚ùå No token'} ${isEnabled ? '(Enabled)' : '(Disabled)'}`, 
                           hasToken && isEnabled ? 'success' : 'info');
                });
            } catch (error) {
                addLog('‚ùå L·ªói t·∫£i danh s√°ch thi·∫øt b·ªã: ' + error.message, 'error');
            }
        }

        function addLog(message, type = 'info') {
            const log = document.getElementById('log');
            if (!log) return;
            const entry = document.createElement('div');
            entry.className = `log-entry log-${type}`;
            const time = new Date().toLocaleTimeString();
            entry.innerHTML = `<span class="log-time">${time}</span> ${message}`;
            log.insertBefore(entry, log.firstChild);
            
            // Gi·ªõi h·∫°n 50 logs thay v√¨ 100 ƒë·ªÉ gi·∫£m DOM size
            if (log.children.length > 50) {
                // X√≥a nhi·ªÅu logs c√πng l√∫c ƒë·ªÉ tr√°nh reflow nhi·ªÅu l·∫ßn
                while (log.children.length > 50) {
                    log.removeChild(log.lastChild);
                }
            }
        }
        
        // WebSocket v·ªõi reconnect optimization
        let wsReconnectAttempts = 0;
        const MAX_RECONNECT_DELAY = 30000; // Max 30s
        
        function connectWS() {
            ws = new WebSocket(`ws://${window.location.host}/ws`);
            ws.onopen = () => {
                addLog('‚úÖ WebSocket connected', 'success');
                wsReconnectAttempts = 0; // Reset counter khi connect th√†nh c√¥ng
            };
            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                if (data.type === 'xiaozhi_status') {
                    const badge = document.getElementById('xiaozhi-status');
                    const text = document.getElementById('xiaozhi-text');
                    if (data.connected) {
                        badge.className = 'status-badge online';
                        text.textContent = 'Connected';
                    } else {
                        badge.className = 'status-badge offline';
                        text.textContent = 'Disconnected';
                    }
                } else if (data.type === 'xiaozhi_activity') {
                    if (data.method !== 'ping') {
                        addLog(`üì° Xiaozhi: ${data.method}`, 'info');
                    }
                }
            };
            ws.onclose = () => {
                addLog('‚ùå WebSocket disconnected', 'error');
                // Exponential backoff cho reconnect
                wsReconnectAttempts++;
                const delay = Math.min(1000 * Math.pow(2, wsReconnectAttempts), MAX_RECONNECT_DELAY);
                setTimeout(connectWS, delay);
            };
        }
        
        // Caching v√† optimization
        let resourceCache = null;
        let lastResourceFetch = 0;
        const RESOURCE_CACHE_TIME = 3000; // Cache 3 gi√¢y
        
        // Playlist list functions (s·ª≠ d·ª•ng API backend thay v√¨ localStorage)
        async function getPlaylists() {
            try {
                const response = await fetch('/api/youtube_playlists');
                const data = await response.json();
                return data.success ? data.playlists : [];
            } catch (e) {
                console.error('Failed to load playlists from API', e);
                return [];
            }
        }

        async function renderPlaylists() {
            const list = await getPlaylists();
            const container = document.getElementById('playlist-list');
            if (!container) return;
            container.innerHTML = '';

            if (list.length === 0) {
                container.innerHTML = '<div style="color:#666;padding:12px;">Ch∆∞a c√≥ playlist n√†o. Nh·∫•n "Ôºã Th√™m Playlist" ƒë·ªÉ th√™m.</div>';
                return;
            }

            list.forEach((item, idx) => {
                const row = document.createElement('div');
                row.style.display = 'flex';
                row.style.alignItems = 'center';
                row.style.justifyContent = 'space-between';
                row.style.padding = '8px';
                row.style.borderBottom = '1px solid #eee';

                const left = document.createElement('div');
                left.style.display = 'flex';
                left.style.flexDirection = 'column';
                left.style.gap = '4px';

                const name = document.createElement('div');
                name.textContent = item.name;
                name.style.fontWeight = '700';
                name.style.color = '#333';

                const url = document.createElement('div');
                url.textContent = item.url;
                url.style.fontSize = '0.85em';
                url.style.color = '#666';

                left.appendChild(name);
                left.appendChild(url);

                const actions = document.createElement('div');
                actions.style.display = 'flex';
                actions.style.gap = '8px';

                const openBtn = document.createElement('button');
                openBtn.textContent = '‚ñ∂';
                openBtn.title = 'M·ªü playlist';
                openBtn.style.padding = '6px 10px';
                openBtn.style.borderRadius = '6px';
                openBtn.style.border = 'none';
                openBtn.style.background = '#10b981';
                openBtn.style.color = 'white';
                openBtn.style.cursor = 'pointer';
                openBtn.onclick = () => openPlaylistByName(item.name);

                const delBtn = document.createElement('button');
                delBtn.textContent = 'üóë';
                delBtn.title = 'X√≥a playlist';
                delBtn.style.padding = '6px 10px';
                delBtn.style.borderRadius = '6px';
                delBtn.style.border = 'none';
                delBtn.style.background = '#ef4444';
                delBtn.style.color = 'white';
                delBtn.style.cursor = 'pointer';
                delBtn.onclick = () => { if (confirm('X√≥a playlist "' + item.name + '"?')) { removePlaylistByName(item.name); } };

                actions.appendChild(openBtn);
                actions.appendChild(delBtn);

                row.appendChild(left);
                row.appendChild(actions);

                container.appendChild(row);
            });
        }

        function promptAddPlaylist() {
            const name = prompt('Nh·∫≠p t√™n playlist (v√≠ d·ª•: "Nh·∫°c chill"):');
            if (!name) return;
            const url = prompt('D√°n link playlist YouTube (ho·∫∑c video trong playlist):');
            if (!url) return;
            addPlaylist(name.trim(), url.trim());
        }

        async function addPlaylist(name, url) {
            if (!name || !url) {
                addLog('‚ùå T√™n v√† URL kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng', 'error');
                return;
            }
            try {
                const response = await fetch('/api/youtube_playlists/add', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({name, url})
                });
                const data = await response.json();
                if (data.success) {
                    await renderPlaylists();
                    addLog('‚úÖ ƒê√£ th√™m playlist: ' + name, 'success');
                } else {
                    addLog('‚ùå ' + (data.error || 'Kh√¥ng th·ªÉ th√™m playlist'), 'error');
                }
            } catch (e) {
                console.error('Failed to add playlist', e);
                addLog('‚ùå L·ªói khi th√™m playlist', 'error');
            }
        }

        async function removePlaylistByName(name) {
            try {
                const response = await fetch('/api/youtube_playlists/remove', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({name})
                });
                const data = await response.json();
                if (data.success) {
                    await renderPlaylists();
                    addLog('üóë ƒê√£ x√≥a playlist: ' + name, 'info');
                } else {
                    addLog('‚ùå ' + (data.error || 'Kh√¥ng th·ªÉ x√≥a playlist'), 'error');
                }
            } catch (e) {
                console.error('Failed to remove playlist', e);
                addLog('‚ùå L·ªói khi x√≥a playlist', 'error');
            }
        }

        async function openPlaylistByName(name) {
            const list = await getPlaylists();
            const item = list.find(p => p.name === name);
            if (item) {
                window.open(item.url, '_blank');
                addLog('‚ñ∂ M·ªü playlist: ' + name, 'info');
            }
        }

        // Expose function for voice/AI integration: open by keyword search (fuzzy matching)
        async function triggerPlayByName(keyword) {
            if (!keyword || keyword.trim() === '') return false;
            
            keyword = keyword.trim().toLowerCase();
            const list = await getPlaylists();
            
            if (list.length === 0) {
                addLog('‚ö† Danh s√°ch playlist tr·ªëng. H√£y th√™m playlist tr∆∞·ªõc!', 'error');
                return false;
            }
            
            // B∆∞·ªõc 1: T√¨m ch√≠nh x√°c (exact match)
            let found = list.find(item => item.name.toLowerCase() === keyword);
            
            // B∆∞·ªõc 2: T√¨m b·∫Øt ƒë·∫ßu b·∫±ng t·ª´ kh√≥a (starts with)
            if (!found) {
                found = list.find(item => item.name.toLowerCase().startsWith(keyword));
            }
            
            // B∆∞·ªõc 3: T√¨m ch·ª©a t·ª´ kh√≥a (contains)
            if (!found) {
                found = list.find(item => item.name.toLowerCase().includes(keyword));
            }
            
            // B∆∞·ªõc 4: T√¨m theo t·ª´ng t·ª´ trong t√™n playlist
            if (!found) {
                found = list.find(item => {
                    const words = item.name.toLowerCase().split(/\\s+/);
                    return words.some(word => word.includes(keyword) || keyword.includes(word));
                });
            }
            
            if (found) {
                window.open(found.url, '_blank');
                addLog('üîä Ph√°t playlist: "' + found.name + '" (t·ª´ kh√≥a: "' + keyword + '")', 'success');
                return true;
            } else {
                // Hi·ªÉn th·ªã g·ª£i √Ω c√°c playlist c√≥ s·∫µn
                const suggestions = list.map(item => item.name).slice(0, 5).join(', ');
                addLog('‚ö† Kh√¥ng t√¨m th·∫•y playlist v·ªõi t·ª´ kh√≥a: "' + keyword + '"', 'error');
                addLog('üí° G·ª£i √Ω: ' + suggestions, 'info');
                return false;
            }
        }
        
        // H√†m m·ªü playlist nhanh (alias) - d·ªÖ nh·ªõ h∆°n cho voice command
        function moPlaylist(keyword) {
            return triggerPlayByName(keyword);
        }
        
        function danhSachNhac(keyword) {
            return triggerPlayByName(keyword);
        }

        // Initialize playlist list on load
        function initPlaylists() {
            renderPlaylists();
        }
        
        // ============================================================
        // KNOWLEDGE BASE FUNCTIONS
        // ============================================================
        
        async function loadKnowledgeBase() {
            try {
                const response = await fetch('/api/knowledge/status');
                const data = await response.json();
                
                if (data.success) {
                    document.getElementById('knowledge-folder-path').value = data.folder_path || '';
                    document.getElementById('kb-total-files').textContent = data.total_files || 0;
                    document.getElementById('kb-indexed-files').textContent = data.indexed_files || 0;
                    document.getElementById('kb-total-size').textContent = formatFileSize(data.total_size || 0);
                    document.getElementById('kb-last-update').textContent = data.last_update || '--';
                    
                    if (data.files && data.files.length > 0) {
                        renderKnowledgeFiles(data.files);
                    }
                }
            } catch (error) {
                console.error('Error loading knowledge base:', error);
            }
        }
        
        function formatFileSize(bytes) {
            if (bytes === 0) return '0 B';
            const k = 1024;
            const sizes = ['B', 'KB', 'MB', 'GB'];
            const i = Math.floor(Math.log(bytes) / Math.log(k));
            return parseFloat((bytes / Math.pow(k, i)).toFixed(1)) + ' ' + sizes[i];
        }
        
        function renderKnowledgeFiles(files) {
            const container = document.getElementById('knowledge-file-list');
            if (!files || files.length === 0) {
                container.innerHTML = '<p style="color: #666; text-align: center; padding: 40px;">üìÇ Kh√¥ng t√¨m th·∫•y file n√†o.</p>';
                return;
            }
            
            const fileIcons = {
                'pdf': 'üìï',
                'txt': 'üìÑ',
                'docx': 'üìò',
                'doc': 'üìò',
                'md': 'üìù',
                'json': 'üìã',
                'csv': 'üìä',
                'xlsx': 'üìó',
                'xls': 'üìó'
            };
            
            let html = '<div style="display: flex; flex-direction: column; gap: 8px;">';
            files.forEach((file, index) => {
                const ext = file.name.split('.').pop().toLowerCase();
                const icon = fileIcons[ext] || 'üìÑ';
                const indexed = file.indexed ? '‚úÖ' : '‚è≥';
                const escapedPath = btoa(unescape(encodeURIComponent(file.path))); // Base64 encode ƒë·ªÉ tr√°nh l·ªói escape
                
                html += `
                    <div style="display: flex; align-items: center; padding: 12px; background: white; border-radius: 8px; border: 1px solid #e5e7eb; gap: 12px;">
                        <span style="font-size: 1.5em;">${icon}</span>
                        <div style="flex: 1;">
                            <div style="font-weight: 600; color: #333;">${file.name}</div>
                            <div style="font-size: 0.85em; color: #666;">${formatFileSize(file.size)} ‚Ä¢ ${file.modified || ''}</div>
                        </div>
                        <span title="${file.indexed ? 'ƒê√£ index' : 'Ch∆∞a index'}">${indexed}</span>
                        <button onclick="indexSingleFileB64('${escapedPath}')" 
                                style="padding: 6px 12px; background: #667eea; color: white; border: none; border-radius: 6px; cursor: pointer; font-size: 0.85em;">
                            Index
                        </button>
                    </div>
                `;
            });
            html += '</div>';
            container.innerHTML = html;
        }
        
        async function saveKnowledgeFolder() {
            const folderPath = document.getElementById('knowledge-folder-path').value.trim();
            console.log('[Knowledge] saveKnowledgeFolder called, path:', folderPath);
            if (!folderPath) {
                addLog('‚ùå Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c', 'error');
                alert('Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c!');
                return;
            }
            
            try {
                addLog('üíæ ƒêang l∆∞u c·∫•u h√¨nh th∆∞ m·ª•c...', 'info');
                console.log('[Knowledge] Calling API /api/knowledge/set_folder');
                const response = await fetch('/api/knowledge/set_folder', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ folder_path: folderPath })
                });
                console.log('[Knowledge] Response status:', response.status);
                const data = await response.json();
                console.log('[Knowledge] Response data:', data);
                
                if (data.success) {
                    addLog('‚úÖ ' + data.message, 'success');
                    alert('‚úÖ ' + data.message);
                    loadKnowledgeBase();
                } else {
                    addLog('‚ùå ' + (data.error || 'L·ªói kh√¥ng x√°c ƒë·ªãnh'), 'error');
                    alert('‚ùå ' + (data.error || 'L·ªói kh√¥ng x√°c ƒë·ªãnh'));
                }
            } catch (error) {
                console.error('[Knowledge] Error:', error);
                addLog('‚ùå L·ªói: ' + error.message, 'error');
                alert('‚ùå L·ªói: ' + error.message);
            }
        }
        
        async function scanKnowledgeFolder() {
            const folderPath = document.getElementById('knowledge-folder-path').value.trim();
            console.log('[Knowledge] scanKnowledgeFolder called, path:', folderPath);
            if (!folderPath) {
                addLog('‚ùå Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c tr∆∞·ªõc', 'error');
                alert('Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c tr∆∞·ªõc!');
                return;
            }
            
            try {
                addLog('üîç ƒêang qu√©t th∆∞ m·ª•c...', 'info');
                console.log('[Knowledge] Calling API /api/knowledge/scan');
                const response = await fetch('/api/knowledge/scan', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ folder_path: folderPath })
                });
                console.log('[Knowledge] Response status:', response.status);
                const data = await response.json();
                console.log('[Knowledge] Response data:', data);
                
                if (data.success) {
                    addLog('‚úÖ T√¨m th·∫•y ' + data.total_files + ' files', 'success');
                    document.getElementById('kb-total-files').textContent = data.total_files;
                    document.getElementById('kb-total-size').textContent = formatFileSize(data.total_size);
                    renderKnowledgeFiles(data.files);
                } else {
                    addLog('‚ùå ' + (data.error || 'L·ªói kh√¥ng x√°c ƒë·ªãnh'), 'error');
                    alert('‚ùå ' + (data.error || 'L·ªói kh√¥ng x√°c ƒë·ªãnh'));
                }
            } catch (error) {
                console.error('[Knowledge] Scan error:', error);
                addLog('‚ùå L·ªói: ' + error.message, 'error');
                alert('‚ùå L·ªói: ' + error.message);
            }
        }
        
        async function indexAllFiles() {
            try {
                addLog('üîÑ ƒêang index t·∫•t c·∫£ files...', 'info');
                const response = await fetch('/api/knowledge/index_all', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' }
                });
                const data = await response.json();
                
                if (data.success) {
                    addLog('‚úÖ ' + data.message, 'success');
                    document.getElementById('kb-indexed-files').textContent = data.indexed_count;
                    document.getElementById('kb-last-update').textContent = data.last_update || 'V·ª´a xong';
                    loadKnowledgeBase();
                } else {
                    addLog('‚ùå ' + (data.error || 'L·ªói kh√¥ng x√°c ƒë·ªãnh'), 'error');
                }
            } catch (error) {
                addLog('‚ùå L·ªói: ' + error.message, 'error');
            }
        }
        
        // Decode Base64 path v√† g·ªçi indexSingleFile
        async function indexSingleFileB64(base64Path) {
            try {
                const filePath = decodeURIComponent(escape(atob(base64Path)));
                await indexSingleFile(filePath);
            } catch (error) {
                addLog('‚ùå L·ªói decode path: ' + error.message, 'error');
            }
        }
        
        async function indexSingleFile(filePath) {
            try {
                addLog('üîÑ ƒêang index file: ' + filePath.split(/[\\/]/).pop(), 'info');
                const response = await fetch('/api/knowledge/index_file', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ file_path: filePath })
                });
                const data = await response.json();
                
                if (data.success) {
                    addLog('‚úÖ ' + data.message, 'success');
                    loadKnowledgeBase();
                } else {
                    addLog('‚ùå ' + (data.error || 'L·ªói kh√¥ng x√°c ƒë·ªãnh'), 'error');
                }
            } catch (error) {
                addLog('‚ùå L·ªói: ' + error.message, 'error');
            }
        }
        
        async function clearKnowledgeBase() {
            if (!confirm('B·∫°n c√≥ ch·∫Øc mu·ªën x√≥a to√†n b·ªô index? D·ªØ li·ªáu g·ªëc kh√¥ng b·ªã ·∫£nh h∆∞·ªüng.')) {
                return;
            }
            
            try {
                addLog('üóëÔ∏è ƒêang x√≥a index...', 'info');
                const response = await fetch('/api/knowledge/clear', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' }
                });
                const data = await response.json();
                
                if (data.success) {
                    addLog('‚úÖ ' + data.message, 'success');
                    document.getElementById('kb-indexed-files').textContent = '0';
                    loadKnowledgeBase();
                } else {
                    addLog('‚ùå ' + (data.error || 'L·ªói kh√¥ng x√°c ƒë·ªãnh'), 'error');
                }
            } catch (error) {
                addLog('‚ùå L·ªói: ' + error.message, 'error');
            }
        }
        
        // ============================================================
        // CONVERSATION HISTORY FUNCTIONS (WeChat Style)
        // ============================================================
        
        async function loadConversationHistory() {
            try {
                addLog('üìö ƒêang t·∫£i l·ªãch s·ª≠ h·ªôi tho·∫°i t·ª´ server...', 'info');
                const response = await fetch('/api/conversation/history');
                const data = await response.json();
                
                if (data.success) {
                    const messages = data.messages || [];
                    const totalMessages = data.total_messages || 0;
                    
                    displayConversationHistory(messages);
                    document.getElementById('total-messages').textContent = totalMessages;
                    
                    if (messages.length > 0) {
                        const lastMsg = messages[messages.length - 1];
                        const updateTime = lastMsg.timestamp || 'Kh√¥ng r√µ';
                        document.getElementById('last-update').textContent = 'C·∫≠p nh·∫≠t: ' + updateTime;
                        addLog('‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng ' + totalMessages + ' tin nh·∫Øn (c·∫≠p nh·∫≠t l·∫ßn cu·ªëi: ' + updateTime + ')', 'success');
                    } else {
                        document.getElementById('last-update').textContent = 'Ch∆∞a c√≥ tin nh·∫Øn';
                        addLog('‚úÖ L·ªãch s·ª≠ h·ªôi tho·∫°i tr·ªëng', 'success');
                    }
                } else {
                    addLog('‚ùå L·ªói t·∫£i l·ªãch s·ª≠ h·ªôi tho·∫°i: ' + (data.error || 'Unknown error'), 'error');
                    displayConversationHistory([]);
                }
            } catch (e) {
                console.error('Failed to load conversation history', e);
                addLog('‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server ƒë·ªÉ t·∫£i l·ªãch s·ª≠', 'error');
                displayConversationHistory([]);
            }
        }
        
        function displayConversationHistory(messages) {
            const container = document.getElementById('chat-container');
            container.innerHTML = '';
            
            if (!messages || messages.length === 0) {
                container.innerHTML = '<div style="text-align:center; color:#999; padding:40px; font-size:1.1em;">Ch∆∞a c√≥ tin nh·∫Øn n√†o üí¨</div>';
                return;
            }
            
            messages.forEach(msg => {
                const messageDiv = document.createElement('div');
                messageDiv.className = 'chat-message ' + msg.role;
                
                // Avatar
                const avatar = document.createElement('div');
                avatar.className = 'chat-avatar ' + msg.role;
                const roleIcons = {
                    user: 'üë§',
                    assistant: 'ü§ñ',
                    system: '‚öôÔ∏è',
                    tool: 'üîß'
                };
                avatar.textContent = roleIcons[msg.role] || 'üí¨';
                
                // Bubble
                const bubble = document.createElement('div');
                bubble.className = 'chat-bubble';
                
                // Content
                const content = document.createElement('div');
                content.className = 'chat-content';
                content.textContent = msg.content;
                bubble.appendChild(content);
                
                // Metadata
                if (msg.metadata && Object.keys(msg.metadata).length > 0) {
                    const metadata = document.createElement('div');
                    metadata.className = 'chat-metadata';
                    
                    // Show relevant metadata
                    if (msg.metadata.source) {
                        const sourceTag = document.createElement('span');
                        sourceTag.className = 'chat-metadata-item';
                        const sourceIcons = {
                            mcp: 'üîå MCP',
                            web_ui: 'üåê Web UI',
                            websocket: 'üì° WebSocket'
                        };
                        sourceTag.textContent = sourceIcons[msg.metadata.source] || msg.metadata.source;
                        metadata.appendChild(sourceTag);
                    }
                    
                    if (msg.metadata.method) {
                        const methodTag = document.createElement('span');
                        methodTag.className = 'chat-metadata-item';
                        methodTag.textContent = 'üìã ' + msg.metadata.method;
                        metadata.appendChild(methodTag);
                    }
                    
                    if (msg.metadata.model) {
                        const modelTag = document.createElement('span');
                        modelTag.className = 'chat-metadata-item';
                        modelTag.textContent = 'üß† ' + msg.metadata.model;
                        metadata.appendChild(modelTag);
                    }
                    
                    if (msg.metadata.success !== undefined) {
                        const statusTag = document.createElement('span');
                        statusTag.className = 'chat-metadata-item';
                        statusTag.textContent = msg.metadata.success ? '‚úÖ Success' : '‚ùå Failed';
                        metadata.appendChild(statusTag);
                    }
                    
                    bubble.appendChild(metadata);
                }
                
                // Timestamp
                const timestamp = document.createElement('div');
                timestamp.className = 'chat-timestamp';
                timestamp.textContent = msg.timestamp;
                bubble.appendChild(timestamp);
                
                messageDiv.appendChild(avatar);
                messageDiv.appendChild(bubble);
                container.appendChild(messageDiv);
            });
            
            // Auto scroll to bottom
            container.scrollTop = container.scrollHeight;
        }
        
        async function exportConversation() {
            try {
                addLog('üíæ ƒêang xu·∫•t l·ªãch s·ª≠...', 'info');
                const response = await fetch('/api/conversation/export', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({})
                });
                const data = await response.json();
                
                if (data.success) {
                    addLog('‚úÖ ƒê√£ xu·∫•t file: ' + data.path, 'success');
                    alert('‚úÖ ƒê√£ xu·∫•t l·ªãch s·ª≠ h·ªôi tho·∫°i!\\n\\nƒê∆∞·ªùng d·∫´n: ' + data.path + '\\n\\nT·ªïng: ' + data.message);
                } else {
                    addLog('‚ùå L·ªói xu·∫•t file: ' + (data.error || 'Unknown'), 'error');
                }
            } catch (e) {
                console.error('Failed to export conversation', e);
                addLog('‚ùå Kh√¥ng th·ªÉ xu·∫•t file', 'error');
            }
        }
        
        async function clearConversationHistory() {
            if (!confirm('‚ö†Ô∏è B·∫°n c√≥ ch·∫Øc mu·ªën X√ìA T·∫§T C·∫¢ l·ªãch s·ª≠ h·ªôi tho·∫°i?\\n\\nH√†nh ƒë·ªông n√†y KH√îNG TH·ªÇ HO√ÄN T√ÅC!')) {
                return;
            }
            
            try {
                addLog('üóëÔ∏è ƒêang x√≥a l·ªãch s·ª≠...', 'info');
                const response = await fetch('/api/conversation/clear', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    document.getElementById('chat-container').innerHTML = '<div style="text-align:center; color:#999; padding:40px; font-size:1.1em;">Ch∆∞a c√≥ tin nh·∫Øn n√†o üí¨</div>';
                    document.getElementById('total-messages').textContent = '0';
                    document.getElementById('last-update').textContent = 'Ch∆∞a c√≥ d·ªØ li·ªáu';
                    addLog('‚úÖ ƒê√£ x√≥a to√†n b·ªô l·ªãch s·ª≠', 'success');
                } else {
                    addLog('‚ùå L·ªói x√≥a l·ªãch s·ª≠: ' + (data.error || 'Unknown'), 'error');
                }
            } catch (e) {
                console.error('Failed to clear conversation', e);
                addLog('‚ùå Kh√¥ng th·ªÉ x√≥a l·ªãch s·ª≠', 'error');
            }
        }
        
        // ===== MUSIC PLAYER FUNCTIONS =====
        let currentPlaylist = [];
        let allMusicFiles = []; // Store all files for filtering
        let currentTrackIndex = -1;
        let isPlaying = false;
        let isShuffleOn = false;
        let repeatMode = 0; // 0: off, 1: repeat all, 2: repeat one
        let currentMusicSource = 'library'; // 'library' or 'user'
        let vlcStatusInterval = null; // VLC status polling interval
        
        // ===== VLC STATUS POLLING - Real-time sync with python-vlc =====
        async function pollVlcStatus() {
            try {
                const response = await fetch('/api/vlc_status');
                const status = await response.json();
                
                if (status.state && status.state !== 'not_initialized') {
                    // Update play state
                    isPlaying = status.is_playing;
                    document.getElementById('play-btn').textContent = isPlaying ? '‚è∏Ô∏è' : '‚ñ∂Ô∏è';
                    
                    // Update progress slider (only if not dragging)
                    if (status.position !== undefined && !isDraggingProgress) {
                        const percent = (status.position * 100).toFixed(1);
                        const slider = document.getElementById('progress-slider');
                        if (slider) {
                            slider.value = percent;
                            slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${percent}%, #374151 ${percent}%, #374151 100%)`;
                        }
                    }
                    
                    // Update time display
                    if (status.current_time_formatted) {
                        document.getElementById('current-time').textContent = status.current_time_formatted;
                    }
                    if (status.duration_formatted) {
                        document.getElementById('total-time').textContent = status.duration_formatted;
                    }
                    
                    // Update volume (sync from VLC)
                    if (status.volume !== undefined) {
                        const slider = document.getElementById('volume-slider');
                        if (document.activeElement !== slider) { // Don't update while user is dragging
                            slider.value = status.volume;
                            document.getElementById('volume-value').textContent = status.volume + '%';
                            slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${status.volume}%, #374151 ${status.volume}%, #374151 100%)`;
                        }
                    }
                    
                    // Update current track name
                    if (status.current_track) {
                        document.getElementById('current-track').textContent = 'üéµ ' + status.current_track;
                        document.getElementById('track-info').textContent = 
                            `${status.playlist_index + 1}/${status.playlist_count} b√†i ‚Ä¢ VLC Player`;
                    }
                    
                    // Sync shuffle/repeat state from VLC
                    if (status.shuffle !== undefined) {
                        isShuffleOn = status.shuffle;
                        const shuffleBtn = document.getElementById('shuffle-btn');
                        if (shuffleBtn) {
                            shuffleBtn.style.opacity = isShuffleOn ? '1' : '0.6';
                            shuffleBtn.style.transform = isShuffleOn ? 'scale(1.1)' : 'scale(1)';
                        }
                    }
                    if (status.repeat_mode !== undefined) {
                        repeatMode = status.repeat_mode;
                        const repeatBtn = document.getElementById('repeat-btn');
                        if (repeatBtn) {
                            repeatBtn.textContent = repeatMode === 2 ? 'üîÇ' : 'üîÅ';
                            repeatBtn.style.opacity = repeatMode > 0 ? '1' : '0.6';
                        }
                    }
                }
            } catch (e) {
                // Silent fail - VLC may not be playing
            }
        }
        
        function startVlcPolling() {
            if (vlcStatusInterval) clearInterval(vlcStatusInterval);
            vlcStatusInterval = setInterval(pollVlcStatus, 1000); // Poll every 1 second
        }
        
        function stopVlcPolling() {
            if (vlcStatusInterval) {
                clearInterval(vlcStatusInterval);
                vlcStatusInterval = null;
            }
        }
        
        // Click on progress bar to seek
        async function seekToPosition(event) {
            const progressBar = event.currentTarget;
            const rect = progressBar.getBoundingClientRect();
            const position = (event.clientX - rect.left) / rect.width;
            
            try {
                await fetch('/api/vlc_seek', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({position: position})
                });
            } catch (e) {
                console.error('Seek failed', e);
            }
        }
        
        // Music Source Selector Functions
        function setMusicSource(source) {
            currentMusicSource = source;
            localStorage.setItem('musicSource', source);
            
            // Update button styles
            const libraryBtn = document.getElementById('source-library-btn');
            const userBtn = document.getElementById('source-user-btn');
            
            if (source === 'library') {
                libraryBtn.style.background = '#667eea';
                libraryBtn.style.color = 'white';
                userBtn.style.background = 'transparent';
                userBtn.style.color = '#667eea';
                document.getElementById('source-path-display').textContent = 'music_library/';
            } else {
                libraryBtn.style.background = 'transparent';
                libraryBtn.style.color = '#667eea';
                userBtn.style.background = '#667eea';
                userBtn.style.color = 'white';
                const userPath = localStorage.getItem('musicFolderPath') || 'Ch∆∞a c·∫•u h√¨nh';
                document.getElementById('source-path-display').textContent = userPath;
            }
            
            // Reload music library from new source
            loadMusicLibrary();
            addLog(`üéØ ƒê√£ chuy·ªÉn ngu·ªìn ph√°t: ${source === 'library' ? 'Music Library' : 'Th∆∞ m·ª•c c√° nh√¢n'}`, 'success');
        }
        
        function loadMusicSourcePreference() {
            const saved = localStorage.getItem('musicSource') || 'library';
            setMusicSource(saved);
        }
        
        // Search/Filter Music Library
        function filterMusicLibrary(query) {
            if (!query || query.trim() === '') {
                renderMusicLibrary(allMusicFiles);
                return;
            }
            
            const lowerQuery = query.toLowerCase();
            const filtered = allMusicFiles.filter(file => 
                file.filename.toLowerCase().includes(lowerQuery) ||
                (file.path && file.path.toLowerCase().includes(lowerQuery))
            );
            renderMusicLibrary(filtered);
        }
        
        async function loadMusicLibrary() {
            try {
                // Determine which source to load from
                // IMPORTANT: auto_play=false ƒë·ªÉ kh√¥ng t·ª± ph√°t khi load danh s√°ch
                const args = currentMusicSource === 'user' 
                    ? { folder: localStorage.getItem('musicFolderPath') || '', auto_play: false }
                    : { auto_play: false };
                
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'list_music', args: args})
                });
                const data = await response.json();
                
                if (data.success && data.files) {
                    allMusicFiles = data.files;
                    currentPlaylist = data.files;
                    renderMusicLibrary(data.files);
                } else {
                    document.getElementById('music-library').innerHTML = '<p style="text-align:center; color:#999; padding:40px;">‚ùå Kh√¥ng t√¨m th·∫•y nh·∫°c trong th∆∞ vi·ªán</p>';
                }
            } catch (e) {
                console.error('Failed to load music library', e);
                document.getElementById('music-library').innerHTML = '<p style="text-align:center; color:#f44336; padding:40px;">‚ùå L·ªói t·∫£i danh s√°ch nh·∫°c</p>';
            }
        }
        
        function renderMusicLibrary(files) {
            const html = files.map((file, index) => {
                const originalIndex = allMusicFiles.findIndex(f => f.filename === file.filename);
                const isCurrentTrack = originalIndex === currentTrackIndex;
                const isTrackPlaying = isCurrentTrack && isPlaying;
                
                return `
                <div class="music-item ${isTrackPlaying ? 'playing' : ''}" 
                     data-index="${originalIndex}"
                     onmouseenter="this.querySelector('.play-btn-hover').style.opacity='1'" 
                     onmouseleave="this.querySelector('.play-btn-hover').style.opacity='0'" 
                     style="cursor:pointer; display: flex; align-items: center; padding: 12px; border-radius: 8px; margin-bottom: 8px; background: ${isCurrentTrack ? 'linear-gradient(135deg, rgba(102,126,234,0.12) 0%, rgba(118,75,162,0.12) 100%)' : '#f9fafb'}; transition: all 0.2s ease; border-left: 4px solid ${isCurrentTrack ? '#667eea' : 'transparent'}; border: 1px solid ${isCurrentTrack ? '#c7d2fe' : 'transparent'};">
                    
                    <!-- Play Button (hover) -->
                    <div class="play-btn-hover" onclick="playTrack(${originalIndex}); event.stopPropagation();" 
                         style="width: 42px; height: 42px; margin-right: 12px; border-radius: 50%; background: ${isTrackPlaying ? '#667eea' : 'linear-gradient(135deg, #667eea, #764ba2)'}; display: flex; align-items: center; justify-content: center; color: white; font-size: 16px; opacity: ${isTrackPlaying ? '1' : '0'}; transition: all 0.2s ease; box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3); cursor: pointer;" 
                         title="${isTrackPlaying ? 'ƒêang ph√°t' : 'Click ƒë·ªÉ ph√°t'}">
                        ${isTrackPlaying ? '‚è∏' : '‚ñ∂'}
                    </div>
                    
                    <!-- Music Icon (default state) -->
                    <div class="icon" style="font-size: 1.5em; margin-right: 12px; ${isTrackPlaying ? 'display:none;' : ''}">${isCurrentTrack ? 'üîä' : 'üéµ'}</div>
                    
                    <!-- Track Info (clickable) -->
                    <div class="info" onclick="playTrack(${originalIndex})" style="flex: 1; cursor: pointer;">
                        <div class="name" style="font-weight: 600; color: ${isCurrentTrack ? '#667eea' : '#333'}; margin-bottom: 3px;">${file.filename}</div>
                        <div class="details" style="font-size: 0.85em; color: #6b7280;">${file.path} ‚Ä¢ ${file.size_mb} MB</div>
                    </div>
                    
                    <!-- Now Playing Indicator -->
                    ${isTrackPlaying ? '<div style="display:flex; align-items:center; gap:5px; color:#667eea; font-size:12px; animation: pulse 1.5s infinite;"><div style="width:3px; height:12px; background:#667eea; animation: wave1 0.8s ease-in-out infinite;"></div><div style="width:3px; height:18px; background:#667eea; animation: wave2 0.8s ease-in-out infinite 0.1s;"></div><div style="width:3px; height:15px; background:#667eea; animation: wave3 0.8s ease-in-out infinite 0.2s;"></div></div>' : ''}
                </div>
            `}).join('');
            
            document.getElementById('music-library').innerHTML = html || '<p style="text-align:center; color:#999; padding:40px;">Kh√¥ng c√≥ b√†i h√°t n√†o</p>';
        }
        
        // Toggle Shuffle
        async function toggleShuffle() {
            try {
                const response = await fetch('/api/vlc_shuffle', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({})
                });
                const data = await response.json();
                
                if (data.success) {
                    isShuffleOn = data.shuffle;
                    const btn = document.getElementById('shuffle-btn');
                    btn.style.opacity = isShuffleOn ? '1' : '0.6';
                    btn.style.transform = isShuffleOn ? 'scale(1.1)' : 'scale(1)';
                    addLog(isShuffleOn ? 'üîÄ B·∫≠t ph√°t ng·∫´u nhi√™n' : 'üîÄ T·∫Øt ph√°t ng·∫´u nhi√™n', 'success');
                }
            } catch (e) {
                console.error('Toggle shuffle failed', e);
            }
        }
        
        // Toggle Repeat
        async function toggleRepeat() {
            try {
                const response = await fetch('/api/vlc_repeat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({})
                });
                const data = await response.json();
                
                if (data.success) {
                    repeatMode = data.repeat_mode;
                    const btn = document.getElementById('repeat-btn');
                    
                    switch(repeatMode) {
                        case 0:
                            btn.textContent = 'üîÅ';
                            btn.style.opacity = '0.6';
                            addLog('üîÅ T·∫Øt l·∫∑p l·∫°i', 'success');
                            break;
                        case 1:
                            btn.textContent = 'üîÅ';
                            btn.style.opacity = '1';
                            addLog('üîÅ L·∫∑p l·∫°i t·∫•t c·∫£', 'success');
                            break;
                        case 2:
                            btn.textContent = 'üîÇ';
                            btn.style.opacity = '1';
                            addLog('üîÇ L·∫∑p l·∫°i m·ªôt b√†i', 'success');
                            break;
                    }
                }
            } catch (e) {
                console.error('Toggle repeat failed', e);
            }
        }
        
        // Volume Control
        function setPlayerVolume(value) {
            document.getElementById('volume-value').textContent = value + '%';
            
            // Update slider gradient
            const slider = document.getElementById('volume-slider');
            slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${value}%, #374151 ${value}%, #374151 100%)`;
            
            // Update icon
            const icon = document.getElementById('volume-icon');
            if (value == 0) {
                icon.textContent = 'üîá';
            } else if (value < 30) {
                icon.textContent = 'üîà';
            } else if (value < 70) {
                icon.textContent = 'üîâ';
            } else {
                icon.textContent = 'üîä';
            }
            
            // Call VLC API directly to set volume
            fetch('/api/vlc_volume', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({level: parseInt(value)})
            }).catch(e => console.error('Volume set failed', e));
        }
        
        let lastVolume = 80;
        function toggleMute() {
            const slider = document.getElementById('volume-slider');
            if (parseInt(slider.value) > 0) {
                lastVolume = slider.value;
                slider.value = 0;
                setPlayerVolume(0);
            } else {
                slider.value = lastVolume;
                setPlayerVolume(lastVolume);
            }
        }
        
        // SINGLE-CLICK TO PLAY (like Spotify/Apple Music)
        // Removed complex double-click logic - direct click to play for better UX
        
        // C·∫≠p nh·∫≠t visualizer state
        function updateVisualizer(playing) {
            const visualizer = document.getElementById('audio-visualizer');
            if (visualizer) {
                if (playing) {
                    visualizer.style.display = 'flex';
                    visualizer.classList.remove('paused');
                } else {
                    visualizer.classList.add('paused');
                }
            }
        }
        
        async function playTrack(index) {
            if (!allMusicFiles[index]) {
                console.error('Track not found at index:', index);
                addLog('‚ùå Kh√¥ng t√¨m th·∫•y b√†i h√°t', 'error');
                return;
            }
            
            try {
                const track = allMusicFiles[index];
                console.log('üéµ Playing track:', track.filename);
                addLog(`‚è≥ ƒêang t·∫£i: ${track.filename}...`, 'info');
                
                // G·ªçi API tr·ª±c ti·∫øp ƒë·ªÉ ph√°t nh·∫°c
                const response = await fetch('/api/vlc_play_file', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({filename: track.filename})
                });
                const data = await response.json();
                console.log('Play response:', data);
                
                if (data.success) {
                    currentTrackIndex = index;
                    isPlaying = true;
                    updateNowPlaying();
                    updateVisualizer(true);
                    renderMusicLibrary(currentPlaylist);
                    document.getElementById('play-btn').textContent = '‚è∏Ô∏è';
                    addLog(`üéµ ƒêang ph√°t: ${track.filename}`, 'success');
                    
                    // Start VLC polling for real-time sync
                    startVlcPolling();
                } else {
                    console.error('Play failed:', data);
                    addLog('‚ùå ' + (data.error || 'Kh√¥ng th·ªÉ ph√°t nh·∫°c'), 'error');
                }
            } catch (e) {
                console.error('Failed to play track', e);
                addLog('‚ùå L·ªói k·∫øt n·ªëi', 'error');
            }
        }
        
        async function musicPlayPause() {
            try {
                // G·ªçi VLC API tr·ª±c ti·∫øp - kh√¥ng qua tool registry
                const response = await fetch('/api/vlc_play_pause', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    isPlaying = data.is_playing;
                    document.getElementById('play-btn').textContent = isPlaying ? '‚è∏Ô∏è' : '‚ñ∂Ô∏è';
                    updateVisualizer(isPlaying);
                    renderMusicLibrary(currentPlaylist);
                    addLog(data.message, 'success');
                } else {
                    addLog('‚ùå ' + (data.error || 'L·ªói play/pause'), 'error');
                }
            } catch (e) {
                console.error('Play/Pause failed', e);
                addLog('‚ùå L·ªói k·∫øt n·ªëi VLC', 'error');
            }
        }
        
        async function musicNext() {
            try {
                const response = await fetch('/api/vlc_next', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    currentTrackIndex = (currentTrackIndex + 1) % currentPlaylist.length;
                    updateNowPlaying();
                    renderMusicLibrary(currentPlaylist);
                    addLog(data.message || '‚è≠Ô∏è B√†i ti·∫øp theo', 'success');
                } else {
                    addLog('‚ùå ' + (data.error || 'Kh√¥ng c√≥ b√†i ti·∫øp'), 'error');
                }
            } catch (e) {
                console.error('Next track failed', e);
                addLog('‚ùå L·ªói chuy·ªÉn b√†i', 'error');
            }
        }
        
        async function musicPrevious() {
            try {
                const response = await fetch('/api/vlc_previous', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    currentTrackIndex = (currentTrackIndex - 1 + currentPlaylist.length) % currentPlaylist.length;
                    updateNowPlaying();
                    renderMusicLibrary(currentPlaylist);
                    addLog(data.message || '‚èÆÔ∏è B√†i tr∆∞·ªõc', 'success');
                } else {
                    addLog('‚ùå ' + (data.error || 'Kh√¥ng c√≥ b√†i tr∆∞·ªõc'), 'error');
                }
            } catch (e) {
                console.error('Previous track failed', e);
                addLog('‚ùå L·ªói chuy·ªÉn b√†i', 'error');
            }
        }
        
        async function musicStop() {
            try {
                const response = await fetch('/api/vlc_stop', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    isPlaying = false;
                    currentTrackIndex = -1;
                    document.getElementById('current-track').textContent = 'üéµ ƒê√£ d·ª´ng ph√°t';
                    document.getElementById('track-info').textContent = 'Ch·ªçn b√†i h√°t ƒë·ªÉ ph√°t';
                    document.getElementById('track-album').textContent = '';
                    document.getElementById('album-art').innerHTML = 'üéµ';
                    document.getElementById('play-btn').textContent = '‚ñ∂Ô∏è';
                    const slider = document.getElementById('progress-slider');
                    if (slider) {
                        slider.value = 0;
                        slider.style.background = 'linear-gradient(to right, #667eea 0%, #667eea 0%, #374151 0%, #374151 100%)';
                    }
                    document.getElementById('current-time').textContent = '0:00';
                    document.getElementById('total-time').textContent = '0:00';
                    addLog(data.message || '‚èπÔ∏è ƒê√£ d·ª´ng nh·∫°c', 'success');
                } else {
                    addLog('‚ùå ' + (data.error || 'L·ªói d·ª´ng nh·∫°c'), 'error');
                    renderMusicLibrary(currentPlaylist);
                    addLog('‚èπÔ∏è ƒê√£ d·ª´ng ph√°t nh·∫°c', 'success');
                }
            } catch (e) {
                console.error('Stop failed', e);
            }
        }
        
        function updateNowPlaying() {
            if (currentTrackIndex >= 0 && allMusicFiles[currentTrackIndex]) {
                const track = allMusicFiles[currentTrackIndex];
                document.getElementById('current-track').textContent = track.filename.replace(/\\.[^/.]+$/, ''); // Remove extension
                document.getElementById('track-info').textContent = `${track.path}`;
                document.getElementById('track-album').textContent = `${track.size_mb} MB ‚Ä¢ B√†i ${currentTrackIndex + 1}/${allMusicFiles.length}`;
                
                // Update album art with music note animation
                const albumArt = document.getElementById('album-art');
                if (albumArt) {
                    albumArt.innerHTML = isPlaying ? '<div style="animation: spin 3s linear infinite;">üéµ</div>' : 'üéµ';
                }
            }
        }
        
        async function updateMusicStatus() {
            try {
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'get_music_status', args: {}})
                });
                const data = await response.json();
                
                if (data.success) {
                    // Sync playing state
                    const wasPlaying = isPlaying;
                    isPlaying = data.is_playing === 1 || data.is_playing === true;
                    
                    // Update play button
                    const playBtn = document.getElementById('play-btn');
                    if (playBtn) {
                        playBtn.textContent = isPlaying ? '‚è∏Ô∏è' : '‚ñ∂Ô∏è';
                    }
                    
                    // Update progress bar and time
                    if (data.current_time !== undefined && data.duration !== undefined) {
                        const currentSec = parseFloat(data.current_time) || 0;
                        const totalSec = parseFloat(data.duration) || 0;
                        
                        if (totalSec > 0) {
                            // Update progress slider (only if not dragging)
                            const percentage = (currentSec / totalSec) * 100;
                            const slider = document.getElementById('progress-slider');
                            if (slider && !isDraggingProgress) {
                                slider.value = Math.min(100, Math.max(0, percentage));
                                slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${percentage}%, #374151 ${percentage}%, #374151 100%)`;
                            }
                            
                            // Update time displays
                            const currentTimeEl = document.getElementById('current-time');
                            const totalTimeEl = document.getElementById('total-time');
                            if (currentTimeEl) currentTimeEl.textContent = formatTime(currentSec);
                            if (totalTimeEl) totalTimeEl.textContent = formatTime(totalSec);
                        }
                    }
                    
                    // Update library UI if play state changed
                    if (wasPlaying !== isPlaying && currentPlaylist.length > 0) {
                        renderMusicLibrary(currentPlaylist);
                    }
                }
            } catch (e) {
                console.error('Update music status error:', e);
            }
        }
        
        function formatTime(seconds) {
            if (!seconds || seconds < 0) return '0:00';
            const mins = Math.floor(seconds / 60);
            const secs = Math.floor(seconds % 60);
            return mins + ':' + (secs < 10 ? '0' : '') + secs;
        }
        
        // Progress bar dragging state
        let isDraggingProgress = false;
        
        // Called while dragging (preview only, no seek)
        function onProgressDrag(value) {
            isDraggingProgress = true;
            // Update slider visual immediately
            const slider = document.getElementById('progress-slider');
            slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${value}%, #374151 ${value}%, #374151 100%)`;
        }
        
        // Called when drag ends (actual seek)
        async function onProgressSeek(value) {
            isDraggingProgress = false;
            const percentage = parseFloat(value);
            
            try {
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'seek_music', args: {percentage: percentage}})
                });
                const data = await response.json();
                
                if (data.success) {
                    await updateMusicStatus();
                }
            } catch (e) {
                console.error('Seek failed', e);
            }
        }
        
        async function seekTrack(event) {
            const progressBar = event.currentTarget;
            const rect = progressBar.getBoundingClientRect();
            const clickX = event.clientX - rect.left;
            const percentage = (clickX / rect.width) * 100;
            
            try {
                // G·ªçi tool ƒë·ªÉ seek (c·∫ßn implement trong backend)
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'seek_music', args: {percentage: percentage}})
                });
                const data = await response.json();
                
                if (data.success) {
                    // C·∫≠p nh·∫≠t progress bar ngay l·∫≠p t·ª©c
                    document.getElementById('progress-fill').style.width = percentage + '%';
                    await updateMusicStatus();
                }
            } catch (e) {
                console.error('Seek failed', e);
            }
        }
        
        // ==========================================
        // REALTIME STATS UPDATE (CPU, RAM, GPU)
        // ==========================================
        async function updateRealtimeStats() {
            try {
                const response = await fetch('/api/realtime_stats');
                const data = await response.json();
                if (data.success) {
                    // CPU
                    const cpuPercent = data.cpu.percent || 0;
                    const cpuEl = document.getElementById('cpu-realtime');
                    if (cpuEl) {
                        cpuEl.textContent = cpuPercent.toFixed(0) + '%';
                        cpuEl.style.color = cpuPercent > 80 ? '#f44336' : (cpuPercent > 50 ? '#ff9800' : '#4CAF50');
                    }
                    const cpuBar = document.getElementById('cpu-bar');
                    if (cpuBar) {
                        cpuBar.style.width = cpuPercent + '%';
                        cpuBar.style.background = cpuPercent > 80 ? '#f44336' : (cpuPercent > 50 ? '#ff9800' : '#4CAF50');
                    }
                    const cpuInfo = document.getElementById('cpu-info');
                    if (cpuInfo) cpuInfo.textContent = (data.cpu.freq || 0) + ' MHz | ' + (data.cpu.cores || 0) + ' cores';
                    
                    // RAM
                    const ramPercent = data.ram.percent || 0;
                    const ramEl = document.getElementById('ram-realtime');
                    if (ramEl) {
                        ramEl.textContent = ramPercent.toFixed(0) + '%';
                        ramEl.style.color = ramPercent > 80 ? '#f44336' : (ramPercent > 50 ? '#ff9800' : '#ff9800');
                    }
                    const ramBar = document.getElementById('ram-bar');
                    if (ramBar) {
                        ramBar.style.width = ramPercent + '%';
                        ramBar.style.background = ramPercent > 80 ? '#f44336' : (ramPercent > 50 ? '#ff9800' : '#ff9800');
                    }
                    const ramInfo = document.getElementById('ram-info');
                    if (ramInfo) ramInfo.textContent = (data.ram.used || 0) + ' / ' + (data.ram.total || 0) + ' GB';
                    
                    // GPU
                    const gpuPercent = data.gpu.percent || 0;
                    const gpuEl = document.getElementById('gpu-realtime');
                    if (gpuEl) {
                        gpuEl.textContent = gpuPercent + '%';
                        gpuEl.style.color = gpuPercent > 80 ? '#f44336' : (gpuPercent > 50 ? '#ff9800' : '#9C27B0');
                    }
                    const gpuBar = document.getElementById('gpu-bar');
                    if (gpuBar) {
                        gpuBar.style.width = gpuPercent + '%';
                        gpuBar.style.background = gpuPercent > 80 ? '#f44336' : (gpuPercent > 50 ? '#ff9800' : '#9C27B0');
                    }
                    const gpuName = document.getElementById('gpu-name');
                    if (gpuName) gpuName.textContent = data.gpu.name || 'Unknown';
                }
            } catch (e) {
                console.error('Realtime stats error:', e);
            }
        }
        
        connectWS();
        // Gi·∫£m polling t·ª´ 5s xu·ªëng 10s ƒë·ªÉ gi·∫£m t·∫£i
        setInterval(getResources, 10000);
        getResources();
        
        // Realtime stats polling (every 2 seconds)
        setInterval(updateRealtimeStats, 2000);
        updateRealtimeStats();
        
        // Load quotas on startup and refresh every 60 seconds
        getQuotas();
        setInterval(getQuotas, 60000);
        
        // Start VLC status polling for real-time sync
        startVlcPolling();
        
        // Initial VLC status check
        setTimeout(pollVlcStatus, 500);
        
        // RunCat Animation - Multiple frames like RunCat365
        let runcatFrame = 0;
        let runcatSpeed = 500; // Default 500ms per frame
        const runcatFrames = ['üê±', 'üêà', 'üò∫', 'üò∏', 'üòπ'];
        
        function animateRunCat() {
            const runcat = document.getElementById('runcat');
            if (!runcat) return;
            
            runcatFrame = (runcatFrame + 1) % runcatFrames.length;
            runcat.textContent = runcatFrames[runcatFrame];
            
            // Apply transform for running effect
            const offset = runcatFrame % 2 === 0 ? -3 : -1;
            const flip = runcatFrame >= 2 && runcatFrame <= 3 ? -1 : 1;
            runcat.style.transform = `translateY(${offset}px) scaleX(${flip})`;
            
            setTimeout(animateRunCat, runcatSpeed);
        }
        
        // Start RunCat animation
        setTimeout(animateRunCat, 100);
        
        // Auto-update music status every 1 second when music section is active
        setInterval(() => {
            const musicSection = document.getElementById('music-section');
            if (musicSection && musicSection.style.display !== 'none') {
                updateMusicStatus();
            }
        }, 1000);
        
        // Music Settings Functions
        function loadMusicFolderSettings() {
            const savedPath = localStorage.getItem('musicFolderPath');
            if (savedPath) {
                document.getElementById('music-folder-path').value = savedPath;
            }
        }
        
        function browseMusicFolder() {
            // Web kh√¥ng th·ªÉ browse folder tr·ª±c ti·∫øp, h∆∞·ªõng d·∫´n user
            alert('üí° H∆∞·ªõng d·∫´n:\\n\\n1. M·ªü File Explorer (Windows + E)\\n2. ƒêi ƒë·∫øn th∆∞ m·ª•c nh·∫°c c·ªßa b·∫°n\\n3. Click v√†o thanh ƒë·ªãa ch·ªâ v√† copy ƒë∆∞·ªùng d·∫´n (Ctrl+C)\\n4. Paste v√†o √¥ b√™n tr√°i (Ctrl+V)\\n5. Click "üíæ L∆∞u"\\n\\nV√≠ d·ª•: C:\\\\\\\\Users\\\\\\\\YourName\\\\\\\\Music');
        }
        
        async function saveMusicFolder() {
            const folderPath = document.getElementById('music-folder-path').value.trim();
            const statusEl = document.getElementById('music-folder-status');
            
            if (!folderPath) {
                statusEl.style.display = 'block';
                statusEl.style.background = '#fee2e2';
                statusEl.style.color = '#991b1b';
                statusEl.innerHTML = '‚ùå Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c!';
                return;
            }
            
            try {
                // L∆∞u v√†o localStorage
                localStorage.setItem('musicFolderPath', folderPath);
                
                // G·ªçi tool ƒë·ªÉ l∆∞u config
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({
                        tool: 'save_music_folder_config',
                        args: {folder_path: folderPath}
                    })
                });
                const data = await response.json();
                
                if (data.success) {
                    statusEl.style.display = 'block';
                    statusEl.style.background = '#d1fae5';
                    statusEl.style.color = '#065f46';
                    statusEl.innerHTML = '‚úÖ ƒê√£ l∆∞u c√†i ƒë·∫∑t th√†nh c√¥ng! LLM s·∫Ω ∆∞u ti√™n ph√°t nh·∫°c t·ª´ th∆∞ m·ª•c n√†y.';
                    addLog(`‚öôÔ∏è ƒê√£ c·∫•u h√¨nh th∆∞ m·ª•c nh·∫°c: ${folderPath}`, 'success');
                } else {
                    throw new Error(data.error || 'Unknown error');
                }
            } catch (e) {
                statusEl.style.display = 'block';
                statusEl.style.background = '#fee2e2';
                statusEl.style.color = '#991b1b';
                statusEl.innerHTML = `‚ùå L·ªói: ${e.message}`;
                console.error('Save music folder error:', e);
            }
        }
        
        // ============================================================
        // üí¨ LLM CHAT FUNCTIONS - G·ª≠i tin nh·∫Øn cho Robot/LLM
        // ============================================================
        
        async function refreshLLMConnectionStatus() {
            try {
                const response = await fetch('/api/llm_connection_status');
                const data = await response.json();
                
                if (data.success) {
                    data.devices.forEach((device, index) => {
                        // Update old status display (if exists)
                        const statusEl = document.getElementById(`device${index + 1}-status`);
                        if (statusEl) {
                            const icon = device.connected ? '‚úÖ' : (device.enabled ? '‚è≥' : '‚ùå');
                            const text = device.connected ? 'ƒê√£ k·∫øt n·ªëi' : (device.enabled ? 'ƒêang k·∫øt n·ªëi...' : 'Ch∆∞a c·∫•u h√¨nh');
                            statusEl.innerHTML = `üì± ${device.name}: <span class="status-indicator">${icon} ${text}</span>`;
                        }
                        
                        // Update new device card indicator
                        const indicator = document.getElementById(`device-${index + 1}-indicator`);
                        const card = document.getElementById(`device-${index + 1}-card`);
                        if (indicator) {
                            if (device.connected) {
                                indicator.innerHTML = '<span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#10b981;animation:pulse 2s infinite;"></span> ‚úÖ ƒê√£ k·∫øt n·ªëi';
                                indicator.style.background = '#d1fae5';
                                indicator.style.color = '#047857';
                                if (card) card.style.boxShadow = '0 0 20px rgba(16, 185, 129, 0.4)';
                            } else if (device.enabled) {
                                indicator.innerHTML = '<span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#f59e0b;animation:blink 1s infinite;"></span> ‚è≥ ƒêang k·∫øt n·ªëi...';
                                indicator.style.background = '#fef3c7';
                                indicator.style.color = '#b45309';
                                if (card) card.style.boxShadow = '0 0 15px rgba(245, 158, 11, 0.3)';
                            } else {
                                indicator.innerHTML = '<span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#6b7280;"></span> ‚ùå Ch∆∞a k·∫øt n·ªëi';
                                indicator.style.background = '#f3f4f6';
                                indicator.style.color = '#6b7280';
                                if (card) card.style.boxShadow = 'none';
                            }
                        }
                    });
                    
                    // Update device selector
                    const select = document.getElementById('llm-device-select');
                    if (select) {
                        data.devices.forEach((device, index) => {
                            const option = select.options[index];
                            if (option) {
                                option.text = `${device.connected ? 'üü¢' : '‚ö™'} ${device.name}`;
                            }
                        });
                    }
                }
            } catch (e) {
                console.error('Error refreshing LLM connection status:', e);
            }
        }
        
        async function sendLLMMessage() {
            const input = document.getElementById('llm-chat-input');
            const message = input.value.trim();
            
            if (!message) {
                addLog('‚ö†Ô∏è Vui l√≤ng nh·∫≠p tin nh·∫Øn', 'error');
                return;
            }
            
            const modelSelect = document.getElementById('llm-chat-model');
            const selectedModel = modelSelect ? modelSelect.value : 'models/gemini-3-flash-preview';
            
            // Add user message to chat
            addLLMChatMessage('user', message, null);
            
            // Clear input
            input.value = '';
            input.style.height = '50px';
            
            // Show typing indicator
            showLLMTyping();
            
            try {
                // Call Gemini AI with Knowledge Base integration
                const response = await fetch('/api/tool/ask_gemini', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        prompt: message,
                        model: selectedModel
                    })
                });
                
                const data = await response.json();
                
                // Hide typing indicator
                hideLLMTyping();
                
                if (data.success) {
                    const responseText = data.response || data.response_text || 'Kh√¥ng c√≥ n·ªôi dung tr·∫£ v·ªÅ';
                    const hasKB = data.knowledge_base_used ? 'üìö' : '';
                    const modelName = getModelDisplayName(selectedModel);
                    
                    addLLMChatMessage('assistant', responseText, `Gemini ${modelName}${hasKB}`);
                    
                    if (data.knowledge_base_used) {
                        addLog(`‚úÖ Gemini tr·∫£ l·ªùi (s·ª≠ d·ª•ng Knowledge Base)`, 'success');
                    } else {
                        addLog(`‚úÖ Gemini tr·∫£ l·ªùi th√†nh c√¥ng`, 'success');
                    }
                    
                    // üîä Text-to-Speech n·∫øu ƒë∆∞·ª£c b·∫≠t
                    const ttsToggle = document.getElementById('llm-tts-toggle');
                    const ttsEnabled = ttsToggle?.checked;
                    console.log('TTS Toggle element:', ttsToggle);
                    console.log('TTS Enabled:', ttsEnabled);
                    if (ttsEnabled && responseText) {
                        console.log('Calling speakText with:', responseText.substring(0, 100));
                        speakText(responseText);
                    }
                } else {
                    addLLMChatMessage('assistant', `‚ùå L·ªói: ${data.error}`, 'System');
                    addLog(`‚ùå L·ªói Gemini: ${data.error}`, 'error');
                }
            } catch (e) {
                hideLLMTyping();
                addLLMChatMessage('assistant', `‚ùå L·ªói k·∫øt n·ªëi: ${e.message}`, 'System');
                addLog(`‚ùå L·ªói: ${e.message}`, 'error');
            }
        }
        
        function getModelDisplayName(model) {
            if (model.includes('gemini-3')) return '3 Flash ‚ö°';
            if (model.includes('2.5-pro')) return '2.5 Pro üíé';
            if (model.includes('2.5-flash')) return '2.5 Flash ‚ö°';
            if (model.includes('2.0-flash')) return '2.0 Flash ‚ö°';
            return '';
        }
        
        function saveLLMChatModel() {
            const model = document.getElementById('llm-chat-model')?.value;
            if (model) {
                localStorage.setItem('llm_chat_model', model);
            }
        }
        
        function loadLLMChatModel() {
            const saved = localStorage.getItem('llm_chat_model') || 'models/gemini-3-flash-preview';
            const select = document.getElementById('llm-chat-model');
            if (select) {
                select.value = saved;
            }
            // Load TTS preference
            loadTTSPreference();
        }
        
        // ===== STT (Speech-to-Text) Functions - Microphone Input =====
        let llmRecognition = null;
        let llmIsRecording = false;
        let llmSilenceTimer = null;
        let llmLastSpeechTime = 0;
        const SILENCE_TIMEOUT = 2000; // 2 gi√¢y im l·∫∑ng th√¨ t·ª± g·ª≠i
        
        // üéØ Wake Word Detection
        let wakeWordRecognition = null;
        let wakeWordActive = false;
        let wakeWordWasActive = false; // üÜï Track n·∫øu wake word ƒëang b·∫≠t tr∆∞·ªõc khi chat
        let wakeWordIdleTimer = null; // üÜï Timer t·ª± t·∫Øt sau 20s kh√¥ng d√πng
        const WAKE_WORD_IDLE_TIMEOUT = 20000; // 20 gi√¢y kh√¥ng d√πng th√¨ t·ª± t·∫Øt
        const WAKE_WORDS = ['hey gemini', 'h√™ gemini', 'ok gemini', '√¥ k√™ gemini', 'xin ch√†o', 'n√†y gemini', 'gemini ∆°i', '√™ gemini'];
        const GOODBYE_WORDS = ['goodbye', 'good bye', 't·∫°m bi·ªát', 'bye bye', 'bye', 'bai bai', 'ng·ªß ƒëi', 'ƒëi ng·ªß', 't·∫Øt ƒëi', 'd·ª´ng l·∫°i'];
        
        function initWakeWordDetection() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) return null;
            
            const recognition = new SpeechRecognition();
            recognition.lang = 'vi-VN';
            recognition.continuous = true;
            recognition.interimResults = true;
            
            recognition.onresult = (event) => {
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript.toLowerCase().trim();
                    
                    // üÜï Check goodbye word - T·∫Øt wake word
                    const isGoodbye = GOODBYE_WORDS.some(word => transcript.includes(word));
                    if (isGoodbye) {
                        console.log('üëã Goodbye detected:', transcript);
                        addLog('üëã Goodbye! T·∫Øt Wake Word...', 'info');
                        showVoiceStatus('üëã T·∫°m bi·ªát! ƒê√£ t·∫Øt Wake Word.', 'success');
                        stopWakeWordDetection();
                        wakeWordWasActive = false;
                        localStorage.setItem('wake_word_enabled', 'false');
                        setTimeout(() => hideVoiceStatus(), 2000);
                        return;
                    }
                    
                    // Check wake word
                    const isWakeWord = WAKE_WORDS.some(word => transcript.includes(word));
                    if (isWakeWord && !llmIsRecording) {
                        console.log('üéØ Wake word detected:', transcript);
                        addLog('üéØ Wake word detected! B·∫Øt ƒë·∫ßu nghe...', 'success');
                        showVoiceStatus('üéØ ƒê√£ nghe th·∫•y! ƒêang chuy·ªÉn sang ch·∫ø ƒë·ªô chat...', 'success');
                        
                        // üÜï Mark wake word was active
                        wakeWordWasActive = true;
                        resetWakeWordIdleTimer();
                        
                        // Stop wake word detection, start chat recording
                        stopWakeWordDetection();
                        setTimeout(() => startLLMVoiceInput(), 300);
                        return;
                    }
                }
            };
            
            recognition.onend = () => {
                if (wakeWordActive) {
                    try { recognition.start(); } catch(e) {}
                }
            };
            
            recognition.onerror = (event) => {
                if (event.error !== 'no-speech' && event.error !== 'aborted') {
                    console.error('Wake word error:', event.error);
                }
            };
            
            return recognition;
        }
        
        // üÜï Reset idle timer - Sau 20s kh√¥ng n√≥i g√¨ s·∫Ω t·ª± t·∫Øt wake word
        function resetWakeWordIdleTimer() {
            if (wakeWordIdleTimer) {
                clearTimeout(wakeWordIdleTimer);
            }
            wakeWordIdleTimer = setTimeout(() => {
                if (wakeWordActive && !llmIsRecording) {
                    addLog('‚è∞ Wake Word t·ª± t·∫Øt sau 20s kh√¥ng ho·∫°t ƒë·ªông', 'info');
                    showVoiceStatus('‚è∞ Wake Word t·ª± t·∫Øt (h·∫øt th·ªùi gian ch·ªù)', 'warning');
                    stopWakeWordDetection();
                    wakeWordWasActive = false;
                    localStorage.setItem('wake_word_enabled', 'false');
                    setTimeout(() => hideVoiceStatus(), 2000);
                }
            }, WAKE_WORD_IDLE_TIMEOUT);
        }
        
        function startWakeWordDetection() {
            if (!wakeWordRecognition) {
                wakeWordRecognition = initWakeWordDetection();
            }
            if (!wakeWordRecognition) {
                addLog('‚ùå Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ Wake Word', 'error');
                return;
            }
            
            wakeWordActive = true;
            wakeWordWasActive = true;
            localStorage.setItem('wake_word_enabled', 'true');
            
            try {
                wakeWordRecognition.start();
                updateWakeWordButton(true);
                showVoiceStatus('üëÇ ƒêang l·∫Øng nghe... N√≥i "Hey Gemini" ho·∫∑c "Goodbye" ƒë·ªÉ t·∫Øt', 'recording');
                addLog('üëÇ Wake word ƒëang l·∫Øng nghe... N√≥i "Hey Gemini" ƒë·ªÉ chat, "Goodbye" ƒë·ªÉ t·∫Øt', 'info');
                resetWakeWordIdleTimer();
            } catch(e) {
                if (e.name === 'InvalidStateError') {
                    wakeWordRecognition.stop();
                    setTimeout(() => startWakeWordDetection(), 100);
                }
            }
        }
        
        function stopWakeWordDetection() {
            wakeWordActive = false;
            if (wakeWordIdleTimer) {
                clearTimeout(wakeWordIdleTimer);
                wakeWordIdleTimer = null;
            }
            if (wakeWordRecognition) {
                try { wakeWordRecognition.stop(); } catch(e) {}
            }
            updateWakeWordButton(false);
        }
        
        function toggleWakeWord() {
            if (wakeWordActive) {
                stopWakeWordDetection();
                wakeWordWasActive = false;
                localStorage.setItem('wake_word_enabled', 'false');
                addLog('üëÇ ƒê√£ t·∫Øt Wake Word detection', 'info');
                hideVoiceStatus();
            } else {
                startWakeWordDetection();
            }
        }
        
        // üÜï Re-enable wake word after chat response (n·∫øu tr∆∞·ªõc ƒë√≥ ƒëang b·∫≠t)
        function reEnableWakeWordAfterResponse() {
            if (wakeWordWasActive) {
                setTimeout(() => {
                    if (!llmIsRecording && wakeWordWasActive) {
                        startWakeWordDetection();
                    }
                }, 1500); // Wait 1.5s after response
            }
        }
        
        function updateWakeWordButton(active) {
            const btn = document.getElementById('llm-wakeword-btn');
            if (btn) {
                if (active) {
                    btn.style.background = 'linear-gradient(135deg,#8b5cf6,#7c3aed)';
                    btn.innerHTML = 'üëÇ';
                    btn.title = 'üëÇ Wake Word ƒëang l·∫Øng nghe... (Click ƒë·ªÉ t·∫Øt)';
                    btn.style.animation = 'pulse 2s infinite';
                } else {
                    btn.style.background = 'linear-gradient(135deg,#6b7280,#4b5563)';
                    btn.innerHTML = 'üëÇ';
                    btn.title = 'üëÇ B·∫≠t Wake Word (n√≥i "Hey Gemini" ƒë·ªÉ chat)';
                    btn.style.animation = 'none';
                }
            }
        }
        
        function initLLMSpeechRecognition() {
            // Check for browser support
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                console.warn('Browser does not support Speech Recognition');
                return null;
            }
            
            const recognition = new SpeechRecognition();
            recognition.lang = 'vi-VN'; // Vietnamese
            recognition.continuous = true; // Keep listening
            recognition.interimResults = true; // Show partial results
            recognition.maxAlternatives = 1;
            
            recognition.onstart = () => {
                llmIsRecording = true;
                llmLastSpeechTime = Date.now();
                updateMicButton(true);
                showVoiceStatus('üé§ ƒêang nghe... N√≥i xong s·∫Ω t·ª± ƒë·ªông g·ª≠i!', 'recording');
                addLog('üé§ B·∫Øt ƒë·∫ßu ghi √¢m (auto-send sau 2s im l·∫∑ng)', 'info');
                startSilenceDetection();
            };
            
            recognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Reset silence timer on speech
                llmLastSpeechTime = Date.now();
                
                const input = document.getElementById('llm-chat-input');
                if (input) {
                    if (finalTranscript) {
                        // Append final result to existing text
                        const existingText = input.value.trim();
                        input.value = existingText ? existingText + ' ' + finalTranscript : finalTranscript;
                        showVoiceStatus('‚úÖ ' + input.value.substring(0, 60) + (input.value.length > 60 ? '...' : ''), 'success');
                    } else if (interimTranscript) {
                        // Show interim result
                        showVoiceStatus('üé§ ' + interimTranscript, 'recording');
                    }
                }
            };
            
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                if (event.error === 'not-allowed') {
                    showVoiceStatus('‚ùå Vui l√≤ng cho ph√©p truy c·∫≠p microphone!', 'error');
                    addLog('‚ùå Microphone b·ªã t·ª´ ch·ªëi quy·ªÅn truy c·∫≠p', 'error');
                } else if (event.error === 'no-speech') {
                    // Auto-send if have text and no speech
                    autoSendIfHaveText();
                    return;
                } else {
                    showVoiceStatus('‚ùå L·ªói: ' + event.error, 'error');
                    addLog('‚ùå STT l·ªói: ' + event.error, 'error');
                }
                stopLLMVoiceInput();
            };
            
            recognition.onend = () => {
                if (llmIsRecording) {
                    // Check if should auto-send
                    const timeSinceLastSpeech = Date.now() - llmLastSpeechTime;
                    if (timeSinceLastSpeech >= SILENCE_TIMEOUT) {
                        autoSendIfHaveText();
                    } else {
                        // Auto-restart if still recording
                        try {
                            recognition.start();
                        } catch (e) {
                            stopLLMVoiceInput();
                        }
                    }
                } else {
                    updateMicButton(false);
                    hideVoiceStatus();
                }
            };
            
            return recognition;
        }
        
        function startSilenceDetection() {
            if (llmSilenceTimer) clearInterval(llmSilenceTimer);
            
            llmSilenceTimer = setInterval(() => {
                if (!llmIsRecording) {
                    clearInterval(llmSilenceTimer);
                    return;
                }
                
                const timeSinceLastSpeech = Date.now() - llmLastSpeechTime;
                const input = document.getElementById('llm-chat-input');
                
                if (timeSinceLastSpeech >= SILENCE_TIMEOUT && input && input.value.trim()) {
                    // Auto-send after silence
                    autoSendIfHaveText();
                } else if (timeSinceLastSpeech >= 1000 && input && input.value.trim()) {
                    // Show countdown
                    const remaining = Math.ceil((SILENCE_TIMEOUT - timeSinceLastSpeech) / 1000);
                    showVoiceStatus(`‚è≥ G·ª≠i sau ${remaining}s... (n√≥i ti·∫øp ƒë·ªÉ h·ªßy)`, 'warning');
                }
            }, 500);
        }
        
        function autoSendIfHaveText() {
            const input = document.getElementById('llm-chat-input');
            if (input && input.value.trim()) {
                showVoiceStatus('üì§ ƒêang g·ª≠i tin nh·∫Øn...', 'success');
                stopLLMVoiceInput();
                
                // Small delay then send
                setTimeout(() => {
                    sendLLMMessage();
                    // üÜï Re-enable wake word after response (d√πng function m·ªõi)
                    reEnableWakeWordAfterResponse();
                }, 300);
            } else {
                stopLLMVoiceInput();
                // üÜï N·∫øu kh√¥ng c√≥ text, v·∫´n re-enable wake word
                reEnableWakeWordAfterResponse();
            }
        }
        
        function toggleLLMVoiceInput() {
            if (llmIsRecording) {
                // If recording, stop and send if have text
                autoSendIfHaveText();
            } else {
                startLLMVoiceInput();
            }
        }
        
        function startLLMVoiceInput() {
            // Stop wake word if active
            if (wakeWordActive) {
                stopWakeWordDetection();
            }
            
            if (!llmRecognition) {
                llmRecognition = initLLMSpeechRecognition();
            }
            
            if (!llmRecognition) {
                showVoiceStatus('‚ùå Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ STT. H√£y d√πng Chrome!', 'error');
                addLog('‚ùå Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ Speech Recognition', 'error');
                return;
            }
            
            // Clear input for fresh start
            const input = document.getElementById('llm-chat-input');
            if (input) input.value = '';
            
            try {
                llmRecognition.start();
            } catch (e) {
                if (e.name === 'InvalidStateError') {
                    // Already started
                    stopLLMVoiceInput();
                    setTimeout(() => startLLMVoiceInput(), 100);
                } else {
                    console.error('Start speech recognition error:', e);
                    showVoiceStatus('‚ùå Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m', 'error');
                }
            }
        }
        
        function stopLLMVoiceInput() {
            llmIsRecording = false;
            if (llmSilenceTimer) {
                clearInterval(llmSilenceTimer);
                llmSilenceTimer = null;
            }
            if (llmRecognition) {
                try {
                    llmRecognition.stop();
                } catch (e) {}
            }
            updateMicButton(false);
            setTimeout(() => hideVoiceStatus(), 1500);
        }
        
        function updateMicButton(isRecording) {
            const btn = document.getElementById('llm-mic-btn');
            if (btn) {
                if (isRecording) {
                    btn.style.background = 'linear-gradient(135deg,#ef4444,#dc2626)';
                    btn.innerHTML = '‚èπÔ∏è';
                    btn.title = '‚èπÔ∏è Nh·∫•n ƒë·ªÉ d·ª´ng v√† g·ª≠i';
                    btn.style.animation = 'pulse 1s infinite';
                } else {
                    btn.style.background = 'linear-gradient(135deg,#10b981,#059669)';
                    btn.innerHTML = 'üé§';
                    btn.title = 'üé§ Nh·∫•n ƒë·ªÉ n√≥i (auto-send)';
                    btn.style.animation = 'none';
                }
            }
        }
        
        function showVoiceStatus(text, type) {
            const statusDiv = document.getElementById('llm-voice-status');
            const statusText = document.getElementById('llm-voice-status-text');
            if (statusDiv && statusText) {
                statusDiv.style.display = 'block';
                statusText.textContent = text;
                
                if (type === 'recording') {
                    statusDiv.style.background = 'linear-gradient(135deg,#fef3c7,#fde68a)';
                } else if (type === 'success') {
                    statusDiv.style.background = 'linear-gradient(135deg,#d1fae5,#a7f3d0)';
                } else if (type === 'error') {
                    statusDiv.style.background = 'linear-gradient(135deg,#fee2e2,#fecaca)';
                } else if (type === 'warning') {
                    statusDiv.style.background = 'linear-gradient(135deg,#ffedd5,#fed7aa)';
                }
            }
        }
        
        function hideVoiceStatus() {
            const statusDiv = document.getElementById('llm-voice-status');
            if (statusDiv) {
                statusDiv.style.display = 'none';
            }
        }
        
        // ===== TTS (Text-to-Speech) Functions =====
        function saveTTSPreference() {
            const enabled = document.getElementById('llm-tts-toggle')?.checked || false;
            localStorage.setItem('llm_tts_enabled', enabled);
            if (enabled) {
                addLog('üîä ƒê√£ b·∫≠t ƒë·ªçc to c√¢u tr·∫£ l·ªùi', 'info');
            } else {
                addLog('üîá ƒê√£ t·∫Øt ƒë·ªçc to c√¢u tr·∫£ l·ªùi', 'info');
            }
        }
        
        function loadTTSPreference() {
            const saved = localStorage.getItem('llm_tts_enabled') === 'true';
            const toggle = document.getElementById('llm-tts-toggle');
            if (toggle) {
                toggle.checked = saved;
            }
        }
        
        let currentTTSAudio = null; // Track current TTS audio
        
        async function speakText(text) {
            try {
                // Hi·ªÉn th·ªã indicator ƒëang ƒë·ªçc
                showSpeakingIndicator();
                
                // G·ªçi API TTS backend
                const response = await fetch('/api/tts', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: text })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    addLog(`üîä ƒêang ƒë·ªçc: ${text.substring(0, 50)}...`, 'info');
                } else {
                    addLog(`‚ùå TTS l·ªói: ${data.error}`, 'error');
                }
                
                hideSpeakingIndicator();
            } catch (e) {
                console.error('TTS error:', e);
                addLog(`‚ùå TTS l·ªói: ${e.message}`, 'error');
                hideSpeakingIndicator();
            }
        }
        
        function stopSpeaking() {
            // G·ªçi API d·ª´ng TTS
            fetch('/api/tts/stop', { method: 'POST' })
                .then(() => {
                    addLog('üîá ƒê√£ d·ª´ng ƒë·ªçc', 'info');
                    hideSpeakingIndicator();
                })
                .catch(e => console.error('Stop TTS error:', e));
        }
        
        function showSpeakingIndicator() {
            // Th√™m indicator v√†o status bar
            const statusBar = document.getElementById('llm-ai-status');
            if (statusBar && !document.getElementById('speaking-indicator')) {
                const indicator = document.createElement('span');
                indicator.id = 'speaking-indicator';
                indicator.innerHTML = '<span style="animation:pulse 1s infinite;">üîä ƒêang ƒë·ªçc...</span> <button onclick="stopSpeaking()" style="background:rgba(255,255,255,0.3);border:none;padding:2px 8px;border-radius:4px;cursor:pointer;font-size:0.8em;">‚èπÔ∏è D·ª´ng</button>';
                indicator.style.cssText = 'font-size:0.85em; background:rgba(255,255,255,0.2); padding:4px 10px; border-radius:20px; display:flex; align-items:center; gap:8px;';
                statusBar.appendChild(indicator);
            }
        }
        
        function hideSpeakingIndicator() {
            const indicator = document.getElementById('speaking-indicator');
            if (indicator) indicator.remove();
        }
        
        function addLLMChatMessage(role, content, deviceName) {
            const container = document.getElementById('llm-chat-messages');
            
            // Remove welcome message if exists
            const welcome = container.querySelector('div[style*="text-align:center"]');
            if (welcome) welcome.remove();
            
            const msgDiv = document.createElement('div');
            msgDiv.className = `llm-message ${role}`;
            
            const time = new Date().toLocaleTimeString('vi-VN', { hour: '2-digit', minute: '2-digit' });
            
            let deviceTag = '';
            if (deviceName && role === 'assistant') {
                deviceTag = `<span class="device-tag">${deviceName}</span>`;
            }
            
            msgDiv.innerHTML = `
                <div class="content">${content}${deviceTag}</div>
                <span class="time">${time}</span>
            `;
            
            container.appendChild(msgDiv);
            container.scrollTop = container.scrollHeight;
            
            // Store message
            llmChatMessages.push({ role, content, deviceName, time: new Date().toISOString() });
        }
        
        function showLLMTyping() {
            const container = document.getElementById('llm-chat-messages');
            const typingDiv = document.createElement('div');
            typingDiv.id = 'llm-typing-indicator';
            typingDiv.className = 'llm-message assistant';
            typingDiv.innerHTML = `
                <div class="llm-typing">
                    <span></span><span></span><span></span>
                </div>
            `;
            container.appendChild(typingDiv);
            container.scrollTop = container.scrollHeight;
        }
        
        function hideLLMTyping() {
            const typing = document.getElementById('llm-typing-indicator');
            if (typing) typing.remove();
        }
        
        function handleLLMChatKeydown(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault();
                sendLLMMessage();
            }
        }
        
        function autoResizeLLMInput(textarea) {
            textarea.style.height = '50px';
            textarea.style.height = Math.min(textarea.scrollHeight, 150) + 'px';
        }
        
        function sendQuickMessage(message) {
            const input = document.getElementById('llm-chat-input');
            input.value = message;
            sendLLMMessage();
        }
        
        function clearLLMChat() {
            const container = document.getElementById('llm-chat-messages');
            container.innerHTML = `
                <div style="text-align:center; color:#666; padding:40px 20px;">
                    <div style="font-size:4em; margin-bottom:15px;">ü§ñ</div>
                    <h3 style="color:#667eea; margin-bottom:10px;">Ch√†o m·ª´ng ƒë·∫øn Chat v·ªõi Gemini AI!</h3>
                    <p style="font-size:0.95em; max-width:400px; margin:0 auto;">
                        Chat tr·ª±c ti·∫øp v·ªõi Gemini AI.<br>
                        AI s·∫Ω t·ª± ƒë·ªông t√¨m ki·∫øm trong Knowledge Base c·ªßa b·∫°n ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c h∆°n.
                    </p>
                </div>
            `;
            llmChatMessages = [];
            addLog('üóëÔ∏è ƒê√£ x√≥a l·ªãch s·ª≠ chat', 'info');
        }
        
        // Load music folder settings when opening the section
        document.addEventListener('DOMContentLoaded', () => {
            loadMusicFolderSettings();
            // üî• FIX: Auto-load API keys when page loads
            loadCurrentEndpoint();
            // üî• FIX: Auto-refresh connection status
            refreshLLMConnectionStatus();
            // ‚è∞ Refresh connection status every 3 seconds
            setInterval(refreshLLMConnectionStatus, 3000);
        });
        
    // Initialize playlists on page load
    initPlaylists();
    </script>
    
    <!-- MINIZ FOOTER - Compact Corner -->
    <div class="footer-miniz">
        <div class="footer-logo-compact">
            <img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'%3E%3Ccircle cx='50' cy='50' r='48' fill='%23667eea'/%3E%3Cpath d='M30 40 L50 25 L70 40 M50 25 L50 75 M35 55 L50 50 L65 55 M35 70 L50 65 L65 70' stroke='white' stroke-width='3' fill='none'/%3E%3Ctext x='50' y='88' text-anchor='middle' fill='white' font-size='14' font-weight='bold' font-family='Arial'%3EminiZ%3C/text%3E%3C/svg%3E" alt="miniZ Logo">
            <span class="footer-brand-compact">miniZ</span>
        </div>
        <div class="footer-separator"></div>
        <a href="https://youtube.com/@minizjp?si=LRg5piGHmxYtsFJU" target="_blank" class="footer-youtube-compact" title="K√™nh YouTube miniZ">
            <svg viewBox="0 0 24 24"><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg>
            YouTube
        </a>
    </div>
</body>
</html>
    """
    return html

# ============================================================
# üì® API ENDPOINT: SEND MESSAGE TO LLM
# ============================================================

class SendMessageRequest(BaseModel):
    message: str
    device_index: int = None
    wait_response: bool = True
    timeout: int = 30

class BroadcastMessageRequest(BaseModel):
    message: str
    wait_response: bool = False

@app.post("/api/send_message_to_llm")
async def api_send_message_to_llm(request: SendMessageRequest):
    """
    API endpoint ƒë·ªÉ g·ª≠i tin nh·∫Øn cho LLM qua WebSocket.
    LLM s·∫Ω ƒë·ªçc ƒë∆∞·ª£c tin nh·∫Øn v√† t·ª± tr·∫£ l·ªùi.
    """
    result = await send_message_to_llm(
        message=request.message,
        device_index=request.device_index,
        wait_response=request.wait_response,
        timeout=request.timeout
    )
    return result

@app.post("/api/broadcast_to_llm")
async def api_broadcast_to_llm(request: BroadcastMessageRequest):
    """
    API endpoint ƒë·ªÉ broadcast tin nh·∫Øn ƒë·∫øn t·∫•t c·∫£ LLM ƒëang k·∫øt n·ªëi.
    """
    result = await broadcast_to_all_llm(
        message=request.message,
        wait_response=request.wait_response
    )
    return result

@app.get("/api/llm_connection_status")
async def api_llm_connection_status():
    """
    Ki·ªÉm tra tr·∫°ng th√°i k·∫øt n·ªëi c·ªßa c√°c thi·∫øt b·ªã LLM.
    """
    status = {
        "success": True,
        "devices": []
    }
    
    for i in range(3):
        device_status = {
            "index": i,
            "name": endpoints_config[i].get("name", f"Thi·∫øt b·ªã {i + 1}"),
            "connected": xiaozhi_connected.get(i, False),
            "enabled": endpoints_config[i].get("enabled", False),
            "has_token": bool(endpoints_config[i].get("token", ""))
        }
        status["devices"].append(device_status)
    
    status["active_index"] = active_endpoint_index
    status["total_connected"] = sum(1 for v in xiaozhi_connected.values() if v)
    
    return status

@app.get("/api/connection_errors")
async def api_connection_errors():
    """
    L·∫•y danh s√°ch c√°c l·ªói k·∫øt n·ªëi g·∫ßn ƒë√¢y v√† ch·∫©n ƒëo√°n.
    H·ªØu √≠ch ƒë·ªÉ debug khi kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c endpoint.
    """
    return {
        "success": True,
        "total_errors": len(connection_error_log),
        "errors": connection_error_log[-10:],  # 10 l·ªói g·∫ßn nh·∫•t
        "message": "Xem chi ti·∫øt l·ªói k·∫øt n·ªëi v√† gi·∫£i ph√°p g·ª£i √Ω"
    }

@app.get("/api/diagnose_connection/{device_index}")
async def api_diagnose_connection(device_index: int):
    """
    Ch·∫©n ƒëo√°n k·∫øt n·ªëi cho m·ªôt thi·∫øt b·ªã c·ª• th·ªÉ.
    """
    if device_index < 0 or device_index >= 3:
        return {"success": False, "error": "device_index ph·∫£i t·ª´ 0-2"}
    
    ep = endpoints_config[device_index]
    
    # T·∫°o m·ªôt fake error ƒë·ªÉ trigger diagnosis
    class DiagnosticCheck(Exception):
        pass
    
    diagnosis = await diagnose_connection_error(
        ep.get('name', f'Thi·∫øt b·ªã {device_index + 1}'),
        ep.get('token', ''),
        DiagnosticCheck("Manual diagnostic check")
    )
    
    # Th√™m th√¥ng tin b·ªï sung
    diagnosis["device_index"] = device_index
    diagnosis["currently_connected"] = xiaozhi_connected.get(device_index, False)
    diagnosis["enabled"] = ep.get("enabled", False)
    diagnosis["report"] = format_diagnosis_report(diagnosis)
    
    return {
        "success": True,
        "diagnosis": diagnosis
    }

# API Endpoints
@app.post("/api/volume")
async def api_volume(request: VolumeRequest):
    result = await set_volume(request.level)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/screenshot")
async def api_screenshot():
    result = await take_screenshot()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/notification")
async def api_notification(request: NotificationRequest):
    result = await show_notification(request.title, request.message)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.get("/api/resources")
async def api_resources():
    result = await get_system_resources()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.get("/api/system_info")
async def api_system_info():
    """L·∫•y th√¥ng tin chi ti·∫øt h·ªá th·ªëng"""
    result = await get_system_info(category="all")
    return result

@app.get("/api/realtime_stats")
async def api_realtime_stats():
    """L·∫•y th·ªëng k√™ realtime CPU, RAM, GPU cho UI"""
    try:
        import psutil
        import subprocess
        
        # CPU
        cpu_percent = psutil.cpu_percent(interval=0.1)
        cpu_freq = psutil.cpu_freq()
        cpu_cores = psutil.cpu_count(logical=False)
        
        # RAM
        mem = psutil.virtual_memory()
        ram_percent = mem.percent
        ram_used = round(mem.used / (1024**3), 1)
        ram_total = round(mem.total / (1024**3), 1)
        
        # GPU - Th·ª≠ d√πng nvidia-smi cho NVIDIA GPU
        gpu_percent = 0
        gpu_name = "Unknown"
        try:
            result = subprocess.run(
                ['nvidia-smi', '--query-gpu=utilization.gpu,name', '--format=csv,noheader,nounits'],
                capture_output=True, text=True, timeout=2
            )
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                if lines:
                    parts = lines[0].split(',')
                    if len(parts) >= 2:
                        gpu_percent = int(parts[0].strip())
                        gpu_name = parts[1].strip()
        except:
            # Fallback: Th·ª≠ AMD ho·∫∑c generic
            try:
                result = subprocess.run(['wmic', 'path', 'win32_videocontroller', 'get', 'name'], 
                                      capture_output=True, text=True, timeout=2)
                lines = [l.strip() for l in result.stdout.strip().split('\n') if l.strip() and 'Name' not in l]
                if lines:
                    gpu_name = lines[0][:40]  # Gi·ªõi h·∫°n 40 k√Ω t·ª±
            except:
                pass
        
        return {
            "success": True,
            "cpu": {
                "percent": cpu_percent,
                "freq": round(cpu_freq.current, 0) if cpu_freq else 0,
                "cores": cpu_cores or 0
            },
            "ram": {
                "percent": ram_percent,
                "used": ram_used,
                "total": ram_total
            },
            "gpu": {
                "percent": gpu_percent,
                "name": gpu_name
            }
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/pc_config")
async def api_pc_config():
    """L·∫•y c·∫•u h√¨nh m√°y t√≠nh chi ti·∫øt: CPU, RAM, GPU, Disk, Motherboard"""
    try:
        import platform
        import psutil
        import socket
        import subprocess
        import re
        
        result = {
            "success": True,
            "timestamp": __import__('datetime').datetime.now().strftime("%d/%m/%Y %H:%M:%S")
        }
        
        # OS Info
        result["os"] = {
            "name": f"{platform.system()} {platform.release()}",
            "version": platform.version(),
            "build": platform.win32_ver()[1] if platform.system() == "Windows" else "N/A",
            "architecture": platform.architecture()[0],
            "hostname": socket.gethostname()
        }
        
        # CPU Info
        cpu_info = {
            "name": platform.processor(),
            "cores": psutil.cpu_count(logical=False),
            "threads": psutil.cpu_count(logical=True),
            "usage": psutil.cpu_percent(interval=0.5)
        }
        
        # CPU frequency
        freq = psutil.cpu_freq()
        if freq:
            cpu_info["freq_current"] = freq.current
            cpu_info["freq_max"] = freq.max
        
        # Get detailed CPU name from Windows registry
        try:
            if platform.system() == "Windows":
                import winreg
                key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, r"HARDWARE\DESCRIPTION\System\CentralProcessor\0")
                cpu_name = winreg.QueryValueEx(key, "ProcessorNameString")[0].strip()
                cpu_info["name"] = cpu_name
                winreg.CloseKey(key)
                
                # Detect generation
                cpu_lower = cpu_name.lower()
                if "intel" in cpu_lower:
                    for gen in ["14th", "13th", "12th", "11th", "10th", "9th", "8th", "7th"]:
                        if gen in cpu_lower:
                            cpu_info["generation"] = f"Intel {gen} Gen"
                            break
                elif "amd" in cpu_lower:
                    if "7" in cpu_lower and "000" in cpu_lower:
                        cpu_info["generation"] = "AMD Ryzen 7000 (Zen 4)"
                    elif "5" in cpu_lower and "000" in cpu_lower:
                        cpu_info["generation"] = "AMD Ryzen 5000 (Zen 3)"
        except:
            pass
        
        result["cpu"] = cpu_info
        
        # RAM Info
        mem = psutil.virtual_memory()
        result["ram"] = {
            "total_gb": mem.total / (1024**3),
            "used_gb": mem.used / (1024**3),
            "available_gb": mem.available / (1024**3),
            "percent": mem.percent,
            "type": "DDR4/DDR5"
        }
        
        # GPU Info
        gpus = []
        try:
            import GPUtil
            for gpu in GPUtil.getGPUs():
                gpu_data = {
                    "name": gpu.name,
                    "memory_total": int(gpu.memoryTotal),
                    "memory_used": int(gpu.memoryUsed),
                    "load": round(gpu.load * 100, 1),
                    "temperature": gpu.temperature
                }
                # Detect GPU generation
                name_lower = gpu.name.lower()
                if "rtx 40" in name_lower or "4090" in name_lower or "4080" in name_lower or "4070" in name_lower:
                    gpu_data["generation"] = "NVIDIA RTX 40 Series (Ada Lovelace)"
                elif "rtx 30" in name_lower or "3090" in name_lower or "3080" in name_lower or "3070" in name_lower or "3060" in name_lower:
                    gpu_data["generation"] = "NVIDIA RTX 30 Series (Ampere)"
                elif "rtx 20" in name_lower or "2080" in name_lower or "2070" in name_lower or "2060" in name_lower:
                    gpu_data["generation"] = "NVIDIA RTX 20 Series (Turing)"
                elif "gtx 16" in name_lower or "1660" in name_lower or "1650" in name_lower:
                    gpu_data["generation"] = "NVIDIA GTX 16 Series (Turing)"
                elif "gtx 10" in name_lower or "1080" in name_lower or "1070" in name_lower or "1060" in name_lower:
                    gpu_data["generation"] = "NVIDIA GTX 10 Series (Pascal)"
                elif "radeon" in name_lower:
                    if "rx 7" in name_lower:
                        gpu_data["generation"] = "AMD Radeon RX 7000 (RDNA 3)"
                    elif "rx 6" in name_lower:
                        gpu_data["generation"] = "AMD Radeon RX 6000 (RDNA 2)"
                gpus.append(gpu_data)
        except:
            pass
        
        # Fallback: WMI for GPU
        if not gpus:
            try:
                wmi_result = subprocess.check_output(
                    'wmic path win32_VideoController get name,AdapterRAM,DriverVersion /format:csv',
                    shell=True, text=True, encoding='utf-8', errors='ignore'
                )
                for line in wmi_result.strip().split('\n')[1:]:
                    parts = line.strip().split(',')
                    if len(parts) >= 4 and parts[2]:
                        vram_bytes = int(parts[1]) if parts[1] else 0
                        gpus.append({
                            "name": parts[2],
                            "memory_total": vram_bytes // (1024*1024) if vram_bytes > 0 else "N/A",
                            "driver": parts[3] if parts[3] else "N/A"
                        })
            except:
                pass
        
        result["gpu"] = gpus
        
        # Disk Info
        disks = []
        for part in psutil.disk_partitions():
            try:
                usage = psutil.disk_usage(part.mountpoint)
                disks.append({
                    "device": part.device,
                    "mountpoint": part.mountpoint,
                    "type": part.fstype,
                    "total_gb": usage.total / (1024**3),
                    "used_gb": usage.used / (1024**3),
                    "free_gb": usage.free / (1024**3),
                    "percent": usage.percent
                })
            except:
                pass
        result["disks"] = disks
        
        # Motherboard Info
        try:
            mb_result = subprocess.check_output(
                'wmic baseboard get manufacturer,product,serialnumber /format:csv',
                shell=True, text=True, encoding='utf-8', errors='ignore'
            )
            for line in mb_result.strip().split('\n')[1:]:
                parts = line.strip().split(',')
                if len(parts) >= 4:
                    result["motherboard"] = {
                        "manufacturer": parts[1] if parts[1] else "Unknown",
                        "product": parts[2] if parts[2] else "Unknown",
                        "serial": parts[3] if parts[3] else "N/A"
                    }
                    break
        except:
            result["motherboard"] = {"manufacturer": "Unknown", "product": "Unknown"}
        
        # Network Adapters
        networks = []
        for iface, addrs in psutil.net_if_addrs().items():
            for addr in addrs:
                if addr.family == socket.AF_INET:
                    mac = None
                    for a in addrs:
                        if a.family == psutil.AF_LINK:
                            mac = a.address
                            break
                    networks.append({
                        "name": iface,
                        "ip": addr.address,
                        "mac": mac
                    })
        result["network"] = networks
        
        return result
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

@app.get("/api/quotas")
async def api_quotas():
    """L·∫•y th√¥ng tin quota c·ªßa Gemini v√† Serper APIs"""
    result = await get_api_quotas()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.get("/api/vlc_status")
async def api_vlc_status():
    """VLC status - MCP-style response v·ªõi session tracking"""
    try:
        # Cache status ƒë·ªÉ tr√°nh query li√™n t·ª•c (200ms)
        import time
        now = time.time()
        if not hasattr(vlc_player, '_status_cache') or (now - vlc_player._status_cache_time) > 0.2:
            status = vlc_player.get_full_status()
            # MCP-style: th√™m metadata
            status['timestamp'] = int(now * 1000)  # milliseconds
            status['session_id'] = getattr(vlc_player, '_session_id', 'default')
            vlc_player._status_cache = status
            vlc_player._status_cache_time = now
        return vlc_player._status_cache
    except Exception as e:
        return {
            "success": False, 
            "error": str(e), 
            "state": "error",
            "timestamp": int(time.time() * 1000)
        }

@app.post("/api/vlc_seek")
async def api_vlc_seek(data: dict):
    """Seek VLC player - MCP-style v·ªõi validation v√† state tracking"""
    try:
        position = float(data.get("position", 0))
        
        # Validate input (xiaozhi pattern: validate before execution)
        if not 0.0 <= position <= 1.0:
            return {
                "success": False,
                "error": "Position must be between 0.0 and 1.0",
                "error_type": "validation_error",
                "provided_value": position
            }
        
        # Get current state
        old_position = vlc_player.get_position()
        current_time = vlc_player.get_time()
        
        # Execute seek
        vlc_player.set_position(position)
        
        # Calculate time delta
        new_time = vlc_player.get_time()
        
        return {
            "success": True,
            "action": "seek",
            "position": position,
            "previous_position": old_position,
            "time_delta_ms": new_time - current_time,
            "timestamp": int(time.time() * 1000),
            "message": f"Sought to {int(position * 100)}%"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "error_type": "exception",
            "timestamp": int(time.time() * 1000)
        }

@app.post("/api/vlc_volume")
async def api_vlc_volume(data: dict):
    """Set VLC player volume (0-100)"""
    try:
        level = int(data.get("level", 80))
        vlc_player.set_volume(level)
        return {"success": True, "volume": level}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_shuffle")
async def api_vlc_shuffle(data: dict):
    """Toggle or set shuffle mode"""
    try:
        enabled = data.get("enabled")
        if enabled is None:
            # Toggle
            enabled = not vlc_player.get_shuffle()
        vlc_player.set_shuffle(enabled)
        return {"success": True, "shuffle": enabled}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_repeat")
async def api_vlc_repeat(data: dict):
    """Set repeat mode: 0=off, 1=all, 2=one"""
    try:
        mode = data.get("mode")
        if mode is None:
            # Cycle through modes
            current = vlc_player.get_repeat_mode()
            mode = (current + 1) % 3
        vlc_player.set_repeat_mode(mode)
        return {"success": True, "repeat_mode": mode}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_play_file")
async def api_vlc_play_file(data: dict):
    """Ph√°t file nh·∫°c tr·ª±c ti·∫øp qua VLC - cho Web UI double-click"""
    try:
        filename = data.get("filename", "")
        if not filename:
            return {"success": False, "error": "Thi·∫øu filename"}
        
        print(f"üéµ [API] vlc_play_file: {filename}")
        
        # G·ªçi h√†m play_music
        result = await play_music(filename=filename, create_playlist=True)
        print(f"üéµ [API] play_music result: {result}")
        return result
    except Exception as e:
        print(f"‚ùå [API] vlc_play_file error: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_play_pause")
async def api_vlc_play_pause():
    """Toggle VLC play/pause - MCP-style v·ªõi state tracking"""
    try:
        if vlc_player and vlc_player._player:
            # Track state before action (xiaozhi pattern)
            was_playing = vlc_player.is_playing()
            
            # Execute command
            vlc_player.pause()
            
            # Get new state
            is_playing = vlc_player.is_playing()
            
            return {
                "success": True,
                "is_playing": is_playing,
                "previous_state": "playing" if was_playing else "paused",
                "current_state": "playing" if is_playing else "paused",
                "action": "pause" if was_playing else "play",
                "message": "‚ñ∂Ô∏è ƒêang ph√°t" if is_playing else "‚è∏Ô∏è ƒê√£ t·∫°m d·ª´ng",
                "timestamp": int(time.time() * 1000)
            }
        return {
            "success": False, 
            "error": "VLC ch∆∞a kh·ªüi t·∫°o ho·∫∑c ch∆∞a ph√°t nh·∫°c",
            "state": "not_initialized"
        }
    except Exception as e:
        return {
            "success": False, 
            "error": str(e),
            "error_type": "exception",
            "timestamp": int(time.time() * 1000)
        }

@app.post("/api/vlc_stop")
async def api_vlc_stop():
    """Stop VLC player - MCP-style v·ªõi state cleanup"""
    try:
        if vlc_player and vlc_player._player:
            # Get current state before stopping
            was_playing = vlc_player.is_playing()
            current_media = vlc_player._player.get_media()
            stopped_track = current_media.get_meta(0) if current_media else "Unknown"
            
            # Execute stop
            vlc_player.stop()
            
            return {
                "success": True,
                "action": "stop",
                "message": "‚èπÔ∏è ƒê√£ d·ª´ng nh·∫°c",
                "previous_state": "playing" if was_playing else "paused",
                "stopped_track": stopped_track,
                "timestamp": int(time.time() * 1000)
            }
        return {
            "success": False,
            "error": "VLC ch∆∞a kh·ªüi t·∫°o ho·∫∑c ch∆∞a ph√°t nh·∫°c",
            "state": "not_initialized"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_next")
async def api_vlc_next():
    """Next track - MCP-style async v·ªõi immediate response"""
    try:
        if vlc_player and vlc_player._list_player:
            # Get current track info before switching (xiaozhi pattern)
            current_media = vlc_player._player.get_media()
            current_title = current_media.get_meta(0) if current_media else "Unknown"
            current_index = vlc_player._list_player.get_media_player().get_position()
            
            # Execute command
            vlc_player._list_player.next()
            vlc_player._list_player.play()  # ƒê·∫£m b·∫£o ph√°t
            
            # MCP-style: tr·∫£ v·ªÅ immediate response + track info
            return {
                "success": True,
                "action": "next",
                "message": "‚è≠Ô∏è Chuy·ªÉn b√†i ti·∫øp theo",
                "is_playing": True,
                "previous_track": {
                    "title": current_title,
                    "position": current_index
                },
                "timestamp": int(time.time() * 1000),
                "note": "Track info s·∫Ω update sau 500ms qua /api/vlc_status"
            }
        return {
            "success": False,
            "error": "VLC ch∆∞a kh·ªüi t·∫°o",
            "state": "not_initialized"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_previous")
async def api_vlc_previous():
    """Previous track - T·ªêI ∆ØU: Kh√¥ng block UI v·ªõi sleep"""
    try:
        if vlc_player and vlc_player._list_player:
            vlc_player._list_player.previous()
            vlc_player._list_player.play()  # ƒê·∫£m b·∫£o ph√°t
            # Tr·∫£ v·ªÅ ngay - Web UI s·∫Ω poll status ƒë·ªÉ update
            return {
                "success": True, 
                "message": "‚èÆÔ∏è Chuy·ªÉn b√†i tr∆∞·ªõc",
                "is_playing": True
            }
        return {"success": False, "error": "VLC ch∆∞a kh·ªüi t·∫°o"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/time")
async def api_time():
    result = await get_current_time()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return {"data": result}

@app.post("/api/calculator")
async def api_calculator(request: CalculatorRequest):
    result = await calculator(request.expression)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result


# ===== GENERIC TOOL CALLER =====

@app.post("/api/call_tool")
async def call_any_tool(data: dict):
    """Generic endpoint to call ANY tool from TOOLS registry"""
    tool_name = data.get("tool", data.get("name", ""))
    args = data.get("args", data.get("arguments", {}))
    
    if not tool_name:
        raise HTTPException(400, "Tool name is required")
    
    if tool_name not in TOOLS:
        raise HTTPException(404, f"Tool '{tool_name}' not found")
    
    try:
        handler = TOOLS[tool_name]["handler"]
        result = await handler(**args)
        return result
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# üéØ VLC MCP ENDPOINTS - Hybrid System
# ============================================================

@app.post("/mcp/vlc/call")
async def mcp_vlc_call(request: dict):
    """
    MCP endpoint for VLC control (JSON-RPC 2.0)
    
    Xiaozhi-esp32 style protocol:
    {
      "jsonrpc": "2.0",
      "method": "tools/call",
      "params": {
        "name": "vlc.play",
        "arguments": {"file": "song.mp3"}
      },
      "id": 1
    }
    """
    if not VLC_MCP_AVAILABLE:
        return {
            "jsonrpc": "2.0",
            "error": {
                "code": -32603,
                "message": "VLC MCP server not available"
            },
            "id": request.get("id")
        }
    
    try:
        response = await vlc_mcp_server.handle_mcp_request(request)
        return response
    except Exception as e:
        return {
            "jsonrpc": "2.0",
            "error": {
                "code": -32603,
                "message": f"Internal error: {str(e)}"
            },
            "id": request.get("id")
        }

@app.get("/mcp/vlc/tools")
async def mcp_vlc_list_tools():
    """List all available VLC MCP tools"""
    if not VLC_MCP_AVAILABLE:
        return {
            "success": False,
            "error": "VLC MCP server not available"
        }
    
    return {
        "success": True,
        "tools": vlc_mcp_server.list_tools()
    }

@app.get("/mcp/vlc/status")
async def mcp_vlc_status():
    """Get VLC MCP server status"""
    return {
        "success": True,
        "mcp_available": VLC_MCP_AVAILABLE,
        "vlc_available": VLC_AVAILABLE,
        "total_tools": len(vlc_mcp_server.tools) if VLC_MCP_AVAILABLE else 0,
        "protocol": "JSON-RPC 2.0",
        "architecture": "xiaozhi-esp32"
    }

# ============================================================
# üß† INTENT DETECTION API ENDPOINTS
# ============================================================

@app.post("/api/detect_intent")
async def api_detect_intent(data: dict):
    """
    Ph√¢n t√≠ch intent t·ª´ text input
    Tr·∫£ v·ªÅ suggested tool v√† confidence
    """
    text = data.get("text", data.get("query", ""))
    use_llm = data.get("use_llm", False)
    
    if not text:
        raise HTTPException(400, "Text is required")
    
    try:
        if use_llm:
            result = await intent_detector.detect_with_llm(text, GEMINI_API_KEY)
        else:
            result = intent_detector.detect_intent(text)
        
        return {
            "success": True,
            "text": text,
            **result
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/auto_execute")
async def api_auto_execute(data: dict):
    """
    ü§ñ AUTO TOOL EXECUTOR v2.0 - N√ÇNG C·∫§P
    
    Ph√¢n t√≠ch TH√îNG MINH response t·ª´ LLM v√† t·ª± ƒë·ªông g·ªçi tool
    
    IMPROVEMENTS:
    - ‚úÖ ∆Øu ti√™n ph√¢n t√≠ch USER QUERY tr∆∞·ªõc (ch√≠nh x√°c h∆°n)
    - ‚úÖ Ph√°t hi·ªán c√¢u PH·ª¶ ƒê·ªäNH (kh√¥ng, ch∆∞a, ƒë·ª´ng)
    - ‚úÖ Ph√°t hi·ªán c√¢u H·ªéI (c√≥ ph·∫£i, c√≥ n√™n)
    - ‚úÖ Context-aware patterns (xem tr∆∞·ªõc/sau)
    - ‚úÖ Multi-language support (Vi + En)
    - ‚úÖ Better logging v√† debug info
    
    Args:
        llm_response: Text response t·ª´ LLM
        original_query: C√¢u h·ªèi g·ªëc c·ªßa user (QUAN TR·ªåNG - ∆∞u ti√™n cao)
        auto_execute: True ƒë·ªÉ t·ª± ƒë·ªông g·ªçi tool (default: True)
    
    Returns:
        {
            "success": bool,
            "intent_detected": str,
            "tool_suggested": str,
            "confidence": float,
            "tool_executed": bool,
            "tool_result": dict,
            "analysis": {
                "source": "query|response",
                "matched_pattern": str,
                "is_question": bool,
                "is_negative": bool
            }
        }
    """
    try:
        llm_response = data.get("llm_response", data.get("response", "")).strip()
        original_query = data.get("original_query", data.get("query", "")).strip()
        auto_execute = data.get("auto_execute", True)
        
        print(f"\n{'='*70}")
        print(f"ü§ñ [Auto Execute v2.0] NEW REQUEST")
        print(f"{'='*70}")
        print(f"üìù User Query: '{original_query}'")
        print(f"üí¨ LLM Response: '{llm_response}'")
        print(f"‚öôÔ∏è  Auto Execute: {auto_execute}")
        print(f"{'-'*70}")
        
        # ===== B∆Ø·ªöC 1: PH√ÇN T√çCH NG·ªÆ C·∫¢NH =====
        import re
        
        # Ph√°t hi·ªán c√¢u ph·ªß ƒë·ªãnh
        negative_patterns = [
            r'\b(kh√¥ng|ch∆∞a|ƒë·ª´ng|ch·ªõ|th√¥i|ng∆∞ng)\b',
            r'\b(no|not|don\'t|stop|cancel)\b'
        ]
        
        # Ph√°t hi·ªán c√¢u h·ªèi
        question_patterns = [
            r'\b(c√≥ ph·∫£i|c√≥ n√™n|c√≥ th·ªÉ|ƒë∆∞·ª£c kh√¥ng|nh∆∞ th·∫ø n√†o)\b',
            r'\?$',  # K·∫øt th√∫c b·∫±ng d·∫•u ?
            r'\b(is|are|can|could|should|would|do|does)\b.+\?'
        ]
        
        # ===== B∆Ø·ªöC 2: PATTERNS N√ÇNG CAP - CONTEXT AWARE =====
        enhanced_vlc_patterns = {
            "music_next": {
                "patterns": [
                    r'\b(b√†i ti·∫øp theo|b√†i ti·∫øp|next song|next track)\b',
                    r'\b(chuy·ªÉn b√†i|skip|b√†i sau|b√†i k·∫ø|sang b√†i)\b',
                    r'\b(ti·∫øp theo|next|forward)\b',
                    r'\b(ph√°t b√†i ti·∫øp|play next)\b'
                ],
                "keywords": ["next", "ti·∫øp", "skip", "chuy·ªÉn", "sau", "forward"]
            },
            "music_previous": {
                "patterns": [
                    r'\b(b√†i tr∆∞·ªõc|previous song|previous track)\b',
                    r'\b(quay l·∫°i|back|l√πi l·∫°i|tr·ªü l·∫°i)\b',
                    r'\b(b√†i tr∆∞·ªõc ƒë√≥|b√†i c≈©)\b',
                    r'\b(ph√°t b√†i tr∆∞·ªõc|play previous)\b'
                ],
                "keywords": ["previous", "tr∆∞·ªõc", "back", "quay", "l√πi"]
            },
            "pause_music": {
                "patterns": [
                    r'\b(t·∫°m d·ª´ng|pause)\b',
                    r'\b(d·ª´ng l·∫°i|stop playing|ng·ª´ng)\b',
                    r'\b(t·∫°m ng∆∞ng)\b'
                ],
                "keywords": ["pause", "t·∫°m", "d·ª´ng l·∫°i"]
            },
            "resume_music": {
                "patterns": [
                    r'\b(ti·∫øp t·ª•c|resume|continue)\b',
                    r'\b(ph√°t ti·∫øp|play again|ch·∫°y ti·∫øp)\b',
                    r'\b(m·ªü l·∫°i|b·∫≠t l·∫°i)\b'
                ],
                "keywords": ["resume", "ti·∫øp t·ª•c", "continue", "ph√°t ti·∫øp"]
            },
            "stop_music": {
                "patterns": [
                    r'\b(d·ª´ng h·∫≥n|stop completely)\b',
                    r'\b(t·∫Øt nh·∫°c|stop music|ng·ª´ng nh·∫°c)\b',
                    r'\b(d·ª´ng|stop)\b(?!.*playing)'  # "d·ª´ng" nh∆∞ng kh√¥ng c√≥ "playing"
                ],
                "keywords": ["stop", "d·ª´ng", "t·∫Øt", "ng·ª´ng"]
            },
            "play_music": {
                "patterns": [
                    r'\b(ph√°t nh·∫°c|play music)\b',
                    r'\b(m·ªü nh·∫°c|b·∫≠t nh·∫°c|ch·∫°y nh·∫°c)\b',
                    r'\b(play song|start music)\b'
                ],
                "keywords": ["play", "ph√°t", "m·ªü", "b·∫≠t", "ch·∫°y"]
            }
        }
        
        # ===== B∆Ø·ªöC 3: PH√ÇN T√çCH ∆ØU TI√äN USER QUERY TR∆Ø·ªöC =====
        detected_tool = None
        confidence = 0.0
        matched_pattern = None
        analysis_source = "none"
        
        # Priority 1: Ph√¢n t√≠ch USER QUERY (ch√≠nh x√°c nh·∫•t)
        if original_query:
            query_lower = original_query.lower()
            
            # Ki·ªÉm tra ph·ªß ƒë·ªãnh v√† c√¢u h·ªèi trong query
            is_negative = any(re.search(p, query_lower) for p in negative_patterns)
            is_question = any(re.search(p, query_lower) for p in question_patterns)
            
            print(f"üîç [Analysis] Query Context:")
            print(f"   - Is Negative: {is_negative}")
            print(f"   - Is Question: {is_question}")
            
            if not is_negative and not is_question:
                # Ch·ªâ ph√¢n t√≠ch khi KH√îNG ph·∫£i c√¢u ph·ªß ƒë·ªãnh ho·∫∑c c√¢u h·ªèi
                for tool_name, tool_data in enhanced_vlc_patterns.items():
                    # Ki·ªÉm tra patterns
                    for pattern in tool_data["patterns"]:
                        if re.search(pattern, query_lower):
                            detected_tool = tool_name
                            confidence = 0.95  # VERY HIGH confidence v√¨ t·ª´ user query
                            matched_pattern = pattern
                            analysis_source = "user_query"
                            print(f"‚úÖ [Query Match] Tool: {tool_name} | Pattern: {pattern}")
                            break
                    
                    # N·∫øu ch∆∞a match, th·ª≠ keyword matching
                    if not detected_tool:
                        keyword_count = sum(1 for kw in tool_data["keywords"] if kw in query_lower)
                        if keyword_count >= 1:
                            detected_tool = tool_name
                            confidence = 0.7 + (keyword_count * 0.1)  # C√†ng nhi·ªÅu keyword c√†ng cao
                            matched_pattern = f"keywords: {[kw for kw in tool_data['keywords'] if kw in query_lower]}"
                            analysis_source = "user_query_keywords"
                            print(f"‚úÖ [Query Keywords] Tool: {tool_name} | Matched: {keyword_count}")
                            break
                    
                    if detected_tool:
                        break
            else:
                print(f"‚ö†Ô∏è [Query Skip] Skipped analysis (negative or question)")
        
        # Priority 2: Ph√¢n t√≠ch LLM RESPONSE (n·∫øu query kh√¥ng c√≥ k·∫øt qu·∫£)
        if not detected_tool and llm_response:
            response_lower = llm_response.lower()
            
            # Ki·ªÉm tra ph·ªß ƒë·ªãnh v√† c√¢u h·ªèi trong response
            is_negative = any(re.search(p, response_lower) for p in negative_patterns)
            is_question = any(re.search(p, response_lower) for p in question_patterns)
            
            print(f"üîç [Analysis] Response Context:")
            print(f"   - Is Negative: {is_negative}")
            print(f"   - Is Question: {is_question}")
            
            if not is_negative and not is_question:
                for tool_name, tool_data in enhanced_vlc_patterns.items():
                    for pattern in tool_data["patterns"]:
                        if re.search(pattern, response_lower):
                            detected_tool = tool_name
                            confidence = 0.75  # Lower than query but still good
                            matched_pattern = pattern
                            analysis_source = "llm_response"
                            print(f"‚úÖ [Response Match] Tool: {tool_name} | Pattern: {pattern}")
                            break
                    if detected_tool:
                        break
            else:
                print(f"‚ö†Ô∏è [Response Skip] Skipped analysis (negative or question)")
        
        # Priority 3: Intent Detector fallback (n·∫øu c·∫£ 2 ƒë·ªÅu kh√¥ng c√≥ k·∫øt qu·∫£)
        if not detected_tool:
            print(f"üîç [Fallback] Using Intent Detector...")
            try:
                text_to_analyze = original_query if original_query else llm_response
                intent_result = intent_detector.detect_intent(text_to_analyze)
                detected_tool = intent_result.get("suggested_tool")
                confidence = intent_result.get("confidence", 0.0) * 0.8  # Gi·∫£m 20% v√¨ fallback
                matched_pattern = "intent_detector"
                analysis_source = "intent_detector"
                print(f"üîç [Intent Detector] Tool: {detected_tool} | Confidence: {confidence:.2f}")
            except Exception as e:
                print(f"‚ùå [Intent Detector] Error: {e}")
        
        # ===== B∆Ø·ªöC 4: T·ª∞ ƒê·ªòNG G·ªåI TOOL =====
        tool_executed = False
        tool_result = None
        
        print(f"\nüìä [Decision]")
        print(f"   - Tool Detected: {detected_tool}")
        print(f"   - Confidence: {confidence:.2f}")
        print(f"   - Source: {analysis_source}")
        print(f"   - Threshold: 0.5")
        
        if auto_execute and detected_tool and confidence >= 0.5:  # Gi·∫£m threshold xu·ªëng 0.5
            if detected_tool in TOOLS and TOOLS[detected_tool]["handler"]:
                print(f"üöÄ [Execute] Calling tool: {detected_tool}")
                
                try:
                    handler = TOOLS[detected_tool]["handler"]
                    tool_args = {}
                    
                    # Extract arguments cho play_music
                    if detected_tool == "play_music" and original_query:
                        # Tr√≠ch xu·∫•t t√™n b√†i h√°t
                        for kw in ["ph√°t", "play", "b√†i", "song", "m·ªü", "b·∫≠t"]:
                            if kw in original_query.lower():
                                parts = original_query.lower().split(kw, 1)
                                if len(parts) > 1:
                                    filename = parts[1].strip()
                                    # Lo·∫°i b·ªè c√°c t·ª´ th·ª´a
                                    filename = re.sub(r'\b(cho t√¥i|gi√∫p t√¥i|gi√∫p m√¨nh|nh√©|ƒëi)\b', '', filename).strip()
                                    if filename:
                                        tool_args["filename"] = filename
                                        print(f"üéµ [Extract] Filename: '{filename}'")
                                    break
                    
                    # G·ªçi tool
                    tool_result = await handler(**tool_args)
                    tool_executed = True
                    
                    print(f"‚úÖ [Execute] Success!")
                    print(f"üìä [Result] {str(tool_result)[:150]}...")
                    
                except Exception as e:
                    print(f"‚ùå [Execute] Error: {e}")
                    import traceback
                    traceback.print_exc()
                    tool_result = {"success": False, "error": str(e)}
            else:
                print(f"‚ö†Ô∏è [Execute] Tool '{detected_tool}' not found in registry")
        elif not auto_execute:
            print(f"‚ÑπÔ∏è [Execute] Skipped (auto_execute=False)")
        elif not detected_tool:
            print(f"‚ö†Ô∏è [Execute] Skipped (no tool detected)")
        elif confidence < 0.5:
            print(f"‚ö†Ô∏è [Execute] Skipped (confidence {confidence:.2f} < 0.5)")
        
        print(f"{'='*70}\n")
        
        # ===== B∆Ø·ªöC 5: TR·∫¢ V·ªÄ K·∫æT QU·∫¢ =====
        return {
            "success": True,
            "llm_response": llm_response,
            "original_query": original_query,
            "intent_detected": detected_tool or "unknown",
            "tool_suggested": detected_tool,
            "confidence": confidence,
            "tool_executed": tool_executed,
            "tool_result": tool_result,
            "analysis": {
                "source": analysis_source,
                "matched_pattern": matched_pattern,
                "is_negative": is_negative if 'is_negative' in locals() else False,
                "is_question": is_question if 'is_question' in locals() else False
            },
            "message": f"‚úÖ Detected: {detected_tool} ({analysis_source}) | Executed: {tool_executed}" if detected_tool else "‚ö†Ô∏è No tool detected"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }


# ============================================================
# üß† SMART CONVERSATION ANALYZER v1.0
# Ph√¢n t√≠ch h·ªôi tho·∫°i th√¥ng minh & t·ª± ƒë·ªông ƒëi·ªÅu khi·ªÉn M·ªåI tool
# ============================================================

class SmartConversationAnalyzer:
    """
    üß† SMART CONVERSATION ANALYZER
    
    Ph√¢n t√≠ch TO√ÄN B·ªò l·ªãch s·ª≠ h·ªôi tho·∫°i ƒë·ªÉ:
    1. Hi·ªÉu INTENT th·ª±c s·ª± c·ªßa user (kh√¥ng ph·ª• thu·ªôc t·ª´ kh√≥a c·ª©ng)
    2. Ph√°t hi·ªán tool ph√π h·ª£p nh·∫•t t·ª´ 50+ tools
    3. Extract arguments th√¥ng minh
    4. T·ª± ƒë·ªông th·ª±c thi tool
    
    ƒê·∫∂C BI·ªÜT:
    - D√πng AI (Gemini/GPT-4) ƒë·ªÉ ph√¢n t√≠ch ‚Üí HI·ªÇU NG·ªÆ C·∫¢NH
    - Kh√¥ng c·∫ßn regex patterns cho t·ª´ng tool
    - H·ªó tr·ª£ T·∫§T C·∫¢ tools (kh√¥ng ch·ªâ VLC)
    - Context-aware: hi·ªÉu conversation history
    """
    
    def __init__(self):
        self.conversation_history = []  # L∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i
        self.max_history = 20  # Gi·ªØ 20 tin nh·∫Øn g·∫ßn nh·∫•t
        self.last_executed_tool = None
        self.last_tool_result = None
        
        # Build tool catalog t·ª´ TOOLS dictionary
        self.tool_catalog = self._build_tool_catalog()
        
    def _build_tool_catalog(self) -> str:
        """T·∫°o catalog tools cho AI prompt"""
        catalog_lines = []
        for tool_name, tool_info in TOOLS.items():
            desc = tool_info.get("description", "")[:100]
            params = list(tool_info.get("parameters", {}).keys())
            params_str = ", ".join(params) if params else "none"
            catalog_lines.append(f"- {tool_name}: {desc}... | params: {params_str}")
        return "\n".join(catalog_lines)
    
    def add_message(self, role: str, content: str, tool_called: str = None):
        """Th√™m message v√†o history"""
        self.conversation_history.append({
            "role": role,  # "user" ho·∫∑c "assistant" ho·∫∑c "system"
            "content": content,
            "tool_called": tool_called,
            "timestamp": datetime.now().isoformat()
        })
        # Gi·ªØ max history
        if len(self.conversation_history) > self.max_history:
            self.conversation_history = self.conversation_history[-self.max_history:]
    
    def get_conversation_context(self, last_n: int = 10) -> str:
        """L·∫•y context t·ª´ conversation history"""
        recent = self.conversation_history[-last_n:] if len(self.conversation_history) > last_n else self.conversation_history
        context_lines = []
        for msg in recent:
            role = "USER" if msg["role"] == "user" else "ASSISTANT"
            tool_info = f" [called: {msg['tool_called']}]" if msg.get("tool_called") else ""
            context_lines.append(f"{role}: {msg['content']}{tool_info}")
        return "\n".join(context_lines)
    
    async def analyze_with_ai(self, user_query: str, llm_response: str = "") -> dict:
        """
        D√πng AI ƒë·ªÉ ph√¢n t√≠ch conversation v√† x√°c ƒë·ªãnh tool c·∫ßn g·ªçi
        
        Returns:
            {
                "tool_name": str,           # Tool c·∫ßn g·ªçi
                "arguments": dict,          # Arguments cho tool
                "confidence": float,        # ƒê·ªô tin c·∫≠y (0-1)
                "reasoning": str,           # Gi·∫£i th√≠ch l√Ω do
                "should_execute": bool      # C√≥ n√™n th·ª±c thi kh√¥ng
            }
        """
        # L·∫•y conversation context
        context = self.get_conversation_context(last_n=5)
        
        # Build prompt cho AI
        analysis_prompt = f"""üß† B·∫†N L√Ä TOOL ANALYZER - Ph√¢n t√≠ch h·ªôi tho·∫°i v√† x√°c ƒë·ªãnh TOOL c·∫ßn g·ªçi.

üìã DANH S√ÅCH TOOLS C√ì S·∫¥N:
{self.tool_catalog}

üìú L·ªäCH S·ª¨ H·ªòI THO·∫†I G·∫¶N ƒê√ÇY:
{context}

üìù Y√äU C·∫¶U HI·ªÜN T·∫†I C·ª¶A USER:
"{user_query}"

üí¨ LLM ƒê√É PH·∫¢N H·ªíI (n·∫øu c√≥):
"{llm_response}"

üéØ NHI·ªÜM V·ª§: Ph√¢n t√≠ch v√† tr·∫£ v·ªÅ JSON v·ªõi format CH√çNH X√ÅC:
{{
    "tool_name": "t√™n_tool_c·∫ßn_g·ªçi ho·∫∑c null n·∫øu kh√¥ng c·∫ßn tool",
    "arguments": {{"param1": "value1", "param2": "value2"}} ho·∫∑c {{}},
    "confidence": 0.0 ƒë·∫øn 1.0,
    "reasoning": "gi·∫£i th√≠ch ng·∫Øn g·ªçn l√Ω do ch·ªçn tool n√†y",
    "should_execute": true ho·∫∑c false
}}

üö® L∆ØU √ù QUAN TR·ªåNG:
1. N·∫æU user h·ªèi c√¢u h·ªèi chung (th·ªùi ti·∫øt, tin t·ª©c...) ‚Üí KH√îNG c·∫ßn tool ‚Üí tool_name: null
2. N·∫æU user y√™u c·∫ßu h√†nh ƒë·ªông C·ª§ TH·ªÇ ‚Üí t√¨m tool ph√π h·ª£p
3. N·∫æU LLM ƒë√£ n√≥i "ƒë√£ chuy·ªÉn b√†i", "ƒë√£ t·∫°m d·ª´ng" nh∆∞ng KH√îNG g·ªçi tool ‚Üí c·∫ßn g·ªçi tool
4. Confidence < 0.6 ‚Üí should_execute: false
5. CH·ªà tr·∫£ v·ªÅ JSON, kh√¥ng c√≥ text kh√°c

V√ç D·ª§:
- User: "ph√°t nh·∫°c" ‚Üí {{"tool_name": "play_music", "arguments": {{}}, "confidence": 0.95, "reasoning": "user mu·ªën ph√°t nh·∫°c", "should_execute": true}}
- User: "b√†i ti·∫øp theo" ‚Üí {{"tool_name": "music_next", "arguments": {{}}, "confidence": 0.95, "reasoning": "user mu·ªën chuy·ªÉn b√†i", "should_execute": true}}
- User: "m·ªü chrome" ‚Üí {{"tool_name": "open_application", "arguments": {{"app_name": "chrome"}}, "confidence": 0.95, "reasoning": "m·ªü tr√¨nh duy·ªát", "should_execute": true}}
- User: "h√¥m nay th·ªùi ti·∫øt th·∫ø n√†o?" ‚Üí {{"tool_name": null, "arguments": {{}}, "confidence": 0.0, "reasoning": "c√¢u h·ªèi th√¥ng th∆∞·ªùng, kh√¥ng c·∫ßn tool", "should_execute": false}}

TR·∫¢ V·ªÄ JSON:"""

        try:
            # Th·ª≠ d√πng Gemini tr∆∞·ªõc
            if GEMINI_AVAILABLE and hasattr(genai, '_client') or os.getenv("GEMINI_API_KEY"):
                try:
                    api_key = os.getenv("GEMINI_API_KEY", "")
                    if api_key:
                        genai.configure(api_key=api_key)
                        model = genai.GenerativeModel('models/gemini-3-flash-preview')
                        response = model.generate_content(analysis_prompt)
                        ai_result = response.text.strip()
                        print(f"ü§ñ [AI Analysis] Gemini response: {ai_result[:200]}...")
                        return self._parse_ai_response(ai_result)
                except Exception as e:
                    print(f"‚ö†Ô∏è [AI Analysis] Gemini error: {e}")
            
            # Fallback: d√πng OpenAI
            if OPENAI_AVAILABLE:
                try:
                    api_key = os.getenv("OPENAI_API_KEY", "")
                    if api_key:
                        client = OpenAI(api_key=api_key)
                        response = client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[{"role": "user", "content": analysis_prompt}],
                            temperature=0.1,
                            max_tokens=500
                        )
                        ai_result = response.choices[0].message.content.strip()
                        print(f"ü§ñ [AI Analysis] GPT-4 response: {ai_result[:200]}...")
                        return self._parse_ai_response(ai_result)
                except Exception as e:
                    print(f"‚ö†Ô∏è [AI Analysis] OpenAI error: {e}")
            
            # Fallback cu·ªëi: d√πng rule-based
            print("‚ö†Ô∏è [AI Analysis] No AI available, using rule-based analysis")
            return await self._rule_based_analysis(user_query, llm_response)
            
        except Exception as e:
            print(f"‚ùå [AI Analysis] Error: {e}")
            return await self._rule_based_analysis(user_query, llm_response)
    
    def _parse_ai_response(self, ai_text: str) -> dict:
        """Parse JSON t·ª´ AI response"""
        try:
            # T√¨m JSON trong response
            import json
            
            # Th·ª≠ parse tr·ª±c ti·∫øp
            try:
                return json.loads(ai_text)
            except:
                pass
            
            # T√¨m JSON block
            json_match = re.search(r'\{[\s\S]*\}', ai_text)
            if json_match:
                return json.loads(json_match.group())
            
            # Kh√¥ng t√¨m ƒë∆∞·ª£c JSON
            return {
                "tool_name": None,
                "arguments": {},
                "confidence": 0.0,
                "reasoning": "Could not parse AI response",
                "should_execute": False
            }
        except Exception as e:
            print(f"‚ùå [Parse] Error: {e}")
            return {
                "tool_name": None,
                "arguments": {},
                "confidence": 0.0,
                "reasoning": f"Parse error: {e}",
                "should_execute": False
            }
    
    async def _rule_based_analysis(self, user_query: str, llm_response: str) -> dict:
        """Fallback: ph√¢n t√≠ch b·∫±ng rules khi kh√¥ng c√≥ AI"""
        query_lower = user_query.lower() if user_query else ""
        response_lower = llm_response.lower() if llm_response else ""
        combined = (query_lower + " " + response_lower).strip()
        
        print(f"üîç [Rule-Based] Analyzing: '{combined}'")
        
        # Extended patterns cho T·∫§T C·∫¢ tools (H·ªñ TR·ª¢ TI·∫æNG VI·ªÜT KH√îNG D·∫§U)
        all_tool_patterns = {
            # === MUSIC CONTROLS ===
            "music_next": {
                "patterns": [
                    r"b√†i ti·∫øp|bai tiep|next|skip|chuy·ªÉn b√†i|chuyen bai",
                    r"b√†i sau|bai sau|b√†i k·∫ø|bai ke|sang b√†i|sang bai",
                    r"tiep theo|ti·∫øp theo|ke tiep|k·∫ø ti·∫øp"
                ],
                "keywords": ["next", "ti·∫øp", "tiep", "skip", "chuy·ªÉn", "chuyen", "sau", "k·∫ø", "ke"]
            },
            "music_previous": {
                "patterns": [
                    r"b√†i tr∆∞·ªõc|bai truoc|previous|quay l·∫°i|quay lai",
                    r"back|l√πi|lui|tr·ªü l·∫°i|tro lai|bai cu|b√†i c≈©"
                ],
                "keywords": ["previous", "tr∆∞·ªõc", "truoc", "back", "quay", "l√πi", "lui"]
            },
            "pause_music": {
                "patterns": [r"t·∫°m d·ª´ng|tam dung|pause|d·ª´ng l·∫°i|dung lai|ng∆∞ng|ngung"],
                "keywords": ["pause", "t·∫°m", "tam", "d·ª´ng", "dung"]
            },
            "resume_music": {
                "patterns": [r"ti·∫øp t·ª•c|tiep tuc|resume|continue|ph√°t ti·∫øp|phat tiep|ch·∫°y ti·∫øp|chay tiep"],
                "keywords": ["resume", "ti·∫øp t·ª•c", "tiep tuc", "continue"]
            },
            "stop_music": {
                "patterns": [r"d·ª´ng h·∫≥n|dung han|stop|t·∫Øt nh·∫°c|tat nhac|ng·ª´ng nh·∫°c|ngung nhac"],
                "keywords": ["stop", "t·∫Øt", "tat", "d·ª´ng h·∫≥n", "dung han"]
            },
            "play_music": {
                "patterns": [
                    r"ph√°t nh·∫°c|phat nhac|play music|b·∫≠t nh·∫°c|bat nhac",
                    r"m·ªü nh·∫°c|mo nhac|nghe nh·∫°c|nghe nhac"
                ],
                "keywords": ["ph√°t", "phat", "play", "b·∫≠t", "bat", "m·ªü", "mo", "nghe"]
            },
            
            # === VOLUME CONTROLS ===
            "volume_up": {
                "patterns": [r"tƒÉng √¢m|tang am|volume up|to h∆°n|to hon|l·ªõn h∆°n|lon hon"],
                "keywords": ["tƒÉng", "tang", "up", "to h∆°n", "to hon", "l·ªõn", "lon"]
            },
            "volume_down": {
                "patterns": [r"gi·∫£m √¢m|giam am|volume down|nh·ªè h∆°n|nho hon|b·ªõt to|bot to"],
                "keywords": ["gi·∫£m", "giam", "down", "nh·ªè", "nho", "b·ªõt", "bot"]
            },
            "mute_volume": {
                "patterns": [r"t·∫Øt ti·∫øng|tat tieng|mute|c√¢m|cam|im l·∫∑ng|im lang"],
                "keywords": ["mute", "t·∫Øt ti·∫øng", "tat tieng", "c√¢m", "cam"]
            },
            "set_volume": {
                "patterns": [r"√¢m l∆∞·ª£ng \d+|am luong \d+|volume \d+|ƒë·∫∑t √¢m|dat am|ch·ªânh √¢m|chinh am"],
                "keywords": ["√¢m l∆∞·ª£ng", "am luong", "volume"]
            },
            
            # === APPLICATIONS ===
            "open_application": {
                "patterns": [
                    r"m·ªü ·ª©ng d·ª•ng|mo ung dung|open app|m·ªü chrome|mo chrome",
                    r"m·ªü word|mo word|m·ªü excel|mo excel|m·ªü notepad|mo notepad",
                    r"kh·ªüi ƒë·ªông|khoi dong"
                ],
                "keywords": ["m·ªü", "mo", "open", "kh·ªüi ƒë·ªông", "khoi dong", "ch·∫°y", "chay"]
            },
            "kill_process": {
                "patterns": [r"t·∫Øt ·ª©ng d·ª•ng|tat ung dung|kill|ƒë√≥ng app|dong app|close app"],
                "keywords": ["t·∫Øt", "tat", "kill", "ƒë√≥ng", "dong", "close"]
            },
            
            # === SYSTEM ===
            "take_screenshot": {
                "patterns": [r"ch·ª•p m√†n h√¨nh|chup man hinh|screenshot|capture screen"],
                "keywords": ["ch·ª•p", "chup", "screenshot", "capture"]
            },
            "get_system_resources": {
                "patterns": [r"t√†i nguy√™n|tai nguyen|system info|cpu|ram|memory"],
                "keywords": ["t√†i nguy√™n", "tai nguyen", "system", "cpu", "ram"]
            },
            "get_current_time": {
                "patterns": [r"m·∫•y gi·ªù|may gio|th·ªùi gian|thoi gian|time now|gi·ªù hi·ªán t·∫°i|gio hien tai"],
                "keywords": ["gi·ªù", "gio", "time", "th·ªùi gian", "thoi gian"]
            },
            
            # === FILES ===
            "create_file": {
                "patterns": [r"t·∫°o file|tao file|create file|vi·∫øt file|viet file"],
                "keywords": ["t·∫°o file", "tao file", "create file", "vi·∫øt", "viet"]
            },
            "read_file": {
                "patterns": [r"ƒë·ªçc file|doc file|read file|xem file"],
                "keywords": ["ƒë·ªçc", "doc", "read", "xem"]
            },
            "list_files": {
                "patterns": [r"li·ªát k√™ file|liet ke file|list files|xem th∆∞ m·ª•c|xem thu muc"],
                "keywords": ["li·ªát k√™", "liet ke", "list", "th∆∞ m·ª•c", "thu muc"]
            },
            
            # === CALCULATOR ===
            "calculator": {
                "patterns": [r"t√≠nh|tinh|calculate|bao nhi√™u|bao nhieu|\d+\s*[\+\-\*\/]\s*\d+"],
                "keywords": ["t√≠nh", "tinh", "calculate", "c·ªông", "cong", "tr·ª´", "tru", "nh√¢n", "nhan", "chia"]
            },
            
            # === CLIPBOARD ===
            "get_clipboard": {
                "patterns": [r"clipboard|ƒë√£ copy g√¨|da copy gi|l·∫•y clipboard|lay clipboard"],
                "keywords": ["clipboard", "copy"]
            },
            "set_clipboard": {
                "patterns": [r"copy v√†o clipboard|copy vao clipboard|set clipboard"],
                "keywords": ["copy v√†o", "copy vao", "set clipboard"]
            },
            
            # === BROWSER ===
            "search_web": {
                "patterns": [r"t√¨m ki·∫øm google|tim kiem google|search google|m·ªü google t√¨m|mo google tim"],
                "keywords": ["google", "search web", "t√¨m ki·∫øm", "tim kiem"]
            },
            "open_youtube": {
                "patterns": [r"m·ªü youtube|mo youtube|youtube|xem video"],
                "keywords": ["youtube", "video"]
            },
            
            # === BRIGHTNESS ===
            "set_brightness": {
                "patterns": [r"ƒë·ªô s√°ng|do sang|brightness|s√°ng h∆°n|sang hon|t·ªëi h∆°n|toi hon"],
                "keywords": ["s√°ng", "sang", "brightness", "t·ªëi", "toi"]
            }
        }
        
        # T√¨m tool match nh·∫•t
        best_match = None
        best_confidence = 0.0
        best_reason = ""
        
        for tool_name, tool_patterns in all_tool_patterns.items():
            # Check patterns
            for pattern in tool_patterns["patterns"]:
                if re.search(pattern, combined):
                    confidence = 0.85
                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_match = tool_name
                        best_reason = f"Pattern match: {pattern}"
                        print(f"‚úÖ [Rule-Based] Pattern matched: {tool_name} ({pattern})")
                    break
            
            # ALWAYS check keywords (kh√¥ng ch·ªâ khi ch∆∞a c√≥ match)
            keyword_count = sum(1 for kw in tool_patterns["keywords"] if kw in combined)
            if keyword_count >= 1:
                confidence = 0.6 + (keyword_count * 0.1)
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_match = tool_name
                    best_reason = f"Keywords: {keyword_count} matches"
                    print(f"‚úÖ [Rule-Based] Keywords matched: {tool_name} ({keyword_count} keywords)")
        
        print(f"üìä [Rule-Based] Result: {best_match} (confidence: {best_confidence:.2f})")
        
        # Extract arguments
        arguments = {}
        if best_match:
            # D√πng combined text ƒë·ªÉ extract args n·∫øu query tr·ªëng
            text_for_args = user_query if user_query else llm_response
            arguments = self._extract_arguments(best_match, text_for_args)
        
        return {
            "tool_name": best_match,
            "arguments": arguments,
            "confidence": best_confidence,
            "reasoning": best_reason,
            "should_execute": best_confidence >= 0.5
        }
    
    def _extract_arguments(self, tool_name: str, query: str) -> dict:
        """Extract arguments cho tool t·ª´ query"""
        args = {}
        query_lower = query.lower()
        
        # play_music ‚Üí extract filename
        if tool_name == "play_music":
            for kw in ["ph√°t", "play", "b√†i", "song", "m·ªü", "b·∫≠t", "nghe"]:
                if kw in query_lower:
                    parts = query_lower.split(kw, 1)
                    if len(parts) > 1:
                        filename = parts[1].strip()
                        filename = re.sub(r'\b(cho t√¥i|gi√∫p t√¥i|nh√©|ƒëi|n√†o)\b', '', filename).strip()
                        if filename and len(filename) > 1:
                            args["filename"] = filename
                        break
        
        # open_application ‚Üí extract app_name
        elif tool_name == "open_application":
            for kw in ["m·ªü", "open", "kh·ªüi ƒë·ªông", "ch·∫°y"]:
                if kw in query_lower:
                    parts = query_lower.split(kw, 1)
                    if len(parts) > 1:
                        app = parts[1].strip()
                        app = re.sub(r'\b(cho t√¥i|gi√∫p|nh√©|ƒëi|·ª©ng d·ª•ng|app)\b', '', app).strip()
                        if app:
                            args["app_name"] = app
                        break
        
        # set_volume ‚Üí extract level
        elif tool_name == "set_volume":
            match = re.search(r'(\d+)\s*(%)?', query)
            if match:
                level = int(match.group(1))
                args["level"] = min(100, max(0, level))
        
        # calculator ‚Üí extract expression
        elif tool_name == "calculator":
            # T√¨m bi·ªÉu th·ª©c to√°n
            expr_match = re.search(r'(\d+[\s\+\-\*\/\(\)]+\d+[\s\d\+\-\*\/\(\)]*)', query)
            if expr_match:
                args["expression"] = expr_match.group(1).strip()
        
        # set_brightness ‚Üí extract level
        elif tool_name == "set_brightness":
            match = re.search(r'(\d+)\s*(%)?', query)
            if match:
                level = int(match.group(1))
                args["level"] = min(100, max(0, level))
        
        # search_web ‚Üí extract query
        elif tool_name == "search_web":
            for kw in ["t√¨m", "search", "google"]:
                if kw in query_lower:
                    parts = query_lower.split(kw, 1)
                    if len(parts) > 1:
                        search_query = parts[1].strip()
                        search_query = re.sub(r'\b(v·ªÅ|cho t√¥i|gi√∫p|tr√™n)\b', '', search_query).strip()
                        if search_query:
                            args["query"] = search_query
                        break
        
        return args
    
    async def execute_tool(self, tool_name: str, arguments: dict) -> dict:
        """Th·ª±c thi tool v·ªõi arguments"""
        try:
            if tool_name not in TOOLS:
                return {"success": False, "error": f"Tool '{tool_name}' not found"}
            
            handler = TOOLS[tool_name]["handler"]
            if not handler:
                return {"success": False, "error": f"Tool '{tool_name}' has no handler"}
            
            # G·ªçi tool
            result = await handler(**arguments)
            
            # L∆∞u l·∫°i
            self.last_executed_tool = tool_name
            self.last_tool_result = result
            
            return {"success": True, "tool": tool_name, "result": result}
            
        except Exception as e:
            import traceback
            return {"success": False, "error": str(e), "traceback": traceback.format_exc()}


# Global instance
smart_analyzer = SmartConversationAnalyzer()


@app.post("/api/smart_analyze")
async def api_smart_analyze(data: dict):
    """
    üß† SMART CONVERSATION ANALYZER API
    
    Ph√¢n t√≠ch h·ªôi tho·∫°i th√¥ng minh, t·ª± ƒë·ªông ƒëi·ªÅu khi·ªÉn M·ªåI tool.
    Kh√¥ng ph·ª• thu·ªôc t·ª´ kh√≥a c·ª©ng - d√πng AI ƒë·ªÉ hi·ªÉu ng·ªØ c·∫£nh.
    
    Args:
        user_query: Y√™u c·∫ßu c·ªßa user
        llm_response: Ph·∫£n h·ªìi t·ª´ LLM (optional)
        conversation_history: L·ªãch s·ª≠ h·ªôi tho·∫°i (optional, list of {role, content})
        auto_execute: T·ª± ƒë·ªông th·ª±c thi tool (default: True)
        use_ai: D√πng AI ƒë·ªÉ ph√¢n t√≠ch (default: True, fallback to rules)
    
    Returns:
        {
            "success": bool,
            "analysis": {
                "tool_name": str,
                "arguments": dict,
                "confidence": float,
                "reasoning": str,
                "should_execute": bool
            },
            "execution": {
                "executed": bool,
                "result": dict
            },
            "message": str
        }
    """
    try:
        user_query = data.get("user_query", data.get("query", "")).strip()
        llm_response = data.get("llm_response", data.get("response", "")).strip()
        conversation_history = data.get("conversation_history", [])
        auto_execute = data.get("auto_execute", True)
        use_ai = data.get("use_ai", True)
        
        print(f"\n{'='*70}")
        print(f"üß† [Smart Analyze] NEW REQUEST")
        print(f"{'='*70}")
        print(f"üìù User Query: '{user_query}'")
        print(f"üí¨ LLM Response: '{llm_response[:100]}...' " if llm_response else "")
        print(f"‚öôÔ∏è  Auto Execute: {auto_execute} | Use AI: {use_ai}")
        print(f"üìú History Length: {len(conversation_history)}")
        print(f"{'-'*70}")
        
        if not user_query and not llm_response:
            return {
                "success": False,
                "error": "user_query or llm_response is required"
            }
        
        # Th√™m conversation history n·∫øu c√≥
        for msg in conversation_history:
            smart_analyzer.add_message(
                role=msg.get("role", "user"),
                content=msg.get("content", "")
            )
        
        # Th√™m message hi·ªán t·∫°i
        if user_query:
            smart_analyzer.add_message("user", user_query)
        if llm_response:
            smart_analyzer.add_message("assistant", llm_response)
        
        # === PH√ÇN T√çCH ===
        if use_ai:
            analysis = await smart_analyzer.analyze_with_ai(user_query, llm_response)
        else:
            analysis = await smart_analyzer._rule_based_analysis(user_query, llm_response)
        
        print(f"\nüéØ [Analysis Result]")
        print(f"   - Tool: {analysis.get('tool_name')}")
        print(f"   - Arguments: {analysis.get('arguments')}")
        print(f"   - Confidence: {analysis.get('confidence', 0):.2f}")
        print(f"   - Should Execute: {analysis.get('should_execute')}")
        print(f"   - Reasoning: {analysis.get('reasoning')}")
        
        # === TH·ª∞C THI ===
        execution = {"executed": False, "result": None}
        
        if auto_execute and analysis.get("should_execute") and analysis.get("tool_name"):
            tool_name = analysis["tool_name"]
            arguments = analysis.get("arguments", {})
            
            print(f"\nüöÄ [Execute] Calling: {tool_name}({arguments})")
            
            exec_result = await smart_analyzer.execute_tool(tool_name, arguments)
            execution = {
                "executed": exec_result.get("success", False),
                "result": exec_result
            }
            
            # C·∫≠p nh·∫≠t history v·ªõi tool ƒë√£ g·ªçi
            smart_analyzer.add_message("system", f"Tool executed: {tool_name}", tool_called=tool_name)
            
            if exec_result.get("success"):
                print(f"‚úÖ [Execute] Success!")
            else:
                print(f"‚ùå [Execute] Failed: {exec_result.get('error')}")
        
        print(f"{'='*70}\n")
        
        return {
            "success": True,
            "user_query": user_query,
            "llm_response": llm_response,
            "analysis": analysis,
            "execution": execution,
            "message": f"‚úÖ Tool: {analysis.get('tool_name')} | Executed: {execution['executed']}" if analysis.get('tool_name') else "‚ö†Ô∏è No tool needed"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }


# NOTE: ƒê√£ x√≥a duplicate endpoint /api/conversation/add (line 13967)
# Endpoint ch√≠nh n·∫±m ·ªü ph·∫ßn CONVERSATION HISTORY API (line ~15208)
# Gi·ªØ l·∫°i ƒë·ªÉ tr√°nh conflict v·ªõi SmartConversationAnalyzer


@app.post("/api/smart_chat")
async def api_smart_chat(data: dict):
    """
    Smart Chat v·ªõi Intent Detection t·ª± ƒë·ªông + VLC MCP Integration + Google Search Grounding
    1. Ph√¢n t√≠ch intent
    2. N·∫øu c·∫ßn tool ‚Üí t·ª± ƒë·ªông g·ªçi tool (REST) ho·∫∑c MCP (VLC)
    3. G·ª≠i k·∫øt qu·∫£ tool + query ƒë·∫øn Gemini
    4. Tr·∫£ v·ªÅ response ho√†n ch·ªânh
    
    üÜï VLC MCP: T·ª± ƒë·ªông d√πng MCP protocol cho VLC commands
    üÜï Google Search: T·ª± ƒë·ªông tra c·ª©u Google cho c√¢u h·ªèi realtime
    """
    query = data.get("query", data.get("prompt", data.get("text", "")))
    use_llm_intent = data.get("use_llm_intent", False)
    model = data.get("model", "gemini-2.0-flash")  # Default model h·ªó tr·ª£ grounding
    use_google_search = data.get("use_google_search", True)  # üÜï M·∫∑c ƒë·ªãnh B·∫¨T Google Search
    
    if not query:
        raise HTTPException(400, "Query is required")
    
    try:
        # üÜï STEP -1: Ki·ªÉm tra c√≥ c·∫ßn Google Search kh√¥ng (c√¢u h·ªèi th·ªùi s·ª±, gi√° c·∫£, tin t·ª©c)
        realtime_keywords = [
            'gi√° v√†ng', 'gi√° usd', 't·ª∑ gi√°', 'gi√° bitcoin', 'crypto', 'ch·ª©ng kho√°n',
            'th·ªùi ti·∫øt', 'weather', 'tin t·ª©c', 'news', 'm·ªõi nh·∫•t', 'latest',
            'h√¥m nay', 'b√¢y gi·ªù', 'hi·ªán nay', 'hi·ªán t·∫°i', 'today', 'now', 'current',
            'nƒÉm 2024', 'nƒÉm 2025', 'nƒÉm 2026', '2024', '2025', '2026',
            'v√¥ ƒë·ªãch', 'champion', 'winner', 'k·∫øt qu·∫£', 'score', 'result',
            't·ªïng th·ªëng', 'president', 'th·ªß t∆∞·ªõng', 'ch·ªß t·ªãch', 'ceo',
            'iphone', 'samsung', 'tesla', 'apple', 'google', 'microsoft', 'ra m·∫Øt',
            'l√† ai', 'l√† g√¨', '·ªü ƒë√¢u', 'what is', 'where is', 'how much', 'bao nhi√™u',
            's·ª± ki·ªán', 'event', 'l·ªãch', 'schedule', 'khi n√†o', 'when', 'gi√° xƒÉng', 'gi√° d·∫ßu',
            'covid', 'b√£o', 'ƒë·ªông ƒë·∫•t', 'tai n·∫°n', 'ch√°y', 'chi·∫øn tranh', 'xung ƒë·ªôt'
        ]
        query_lower = query.lower()
        needs_google_search = use_google_search and any(kw in query_lower for kw in realtime_keywords)
        
        # üîç N·∫øu c·∫ßn Google Search, ∆∞u ti√™n d√πng Gemini + Google Search Grounding
        if needs_google_search:
            print(f"üîç [Smart Chat] Ph√°t hi·ªán c√¢u h·ªèi c·∫ßn Google Search: {query[:50]}...")
            try:
                google_result = await ask_gemini_with_google_search(
                    prompt=query,
                    model="gemini-2.0-flash"  # Model h·ªó tr·ª£ grounding t·ªët nh·∫•t
                )
                
                if google_result.get("success"):
                    # L∆∞u v√†o conversation history
                    add_to_conversation(role="user", content=query, metadata={"source": "smart_chat_google_search"})
                    add_to_conversation(
                        role="assistant", 
                        content=google_result.get("response", ""),
                        metadata={
                            "source": "smart_chat_google_search",
                            "model": google_result.get("model"),
                            "google_search_used": True,
                            "search_queries": google_result.get("search_queries", [])
                        }
                    )
                    
                    return {
                        "success": True,
                        "query": query,
                        "response": google_result.get("response"),
                        "intent": {"intent": "realtime_query", "needs_google_search": True},
                        "tool_used": "google_search_grounding",
                        "google_search_used": True,
                        "search_queries": google_result.get("search_queries", []),
                        "grounding_chunks": google_result.get("grounding_chunks", []),
                        "model": google_result.get("model"),
                        "message": google_result.get("message")
                    }
                else:
                    print(f"‚ö†Ô∏è [Smart Chat] Google Search failed, falling back to normal...")
            except Exception as e:
                print(f"‚ö†Ô∏è [Smart Chat] Google Search error: {e}, falling back...")
        
        # üÜï STEP 0: T·ª± ƒë·ªông ph√°t hi·ªán v√† x·ª≠ l√Ω documents/database v·ªõi Gemini
        doc_result = await auto_process_document_with_gemini(query, model=model)
        
        if doc_result.get("activated") and doc_result.get("success"):
            # ƒê√£ x·ª≠ l√Ω document th√†nh c√¥ng v·ªõi Gemini
            print(f"üìö [Auto Document] Success! Documents: {len(doc_result.get('documents_found', []))}")
            
            return {
                "success": True,
                "query": query,
                "response": doc_result.get("gemini_response"),
                "intent": "document_query",
                "tool_used": "auto_process_document_with_gemini",
                "documents_found": doc_result.get("documents_found", []),
                "model": doc_result.get("model_used"),
                "message": doc_result.get("message"),
                "auto_document_processing": True
            }
        
        # Step 1: Detect intent
        if use_llm_intent:
            intent_result = await intent_detector.detect_with_llm(query, GEMINI_API_KEY)
        else:
            intent_result = intent_detector.detect_intent(query)
        
        print(f"üß† [Intent] {intent_result}")
        
        tool_result = None
        tool_used = None
        mcp_used = False
        
        # Step 2: N·∫øu c·∫ßn force tool, g·ªçi tool tr∆∞·ªõc
        if intent_result.get("should_force_tool") and intent_result.get("suggested_tool"):
            tool_name = intent_result["suggested_tool"]
            
            # üÜï CHECK: N·∫øu l√† VLC command ‚Üí d√πng MCP
            vlc_commands = ["music_next", "music_previous", "pause_music", "resume_music", "stop_music", "play_music"]
            
            if VLC_MCP_AVAILABLE and tool_name in vlc_commands:
                print(f"üéØ [VLC MCP] Routing to MCP: {tool_name}")
                
                # Map tool name to MCP tool name
                mcp_tool_map = {
                    "music_next": "vlc.next",
                    "music_previous": "vlc.previous",
                    "pause_music": "vlc.pause",
                    "resume_music": "vlc.play",
                    "stop_music": "vlc.stop",
                    "play_music": "vlc.play"
                }
                
                mcp_tool_name = mcp_tool_map.get(tool_name)
                
                if mcp_tool_name:
                    try:
                        # Call via MCP protocol
                        mcp_request = {
                            "jsonrpc": "2.0",
                            "method": "tools/call",
                            "params": {
                                "name": mcp_tool_name,
                                "arguments": {}
                            },
                            "id": 1
                        }
                        
                        mcp_response = await vlc_mcp_server.handle_mcp_request(mcp_request)
                        
                        if "result" in mcp_response:
                            tool_result = mcp_response["result"]
                            tool_used = mcp_tool_name
                            mcp_used = True
                            print(f"‚úÖ [VLC MCP] Success: {mcp_tool_name}")
                        else:
                            print(f"‚ùå [VLC MCP] Error: {mcp_response.get('error')}")
                            tool_result = {"error": mcp_response.get("error", {}).get("message", "Unknown error")}
                    except Exception as e:
                        print(f"‚ö†Ô∏è [VLC MCP] Exception: {e}")
                        tool_result = {"error": str(e)}
            
            # Fallback: REST API
            elif tool_name in TOOLS and TOOLS[tool_name]["handler"]:
                print(f"üîß [Auto Tool] Calling {tool_name} for query: {query}")
                
                try:
                    # T·∫°o arguments d·ª±a tr√™n intent
                    tool_args = {"query": query}
                    
                    # G·ªçi tool
                    handler = TOOLS[tool_name]["handler"]
                    tool_result = await handler(**tool_args)
                    tool_used = tool_name
                    
                    print(f"‚úÖ [Auto Tool] {tool_name} result: {str(tool_result)[:200]}...")
                except Exception as e:
                    print(f"‚ö†Ô∏è [Auto Tool] Error calling {tool_name}: {e}")
                    tool_result = {"error": str(e)}
        
        # Step 3: G·ª≠i ƒë·∫øn Gemini v·ªõi context t·ª´ tool
        final_prompt = query
        if tool_result and not tool_result.get("error"):
            # Th√™m context t·ª´ tool result
            context = json.dumps(tool_result, ensure_ascii=False, indent=2)
            final_prompt = f"""D·ª±a tr√™n th√¥ng tin tra c·ª©u sau ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa user.

üìä TH√îNG TIN TRA C·ª®U (t·ª´ {tool_used}):
{context}

‚ùì C√ÇU H·ªéI C·ª¶A USER:
{query}

üìù Y√äU C·∫¶U:
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c
- D·ª±a tr√™n th√¥ng tin tra c·ª©u ·ªü tr√™n
- N·∫øu th√¥ng tin kh√¥ng ƒë·ªß, n√≥i r√µ v√† ƒë∆∞a ra nh·ªØng g√¨ c√≥"""
        
        # G·ªçi Gemini
        gemini_result = await ask_gemini(prompt=final_prompt, model=model)
        
        # L∆∞u v√†o conversation history
        add_to_conversation(
            role="user",
            content=query,
            metadata={
                "source": "smart_chat",
                "intent": intent_result.get("intent"),
                "tool_suggested": intent_result.get("suggested_tool")
            }
        )
        
        if gemini_result.get("success"):
            add_to_conversation(
                role="assistant",
                content=gemini_result.get("response", ""),
                metadata={
                    "source": "smart_chat",
                    "tool_used": tool_used,
                    "model": model
                }
            )
        
        return {
            "success": True,
            "query": query,
            "intent": intent_result,
            "tool_used": tool_used,
            "tool_result": tool_result,
            "response": gemini_result.get("response", ""),
            "model": model
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


# ===== üîç GOOGLE SEARCH GROUNDING ENDPOINT =====

@app.post("/api/gemini/google_search")
async def api_gemini_google_search(data: dict):
    """
    üîç Gemini v·ªõi Google Search Grounding - Tra c·ª©u Google t·ª± ƒë·ªông
    
    T√≠nh nƒÉng cho ph√©p Gemini t·ª± ƒë·ªông t√¨m ki·∫øm Google ƒë·ªÉ tr·∫£ l·ªùi
    c√°c c√¢u h·ªèi c·∫ßn th√¥ng tin m·ªõi nh·∫•t, real-time.
    
    Args (JSON body):
        prompt (str): C√¢u h·ªèi c·∫ßn Gemini tra c·ª©u v√† tr·∫£ l·ªùi
        model (str, optional): Model Gemini (default: gemini-2.0-flash)
        
    Returns:
        success: True/False
        response: C√¢u tr·∫£ l·ªùi t·ª´ Gemini
        google_search_used: True n·∫øu ƒë√£ d√πng Google Search
        search_queries: C√°c query ƒë√£ search tr√™n Google
        grounding_chunks: Ngu·ªìn website ƒë∆∞·ª£c tr√≠ch d·∫´n
    
    Example:
        POST /api/gemini/google_search
        {"prompt": "Gi√° v√†ng h√¥m nay l√† bao nhi√™u?"}
    """
    prompt = data.get("prompt", data.get("query", data.get("text", "")))
    model = data.get("model", "gemini-2.0-flash")
    
    if not prompt:
        raise HTTPException(400, "Prompt is required")
    
    print(f"üîç [API Google Search] Query: {prompt[:100]}...")
    
    # L∆∞u user message v√†o history
    add_to_conversation(
        role="user",
        content=prompt,
        metadata={"source": "google_search_api", "model": model}
    )
    
    try:
        # G·ªçi Gemini v·ªõi Google Search Grounding
        result = await ask_gemini_with_google_search(
            prompt=prompt,
            model=model
        )
        
        if result.get("success"):
            # L∆∞u assistant response v√†o history
            add_to_conversation(
                role="assistant",
                content=result.get("response", ""),
                metadata={
                    "source": "google_search_api",
                    "model": result.get("model"),
                    "google_search_used": result.get("google_search_used", False),
                    "search_queries": result.get("search_queries", [])
                }
            )
            
            return {
                "success": True,
                "prompt": prompt,
                "response": result.get("response"),
                "response_text": result.get("response"),  # Alias
                "model": result.get("model"),
                "google_search_used": result.get("google_search_used", False),
                "search_queries": result.get("search_queries", []),
                "grounding_chunks": result.get("grounding_chunks", []),
                "message": result.get("message")
            }
        else:
            return {
                "success": False,
                "error": result.get("error", "Unknown error"),
                "prompt": prompt
            }
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "prompt": prompt
        }


# ===== 23 API ENDPOINTS M·ªöI (Tool 8-30) =====

@app.post("/api/tool/ask_gemini")
async def api_ask_gemini(data: dict):
    """
    Gemini AI endpoint with Knowledge Base + Google Search integration
    
    Flow:
    1. Nh·∫≠n query t·ª´ user
    2. üÜï Ki·ªÉm tra c√≥ ph·∫£i L·ªÜNH ƒêI·ªÄU KHI·ªÇN M√ÅY T√çNH kh√¥ng
    3. N·∫øu l√† l·ªánh ƒëi·ªÅu khi·ªÉn ‚Üí d√πng ask_gemini_with_tools
    4. Ki·ªÉm tra c√≥ c·∫ßn Google Search kh√¥ng (gi√° c·∫£, tin t·ª©c, th·ªùi s·ª±)
    5. N·∫øu c·∫ßn realtime ‚Üí d√πng Google Search Grounding
    6. N·∫øu kh√¥ng ‚Üí search Knowledge Base + Gemini
    7. Tr·∫£ v·ªÅ response
    """
    prompt = data.get("prompt", "")
    model = data.get("model", "gemini-2.0-flash")  # üÜï Default model h·ªó tr·ª£ grounding
    use_google_search = data.get("use_google_search", True)  # üÜï M·∫∑c ƒë·ªãnh B·∫¨T
    # üîí B·∫ÆT BU·ªòC search KB - KH√îNG cho user t·∫Øt
    use_knowledge_base = True  # LU√îN B·∫¨T
    
    if not prompt:
        raise HTTPException(400, "Prompt is required")
    
    prompt_lower = prompt.lower()
    
    # ü§ñ STEP -1: Ki·ªÉm tra c√≥ ph·∫£i L·ªÜNH ƒêI·ªÄU KHI·ªÇN M√ÅY T√çNH kh√¥ng
    control_keywords = [
        # M·ªü/ƒë√≥ng ·ª©ng d·ª•ng
        'm·ªü ', 'open ', 'b·∫≠t ', 'ch·∫°y ', 'kh·ªüi ƒë·ªông ', 'start ', 'launch ',
        'ƒë√≥ng ', 'close ', 't·∫Øt ', 'kill ', 'stop ', 'exit ',
        'notepad', 'chrome', 'firefox', 'word', 'excel', 'powerpoint',
        'calculator', 'calc', 'vlc', 'spotify', 'vscode', 'code',
        
        # ƒêi·ªÅu khi·ªÉn nh·∫°c
        'ph√°t nh·∫°c', 'play music', 'b·∫≠t nh·∫°c', 'nghe nh·∫°c',
        'd·ª´ng nh·∫°c', 'pause', 't·∫°m d·ª´ng', 'ti·∫øp t·ª•c', 'resume',
        'b√†i ti·∫øp', 'next', 'b√†i tr∆∞·ªõc', 'previous', 'prev',
        'tƒÉng √¢m', 'gi·∫£m √¢m', 'volume', '√¢m l∆∞·ª£ng',
        
        # H·ªá th·ªëng
        't·∫Øt m√°y', 'shutdown', 'kh·ªüi ƒë·ªông l·∫°i', 'restart', 'reboot',
        'kh√≥a m√†n h√¨nh', 'lock', 'sleep', 'ng·ªß',
        'ch·ª•p m√†n h√¨nh', 'screenshot', 'capture',
        
        # YouTube
        'youtube', 'ph√°t youtube', 'm·ªü youtube', 'play youtube',
        
        # Website
        'm·ªü web', 'open website', 'truy c·∫≠p', 'v√†o trang',
        'google.com', 'facebook.com', 'youtube.com',
        
        # File/Folder
        'm·ªü folder', 'm·ªü th∆∞ m·ª•c', 'open folder',
        't·∫°o file', 'create file', 't·∫°o th∆∞ m·ª•c',
        
        # Keyboard
        'g√µ ', 'type ', 'nh·∫•n ph√≠m', 'press key', 'ctrl+', 'alt+',
        
        # Desktop & Theme
        'h√¨nh n·ªÅn', 'wallpaper', 'ƒë·ªïi n·ªÅn', 'change wallpaper',
        'ƒë·ªïi theme', 'dark mode', 'light mode', 'theme t·ªëi', 'theme s√°ng',
        'hi·ªán desktop', 'show desktop', '·∫©n c·ª≠a s·ªï',
        
        # M√†n h√¨nh & ƒê·ªô s√°ng
        'ƒë·ªô s√°ng', 'brightness', 'tƒÉng s√°ng', 'gi·∫£m s√°ng',
    ]
    
    is_control_command = any(kw in prompt_lower for kw in control_keywords)
    
    if is_control_command:
        print(f"ü§ñ [ask_gemini] Ph√°t hi·ªán L·ªÜNH ƒêI·ªÄU KHI·ªÇN: '{prompt[:50]}...'")
        print(f"   ‚Üí Chuy·ªÉn sang Gemini Agent mode...")
        
        try:
            agent_result = await ask_gemini_with_tools(
                prompt=prompt,
                model="models/gemini-2.0-flash",
                auto_execute=True,
                max_tool_calls=5
            )
            
            if agent_result.get("success"):
                response_text = agent_result.get("response_text", "")
                tools_called = agent_result.get("tools_called", [])
                
                # Th√™m th√¥ng tin v·ªÅ tools ƒë√£ g·ªçi
                if tools_called:
                    response_text += f"\n\nüõ†Ô∏è ƒê√£ th·ª±c thi: {', '.join(tools_called)}"
                
                # L∆∞u v√†o conversation history
                add_to_conversation(
                    role="assistant",
                    content=response_text,
                    metadata={
                        "source": "gemini_agent",
                        "action": agent_result.get("action"),
                        "tools_called": tools_called,
                        "model": "gemini-2.0-flash"
                    }
                )
                
                return {
                    "success": True,
                    "prompt": prompt,
                    "response": response_text,
                    "response_text": response_text,
                    "model": "gemini-2.0-flash",
                    "agent_mode": True,
                    "action": agent_result.get("action"),
                    "tools_called": tools_called,
                    "tools_results": agent_result.get("tools_results", []),
                    "message": f"ü§ñ Gemini Agent ƒë√£ th·ª±c thi {len(tools_called)} l·ªánh"
                }
            else:
                print(f"‚ö†Ô∏è [ask_gemini] Agent failed: {agent_result.get('error')}, falling back...")
        except Exception as e:
            print(f"‚ö†Ô∏è [ask_gemini] Agent error: {e}, falling back...")
    
    # L∆∞u user message v√†o history
    add_to_conversation(
        role="user",
        content=prompt,
        metadata={
            "source": "web_ui",
            "model_requested": model,
            "ai_provider": "gemini"
        }
    )
    
    # üÜï STEP 0: Ki·ªÉm tra c√≥ c·∫ßn Google Search kh√¥ng
    realtime_keywords = [
        # Gi√° c·∫£, t√†i ch√≠nh
        'gi√° v√†ng', 'gi√° usd', 't·ª∑ gi√°', 'gi√° bitcoin', 'crypto', 'ch·ª©ng kho√°n',
        'gold price', 'exchange rate', 'gi√° xƒÉng', 'gi√° d·∫ßu', 'gi√° cao nh·∫•t', 'gi√° m·ªõi nh·∫•t',
        'stock', 'bitcoin', 'ethereum', 'btc', 'eth',
        
        # Th·ªùi ti·∫øt
        'th·ªùi ti·∫øt', 'weather', 'nhi·ªát ƒë·ªô', 'temperature', 'm∆∞a', 'b√£o',
        
        # Tin t·ª©c, s·ª± ki·ªán
        'tin t·ª©c', 'news', 'm·ªõi nh·∫•t', 'latest', 'breaking', 's·ª± ki·ªán',
        
        # Th·ªùi gian th·ª±c
        'h√¥m nay', 'b√¢y gi·ªù', 'hi·ªán nay', 'hi·ªán t·∫°i', 'today', 'now', 'current',
        'nƒÉm 2024', 'nƒÉm 2025', 'nƒÉm 2026', '2024', '2025', '2026',
        
        # Th·ªÉ thao, cu·ªôc thi
        'v√¥ ƒë·ªãch', 'champion', 'winner', 'k·∫øt qu·∫£', 'score', 'result',
        'world cup', 'euro', 'sea games', 'olympic', 'b√≥ng ƒë√°', 'football',
        
        # Ng∆∞·ªùi n·ªïi ti·∫øng, ch√≠nh tr·ªã
        't·ªïng th·ªëng', 'president', 'th·ªß t∆∞·ªõng', 'ch·ªß t·ªãch', 'ceo',
        'ai l√†', 'who is', 'who won',
        
        # S·∫£n ph·∫©m, c√¥ng ngh·ªá
        'iphone', 'samsung', 'tesla', 'apple', 'google', 'microsoft',
        'ra m·∫Øt', 'launch', 'release', 'announced',
        
        # Tra c·ª©u chung c·∫ßn th√¥ng tin m·ªõi
        'l√† ai', 'l√† g√¨', '·ªü ƒë√¢u', 'what is', 'where is', 'how much', 'bao nhi√™u',
        'khi n√†o', 'when', 'how many'
    ]
    prompt_lower = prompt.lower()
    needs_google_search = use_google_search and any(kw in prompt_lower for kw in realtime_keywords)
    
    # üîç N·∫øu c·∫ßn Google Search, ∆∞u ti√™n d√πng Gemini + Google Search Grounding
    if needs_google_search:
        print(f"üîç [ask_gemini] Ph√°t hi·ªán c√¢u h·ªèi c·∫ßn Google Search: {prompt[:50]}...")
        try:
            google_result = await ask_gemini_with_google_search(
                prompt=prompt,
                model="gemini-2.0-flash"  # Model h·ªó tr·ª£ grounding t·ªët nh·∫•t
            )
            
            if google_result.get("success"):
                response_text = google_result.get("response", "")
                
                # L∆∞u v√†o conversation history
                add_to_conversation(
                    role="assistant",
                    content=response_text,
                    metadata={
                        "source": "web_ui_google_search",
                        "model": google_result.get("model"),
                        "google_search_used": True,
                        "search_queries": google_result.get("search_queries", [])
                    }
                )
                
                return {
                    "success": True,
                    "prompt": prompt,
                    "response": response_text,
                    "response_text": response_text,
                    "model": google_result.get("model"),
                    "google_search_used": True,
                    "search_queries": google_result.get("search_queries", []),
                    "grounding_chunks": google_result.get("grounding_chunks", []),
                    "message": f"‚úÖ Gemini ƒë√£ tra c·ª©u Google v√† tr·∫£ l·ªùi (model: {google_result.get('model')})"
                }
            else:
                print(f"‚ö†Ô∏è [ask_gemini] Google Search failed: {google_result.get('error')}, falling back to KB...")
        except Exception as e:
            print(f"‚ö†Ô∏è [ask_gemini] Google Search error: {e}, falling back to KB...")
    
    # üÜï AUTO-READ ALL KNOWLEDGE BASE (B·∫ÆT BU·ªòC) - Fallback n·∫øu Google Search kh√¥ng d√πng/fail
    enhanced_prompt = prompt
    kb_context_used = False
    
    if use_knowledge_base:  # Lu√¥n = True
        try:
            # ƒê·ªåC TO√ÄN B·ªò Knowledge Base - KH√îNG filter theo query
            kb_result = await get_knowledge_context(
                query="",  # ƒê·ªÇ TR·ªêNG ƒë·ªÉ l·∫•y T·∫§T C·∫¢ documents
                max_chars=50000,  # TƒÉng gi·ªõi h·∫°n ƒë·ªÉ ƒë·ªçc nhi·ªÅu h∆°n
                use_gemini_summary=True  # B·∫≠t Gemini t√≥m t·∫Øt
            )
            
            if kb_result.get("success") and kb_result.get("context"):
                kb_context = kb_result["context"]
                docs_count = kb_result.get("documents_included", 0)
                
                # Th√™m context v√†o prompt
                enhanced_prompt = f"""üìö KNOWLEDGE BASE - TO√ÄN B·ªò C∆† S·ªû D·ªÆ LI·ªÜU ({docs_count} t√†i li·ªáu):
{kb_context}

{'='*60}
‚ùì C√ÇU H·ªéI C·ª¶A USER:
{prompt}

{'='*60}
üí° H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
- B·∫°n ƒë√£ c√≥ TO√ÄN B·ªò n·ªôi dung Knowledge Base ·ªü tr√™n
- Ph√¢n t√≠ch v√† t√≥m t·∫Øt th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi
- Tr·∫£ l·ªùi D·ª∞A TR√äN d·ªØ li·ªáu c√≥ s·∫µn, KH√îNG ƒëo√°n m√≤
- Tr√≠ch d·∫´n ngu·ªìn c·ª• th·ªÉ (t√™n file, ph·∫ßn n·ªôi dung)
- N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin, h√£y n√≥i r√µ "Kh√¥ng c√≥ trong c∆° s·ªü d·ªØ li·ªáu"
"""
                kb_context_used = True
                print(f"‚úÖ [KB] Loaded ALL Knowledge Base: {docs_count} documents, {len(kb_context)} chars")
            else:
                print(f"‚ö†Ô∏è [KB] Knowledge Base is empty or not indexed yet")
        except Exception as e:
            print(f"‚ö†Ô∏è [KB] Error getting context: {e}")
            # Kh√¥ng c√≥ context, d√πng prompt g·ªëc
    
    # G·ªçi Gemini v·ªõi enhanced prompt
    result = await ask_gemini(prompt=enhanced_prompt, model=model)
    
    # Th√™m metadata v·ªÅ KB usage
    if kb_context_used and result.get("success"):
        result["knowledge_base_used"] = True
        result["message"] = result.get("response", "") + "\n\nüìö *Tr·∫£ l·ªùi d·ª±a tr√™n Knowledge Base c·ªßa b·∫°n*"
    
    # L∆∞u AI response v√†o history
    if result.get("success"):
        add_to_conversation(
            role="assistant",
            content=result.get("response", ""),
            metadata={
                "source": "web_ui",
                "model": model,
                "ai_provider": "gemini",
                "knowledge_base_used": kb_context_used,
                "token_count": result.get("token_count", 0) if "token_count" in result else None
            }
        )
    
    return result


# ===== ü§ñ GEMINI AGENT - ƒêI·ªÄU KHI·ªÇN M√ÅY T√çNH API =====

@app.post("/api/gemini/agent")
async def api_gemini_agent(data: dict):
    """
    ü§ñ GEMINI AI AGENT - Cho ph√©p Gemini ƒëi·ªÅu khi·ªÉn m√°y t√≠nh
    
    Endpoint n√†y cho ph√©p g·ªçi Gemini AI ƒë·ªÉ T·ª∞ ƒê·ªòNG th·ª±c thi c√°c MCP tools
    nh∆∞ LLM Xiaozhi, bao g·ªìm:
    - M·ªü/ƒë√≥ng ·ª©ng d·ª•ng (Notepad, Chrome, VLC, Spotify...)
    - ƒêi·ªÅu khi·ªÉn nh·∫°c (play, pause, volume, next, previous...)
    - ƒêi·ªÅu khi·ªÉn h·ªá th·ªëng (shutdown, restart, lock, sleep...)
    - Ch·ª•p m√†n h√¨nh, l·∫•y th√¥ng tin h·ªá th·ªëng
    - T√¨m ki·∫øm web, m·ªü website
    
    Args (JSON body):
        prompt (str): L·ªánh ƒëi·ªÅu khi·ªÉn m√°y t√≠nh
        model (str, optional): Model Gemini (default: gemini-2.0-flash)
        auto_execute (bool, optional): T·ª± ƒë·ªông th·ª±c thi (default: True)
        max_tool_calls (int, optional): S·ªë tools t·ªëi ƒëa (default: 5)
        
    Returns:
        success: True/False
        action: "executed", "respond", "suggest", "clarify"
        response_text: Ph·∫£n h·ªìi t·ª´ Gemini
        tools_called: List c√°c tools ƒë√£ g·ªçi
        tools_results: K·∫øt qu·∫£ t·ª´ng tool
        
    Example:
        POST /api/gemini/agent
        {"prompt": "m·ªü notepad v√† chrome"}
        
        POST /api/gemini/agent  
        {"prompt": "ph√°t nh·∫°c r·ªìi tƒÉng volume l√™n 80"}
        
        POST /api/gemini/agent
        {"prompt": "t·∫Øt m√°y sau 10 ph√∫t"}
    """
    prompt = data.get("prompt", data.get("query", data.get("text", "")))
    model = data.get("model", "models/gemini-2.0-flash")
    auto_execute = data.get("auto_execute", True)
    max_tool_calls = data.get("max_tool_calls", 5)
    
    if not prompt:
        raise HTTPException(400, "Prompt is required")
    
    print(f"\n{'='*70}")
    print(f"ü§ñ [API Gemini Agent] Received: '{prompt}'")
    print(f"   Model: {model}, Auto-execute: {auto_execute}, Max tools: {max_tool_calls}")
    print(f"{'='*70}")
    
    # L∆∞u user message v√†o history
    add_to_conversation(
        role="user",
        content=f"[GEMINI AGENT] {prompt}",
        metadata={
            "source": "gemini_agent",
            "model": model,
            "auto_execute": auto_execute
        }
    )
    
    try:
        # G·ªçi Gemini Agent
        result = await ask_gemini_with_tools(
            prompt=prompt,
            model=model,
            auto_execute=auto_execute,
            max_tool_calls=max_tool_calls
        )
        
        if result.get("success"):
            # L∆∞u assistant response
            add_to_conversation(
                role="assistant",
                content=result.get("response_text", ""),
                metadata={
                    "source": "gemini_agent",
                    "action": result.get("action"),
                    "tools_called": result.get("tools_called", []),
                    "model": model
                }
            )
        
        return {
            "success": result.get("success", False),
            "prompt": prompt,
            "action": result.get("action", "respond"),
            "response_text": result.get("response_text", ""),
            "response": result.get("response_text", ""),  # Alias
            "tools_called": result.get("tools_called", []),
            "tools_results": result.get("tools_results", []),
            "tools_suggested": result.get("tools_suggested", []),
            "explanation": result.get("explanation", ""),
            "message": result.get("message", ""),
            "model": model,
            "auto_execute": auto_execute
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "prompt": prompt
        }


@app.post("/api/tool/gemini_agent")
async def api_tool_gemini_agent(data: dict):
    """
    Alias endpoint cho /api/gemini/agent ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi tool calling
    """
    return await api_gemini_agent(data)


# ===== TTS (Text-to-Speech) API =====
# Global variable ƒë·ªÉ track tr·∫°ng th√°i TTS
tts_is_playing = False
tts_stop_requested = False

@app.post("/api/tts")
async def api_text_to_speech(data: dict):
    """
    API ƒë·ªçc to vƒÉn b·∫£n - ∆Øu ti√™n Gemini TTS, fallback to gTTS/SAPI
    ‚ö° FAST MODE: Ch·ªâ ƒë·ªçc 500 k√Ω t·ª± ƒë·∫ßu ƒë·ªÉ response nhanh
    """
    global tts_is_playing, tts_stop_requested
    
    print(f"üîä [TTS API] Received request")
    
    text = data.get("text", "")
    if not text:
        print("‚ùå [TTS API] No text provided")
        return {"success": False, "error": "Kh√¥ng c√≥ vƒÉn b·∫£n ƒë·ªÉ ƒë·ªçc"}
    
    # ‚ö° FAST MODE: Gi·ªõi h·∫°n 500 k√Ω t·ª± ƒë·ªÉ TTS nhanh (real-time feel)
    max_chars = 500
    original_length = len(text)
    if len(text) > max_chars:
        # C·∫Øt t·∫°i d·∫•u c√¢u g·∫ßn nh·∫•t ƒë·ªÉ kh√¥ng b·ªã c·∫Øt gi·ªØa t·ª´
        cut_text = text[:max_chars]
        last_sentence = max(
            cut_text.rfind('.'),
            cut_text.rfind('!'),
            cut_text.rfind('?'),
            cut_text.rfind('„ÄÇ')
        )
        if last_sentence > max_chars // 2:
            text = text[:last_sentence + 1]
        else:
            text = cut_text
        print(f"üîä [TTS API] Truncated from {original_length} to {len(text)} chars for fast response")
    
    # Lo·∫°i b·ªè markdown formatting
    text = clean_markdown_for_tts(text)
    
    tts_is_playing = True
    tts_stop_requested = False
    
    try:
        # ∆Øu ti√™n Gemini TTS (ch·∫•t l∆∞·ª£ng cao)
        print(f"üéôÔ∏è [TTS API] Trying Gemini TTS ({len(text)} chars)...")
        voice = data.get("voice", "Aoede")  # Default female voice
        result = await gemini_text_to_speech(text, voice=voice, save_audio=False)
        
        if result.get("success"):
            print(f"‚úÖ [TTS API] Gemini TTS success!")
            tts_is_playing = False
            return result
        
        # Fallback to gTTS/SAPI
        print(f"‚ö†Ô∏è [TTS API] Gemini TTS failed, falling back to gTTS/SAPI...")
        result = await text_to_speech(text, save_audio=False)
        print(f"üîä [TTS API] Result: {result}")
        tts_is_playing = False
        return result
    except Exception as e:
        print(f"‚ùå [TTS API] Error: {e}")
        import traceback
        traceback.print_exc()
        tts_is_playing = False
        return {"success": False, "error": str(e)}


@app.post("/api/tts/stop")
async def api_tts_stop():
    """
    D·ª´ng TTS ƒëang ph√°t
    """
    global tts_is_playing, tts_stop_requested
    
    tts_stop_requested = True
    
    try:
        import pygame
        if pygame.mixer.get_init():
            pygame.mixer.music.stop()
            pygame.mixer.quit()
        tts_is_playing = False
        return {"success": True, "message": "ƒê√£ d·ª´ng TTS"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/tts/status")
async def api_tts_status():
    """
    Ki·ªÉm tra tr·∫°ng th√°i TTS
    """
    global tts_is_playing
    return {"is_playing": tts_is_playing}


@app.post("/api/tool/open_application")
async def api_open_app(data: dict):
    result = await open_application(data.get("app_name", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

# MEDIA PLAYER CONTROL ENDPOINTS
@app.post("/api/tool/media_play_pause")
async def api_media_play_pause(data: dict):
    result = await media_play_pause()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/media_next_track")
async def api_media_next(data: dict):
    result = await media_next_track()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/media_previous_track")
async def api_media_previous(data: dict):
    result = await media_previous_track()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/media_stop")
async def api_media_stop(data: dict):
    result = await media_stop()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/media_control")
async def api_media_control(data: dict):
    result = await media_control(data.get("action", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_active_media_players")
async def api_get_active_media(data: dict):
    result = await get_active_media_players()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/list_running_processes")
async def api_list_procs(data: dict):
    result = await list_running_processes(data.get("limit", 10))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/kill_process")
async def api_kill_proc(data: dict):
    result = await kill_process(data.get("identifier", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/create_file")
async def api_create_file(data: dict):
    result = await create_file(data.get("path", ""), data.get("content", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/read_file")
async def api_read_file(data: dict):
    result = await read_file(data.get("path", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/list_files")
async def api_list_files(data: dict):
    result = await list_files(data.get("directory", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_disk_usage")
async def api_disk_usage():
    result = await get_disk_usage()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_network_info")
async def api_network():
    result = await get_network_info()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_battery_status")
async def api_battery():
    result = await get_battery_status()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/search_web")
async def api_search(data: dict):
    result = await search_web(data.get("query", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_clipboard")
async def api_get_clip():
    result = await get_clipboard()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/set_clipboard")
async def api_set_clip(data: dict):
    result = await set_clipboard(data.get("text", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/play_sound")
async def api_sound(data: dict):
    result = await play_sound(data.get("frequency", 1000), data.get("duration", 500))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/set_volume")
async def api_tool_set_volume(data: dict):
    result = await set_volume(data.get("level", 50))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/set_brightness")
async def api_brightness(data: dict):
    result = await set_brightness(data.get("level", 50))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/mute_volume")
async def api_mute_volume(data: dict):
    result = await mute_volume()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/unmute_volume")
async def api_unmute_volume(data: dict):
    result = await unmute_volume()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/volume_up")
async def api_volume_up(data: dict):
    result = await volume_up(data.get("steps", 5))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/volume_down")
async def api_volume_down(data: dict):
    result = await volume_down(data.get("steps", 5))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/minimize_all_windows")
async def api_minimize():
    result = await show_desktop()  # S·ª≠ d·ª•ng show_desktop thay v√¨ minimize_all_windows
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/undo_action")
async def api_undo():
    result = await undo_operation()  # S·ª≠ d·ª•ng undo_operation thay v√¨ undo_action
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/toggle_dark_mode")
async def api_theme():
    result = await set_theme(dark_mode=None)  # Toggle b·∫±ng c√°ch ƒë·ªÉ None, h√†m set_theme s·∫Ω x·ª≠ l√Ω
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/change_wallpaper")
async def api_change_wallpaper(data: dict):
    """ƒê·ªïi h√¨nh n·ªÅn - endpoint cho Web UI"""
    keyword = data.get("keyword", "")
    path = data.get("path", "")
    result = await change_wallpaper(keyword=keyword, custom_path=path)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/set_wallpaper")
async def api_wallpaper(data: dict):
    """Alias c·ªßa change_wallpaper"""
    path = data.get("path", "")
    keyword = data.get("keyword", "")
    result = await change_wallpaper(keyword=keyword, custom_path=path)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/paste_text")
async def api_paste():
    result = await paste_content(content="")  # paste_content v·ªõi clipboard hi·ªán t·∫°i
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/press_enter")
async def api_enter():
    result = await press_enter()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/find_on_screen")
async def api_find(data: dict):
    result = await find_in_document(data.get("text", ""))  # S·ª≠ d·ª•ng find_in_document
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/lock_computer")
async def api_lock():
    result = await lock_computer()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/shutdown_schedule")
async def api_shutdown_schedule(data: dict):
    """L√™n l·ªãch t·∫Øt/kh·ªüi ƒë·ªông l·∫°i m√°y"""
    action = data.get("action", "shutdown")
    delay = data.get("delay", 60)
    result = await shutdown_schedule(action=action, delay=delay)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/show_desktop")
async def api_show_desktop():
    """Hi·ªÉn th·ªã Desktop (minimize all windows)"""
    result = await show_desktop()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/undo_operation")
async def api_undo_operation():
    """Ho√†n t√°c thao t√°c (Ctrl+Z)"""
    result = await undo_operation()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/set_theme")
async def api_set_theme(data: dict):
    """ƒê·ªïi theme (s√°ng/t·ªëi)"""
    dark_mode = data.get("dark_mode", True)
    result = await set_theme(dark_mode=dark_mode)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_desktop_path")
async def api_get_desktop_path():
    """L·∫•y ƒë∆∞·ªùng d·∫´n Desktop"""
    result = await get_desktop_path()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/paste_content")
async def api_paste_content(data: dict):
    """D√°n n·ªôi dung t·ª´ clipboard ho·∫∑c text t√πy ch·ªçn"""
    content = data.get("content", "")
    result = await paste_content(content=content)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/find_in_document")
async def api_find_in_document(data: dict):
    """T√¨m ki·∫øm trong t√†i li·ªáu (Ctrl+F)"""
    search_text = data.get("search_text", "")
    result = await find_in_document(search_text=search_text)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/shutdown_computer")
async def api_shutdown(data: dict):
    delay = data.get("delay", 0)
    # S·ª≠ d·ª•ng shutdown_schedule v·ªõi action="shutdown"
    result = await shutdown_schedule(action="shutdown", delay=delay)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result


@app.get("/logo.png")
async def get_logo():
    from fastapi.responses import FileResponse
    import os
    import sys
    
    # T√¨m logo theo th·ª© t·ª± ∆∞u ti√™n
    possible_paths = []
    
    # 1. PyInstaller frozen EXE - trong th∆∞ m·ª•c _internal ho·∫∑c c√πng th∆∞ m·ª•c EXE
    if getattr(sys, 'frozen', False):
        exe_dir = os.path.dirname(sys.executable)
        possible_paths.extend([
            os.path.join(exe_dir, "_internal", "logo.png"),
            os.path.join(exe_dir, "logo.png"),
            os.path.join(getattr(sys, '_MEIPASS', exe_dir), "logo.png"),
        ])
    
    # 2. Th∆∞ m·ª•c script
    possible_paths.append(os.path.join(os.path.dirname(__file__), "logo.png"))
    
    # 3. Th∆∞ m·ª•c l√†m vi·ªác hi·ªán t·∫°i
    possible_paths.append(os.path.join(os.getcwd(), "logo.png"))
    
    # T√¨m file ƒë·∫ßu ti√™n t·ªìn t·∫°i
    for logo_path in possible_paths:
        if os.path.exists(logo_path):
            return FileResponse(logo_path, media_type="image/png")
    
    # Log ƒë·ªÉ debug
    print(f"‚ö†Ô∏è Logo not found. Checked paths: {possible_paths}")
    raise HTTPException(404, "Logo not found")

@app.get("/api/endpoints")
async def get_endpoints():
    global GEMINI_API_KEY, OPENAI_API_KEY, SERPER_API_KEY
    return {
        "endpoints": endpoints_config,
        "active_index": active_endpoint_index,
        "gemini_api_key": GEMINI_API_KEY,
        "openai_api_key": OPENAI_API_KEY,
        "serper_api_key": SERPER_API_KEY
    }

@app.get("/api/endpoints/status")
async def get_endpoints_status():
    """üî• NEW: Get detailed endpoint connection status with stats"""
    status = {
        "endpoints": [],
        "active_index": active_endpoint_index,
        "total_connected": sum(1 for v in xiaozhi_connected.values() if v)
    }
    
    # Add detailed info for each endpoint
    for i, ep in enumerate(endpoints_config):
        endpoint_status = {
            "index": i,
            "name": ep.get("name", f"Thi·∫øt b·ªã {i+1}"),
            "enabled": ep.get("enabled", False),
            "has_token": bool(ep.get("token")),
            "connected": xiaozhi_connected.get(i, False),
            "is_active": i == active_endpoint_index
        }
        
        # Th√™m stats t·ª´ EndpointManager n·∫øu c√≥
        if ENDPOINT_MANAGER_AVAILABLE:
            try:
                manager = get_endpoint_manager()
                stats = manager.stats.get(i)
                if stats:
                    endpoint_status["stats"] = {
                        "total_connects": stats.total_connects,
                        "total_disconnects": stats.total_disconnects,
                        "total_errors": stats.total_errors,
                        "last_connected": stats.last_connected,
                        "last_error": stats.last_error,
                        "uptime_seconds": stats.uptime_seconds
                    }
            except Exception:
                pass
        
        status["endpoints"].append(endpoint_status)
    
    return status

@app.post("/api/endpoints/reconnect/{index}")
async def reconnect_endpoint(index: int):
    """üî• NEW: Force reconnect an endpoint"""
    global should_reconnect
    
    if index < 0 or index >= len(endpoints_config):
        return {"success": False, "error": f"Invalid index: {index}"}
    
    ep = endpoints_config[index]
    if not ep.get("token"):
        return {"success": False, "error": "Endpoint has no token"}
    
    # Trigger reconnect
    should_reconnect[index] = True
    
    # C·∫≠p nh·∫≠t EndpointManager n·∫øu c√≥
    if ENDPOINT_MANAGER_AVAILABLE:
        try:
            manager = get_endpoint_manager()
            manager.should_reconnect[index] = True
        except Exception:
            pass
    
    return {
        "success": True,
        "message": f"ƒêang reconnect {ep.get('name', f'Thi·∫øt b·ªã {index+1}')}..."
    }

# YouTube Playlists API
@app.get("/api/youtube_playlists")
async def api_get_youtube_playlists():
    """L·∫•y danh s√°ch playlist YouTube"""
    return await get_youtube_playlists()

@app.post("/api/youtube_playlists/add")
async def api_add_youtube_playlist(data: dict):
    """Th√™m playlist YouTube m·ªõi"""
    name = data.get("name", "").strip()
    url = data.get("url", "").strip()
    
    if not name or not url:
        return {"success": False, "error": "T√™n v√† URL kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"}
    
    return await add_youtube_playlist(name, url)

@app.post("/api/youtube_playlists/remove")
async def api_remove_youtube_playlist(data: dict):
    """X√≥a playlist YouTube"""
    name = data.get("name", "").strip()
    
    if not name:
        return {"success": False, "error": "T√™n playlist kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"}
    
    return await remove_youtube_playlist(name)

# ============================================================
# KNOWLEDGE BASE API - Qu·∫£n l√Ω d·ªØ li·ªáu cho LLM
# ============================================================

# File l∆∞u c·∫•u h√¨nh knowledge base - L∆∞u v√†o AppData ƒë·ªÉ tr√°nh Permission denied
def get_knowledge_data_dir():
    """L·∫•y th∆∞ m·ª•c l∆∞u tr·ªØ knowledge base data trong AppData"""
    if os.name == 'nt':  # Windows
        appdata = os.environ.get('LOCALAPPDATA', os.path.expanduser('~\\AppData\\Local'))
        data_dir = Path(appdata) / "miniZ_MCP" / "knowledge"
    else:  # Linux/Mac
        data_dir = Path.home() / ".miniz_mcp" / "knowledge"
    data_dir.mkdir(parents=True, exist_ok=True)
    return data_dir

KNOWLEDGE_DATA_DIR = get_knowledge_data_dir()
KNOWLEDGE_CONFIG_FILE = KNOWLEDGE_DATA_DIR / "knowledge_config.json"
KNOWLEDGE_INDEX_FILE = KNOWLEDGE_DATA_DIR / "knowledge_index.json"

# C√°c extension ƒë∆∞·ª£c h·ªó tr·ª£
SUPPORTED_EXTENSIONS = {'.pdf', '.txt', '.docx', '.doc', '.md', '.json', '.csv', '.xlsx', '.xls', '.rtf'}

def load_knowledge_config():
    """Load c·∫•u h√¨nh knowledge base"""
    if KNOWLEDGE_CONFIG_FILE.exists():
        try:
            # S·ª≠ d·ª•ng utf-8-sig ƒë·ªÉ t·ª± ƒë·ªông x·ª≠ l√Ω BOM
            with open(KNOWLEDGE_CONFIG_FILE, 'r', encoding='utf-8-sig') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è [Knowledge] Error loading config: {e}")
    return {"folder_path": "", "indexed_files": [], "last_update": ""}

def save_knowledge_config(config: dict):
    """L∆∞u c·∫•u h√¨nh knowledge base"""
    try:
        with open(KNOWLEDGE_CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"‚ùå [Knowledge] Error saving config: {e}")
        return False

def load_knowledge_index():
    """Load index ƒë√£ l∆∞u"""
    if KNOWLEDGE_INDEX_FILE.exists():
        try:
            # S·ª≠ d·ª•ng utf-8-sig ƒë·ªÉ t·ª± ƒë·ªông x·ª≠ l√Ω BOM
            with open(KNOWLEDGE_INDEX_FILE, 'r', encoding='utf-8-sig') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è [Knowledge] Error loading index: {e}")
    return {"documents": [], "total_chunks": 0, "last_update": ""}

# ============================================================
# VECTOR SEARCH ENGINE - Global Instance
# ============================================================

_vector_engine = None

def get_vector_engine():
    """L·∫•y ho·∫∑c kh·ªüi t·∫°o VectorSearchEngine"""
    global _vector_engine
    if _vector_engine is None and VECTOR_SEARCH_AVAILABLE:
        _vector_engine = VectorSearchEngine()
        
        # Try loading existing index - ki·ªÉm tra nhi·ªÅu v·ªã tr√≠
        vector_paths = [
            Path("test_vector.faiss"),  # Trong th∆∞ m·ª•c g·ªëc
            KNOWLEDGE_DATA_DIR / "vector_index.faiss",  # Trong AppData
            Path("vector_index.faiss")  # Backup trong g·ªëc
        ]
        
        for vector_index_path in vector_paths:
            if vector_index_path.exists():
                try:
                    # Remove .faiss extension for load_index
                    base_path = str(vector_index_path.with_suffix(''))
                    _vector_engine.load_index(base_path)
                    print(f"‚úÖ [VectorSearch] Loaded index from: {vector_index_path}")
                    print(f"   Statistics: {_vector_engine.get_statistics()}")
                    break
                except Exception as e:
                    print(f"‚ö†Ô∏è [VectorSearch] Failed to load {vector_index_path}: {e}")
                    continue
        else:
            print(f"‚ö†Ô∏è [VectorSearch] No valid index found in any location")
            
    return _vector_engine

def save_knowledge_index(index_data: dict):
    """L∆∞u index"""
    try:
        with open(KNOWLEDGE_INDEX_FILE, 'w', encoding='utf-8') as f:
            json.dump(index_data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"‚ùå [Knowledge] Error saving index: {e}")
        return False

async def summarize_with_gemini(text: str, filename: str) -> dict:
    """T√≥m t·∫Øt document b·∫±ng Gemini Flash (optimized)"""
    try:
        import google.generativeai as genai
        
        # Configure Gemini
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('models/gemini-3-flash-preview')
        
        # ‚ö° PROMPT NG·∫ÆN G·ªåN - ph·∫£n h·ªìi nhanh h∆°n
        prompt = f"""T√≥m t·∫Øt t√†i li·ªáu:

File: {filename}
N·ªôi dung: {text[:6000]}

Tr·∫£ v·ªÅ JSON:
{{
  "summary": "[2-3 c√¢u ch√≠nh]",
  "keywords": ["5-7 t·ª´ kh√≥a"],
  "key_quotes": ["2 tr√≠ch d·∫´n quan tr·ªçng"],
  "category": "[lo·∫°i: technical/business/etc]"
}}"""
        
        print(f"‚ö° [Gemini] T√≥m t·∫Øt: {filename[:30]}...")
        
        # ‚è±Ô∏è Timeout 12 gi√¢y
        loop = asyncio.get_event_loop()
        response = await asyncio.wait_for(
            loop.run_in_executor(None, lambda: model.generate_content(prompt)),
            timeout=12.0
        )
        
        # Parse JSON response
        import json
        result_text = response.text.strip()
        if result_text.startswith("```json"):
            result_text = result_text[7:]
        if result_text.endswith("```"):
            result_text = result_text[:-3]
        result_text = result_text.strip()
        
        result = json.loads(result_text)
        print(f"‚úÖ [Gemini] Done: {filename[:30]}")
        return result
        
    except asyncio.TimeoutError:
        print(f"‚è±Ô∏è [Gemini] Timeout: {filename}")
        return {
            "summary": text[:400] + "...",
            "keywords": [],
            "key_quotes": [],
            "category": "unknown"
        }
    except Exception as e:
        print(f"‚ö†Ô∏è [Gemini] Error {filename}: {e}")
        return {
            "summary": text[:400] + "...",
            "keywords": [],
            "key_quotes": [],
            "category": "unknown"
        }

def extract_text_from_file(file_path: str) -> str:
    """Tr√≠ch xu·∫•t text t·ª´ file"""
    ext = Path(file_path).suffix.lower()
    text = ""
    
    try:
        if ext == '.txt' or ext == '.md':
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                text = f.read()
        
        elif ext == '.json':
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                text = json.dumps(data, ensure_ascii=False, indent=2)
        
        elif ext == '.csv':
            import csv
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                reader = csv.reader(f)
                rows = [', '.join(row) for row in reader]
                text = '\n'.join(rows)
        
        elif ext == '.pdf':
            try:
                import PyPDF2
                with open(file_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
            except ImportError:
                # Fallback: Read as binary and extract text using basic regex
                print(f"‚ö†Ô∏è [Extract] PyPDF2 not installed, using fallback for {file_path}")
                try:
                    with open(file_path, 'rb') as f:
                        content = f.read()
                        import re
                        # Simple extraction: find readable ASCII/Unicode text
                        text = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f]+', ' ', 
                                     content.decode('latin1', errors='ignore'))
                        text = ' '.join(text.split())  # Clean whitespace
                except:
                    text = f"[PDF file - C·∫ßn c√†i PyPDF2: pip install PyPDF2]"
            except Exception as e:
                text = f"[L·ªói ƒë·ªçc PDF: {str(e)}]"
        
        elif ext in ['.docx', '.doc']:
            try:
                from docx import Document
                doc = Document(file_path)
                for para in doc.paragraphs:
                    text += para.text + "\n"
            except ImportError:
                # Fallback: Try reading docx as zip
                print(f"‚ö†Ô∏è [Extract] python-docx not installed, using fallback for {file_path}")
                try:
                    import zipfile
                    import xml.etree.ElementTree as ET
                    with zipfile.ZipFile(file_path) as docx:
                        xml_content = docx.read('word/document.xml')
                        tree = ET.XML(xml_content)
                        paragraphs = []
                        for paragraph in tree.iter('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}t'):
                            if paragraph.text:
                                paragraphs.append(paragraph.text)
                        text = '\n'.join(paragraphs)
                except:
                    text = f"[Word file - C·∫ßn c√†i python-docx: pip install python-docx]"
            except Exception as e:
                text = f"[L·ªói ƒë·ªçc Word: {str(e)}]"
        
        elif ext in ['.xlsx', '.xls']:
            try:
                import openpyxl
                print(f"‚úÖ [Extract] openpyxl loaded, reading: {file_path}")
                wb = openpyxl.load_workbook(file_path, data_only=True)
                rows_read = 0
                for sheet in wb.worksheets:
                    for row in sheet.iter_rows():
                        row_text = ', '.join([str(cell.value) if cell.value else '' for cell in row])
                        if row_text.strip():
                            text += row_text + "\n"
                            rows_read += 1
                print(f"‚úÖ [Extract] Excel read complete: {rows_read} rows")
            except ImportError as ie:
                print(f"‚ùå [Extract] openpyxl ImportError: {ie}")
                text = f"[Excel file - C·∫ßn c√†i openpyxl: pip install openpyxl]"
            except Exception as e:
                print(f"‚ùå [Extract] Excel error: {type(e).__name__}: {e}")
                text = f"[L·ªói ƒë·ªçc Excel: {str(e)}]"
        
        elif ext == '.rtf':
            try:
                from striprtf.striprtf import rtf_to_text
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    rtf_content = f.read()
                text = rtf_to_text(rtf_content)
            except ImportError:
                text = f"[RTF file - C·∫ßn c√†i striprtf: pip install striprtf]"
            except Exception as e:
                text = f"[L·ªói ƒë·ªçc RTF: {str(e)}]"
        
    except Exception as e:
        text = f"[L·ªói ƒë·ªçc file: {str(e)}]"
    
    return text.strip()

def scan_folder_for_files(folder_path: str) -> list:
    """Qu√©t th∆∞ m·ª•c v√† tr·∫£ v·ªÅ danh s√°ch files ƒë∆∞·ª£c h·ªó tr·ª£"""
    files = []
    folder = Path(folder_path)
    
    if not folder.exists():
        print(f"‚ùå [Scan] Folder not exists: {folder_path}")
        return files
    
    print(f"üìÇ [Scan] Scanning folder: {folder_path}")
    total_checked = 0
    
    for file_path in folder.rglob('*'):
        if file_path.is_file():
            total_checked += 1
            ext = file_path.suffix.lower()
            if ext in SUPPORTED_EXTENSIONS:
                try:
                    stat = file_path.stat()
                    files.append({
                        "name": file_path.name,
                        "path": str(file_path),
                        "size": stat.st_size,
                        "modified": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M"),
                        "extension": ext,
                        "indexed": False
                    })
                    print(f"  ‚úÖ Added: {file_path.name} ({ext})")
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Error scanning file {file_path}: {e}")
            else:
                print(f"  ‚è≠Ô∏è Skipped: {file_path.name} ({ext}) - Not supported")
    
    print(f"üìä [Scan] Result: {len(files)} files found (checked {total_checked} files)")
    return files

@app.get("/api/knowledge/status")
async def api_knowledge_status():
    """L·∫•y tr·∫°ng th√°i Knowledge Base"""
    config = load_knowledge_config()
    index = load_knowledge_index()
    
    folder_path = config.get("folder_path", "")
    files = []
    total_size = 0
    
    if folder_path and Path(folder_path).exists():
        files = scan_folder_for_files(folder_path)
        total_size = sum(f["size"] for f in files)
        
        # ƒê√°nh d·∫•u c√°c file ƒë√£ ƒë∆∞·ª£c index
        indexed_paths = set(config.get("indexed_files", []))
        for f in files:
            f["indexed"] = f["path"] in indexed_paths
    
    return {
        "success": True,
        "folder_path": folder_path,
        "total_files": len(files),
        "indexed_files": len(config.get("indexed_files", [])),
        "total_size": total_size,
        "last_update": config.get("last_update", "--"),
        "files": files
    }

@app.post("/api/knowledge/set_folder")
async def api_knowledge_set_folder(data: dict):
    """C·∫•u h√¨nh th∆∞ m·ª•c knowledge base"""
    folder_path = data.get("folder_path", "").strip()
    
    if not folder_path:
        return {"success": False, "error": "ƒê∆∞·ªùng d·∫´n kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"}
    
    # Ki·ªÉm tra th∆∞ m·ª•c t·ªìn t·∫°i
    if not Path(folder_path).exists():
        return {"success": False, "error": f"Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {folder_path}"}
    
    if not Path(folder_path).is_dir():
        return {"success": False, "error": "ƒê∆∞·ªùng d·∫´n ph·∫£i l√† th∆∞ m·ª•c, kh√¥ng ph·∫£i file"}
    
    config = load_knowledge_config()
    config["folder_path"] = folder_path
    config["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
    
    if save_knowledge_config(config):
        return {"success": True, "message": f"ƒê√£ l∆∞u th∆∞ m·ª•c: {folder_path}"}
    else:
        return {"success": False, "error": "L·ªói khi l∆∞u c·∫•u h√¨nh"}

@app.post("/api/knowledge/scan")
async def api_knowledge_scan(data: dict):
    """Qu√©t th∆∞ m·ª•c ƒë·ªÉ t√¨m files"""
    folder_path = data.get("folder_path", "").strip()
    
    if not folder_path:
        config = load_knowledge_config()
        folder_path = config.get("folder_path", "")
    
    if not folder_path:
        return {"success": False, "error": "Ch∆∞a c·∫•u h√¨nh th∆∞ m·ª•c"}
    
    if not Path(folder_path).exists():
        return {"success": False, "error": f"Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {folder_path}"}
    
    files = scan_folder_for_files(folder_path)
    total_size = sum(f["size"] for f in files)
    
    # C·∫≠p nh·∫≠t config
    config = load_knowledge_config()
    config["folder_path"] = folder_path
    indexed_paths = set(config.get("indexed_files", []))
    for f in files:
        f["indexed"] = f["path"] in indexed_paths
    save_knowledge_config(config)
    
    return {
        "success": True,
        "total_files": len(files),
        "total_size": total_size,
        "files": files
    }

@app.post("/api/knowledge/index_all")
async def api_knowledge_index_all():
    """Index t·∫•t c·∫£ files trong th∆∞ m·ª•c (parallel processing)"""
    config = load_knowledge_config()
    folder_path = config.get("folder_path", "")
    
    if not folder_path or not Path(folder_path).exists():
        return {"success": False, "error": "Ch∆∞a c·∫•u h√¨nh th∆∞ m·ª•c ho·∫∑c th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i"}
    
    files = scan_folder_for_files(folder_path)
    print(f"‚ö° [Index] Starting parallel indexing of {len(files)} files...")
    
    # ‚ö° PARALLEL PROCESSING: Index nhi·ªÅu files c√πng l√∫c
    async def index_single_file(file_info):
        try:
            text = extract_text_from_file(file_info["path"])
            
            # Check if extraction failed
            if not text or len(text.strip()) < 10:
                print(f"‚ö†Ô∏è [Index] Skipped {file_info['name']}: No text extracted")
                return None
                
            if text.startswith("["):  # Error message from extract_text_from_file
                print(f"‚ö†Ô∏è [Index] Skipped {file_info['name']}: {text}")
                return None
            
            print(f"üìÑ [Index] Processing {file_info['name']} ({len(text)} chars)...")
            
            # T√≥m t·∫Øt b·∫±ng Gemini Flash
            ai_summary = await summarize_with_gemini(text, file_info["name"])
            
            if not ai_summary or not ai_summary.get("summary"):
                print(f"‚ö†Ô∏è [Index] No summary for {file_info['name']}")
                # Still index with basic info
                ai_summary = {
                    "summary": text[:400] + "...",
                    "keywords": [],
                    "key_quotes": [],
                    "category": "general"
                }
            
            result = {
                "file_path": file_info["path"],
                "file_name": file_info["name"],
                "content": text[:50000],  # Gi·ªõi h·∫°n 50k k√Ω t·ª± m·ªói file
                "summary": ai_summary.get("summary", ""),
                "keywords": ai_summary.get("keywords", []),
                "key_quotes": ai_summary.get("key_quotes", []),
                "category": ai_summary.get("category", "general"),
                "indexed_at": datetime.now().isoformat()
            }
            print(f"‚úÖ [Index] Indexed {file_info['name']}")
            return result
            
        except Exception as e:
            print(f"‚ùå [Index] Error indexing {file_info['name']}: {e}")
            return None
    
    # Process files in parallel (batch of 5 at a time to avoid API rate limits)
    documents = []
    batch_size = 5
    for i in range(0, len(files), batch_size):
        batch = files[i:i+batch_size]
        results = await asyncio.gather(*[index_single_file(f) for f in batch], return_exceptions=True)
        documents.extend([r for r in results if r and not isinstance(r, Exception)])
        print(f"‚ö° [Index] Processed {min(i+batch_size, len(files))}/{len(files)} files...")
    
    indexed_count = len(documents)
    
    # L∆∞u index
    index_data = {
        "documents": documents,
        "total_chunks": indexed_count,
        "last_update": datetime.now().strftime("%Y-%m-%d %H:%M")
    }
    save_knowledge_index(index_data)
    
    # üÜï BUILD VECTOR INDEX with FAISS
    if VECTOR_SEARCH_AVAILABLE and documents:
        try:
            print(f"üî® [VectorSearch] Building vector index for {len(documents)} documents...")
            vector_engine = get_vector_engine()
            
            # Prepare documents in correct format: [{"id": str, "text": str, "metadata": dict}]
            documents_data = [
                {
                    "id": f"doc_{i}",
                    "text": doc["content"],
                    "metadata": {
                        "file_name": doc["file_name"],
                        "file_path": doc["file_path"],
                        "index": i
                    }
                }
                for i, doc in enumerate(documents)
            ]
            
            # Build and save index
            vector_engine.build_index(documents_data)
            vector_engine.save_index()
            
            stats = vector_engine.get_statistics()
            print(f"‚úÖ [VectorSearch] Index built: {stats['num_vectors']} vectors, {stats['embedding_dim']} dims")
        except Exception as e:
            print(f"‚ö†Ô∏è [VectorSearch] Failed to build index: {e}")
    
    # C·∫≠p nh·∫≠t config
    config["indexed_files"] = [f["path"] for f in files if any(d["file_path"] == f["path"] for d in documents)]
    config["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
    save_knowledge_config(config)
    
    return {
        "success": True,
        "message": f"ƒê√£ index {indexed_count}/{len(files)} files",
        "indexed_count": indexed_count,
        "last_update": index_data["last_update"]
    }

@app.post("/api/knowledge/index_file")
async def api_knowledge_index_file(data: dict):
    """Index m·ªôt file c·ª• th·ªÉ"""
    file_path = data.get("file_path", "").strip()
    
    if not file_path or not Path(file_path).exists():
        return {"success": False, "error": "File kh√¥ng t·ªìn t·∫°i"}
    
    try:
        file_name = Path(file_path).name
        print(f"üìÑ [Index] Starting index: {file_name}")
        
        text = extract_text_from_file(file_path)
        if not text or text.startswith("["):
            print(f"‚ùå [Index] Failed to extract: {file_name} - {text[:100] if text else 'Empty'}")
            return {"success": False, "error": f"Kh√¥ng th·ªÉ ƒë·ªçc file: {text}"}
        
        print(f"üìù [Index] Extracted {len(text)} chars from {file_name}")
        
        # Load existing index
        index_data = load_knowledge_index()
        
        # Remove existing entry for this file
        index_data["documents"] = [d for d in index_data["documents"] if d["file_path"] != file_path]
        
        # üÜï TRY summarize, nh∆∞ng fallback n·∫øu fail
        ai_summary = {"summary": "", "keywords": [], "key_quotes": [], "category": "general"}
        try:
            ai_summary = await asyncio.wait_for(
                summarize_with_gemini(text, file_name),
                timeout=30.0  # 30s timeout
            )
            print(f"‚úÖ [Index] AI Summary done for {file_name}")
        except asyncio.TimeoutError:
            print(f"‚ö†Ô∏è [Index] AI Summary timeout for {file_name}, using basic index")
            ai_summary["summary"] = text[:500] + "..."
        except Exception as e:
            print(f"‚ö†Ô∏è [Index] AI Summary error for {file_name}: {e}, using basic index")
            ai_summary["summary"] = text[:500] + "..."
        
        # Add new entry
        index_data["documents"].append({
            "file_path": file_path,
            "file_name": file_name,
            "content": text[:50000],
            "summary": ai_summary.get("summary", ""),
            "keywords": ai_summary.get("keywords", []),
            "key_quotes": ai_summary.get("key_quotes", []),
            "category": ai_summary.get("category", "general"),
            "indexed_at": datetime.now().isoformat()
        })
        index_data["total_chunks"] = len(index_data["documents"])
        index_data["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
        
        save_knowledge_index(index_data)
        print(f"‚úÖ [Index] Saved: {file_name} (total: {index_data['total_chunks']} docs)")
        
        # Update config
        config = load_knowledge_config()
        if file_path not in config.get("indexed_files", []):
            config.setdefault("indexed_files", []).append(file_path)
        config["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
        save_knowledge_config(config)
        
        return {"success": True, "message": f"ƒê√£ index: {file_name}"}
    
    except Exception as e:
        print(f"‚ùå [Index] Error indexing {file_path}: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/knowledge/clear")
async def api_knowledge_clear():
    """X√≥a to√†n b·ªô index"""
    try:
        # Clear index file
        save_knowledge_index({"documents": [], "total_chunks": 0, "last_update": ""})
        
        # Update config
        config = load_knowledge_config()
        config["indexed_files"] = []
        config["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
        save_knowledge_config(config)
        
        return {"success": True, "message": "ƒê√£ x√≥a to√†n b·ªô index"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/knowledge/search")
async def api_knowledge_search(query: str = ""):
    """T√¨m ki·∫øm trong knowledge base"""
    if not query:
        return {"success": False, "error": "Vui l√≤ng nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm"}
    
    index_data = load_knowledge_index()
    documents = index_data.get("documents", [])
    
    if not documents:
        return {"success": False, "error": "Knowledge base ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng index files tr∆∞·ªõc."}
    
    # AI-powered search - t√¨m trong summary, keywords v√† content
    query_lower = query.lower()
    results = []
    
    for doc in documents:
        score = 0
        matched_in = []
        
        # T√¨m trong summary (ƒëi·ªÉm cao nh·∫•t)
        summary = doc.get("summary", "")
        if query_lower in summary.lower():
            score += 10
            matched_in.append("summary")
        
        # T√¨m trong keywords (ƒëi·ªÉm trung b√¨nh)
        keywords = doc.get("keywords", [])
        for keyword in keywords:
            if query_lower in keyword.lower():
                score += 5
                matched_in.append("keywords")
                break
        
        # T√¨m trong content (ƒëi·ªÉm th·∫•p nh·∫•t)
        content = doc.get("content", "")
        if query_lower in content.lower():
            score += 1
            matched_in.append("content")
            
            # T√¨m ƒëo·∫°n text ch·ª©a query
            idx = content.lower().find(query_lower)
            start = max(0, idx - 200)
            end = min(len(content), idx + 200)
            snippet = content[start:end]
        else:
            snippet = summary[:400] if summary else content[:400]
        
        # Ch·ªâ th√™m v√†o results n·∫øu c√≥ match
        if score > 0:
            results.append({
                "file_name": doc.get("file_name", ""),
                "file_path": doc.get("file_path", ""),
                "summary": summary,
                "keywords": keywords,
                "category": doc.get("category", "general"),
                "snippet": "..." + snippet + "...",
                "score": score,
                "matched_in": matched_in,
                "indexed_at": doc.get("indexed_at", "")
            })
    
    # S·∫Øp x·∫øp theo score
    results.sort(key=lambda x: x["score"], reverse=True)
    
    return {
        "success": True,
        "query": query,
        "total_results": len(results),
        "results": results[:20]  # Gi·ªõi h·∫°n 20 k·∫øt qu·∫£
    }

@app.get("/api/knowledge/context")
async def api_knowledge_get_context(query: str = "", max_chars: int = 10000, use_gemini_summary: bool = True):
    """L·∫•y context t·ª´ knowledge base ƒë·ªÉ cung c·∫•p cho LLM - v·ªõi Gemini summarization"""
    result = await get_knowledge_context(query, max_chars, use_gemini_summary)
    return result
    
@app.get("/api/knowledge/context_legacy")
async def api_knowledge_get_context_legacy(query: str = "", max_chars: int = 10000):
    """Legacy endpoint - kh√¥ng d√πng Gemini summarization"""
    index_data = load_knowledge_index()
    documents = index_data.get("documents", [])
    
    if not documents:
        return {"success": False, "context": "", "message": "Knowledge base tr·ªëng"}
    
    context_parts = []
    total_chars = 0
    
    # N·∫øu c√≥ query, ∆∞u ti√™n c√°c document li√™n quan
    if query:
        query_lower = query.lower()
        # S·∫Øp x·∫øp theo ƒë·ªô li√™n quan
        scored_docs = []
        for doc in documents:
            content = doc.get("content", "")
            score = content.lower().count(query_lower)
            scored_docs.append((score, doc))
        scored_docs.sort(key=lambda x: x[0], reverse=True)
        documents = [d for _, d in scored_docs]
    
    for doc in documents:
        file_name = doc.get("file_name", "unknown")
        summary = doc.get("summary", "")
        keywords = doc.get("keywords", [])
        key_quotes = doc.get("key_quotes", [])
        category = doc.get("category", "general")
        
        # ∆Øu ti√™n d√πng summary v√† key_quotes thay v√¨ full content
        # ƒêi·ªÅu n√†y gi·∫£m ƒë√°ng k·ªÉ token v√† tƒÉng ch·∫•t l∆∞·ª£ng context
        
        # Build compact context
        compact_content = f"üìù {summary}\n"
        if keywords:
            compact_content += f"üîë Keywords: {', '.join(keywords[:5])}\n"
        if key_quotes:
            compact_content += f"üí¨ Tr√≠ch d·∫´n:\n"
            for quote in key_quotes[:3]:
                compact_content += f"  ‚Ä¢ {quote}\n"
        
        # Th√™m header cho m·ªói document
        header = f"\n\n=== [{category.upper()}] {file_name} ===\n"
        full_entry = header + compact_content
        
        if total_chars + len(full_entry) > max_chars:
            break
        else:
            context_parts.append(full_entry)
            total_chars += len(full_entry)
    
    full_context = "".join(context_parts)
    
    return {
        "success": True,
        "context": full_context,
        "total_documents": len(documents),
        "context_length": len(full_context)
    }

# ============================================================
# TASK MEMORY API - Ghi nh·ªõ t√°c v·ª• ƒë√£ th·ª±c hi·ªán
# ============================================================

@app.get("/api/tasks/recent")
async def api_get_recent_tasks(limit: int = 10):
    """L·∫•y c√°c t√°c v·ª• g·∫ßn ƒë√¢y"""
    tasks = get_recent_tasks(limit)
    return {
        "success": True,
        "count": len(tasks),
        "tasks": tasks
    }

@app.get("/api/tasks/search/{keyword}")
async def api_search_tasks(keyword: str):
    """T√¨m ki·∫øm t√°c v·ª• theo t·ª´ kh√≥a"""
    results = search_task_memory(keyword)
    return {
        "success": True,
        "count": len(results),
        "tasks": results
    }

@app.get("/api/tasks/all")
async def api_get_all_tasks():
    """L·∫•y to√†n b·ªô l·ªãch s·ª≠ t√°c v·ª•"""
    tasks = load_task_memory()
    return {
        "success": True,
        "total": len(tasks),
        "tasks": tasks
    }

@app.post("/api/tasks/clear")
async def api_clear_tasks():
    """X√≥a to√†n b·ªô l·ªãch s·ª≠ t√°c v·ª•"""
    success = clear_task_memory()
    return {
        "success": success,
        "message": "ƒê√£ x√≥a to√†n b·ªô l·ªãch s·ª≠ t√°c v·ª•" if success else "L·ªói khi x√≥a"
    }

@app.get("/api/tasks/summary")
async def api_get_task_summary():
    """L·∫•y t·ªïng h·ª£p th·ªëng k√™ t√°c v·ª•"""
    tasks = load_task_memory()
    
    if not tasks:
        return {
            "success": True,
            "total_tasks": 0,
            "by_tool": {},
            "success_rate": 0,
            "recent_tools": []
        }
    
    # ƒê·∫øm theo tool
    tool_counts = {}
    success_count = 0
    
    for task in tasks:
        tool = task.get('tool', 'unknown')
        tool_counts[tool] = tool_counts.get(tool, 0) + 1
        if task.get('result_success'):
            success_count += 1
    
    # S·∫Øp x·∫øp theo s·ªë l·∫ßn s·ª≠ d·ª•ng
    sorted_tools = sorted(tool_counts.items(), key=lambda x: x[1], reverse=True)
    
    return {
        "success": True,
        "total_tasks": len(tasks),
        "by_tool": dict(sorted_tools[:20]),
        "success_rate": round(success_count / len(tasks) * 100, 1),
        "recent_tools": [t.get('tool') for t in tasks[-5:]]
    }

# ============================================================
# CONVERSATION HISTORY API
# ============================================================

@app.get("/api/conversation/history")
async def api_get_conversation_history():
    """L·∫•y to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i"""
    return {
        "success": True,
        "total_messages": len(conversation_history),
        "messages": conversation_history
    }

@app.get("/api/conversation/recent/{count}")
async def api_get_recent_conversation(count: int = 10):
    """L·∫•y N messages g·∫ßn nh·∫•t"""
    recent = conversation_history[-count:] if len(conversation_history) > count else conversation_history
    return {
        "success": True,
        "count": len(recent),
        "messages": recent
    }

@app.post("/api/conversation/clear")
async def api_clear_conversation():
    """X√≥a to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i"""
    global conversation_history
    conversation_history = []
    save_conversation_history()
    return {
        "success": True,
        "message": "ƒê√£ x√≥a to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i"
    }

@app.post("/api/conversation/export")
async def api_export_conversation(data: dict = None):
    """Export l·ªãch s·ª≠ h·ªôi tho·∫°i ra file"""
    filename = data.get("filename", "") if data else ""
    return await export_conversation_to_file(filename)

@app.post("/api/conversation/add")
async def api_add_conversation_message(data: dict):
    """Th√™m message t·ª´ Web UI v√†o history"""
    role = data.get("role", "user")
    content = data.get("content", "")
    metadata = data.get("metadata", {})
    
    if not content:
        return {"success": False, "error": "Content kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"}
    
    add_to_conversation(role, content, metadata)
    
    return {
        "success": True,
        "message": "ƒê√£ th√™m message v√†o history"
    }

@app.post("/api/chat/log")
async def api_log_chat_message(data: dict):
    """
    Endpoint ƒë·∫∑c bi·ªát ƒë·ªÉ Web UI log TO√ÄN B·ªò cu·ªôc h·ªôi tho·∫°i
    D√πng cho c√°c chat kh√¥ng qua MCP
    """
    messages = data.get("messages", [])
    
    if not messages:
        return {"success": False, "error": "Kh√¥ng c√≥ messages ƒë·ªÉ log"}
    
    # Log t·ª´ng message
    for msg in messages:
        role = msg.get("role", "user")
        content = msg.get("content", "")
        metadata = msg.get("metadata", {})
        
        if content:
            add_to_conversation(role, content, metadata)
    
    return {
        "success": True,
        "message": f"ƒê√£ log {len(messages)} messages v√†o history",
        "total_messages": len(conversation_history)
    }

# ============================================================
# USER PROFILE API - Hi·ªÉu ng∆∞·ªùi d√πng
# ============================================================

@app.get("/api/user/profile")
async def api_get_user_profile():
    """L·∫•y user profile"""
    return {
        "success": True,
        "profile": load_user_profile(),
        "summary": get_user_profile_summary()
    }

@app.get("/api/user/context")
async def api_get_user_context(max_messages: int = 10):
    """L·∫•y context t·ª´ l·ªãch s·ª≠ h·ªôi tho·∫°i + user profile"""
    return {
        "success": True,
        "user_profile": get_user_profile_summary(),
        "recent_conversation": get_conversation_context(max_messages),
        "hint": "D√πng th√¥ng tin n√†y ƒë·ªÉ hi·ªÉu ng∆∞·ªùi d√πng t·ªët h∆°n"
    }

@app.get("/api/conversation/files")
async def api_list_conversation_files():
    """Li·ªát k√™ c√°c file h·ªôi tho·∫°i ƒë√£ l∆∞u"""
    files = list_conversation_files()
    return {
        "success": True,
        "storage_path": str(CONVERSATION_BASE_DIR),
        "total_files": len(files),
        "files": files
    }

# NOTE: Endpoint /api/conversation/today ƒë√£ b·ªã x√≥a (kh√¥ng c√≤n file theo ng√†y)

@app.post("/api/endpoints/switch/{index}")
async def switch_endpoint(index: int):
    global active_endpoint_index, should_reconnect
    if index < 0 or index >= len(endpoints_config):
        return {"success": False, "error": "Thi·∫øt b·ªã kh√¥ng t·ªìn t·∫°i"}
    
    device = endpoints_config[index]
    if not device.get("token"):
        return {"success": False, "error": "Thi·∫øt b·ªã ch∆∞a c√≥ token. H√£y nh·∫≠p token v√† l∆∞u l·∫°i!"}
    
    # Thay ƒë·ªïi endpoint v√† trigger reconnect
    old_index = active_endpoint_index
    active_endpoint_index = index
    should_reconnect = True  # Trigger reconnect trong xiaozhi_websocket_client
    
    # L∆∞u v√†o file
    save_endpoints_to_file(endpoints_config, active_endpoint_index)
    
    print(f"üîÑ [Endpoint] Switching from device {old_index} to {index} ({device['name']})")
    
    return {"success": True, "message": f"ƒê√£ chuy·ªÉn sang {device['name']}. ƒêang k·∫øt n·ªëi l·∫°i..."}

@app.post("/api/endpoints/save")
async def save_endpoints(data: dict):
    global endpoints_config, should_reconnect
    try:
        devices = data.get('devices', [])
        if not devices:
            return {"success": False, "error": "Kh√¥ng c√≥ d·ªØ li·ªáu"}
        
        # L∆∞u token c≈© c·ªßa thi·∫øt b·ªã ƒëang active ƒë·ªÉ so s√°nh
        old_active_token = endpoints_config[active_endpoint_index].get('token', '') if active_endpoint_index < len(endpoints_config) else ''
        
        # C·∫≠p nh·∫≠t endpoints_config
        endpoints_config = []
        for dev in devices:
            token = dev.get('token', '').strip()  # Strip whitespace
            endpoints_config.append({
                'name': dev.get('name', 'Thi·∫øt b·ªã'),
                'token': token,
                'enabled': bool(token)  # Only enabled if token not empty
            })
        
        # üî• FIX: FORCE SAVE khi user b·∫•m Save - kh√¥ng skip
        if save_endpoints_to_file(endpoints_config, active_endpoint_index, force_save=True):
            print(f"‚úÖ [Endpoint] User saved {len(devices)} devices (forced)")
        else:
            print(f"‚ö†Ô∏è [Endpoint] Failed to save to file, but config updated in memory")
        
        # CH·ªà reconnect n·∫øu token thay ƒë·ªïi V√Ä c√≥ gi√° tr·ªã m·ªõi kh√°c r·ªóng
        new_active_token = endpoints_config[active_endpoint_index].get('token', '') if active_endpoint_index < len(endpoints_config) else ''
        if old_active_token != new_active_token and new_active_token and old_active_token:
            # Token ƒë√£ thay ƒë·ªïi (kh√¥ng ph·∫£i l·∫ßn ƒë·∫ßu nh·∫≠p)
            should_reconnect = True
            print(f"üîÑ [Endpoint] Token changed for active device {active_endpoint_index}. Triggering reconnect...")
        
        return {"success": True, "message": "ƒê√£ l∆∞u c·∫•u h√¨nh"}
    except Exception as e:
        print(f"‚ùå [Endpoint] Error saving: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

@app.post("/api/gemini-key")
async def save_gemini_key(data: dict):
    """Save Gemini API key - Auto-save endpoint"""
    global GEMINI_API_KEY
    try:
        api_key = data.get('api_key', '').strip()
        
        # üî• FIX: Cho ph√©p empty string (user x√≥a key)
        if api_key:
            # Validate format only if key is provided
            if not api_key.startswith('AIzaSy'):
                return {"success": False, "error": "API key kh√¥ng h·ª£p l·ªá (ph·∫£i b·∫Øt ƒë·∫ßu v·ªõi 'AIzaSy')"}
        
        # Update global variable (allow empty)
        GEMINI_API_KEY = api_key
        
        # Save to file
        if save_endpoints_to_file(endpoints_config, active_endpoint_index):
            if api_key:
                print(f"‚úÖ [Gemini] API key saved (ends with ...{api_key[-8:]})")
                return {
                    "success": True,
                    "message": "‚úì ƒê√£ l∆∞u Gemini API key",
                    "key_preview": f"...{api_key[-8:]}"
                }
            else:
                print("‚úÖ [Gemini] API key cleared")
                return {
                    "success": True,
                    "message": "‚úì ƒê√£ x√≥a Gemini API key"
                }
        else:
            return {"success": False, "error": "L·ªói l∆∞u file config"}
    except Exception as e:
        print(f"‚ùå [Gemini] Error saving API key: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/openai-key")
async def save_openai_key(data: dict):
    """Save OpenAI API key - Auto-save endpoint"""
    global OPENAI_API_KEY
    try:
        api_key = data.get('api_key', '').strip()
        
        # üî• FIX: Cho ph√©p empty string (user x√≥a key)
        if api_key:
            # Validate format only if key is provided
            if not api_key.startswith('sk-'):
                return {"success": False, "error": "API key kh√¥ng h·ª£p l·ªá (ph·∫£i b·∫Øt ƒë·∫ßu v·ªõi 'sk-')"}
        
        # Update global variable (allow empty)
        OPENAI_API_KEY = api_key
        
        # Save to file
        if save_endpoints_to_file(endpoints_config, active_endpoint_index):
            if api_key:
                print(f"‚úÖ [OpenAI] API key saved (ends with ...{api_key[-8:]})")
                return {
                    "success": True,
                    "message": "‚úì ƒê√£ l∆∞u OpenAI API key",
                    "key_preview": f"...{api_key[-8:]}"
                }
            else:
                print("‚úÖ [OpenAI] API key cleared")
                return {
                    "success": True,
                    "message": "‚úì ƒê√£ x√≥a OpenAI API key"
                }
        else:
            return {"success": False, "error": "L·ªói l∆∞u file config"}
    except Exception as e:
        print(f"‚ùå [OpenAI] Error saving API key: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/serper-key")
async def save_serper_key(data: dict):
    """Save Serper API key (Google Search) - Auto-save endpoint"""
    global SERPER_API_KEY
    try:
        api_key = data.get('api_key', '').strip()
        
        # üî• FIX: Cho ph√©p empty string (user x√≥a key)
        # Update global variable (allow empty)
        SERPER_API_KEY = api_key
        
        # C·∫≠p nh·∫≠t environment variable ƒë·ªÉ rag_system.py c√≥ th·ªÉ d√πng
        if api_key:
            os.environ['SERPER_API_KEY'] = api_key
        else:
            os.environ.pop('SERPER_API_KEY', None)  # Remove if empty
        
        # Save to file
        if save_endpoints_to_file(endpoints_config, active_endpoint_index):
            if api_key:
                print(f"‚úÖ [Serper] Google Search API key saved (ends with ...{api_key[-8:]})")
                return {
                    "success": True,
                    "message": "‚úì ƒê√£ l∆∞u Serper API key - Google Search s·∫µn s√†ng!",
                    "key_preview": f"...{api_key[-8:]}"
                }
            else:
                print("‚úÖ [Serper] API key cleared")
                return {
                    "success": True,
                    "message": "‚úì ƒê√£ x√≥a Serper API key"
                }
        else:
            return {"success": False, "error": "L·ªói l∆∞u file config"}
    except Exception as e:
        print(f"‚ùå [Serper] Error saving API key: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/serper-key")
async def get_serper_key():
    """Get current Serper API key status"""
    if SERPER_API_KEY:
        return {
            "success": True,
            "has_key": True,
            "key_preview": f"...{SERPER_API_KEY[-8:]}"
        }
    return {"success": True, "has_key": False}


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    active_connections.append(websocket)
    try:
        await websocket.send_json({"type": "xiaozhi_status", "connected": xiaozhi_connected})
        while True:
            data = await websocket.receive_text()
            
            # Parse v√† log WebSocket messages
            try:
                msg_data = json.loads(data)
                msg_type = msg_data.get("type", "")
                
                # L∆∞u user messages t·ª´ Web UI
                if msg_type == "chat_message":
                    user_msg = msg_data.get("message", "")
                    if user_msg:
                        add_to_conversation(
                            role="user",
                            content=user_msg,
                            metadata={
                                "source": "websocket",
                                "msg_type": msg_type
                            }
                        )
                
                # L∆∞u AI responses t·ª´ Web UI
                elif msg_type == "ai_response":
                    ai_msg = msg_data.get("response", "")
                    if ai_msg:
                        add_to_conversation(
                            role="assistant",
                            content=ai_msg,
                            metadata={
                                "source": "websocket",
                                "msg_type": msg_type,
                                "model": msg_data.get("model", "unknown")
                            }
                        )
                
                # üÜï SMART ANALYZE - Ph√¢n t√≠ch th√¥ng minh v·ªõi AI (M·ªöI - ∆ØU TI√äN)
                elif msg_type == "smart_analyze":
                    user_query = msg_data.get("query", "")
                    llm_response = msg_data.get("response", "")
                    auto_execute = msg_data.get("auto_execute", True)
                    use_ai = msg_data.get("use_ai", True)
                    conversation_history = msg_data.get("history", [])
                    
                    print(f"üß† [WebSocket] Smart Analyze: query='{user_query[:50]}...'")
                    
                    # G·ªçi Smart Analyzer API
                    analyze_result = await api_smart_analyze({
                        "user_query": user_query,
                        "llm_response": llm_response,
                        "conversation_history": conversation_history,
                        "auto_execute": auto_execute,
                        "use_ai": use_ai
                    })
                    
                    # G·ª≠i k·∫øt qu·∫£ v·ªÅ client
                    await websocket.send_json({
                        "type": "smart_analyze_result",
                        **analyze_result
                    })
                    
                    print(f"‚úÖ [WebSocket] Smart analyze result sent")
                
                # üîÑ AUTO TOOL EXECUTION (Legacy - v·∫´n gi·ªØ ƒë·ªÉ t∆∞∆°ng th√≠ch)
                elif msg_type == "llm_response_check":
                    llm_response = msg_data.get("response", "")
                    original_query = msg_data.get("query", "")
                    auto_execute = msg_data.get("auto_execute", True)
                    use_smart = msg_data.get("use_smart", True)  # M·∫∑c ƒë·ªãnh d√πng Smart Analyzer
                    
                    if llm_response or original_query:
                        print(f"ü§ñ [WebSocket] Processing: '{(original_query or llm_response)[:50]}...'")
                        
                        if use_smart:
                            # üß† D√πng Smart Analyzer (m·ªõi - th√¥ng minh h∆°n)
                            result = await api_smart_analyze({
                                "user_query": original_query,
                                "llm_response": llm_response,
                                "auto_execute": auto_execute,
                                "use_ai": True
                            })
                            result["type"] = "smart_analyze_result"
                        else:
                            # Legacy: d√πng pattern matching
                            result = await api_auto_execute({
                                "llm_response": llm_response,
                                "original_query": original_query,
                                "auto_execute": auto_execute
                            })
                            result["type"] = "auto_execute_result"
                        
                        # G·ª≠i k·∫øt qu·∫£ v·ªÅ client
                        await websocket.send_json(result)
                        
                        print(f"‚úÖ [WebSocket] Result sent to client")
                
            except json.JSONDecodeError:
                pass  # Not JSON, skip logging
            
            await websocket.send_text(f"Echo: {data}")
    except Exception as e:
        print(f"‚ö†Ô∏è WebSocket client error: {e}")
    finally:
        if websocket in active_connections:
            active_connections.remove(websocket)

@app.on_event("startup")
async def startup():
    """Kh·ªüi ƒë·ªông server v·ªõi endpoint manager c·∫£i ti·∫øn - ghi nh·ªõ endpoint m·ªói l·∫ßn kh·ªüi ƒë·ªông"""
    global endpoints_config, active_endpoint_index
    
    # Check music folder config and notify
    config_info = check_music_folder_config()
    if config_info.get("has_config"):
        folder_path = config_info.get("folder_path", "")
        print(f"üéµ [Music Config] User music folder configured: {folder_path}")
        print(f"‚≠ê [Music Priority] Will use play_music_from_user_folder for music requests")
    else:
        print(f"‚ö†Ô∏è [Music Config] No user music folder configured. Will use VLC music_library as fallback.")
    
    # üî• NEW: S·ª≠ d·ª•ng MCPEndpointManager ƒë·ªÉ qu·∫£n l√Ω k·∫øt n·ªëi
    if ENDPOINT_MANAGER_AVAILABLE:
        try:
            manager = get_endpoint_manager()
            
            # ƒê·ªìng b·ªô config t·ª´ manager (ƒë√£ ƒë∆∞·ª£c load v√† ghi nh·ªõ t·ª´ l·∫ßn tr∆∞·ªõc)
            endpoints_config = manager.endpoints
            active_endpoint_index = manager.active_index
            
            print(f"üìã [Startup] Loaded {len(endpoints_config)} endpoints from saved config")
            print(f"üìç [Startup] Active endpoint: {active_endpoint_index} ({endpoints_config[active_endpoint_index].get('name', 'Unknown')})")
            
            # Register callbacks ƒë·ªÉ ƒë·ªìng b·ªô tr·∫°ng th√°i
            def on_connect_callback(index, name):
                global xiaozhi_connected
                xiaozhi_connected[index] = True
                print(f"üîî [Manager] Device {index + 1} ({name}) connected")
            
            def on_disconnect_callback(index):
                global xiaozhi_connected, xiaozhi_connections
                xiaozhi_connected[index] = False
                xiaozhi_connections[index] = None
                print(f"üîå [Manager] Device {index + 1} disconnected")
            
            def on_error_callback(index, error):
                print(f"‚ùå [Manager] Device {index + 1} error: {error}")
            
            manager.on_connect(on_connect_callback)
            manager.on_disconnect(on_disconnect_callback)
            manager.on_error(on_error_callback)
            
            # V·∫´n d√πng websocket client c≈© ƒë·ªÉ x·ª≠ l√Ω messages, nh∆∞ng th√¥ng tin ƒë∆∞·ª£c ghi nh·ªõ
            print(f"üöÄ [Startup] Starting WebSocket clients with remembered endpoints...")
            
        except Exception as e:
            print(f"‚ö†Ô∏è [Startup] EndpointManager error: {e}")
    
    # Enable WebSocket client with error handling
    try:
        # Kh·ªüi t·∫°o 3 Xiaozhi clients ƒë·ªìng th·ªùi
        for i in range(3):
            asyncio.create_task(xiaozhi_websocket_client(device_index=i))
        print(f"‚úÖ [Startup] WebSocket clients started for {len(endpoints_config)} devices")
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to start WebSocket clients: {e}")

@app.on_event("shutdown")
async def shutdown():
    """Save conversation history v√† endpoint state on shutdown - tr√°nh m·∫•t data"""
    try:
        print("üíæ [Shutdown] Saving conversation history...")
        save_conversation_history()
        print(f"‚úÖ [Shutdown] Saved {len(conversation_history)} messages")
        
        # üî• NEW: L∆∞u endpoint state ƒë·ªÉ ghi nh·ªõ cho l·∫ßn kh·ªüi ƒë·ªông sau
        if ENDPOINT_MANAGER_AVAILABLE:
            try:
                manager = get_endpoint_manager()
                # ƒê·ªìng b·ªô config hi·ªán t·∫°i tr∆∞·ªõc khi l∆∞u
                manager.endpoints = endpoints_config
                manager.active_index = active_endpoint_index
                manager.save_config()
                print(f"üíæ [Shutdown] Saved endpoint config (active: {active_endpoint_index})")
            except Exception as e:
                print(f"‚ö†Ô∏è [Shutdown] Error saving endpoint config: {e}")
        
        # L∆∞u endpoints v√†o file c≈© ƒë·ªÉ backward compatible
        save_endpoints_to_file(endpoints_config, active_endpoint_index)
        print(f"üíæ [Shutdown] Saved {len(endpoints_config)} endpoints")
        
    except Exception as e:
        print(f"‚ö†Ô∏è [Shutdown] Error saving: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import uvicorn
    import webbrowser
    import threading
    
    # ============================================================
    # UNIFIED STARTUP BANNER - PROFESSIONAL EDITION
    # ============================================================
    print("\n")
    print("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë                                                            ‚ïë")
    print("‚ïë          üîê miniZ MCP v4.3.0 - PROFESSIONAL EDITION        ‚ïë")
    print("‚ïë                                                            ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
    print()
    
    # Step 1: FREE EDITION - No License Check
    print("üîç [1/4] Ki·ªÉm tra phi√™n b·∫£n...")
    print("    ‚úÖ miniZ MCP FREE EDITION")
    print("    üì¶ Lo·∫°i: FREE (Kh√¥ng gi·ªõi h·∫°n)")
    print("    üë§ Ng∆∞·ªùi d√πng: Community User")
    
    # Auto-startup check - L·∫ßn ƒë·∫ßu ch·∫°y th√¨ b·∫≠t auto-start
    marker_file = os.path.join(os.path.expanduser("~"), ".miniz_mcp_installed")
    if not os.path.exists(marker_file):
        print("    ‚öôÔ∏è C√†i ƒë·∫∑t kh·ªüi ƒë·ªông c√πng Windows...")
        AutoStartupManager.enable_autostart()
        try:
            with open(marker_file, 'w') as f:
                f.write("installed=true\\nversion=4.3.0\\nedition=FREE")
        except:
            pass
    else:
        if AutoStartupManager.is_autostart_enabled():
            print("    üîÑ Kh·ªüi ƒë·ªông c√πng Windows: B·∫¨T")
    
    print()
    
    # Step 2: Check Firewall/Internet Permission
    print("üî• [2/4] Ki·ªÉm tra quy·ªÅn k·∫øt n·ªëi m·∫°ng...")
    firewall_status = FirewallChecker.check_firewall_rules()
    internet_status = FirewallChecker.check_internet_connection()
    
    if firewall_status['rules_found']:
        print("    ‚úÖ Firewall: ƒê√£ c·∫•p quy·ªÅn")
        print(f"    üìå Rules: {', '.join(firewall_status['rules_found'][:3])}")
    else:
        print("    ‚ö†Ô∏è Firewall: Ch∆∞a c√≥ rule (Windows s·∫Ω h·ªèi khi c·∫ßn)")
        print("    üí° Tip: Nh·∫•n 'Allow' khi Windows h·ªèi cho ph√©p truy c·∫≠p m·∫°ng")
    
    if internet_status['connected']:
        latency = internet_status.get('latency_ms', '?')
        print(f"    ‚úÖ Internet: ƒê√£ k·∫øt n·ªëi ({latency}ms)")
    else:
        print("    ‚ö†Ô∏è Internet: Kh√¥ng k·∫øt n·ªëi ho·∫∑c ƒëang ki·ªÉm tra...")
        print("    üí° ƒê·∫£m b·∫£o m√°y t√≠nh c√≥ k·∫øt n·ªëi m·∫°ng ƒë·ªÉ s·ª≠ d·ª•ng AI")
    
    print()
    
    # Step 3: Initialize Server
    print("üöÄ [3/4] Kh·ªüi ƒë·ªông Server...")
    print("    üåê Web Dashboard: http://localhost:8000")
    print("    üì° WebSocket MCP: Multi-device support")
    print("    üõ†Ô∏è  Tools: 141 c√¥ng c·ª• AI s·∫µn s√†ng")
    print("    ‚úÖ Server initialized")
    
    print()
    
    # Step 4: Open Browser
    print("üåê [4/4] M·ªü giao di·ªán...")
    print("    ‚è≥ Browser s·∫Ω t·ª± ƒë·ªông m·ªü sau 2 gi√¢y...")
    
    def open_browser():
        """Mo browser sau 2 giay"""
        time.sleep(2)
        webbrowser.open("http://localhost:8000")
    
    # Khoi dong thread mo browser
    threading.Thread(target=open_browser, daemon=True).start()
    
    print()
    print("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë                                                            ‚ïë")
    print("‚ïë              ‚úÖ miniZ MCP READY TO USE                      ‚ïë")
    print("‚ïë                                                            ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
    print()
    
    # üîî Ph√°t √¢m thanh ƒë√°nh th·ª©c khi server s·∫µn s√†ng
    play_wake_sound()
    
    # Fix logging error when running as frozen EXE
    import sys
    if getattr(sys, 'frozen', False):
        # Disable uvicorn's default logging config when frozen
        uvicorn.run(app, host="0.0.0.0", port=8000, log_config=None)
    else:
        uvicorn.run(app, host="0.0.0.0", port=8000)

